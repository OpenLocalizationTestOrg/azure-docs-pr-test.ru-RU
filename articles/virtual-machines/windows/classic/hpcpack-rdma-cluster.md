---
title: "aaaSet копирование приложений MPI toorun кластера Windows RDMA | Документы Microsoft"
description: "Узнайте, как toocreate кластера Windows HPC Pack с toouse H16r, H16mr, A8 или A9 ВМ размера hello приложений MPI toorun сети Azure RDMA."
services: virtual-machines-windows
documentationcenter: 
author: dlepow
manager: timlt
editor: 
tags: azure-service-management,hpc-pack
ms.assetid: 7d9f5bc8-012f-48dd-b290-db81c7592215
ms.service: virtual-machines-windows
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: vm-windows
ms.workload: big-compute
ms.date: 06/01/2017
ms.author: danlep
ms.openlocfilehash: 23bc8740dbd05a7c7ab3f998489a41d0df4520a2
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 10/06/2017
---
# <a name="set-up-a-windows-rdma-cluster-with-hpc-pack-toorun-mpi-applications"></a>Настройка кластера Windows RDMA с помощью приложений MPI toorun пакета HPC
Настройка кластера Windows RDMA в Azure с помощью [пакета Microsoft HPC](https://technet.microsoft.com/library/cc514029) и [высокопроизводительных вычислений размеры виртуальных Машин](../sizes-hpc.md?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json) toorun параллельных приложений интерфейса передачи сообщений (MPI). Если настроить узлы с поддержкой RDMA под управлением Windows Server в кластере пакета HPC, приложения MPI будут эффективно взаимодействовать по сети с низкой задержкой и высокой пропускной способностью в Azure, основанной на технологии удаленного доступа к памяти (RDMA).

Toorun рабочих нагрузок MPI на виртуальных машинах Linux сети Azure RDMA hello, доступа к статье [настройки приложений MPI toorun кластеров Linux RDMA](../../linux/classic/rdma-cluster.md).

## <a name="hpc-pack-cluster-deployment-options"></a>Варианты развертывания кластера пакета HPC
Пакет Microsoft HPC — это средство, предоставляемых в toocreate без дополнительных затрат HPC кластеров в локальной или в Azure toorun Windows или Linux HPC приложений. Пакет HPC включает среду выполнения для реализации Майкрософт hello hello сообщение передача интерфейса для Windows (MS-MPI). При использовании с функцией RDMA экземпляры, поддерживаемой операционной системы Windows Server, HPC Pack предоставляет эффективный параметр toorun Windows приложений MPI этой сети Azure RDMA hello доступа. 

В этой статье рассматриваются два сценария и ссылки tooset руководство toodetailed кластера Windows RDMA с помощью пакета Microsoft HPC. 

* Сценарий 1. Развертывание экземпляров рабочих ролей для ресурсоемких вычислений (PaaS)
* Сценарий 2. Развертывание вычислительных узлов на виртуальных машинах с ресурсоемкими вычислениями (IaaS)

Основные обязательные требования toouse экземпляры большим объемом вычислений с Windows, см. [высокопроизводительных вычислений размеры виртуальных Машин](../sizes-hpc.md?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json).

## <a name="scenario-1-deploy-compute-intensive-worker-role-instances-paas"></a>Сценарий 1. Развертывание экземпляров рабочих ролей для ресурсоемких вычислений (PaaS)
Из существующего кластера HPC Pack добавьте дополнительные вычислительные ресурсы в экземплярах рабочих ролей Azure (узлах Azure), запускаемых в облачной службе (PaaS). Эта функция также называется «прорыв tooAzure» из пакета HPC, поддерживает диапазон размеров экземпляров рабочей роли hello. При добавлении hello узлов Azure, укажите один из размеров hello функцией RDMA.

Ниже приведены рекомендации и инструкции tooburst поддержкой tooRDMA экземплярами Azure из существующего (обычно локального) кластера. Используйте аналогичные процедуры tooadd рабочей роли экземпляров tooan головной узел пакета HPC, развернутого в Виртуальной машине Azure.

> [!NOTE]
> Учебника tooburst tooAzure, с помощью пакета HPC, в разделе [Настройка гибридного кластера с помощью пакета HPC](../../../cloud-services/cloud-services-setup-hybrid-hpcpack-cluster.md). Обратите внимание особенности hello в hello, выполните действия, применяемые в частности поддержкой tooRDMA узлов Azure.
> 
> 

![Повышение tooAzure][burst]

### <a name="steps"></a>Действия
1. **Развертывание и настройка головного узла HPC Pack 2012 R2.**
   
    Загрузить hello последнюю версию пакета установки пакета HPC hello [центра загрузки Майкрософт](https://www.microsoft.com/download/details.aspx?id=49922). Требования и инструкции по tooprepare развертыванию прорыва в Azure, в разделе [прорыв экземпляров рабочей tooAzure с пакетом Microsoft HPC](https://technet.microsoft.com/library/gg481749.aspx).
2. **Настройка сертификата управления в подписку Azure hello**
   
    Настройте сертификат toosecure hello соединение между головным узлом hello и Azure. Параметры и процедуры см. в разделе [сценариев tooConfigure hello сертификата управления Azure для пакета HPC](http://technet.microsoft.com/library/gg481759.aspx). В тестовых развертываниях пакет HPC устанавливается по умолчанию Microsoft HPC Azure сертификат управления можно быстро отправить tooyour подписки Azure.
3. **Создание новой облачной службы и учетной записи хранения.**
   
    Используйте hello Azure toocreate портала облачной службы и учетной записи хранилища для развертывания hello в регионе, где доступны экземпляры с поддержкой RDMA hello.
4. **Создание шаблона узла Azure.**
   
    Используйте приветствия мастера шаблона узла в диспетчере кластера HPC. Пошаговые инструкции см. в разделе [создания шаблона узла Azure](http://technet.microsoft.com/library/gg481758.aspx#BKMK_Templ) в «TooDeploy действия узлов Azure с пакетом Microsoft HPC».
   
    Для первоначальных тестов рекомендуется Настройка политики вручную доступности в шаблоне hello.
5. **Добавление узлов кластера toohello**
   
    Здравствуйте, используйте мастер добавления узла в диспетчере кластера HPC. Дополнительные сведения см. в разделе [toohello Добавление узлов Azure кластер Windows HPC](http://technet.microsoft.com/library/gg481758.aspx#BKMK_Add).
   
    При указании размера hello hello узлов, выберите один из размеров экземпляров функцией RDMA hello.
   
   > [!NOTE]
   > В каждой пакетное развертывание tooAzure с большим объемом вычислений экземплярами hello HPC Pack автоматически разворачивает не менее двух экземпляров, имеющих функцию RDMA (таких как A8) в качестве узлов прокси-сервера, кроме toohello экземпляров рабочей роли Azure можно указать. Hello узлов прокси-сервера используют ядра, выделяются toohello подписки и взимается вместе с hello экземпляров рабочей роли Azure.
   > 
   > 
6. **Запуск (провизионирование) узлов hello и их подключением к сети toorun заданий**
   
    Выбор узлов hello и использовать hello **запустить** в диспетчере кластера HPC. По завершении подготовки выберите узлы hello и с помощью hello **перевести в оперативный режим** в диспетчере кластера HPC. узлы Hello — Готово toorun заданий.
7. **Отправка задания toohello кластера**
   
   Используйте кластер HPC Pack задания отправки средства toorun задания. См. раздел [Пакет Microsoft HPC: управление заданиями](http://technet.microsoft.com/library/jj899585.aspx).
8. **Остановка (отзыв) узлов hello**
   
   После завершения выполнения заданий отключите узлы hello и использовать hello **остановить** в диспетчере кластера HPC.

## <a name="scenario-2-deploy-compute-nodes-in-compute-intensive-vms-iaas"></a>Сценарий 2. Развертывание вычислительных узлов на виртуальных машинах с ресурсоемкими вычислениями (IaaS)
В этом сценарии развертывания головного узла HPC Pack hello и вычислительные узлы кластера на виртуальных машинах в виртуальной сети Azure. Пакет HPC предоставляет несколько [вариантов развертывания на виртуальных машинах Azure](../../linux/hpcpack-cluster-options.md), в том числе сценарии автоматизированного развертывания и шаблоны быстрого запуска Azure. Пример: hello следующие рекомендации и инструкции toouse hello [скрипт развертывания IaaS пакета HPC](hpcpack-cluster-powershell-script.md) для автоматизации развертывания hello кластера HPC Pack 2012 R2 в Azure.

![Кластер на виртуальных машинах Azure][iaas]

### <a name="steps"></a>Действия
1. **Создание головного узла кластера и виртуальных машин вычислительных узлов, выполнив скрипт развертывания IaaS пакета HPC hello на клиентском компьютере**
   
    Загрузить пакет скрипта развертывания IaaS пакета HPC hello с hello [центра загрузки Майкрософт](https://www.microsoft.com/download/details.aspx?id=49922).
   
    tooprepare hello клиентского компьютера, создайте файл конфигурации скрипта hello и hello выполнения сценария см. в разделе [создание кластера HPC с помощью скрипта развертывания IaaS пакета HPC hello](hpcpack-cluster-powershell-script.md). 
   
    toodeploy функцией RDMA вычислительные узлы hello Примечание следующие дополнительные вопросы:
   
   * **Виртуальная сеть**: укажите новую виртуальную сеть в регионе, в которых hello функцией RDMA размер экземпляра требуется toouse доступен.
   * **Операционная система Windows Server**: toosupport подключения RDMA, укажите операционную систему Windows Server 2012 R2 или Windows Server 2012 для hello ВМ вычислительных узлов.
   * **Облачные службы.** Мы рекомендуем развертывать головной узел в одной облачной службе, а вычислительные узлы — в другой облачной службе.
   * **Размер головного узла**: для этого сценария рекомендуется выбрать размер хотя бы A4 (очень крупный) для головного узла hello.
   * **Расширение HpcVmDrivers**: hello скрипт развертывания hello агента ВМ Azure и hello расширение HpcVmDrivers автоматически устанавливается при развертывании размер A8 или A9 вычислительных узлов с операционной системой Windows Server. HpcVmDrivers устанавливает драйверы на hello ВМ вычислительных узлов, чтобы они могли подключаться к сети RDMA toohello. На виртуальных машинах серии H функцией RDMA необходимо вручную установить расширение HpcVmDrivers hello. См. [Размеры виртуальных машин, оптимизированных для высокопроизводительных вычислений](../sizes-hpc.md?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json).
   * **Конфигурация сети кластера**: hello сценарий развертывания автоматически настраивает кластер HPC Pack hello с топологией 5 (все узлы в корпоративной сети hello). Данная топология является обязательной для всех развертываний кластера пакета HPC на виртуальных машинах. Не изменяйте топологию сети кластера hello позже.
2. **Переведите hello вычислительных узлов сети toorun заданий**
   
    Выбор узлов hello и использовать hello **перевести в оперативный режим** в диспетчере кластера HPC. узлы Hello — Готово toorun заданий.
3. **Отправка задания toohello кластера**
   
    Подключение toohello головного узла toosubmit заданий или настройте toodo на локальном компьютере это. Сведения см. в разделе [кластера tooan отправки заданий HPC в Azure](../../virtual-machines-windows-hpcpack-cluster-submit-jobs.md?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json).
4. **Take hello узлов вне сети и остановки (освобождения) их**
   
    После завершения выполняющихся заданий, перевести узлы hello в автономном режиме в диспетчере кластера HPC. Затем с помощью tooshut средства управления Azure их работу.

## <a name="run-mpi-applications-on-hello-cluster"></a>Выполнение приложений MPI в кластере hello
### <a name="example-run-mpipingpong-on-an-hpc-pack-cluster"></a>Пример. Выполнение команды mpipingpong в кластере HPC Pack
tooverify развертывания пакета HPC экземпляров hello функцией RDMA, запускаются hello HPC Pack **mpipingpong** на кластере hello. **MPIPingPong** постоянно отправляет пакеты данных между спаренными узлами toocalculate задержки и пропускной способности и статистики для сети приложений с поддержкой RDMA hello. В этом примере показан типичный шаблон для выполнения задания MPI (в этом случае **mpipingpong**) с помощью кластера hello **mpiexec** команды.

В этом примере предполагается, вы добавили узлы Azure в конфигурации «повышение tooAzure» ([сценария 1](#scenario-1.-deploy-compute-intensive-worker-role-instances-\(PaaS\) in this article). При развертывании пакета HPC в кластере виртуальных машин Azure будет требуется toomodify hello команда синтаксис toospecify другую группу узлов и задать переменные среды дополнительных toodirect трафика сети toohello сети RDMA.

toorun mpipingpong в кластере hello:

1. На головном узле hello или на правильно настроенном клиентском компьютере откройте командную строку.
2. tooestimate задержки между парами узлов в развертыванию прорыва в Azure из четырех узлов типа hello, следующая команда toosubmit mpipingpong toorun задания с пакетами небольшого размера и много итераций:
   
    ```Command
    job submit /nodegroup:azurenodes /numnodes:4 mpiexec -c 1 -affinity mpipingpong -p 1:100000 -op -s nul
    ```
   
    Hello команда возвращает идентификатор hello hello задания.
   
    Если вы развернули кластера HPC Pack hello, развернутом на виртуальных машинах Azure, укажите группу узлов, которая содержит ВМ вычислительных узлов развернуты в одной облачной службе и изменения hello **mpiexec** следующим образом:
   
    ```Command
    job submit /nodegroup:vmcomputenodes /numnodes:4 mpiexec -c 1 -affinity -env MSMPI_DISABLE_SOCK 1 -env MSMPI_PRECONNECT all -env MPICH_NETMASK 172.16.0.0/255.255.0.0 mpipingpong -p 1:100000 -op -s nul
    ```
3. По завершении заданий hello tooview hello выходных данных (в данном случае hello выходных данных задачи 1 задания hello), тип hello после
   
    ```Command
    task view <JobID>.1
    ```
   
    где &lt; *JobID* &gt; hello идентификатор отправленного задания hello.
   
    Hello выходные данные содержат следующие toohello аналогичные результаты задержки.
   
    ![Задержка проверки связи][pingpong1]
4. tooestimate пропускной способности между парами Azure burst узлы, тип hello следующая команда toosubmit toorun задания **mpipingpong** с пакетами большого размера и несколько итераций:
   
    ```Command
    job submit /nodegroup:azurenodes /numnodes:4 mpiexec -c 1 -affinity mpipingpong -p 4000000:1000 -op -s nul
    ```
   
    Hello команда возвращает идентификатор hello hello задания.
   
    На кластере HPC Pack, развернутом на виртуальных машинах Azure измените команду hello, как указано в шаге 2.
5. По завершении заданий hello tooview hello выходных данных (в данном случае hello выходных данных задачи 1 задания hello), тип hello следующие:
   
    ```Command
    task view <JobID>.1
    ```
   
   Hello выходные данные содержат следующие toohello аналогичные результаты пропускной способности.
   
   ![Пропускная способность при «пинг-понговой» передаче данных][pingpong2]

### <a name="mpi-application-considerations"></a>Рекомендации по приложениям MPI
Ниже приведены рекомендации по запуску в Azure приложений MPI с пакетом HPC. Некоторые применимы только toodeployments узлов Azure (экземпляры рабочих ролей добавлены в конфигурацию «повышение tooAzure»).

* Экземпляры рабочих ролей в облачной службе периодически повторно подготавливаются без уведомления системой Azure (например, для обслуживания системы или в случае сбоя экземпляра). Если экземпляр провизионируется повторно при выполнении задания MPI, экземпляр hello теряет свои данные и возвращает состояние toohello при ее первоначального развертывания, что может привести к toofail задания MPI hello. Hello дополнительные узлы, используется для выполнения одного задания MPI и hello больше hello задание запускается, hello, скорее всего, что один из экземпляров hello провизионируется повторно во время выполнения задания. Также учитывать при назначении одного узла в развертывании hello как файловый сервер.
* toorun заданий MPI в Azure, у вас нет toouse hello функцией RDMA экземпляры. Вы можете использовать экземпляр любого размера, поддерживаемый пакетом HPC. Тем не менее имеющих функцию RDMA экземпляры hello рекомендуется использовать для выполнения относительно крупномасштабных заданий MPI, которые являются конфиденциальных toohello задержка и пропускная способность hello hello сети, соединяющей узлы hello. При использовании других заданий MPI размеры toorun задержками и пропускной способности, рекомендуется выполнять мелкие задания, в которых каждая отдельная задача работает только на нескольких узлах.
* Приложения, развернутые tooAzure экземпляры являются toohello субъекта, связанных с приложением hello условия лицензии. Проверьте у поставщика hello коммерческих приложений для лицензирования или других ограничений для выполнения в облаке hello. Не все поставщики предлагают лицензирование с оплатой по мере использования.
* Экземпляры Azure требуется дальнейшей установки tooaccess локальных узлов, общие ресурсы и серверы лицензирования. В примере hello tooenable tooaccess узлов Azure к серверу лицензий в локальной среде, можно настроить сайт сайт виртуальной сети Azure.
* toorun приложений MPI на экземплярах Azure зарегистрировать каждое приложение MPI в брандмауэре Windows на экземплярах hello, запустив hello **hpcfwutil** команды. Это позволяет месте tootake MPI связь через порт, динамически назначаемый брандмауэром hello.
  
  > [!NOTE]
  > Для развертываний повышения tooAzure можно также настроить toorun команду исключения брандмауэра автоматически на всех новых узлах Azure, которые добавляются tooyour кластера. После запуска hello **hpcfwutil** команды и убедитесь, что работает вашего приложения, добавить hello команды скрипта запуска tooa для узлов Azure. Дополнительные сведения см. в статье [Использование скрипта запуска для узлов Azure](https://technet.microsoft.com/library/jj899632.aspx).
  > 
  > 
* Пакет HPC использует hello CCP_MPI_NETMASK кластера среды переменной toospecify диапазона допустимых адресов для связи MPI. Начиная с HPC Pack 2012 R2, переменная среды кластера CCP_MPI_NETMASK hello влияет только на связь MPI между вычислительными узлами кластера, присоединенных к домену (локально или на виртуальных машинах Azure). переменная Hello обрабатывается узлами, добавленными в конфигурацию tooAzure повышение.
* Задания MPI не могут выполняться между экземплярами Azure, развернутых в разных облачных службах (например, в развертываниях tooAzure пакетов с разными шаблонами узлов или вычислительные узлы виртуальной Машины Azure развернут в нескольких облачных службах). При наличии нескольких развертываний узлов Azure, которые запускаются на разных шаблонах узлов, задание MPI hello должно выполняться только на одном наборе узлов Azure.
* Добавление узлов Azure tooyour кластера при их подключением к сети, hello служба планировщика заданий HPC немедленно предпринимает toostart заданий на узлах hello. Если только часть рабочей нагрузки можно запустить в Azure, убедитесь, что обновление или создание задания шаблоны toodefine задания, какие типы можно запустить в Azure. Например tooensure, заданий, отправленные с помощью шаблона задания выполняться только на узлах Azure, добавьте шаблон задания toohello свойство группы узлов hello — AzureNodes — hello необходимое значение. toocreate настраиваемых групп для своих узлов Azure с помощью командлета HPC PowerShell Add-HpcGroup hello.

## <a name="next-steps"></a>Дальнейшие действия
* Как альтернативный toousing HPC Pack разрабатывать с toorun служба пакетной службы Azure hello приложений MPI на управляемых пулов вычислительных узлов в Azure. В разделе [несколькими экземплярами использования задачи toorun приложений интерфейса передачи сообщений (MPI) в пакете Azure](../../../batch/batch-mpi.md).
* Если требуется toorun Linux MPI. в разделе приложений, обращающихся к сети Azure RDMA hello, [настройки приложений MPI toorun кластеров Linux RDMA](../../linux/classic/rdma-cluster.md).

<!--Image references-->
[burst]:media/hpcpack-rdma-cluster/burst.png
[iaas]:media/hpcpack-rdma-cluster/iaas.png
[pingpong1]:media/hpcpack-rdma-cluster/pingpong1.png
[pingpong2]:media/hpcpack-rdma-cluster/pingpong2.png
