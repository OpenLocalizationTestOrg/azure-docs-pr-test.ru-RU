---
title: "Руководство по настройке производительности действия копирования | Документация Майкрософт"
description: "Узнайте о ключевых факторах, которые влияют на производительность перемещения данных в фабрике данных Azure при использовании действия копирования."
services: data-factory
documentationcenter: 
author: linda33wj
manager: jhubbard
editor: monicar
ms.assetid: 4b9a6a4f-8cf5-4e0a-a06f-8133a2b7bc58
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 01/10/2018
ms.author: jingwang
robots: noindex
ms.openlocfilehash: 2bec612b1d67eceb0e62b28524b98e852d31ad0f
ms.sourcegitcommit: 9cc3d9b9c36e4c973dd9c9028361af1ec5d29910
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/23/2018
---
# <a name="copy-activity-performance-and-tuning-guide"></a>Руководство по настройке производительности действия копирования
> [!NOTE]
> Статья относится к версии 1 фабрики данных, которая является общедоступной версией. Если вы используете версию 2 службы фабрики данных, которая находится на этапе предварительной версии, ознакомьтесь с [руководством по оптимизации производительности и настройке действий копирования для фабрики данных версии 2](../copy-activity-performance.md).

Действие копирования фабрики данных Azure — первоклассное безопасное, надежное и высокопроизводительное решение для загрузки данных. Оно позволяет ежедневно копировать десятки терабайтов данных в самые разнообразные облачные и локальные хранилища данных. Именно высокоскоростная загрузка данных позволяет сосредоточиться на основных проблемах "больших данных": создании решений расширенной аналитики и получении ценной информации из данных.

Azure предоставляет набор решений корпоративного уровня для хранения данных, а действие копирования предлагает сильно оптимизированные функции загрузки данных, которые легко установить и настроить. Ниже перечислены возможности отдельного действия копирования.

* Загрузка данных в **хранилище данных SQL Azure** со скоростью **1,2 Гбит/с**. Пошаговое руководство и пример использования см. в статье [Загрузка 1 ТБ в хранилище данных SQL Azure с помощью фабрики данных Azure [мастер копирования] менее чем за 15 минут](data-factory-load-sql-data-warehouse.md).
* Загрузка данных в **хранилище BLOB-объектов Azure** на скорости **1,0 Гбит/с**.
* Загрузка данных в **Azure Data Lake Store** на скорости **1,0 Гбит/с**.

Содержание статьи

* [Контрольные показатели производительности](#performance-reference) для поддерживаемых хранилищ данных (источника и приемника), которые помогут при планировании проекта.
* Функции, которые могут значительно повысить пропускную способность копирования в различных сценариях, в том числе [облачные единицы перемещения данных](#cloud-data-movement-units), [параллельное копирование](#parallel-copy) и [промежуточное копирование](#staged-copy).
* [Руководство по настройке производительности](#performance-tuning-steps) , в котором описывается настройка производительности и ключевые факторы, которые могут влиять на производительность копирования.

> [!NOTE]
> Если вам в целом не знакомо действие копирования, перед чтением этой статьи ознакомьтесь со статьей [Перемещение данных с помощью действия копирования](data-factory-data-movement-activities.md) .
>

## <a name="performance-reference"></a>Базовые показатели производительности

В качестве справки ниже представлена таблица, в которой отражены показатели пропускной способности (в Мбит/с) для указанных пар источника и приемника, подученные в ходе внутреннего тестирования. Для сравнения также демонстрируется, как разные параметры [облачных единиц перемещения данных](#cloud-data-movement-units) или [масштабируемости шлюза управления данными](data-factory-data-management-gateway-high-availability-scalability.md) (несколько узлов шлюза) могут помочь определить производительность копирования.

![Матрица производительности](./media/data-factory-copy-activity-performance/CopyPerfRef.png)

>[!IMPORTANT]
>В фабрике данных Azure версии 1 минимальное число единиц перемещения облачных данных для копирования из облака в облако равно двум. Если не указано другое, ознакомьтесь со стандартными единицами перемещения данных, используемыми в [облачных единицах перемещения данных](#cloud-data-movement-units).

**Примечания:**
* Для вычисления пропускной способности используется следующая формула: [размер данных, считанных из источника]/[длительность выполнения действия копирования].
* Контрольные показатели производительности в таблице были измерены с использованием набора данных [TPC-H](http://www.tpc.org/tpch/) для выполнения отдельного действия копирования.
* При использовании хранилищ данных Azure источник и приемник находились в одном регионе Azure.
* Для гибридного перемещения данных (из локальной среды в облако или наоборот) использовался один экземпляр шлюза на компьютере, на котором не находилось локальное хранилище данных. Конфигурация приведена в следующей таблице. При выполнении одного действия в шлюзе операция копирования потребляла только небольшую часть ресурсов ЦП, памяти и пропускной способности сети на тестовом компьютере. Подробнее см.в разделе [Рекомендации относительно шлюза управления данными](#considerations-for-data-management-gateway).
    <table>
    <tr>
        <td>ЦП</td>
        <td>Intel Xeon E5-2660 v2, 32 ядра с частотой 2,20 ГГц</td>
    </tr>
    <tr>
        <td>Память</td>
        <td>128 ГБ</td>
    </tr>
    <tr>
        <td>Сеть</td>
        <td>Веб-интерфейс: 10 Гбит/с; интерфейс интрасети: 40 Гбит/с</td>
    </tr>
    </table>


> [!TIP]
> Пропускную способность можно повысить, используя больше единиц перемещения данных (DMU), чем максимальное количество DMU по умолчанию (32 единицы для выполнения действия копирования из облака в облако). Например, используя 100 DMU, можно достичь скорости копирования данных из большого двоичного объекта Azure в Azure Data Lake Store до **1 Гбит/с**. Подробные сведения об этой функции и поддерживаемый сценарий см. в разделе [Облачные единицы перемещения данных](#cloud-data-movement-units). Чтобы получить дополнительные единицы DMU, отправьте запрос в [службу поддержки Azure](https://azure.microsoft.com/support/).

## <a name="parallel-copy"></a>Параллельное копирование
Данные можно считывать из источника или записывать в приемник **одновременно с выполнением действия копирования**. Эта функция повышает пропускную способность операции копирования и сокращает продолжительность перемещения данных.

Этот параметр отличается от свойства **concurrency** в определении действия. Свойство **concurrency** определяет число **одновременных действий копирования**, выполняемых для обработки данных из разных окон действий (01:00–02:00, 02:00–03:00, 03:00–04:00 и т. д.). Это эффективно в случаях значительной загрузки. Возможность параллельного копирования относится к **выполнению одного действия**.

Рассмотрим пример сценария: представим, что требуется обработать несколько срезов, полученных в прошлом. Фабрика данных запускает экземпляр действия копирования (выполнение действия) для каждого среза.

* Срез данных из первого окна действий (01:00–02:00) == > выполнение действия 1.
* Срез данных из второго окна действий (02:00–03:00) == > выполнение действия 2.
* Срез данных из второго окна действий (03:00–04:00) == > выполнение действия 3.

И т. д.

Значение 2 параметра **concurrency** в этом примере позволяет **выполнению действия 1** и **выполнению действия 2** копировать данные из двух окон действий **одновременно**, что повышает производительность перемещения данных. Тем не менее если в рамках выполнения действия 1 необходимо переместить несколько файлов, служба перемещения данных копирует файлы из источника в приемник по одному.

### <a name="cloud-data-movement-units"></a>Облачные единицы перемещения данных
**Облачная единица перемещения данных** — это мера, представляющая производительность (сочетание выделенных ресурсов ЦП, памяти и сети) одной единицы в фабрике данных. Единица перемещения данных используется для операций копирования из облака в облако, но не для гибридного копирования.

**Минимальное количество облачных единиц перемещения данных для выполнения действия копирования равно двум.** Если не указано другое, в следующей таблице перечислены облачные единицы перемещения данных по умолчанию, используемые в различных сценариях копирования:

| Сценарий копирования | Число облачных единиц перемещения данных по умолчанию, определенное службой |
|:--- |:--- |
| Копирование данных между файловыми хранилищами | От 2 до 16, в зависимости от числа и размеров файлов. |
| Все остальные сценарии копирования | 2 |

Это значение по умолчанию можно переопределить, указав значение для свойства **cloudDataMovementUnits**, как показано ниже. **Допустимые значения** свойства **cloudDataMovementUnits**: 2, 4, 8, 16, 32. **Фактическое число облачных единиц перемещения данных** , используемых во время выполнения операции копирования, меньше или равно заданному значению, в зависимости от шаблона данных. Сведения о том, как можно повысить уровень производительности, настроив дополнительные единицы для определенного источника и приемника, см. в [справочнике по производительности](#performance-reference).

```json
"activities":[  
    {
        "name": "Sample copy activity",
        "description": "",
        "type": "Copy",
        "inputs": [{ "name": "InputDataset" }],
        "outputs": [{ "name": "OutputDataset" }],
        "typeProperties": {
            "source": {
                "type": "BlobSource",
            },
            "sink": {
                "type": "AzureDataLakeStoreSink"
            },
            "cloudDataMovementUnits": 32
        }
    }
]
```

> [!NOTE]
> Если вам требуется больше облачных единиц перемещения данных, чтобы повысить пропускную способность, обратитесь в [службу поддержки Azure](https://azure.microsoft.com/support/). В настоящее время 8 и более облачных единиц перемещения данных поддерживаются только при **копировании нескольких файлов из хранилища BLOB-объектов, Data Lake Store, Amazon S3, облака FTP или облака SFTP в хранилище BLOB-объектов, Data Lake Store или базу данных SQL Azure**.
>

### <a name="parallelcopies"></a>parallelCopies
Можно использовать свойство **parallelCopies** , чтобы задать параллелизм для действия копирования. Считайте это свойство максимальным числом потоков в рамках действия копирования, которые могут параллельно считывать данные из источника или записывать их в хранилища данных-приемники.

Для каждого выполнения действия копирования фабрика данных определяет количество параллельных копий для копирования данных из исходного хранилища данных в целевое хранилище данных. Количество параллельных копий по умолчанию зависит от типов используемых источника и приемника.  

| Источник и приемник | Число параллельных копий по умолчанию, определенное службой |
| --- | --- |
| Копирование данных из одного файлового хранилища данных в другое (хранилище BLOB-объектов, Data Lake Store, Amazon S3, локальная файловая система, локальная файловая система HDFS). |От 1 до 32. Зависит от размера файлов и числа облачных единиц перемещения данных, используемых для копирования данных между двумя облачными хранилищами данных или в пределах физической конфигурации компьютера шлюза, используемого для гибридного копирования (копирования данных из локального хранилища данных и в него). |
| Копирование данных из **любого хранилища данных в хранилище таблиц Azure** |4. |
| Все прочие сочетания источника и приемника |1 |

Обычно поведение по умолчанию должно обеспечить оптимальную пропускную способность. Тем не менее, чтобы управлять загрузкой компьютеров, на которых размещены хранилища данных, или настроить производительность копирования, можно переопределить значение по умолчанию и указать значение свойства **parallelCopies** . Значение должно быть от 1 до 32 (включая оба числа). Во время выполнения действие копирования выберет значение, которое меньше или равно заданному значению, чтобы обеспечить оптимальную производительность.

```json
"activities":[  
    {
        "name": "Sample copy activity",
        "description": "",
        "type": "Copy",
        "inputs": [{ "name": "InputDataset" }],
        "outputs": [{ "name": "OutputDataset" }],
        "typeProperties": {
            "source": {
                "type": "BlobSource",
            },
            "sink": {
                "type": "AzureDataLakeStoreSink"
            },
            "parallelCopies": 8
        }
    }
]
```
Примечания:

* При копировании данных из одного файлового хранилища в другое свойство **parallelCopies** определяет параллелизм на уровне файла. Фрагментирование в пределах файла выполняется автоматически и прозрачно, при этом для определенного типа исходного хранилища данных используется самый подходящий размер блока. Таким образом, данные могут отправляться одновременно и независимо от parallelCopies. Фактическое число параллельных копий, используемых службой перемещения данных для копирования во время выполнения, не превышает количество файлов. Если режим копирования — **mergeFile**, то при копировании параллелизм на уровне файла не будет использоваться.
* При указании значения свойства **parallelCopies** следует учитывать, что это повлечет увеличение нагрузки на хранилище данных источника и приемника, а также на шлюз, если это гибридное копирование. Это особенно актуально при наличии нескольких действий или параллельных выполнений одинаковых действий с одним и тем же хранилищем данных. Если вы заметите, что хранилище данных или шлюз перегружены, уменьшите значение **parallelCopies** , чтобы снизить загрузку.
* При копировании данных из нефайлового хранилища в файловое служба перемещения данных игнорирует свойство **parallelCopies** . В этом случае параллелизм не применяется, даже если задан соответствующий параметр.

> [!NOTE]
> Чтобы применить функцию **parallelCopies** при гибридном копировании, необходимо использовать шлюз управления данными версии не ниже 1.11.
>
>

Чтобы эффективного использовать эти два свойства и повысить пропускную способность перемещения данных, ознакомьтесь с [примерами использования](#case-study-use-parallel-copy). Чтобы воспользоваться преимуществами поведения по умолчанию, настраивать свойство **parallelCopies** не требуется. Если вы зададите для свойства **parallelCopies** невысокое значение, несколько облачных единиц перемещения данных не будут использоваться полностью.  

### <a name="billing-impact"></a>Принцип выставления счетов
**Важно** помнить, что оплата взимается на основе общего времени операции копирования. Если задание копирования обычно занимало один час и одну облачную единицу, а теперь на это требуется 15 минут и четыре облачные единицы, то стоимость практически не изменится. Допустим, используются четыре облачные единицы. Для первой и второй облачных единиц требуется по 10 минут, для третьей и четвертой — по 5 минут, и все это в пределах одного выполнения действия копирования. Плата взимается за общее время копирования (перемещения данных), что составляет 30 минут (10 + 10 + 5 + 5). Использование свойства **parallelCopies** не влияет на выставление счетов.

## <a name="staged-copy"></a>промежуточное копирование
При копировании данных из источника в приемник можно использовать хранилище BLOB-объектов в качестве промежуточного пространства для хранения. Промежуточное хранилище очень удобно в следующих ситуациях.

1. **Вы хотите принимать данные из различных расположений в хранилище данных SQL с помощью PolyBase**. Хранилище данных SQL использует функцию PolyBase, которая обеспечивает высокую пропускную способность при загрузке больших объемов данных в хранилище SQL. Тем не менее исходные данные должны находиться в хранилище BLOB-объектов и соответствовать дополнительным требованиям. При загрузке данных не из хранилища BLOB-объектов можно активировать копирование через промежуточное хранилище BLOB-объектов. В этом случае фабрика данных выполняет необходимые преобразования данных, чтобы обеспечить их соответствие требованиям PolyBase. Затем она загружает данные в хранилище данных SQL с помощью PolyBase. Дополнительные сведения см. в разделе [Загрузка данных в хранилище данных SQL Azure с помощью PolyBase](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse). Пошаговое руководство и пример использования см. в статье [Загрузка 1 ТБ в хранилище данных SQL Azure с помощью фабрики данных Azure [мастер копирования] менее чем за 15 минут](data-factory-load-sql-data-warehouse.md).
2. **Иногда для гибридного перемещения данных (т. е. для копирования данных между локальным и облачным хранилищами данных) требуется некоторое время из-за низкой скорости сетевого подключения**. Чтобы передача в промежуточное хранилище в облаке занимала меньше времени, можно сжать данные в локальном хранилище. Затем данные в промежуточном хранилище распаковываются и загружаются в целевое расположение.
3. **В соответствии с корпоративными политиками ИТ в брандмауэре не рекомендуется открывать порты, отличные от 80 и 443**. Например, при копировании данных из локального хранилища в приемник базы данных SQL Azure или приемник хранилища данных SQL Azure необходимо активировать исходящие TCP-подключения через порт 1433 для брандмауэра Windows и корпоративного брандмауэра. В этом случае можно использовать преимущества шлюза, чтобы сначала скопировать данные в промежуточный экземпляр хранилища BLOB-объектов по протоколу HTTP или HTTPS через порт 443, а уже оттуда загрузить данные в базу данных SQL или хранилище данных SQL. В таком сценарии не нужно включать порт 1433.

### <a name="how-staged-copy-works"></a>Принцип промежуточного копирования
Если активировать функцию промежуточного копирования, сначала данные копируются из исходного хранилища в промежуточное (собственное). Оттуда данные копируются в приемник данных. Фабрика данных автоматически управляет этой двухэтапной процедурой. По окончании перемещения данных фабрика данных удаляет временные данные из промежуточного хранилища.

В случае облачного копирования (источник и приемник данных находятся в облаке) шлюз не используется. Операции копирования выполняет служба фабрики данных.

![Промежуточное копирование: облачный сценарий](media/data-factory-copy-activity-performance/staged-copy-cloud-scenario.png)

В сценарии гибридного копирования (источник размещен в локальной среде, а приемник — в облаке) шлюз перемещает данные из источника в промежуточное хранилище данных. Оттуда служба фабрики данных перемещает данные в приемник. Копирование данных из облачного хранилища данных в локальное с использованием промежуточного хранилища данных также поддерживается при обратном процессе.

![Промежуточное копирование: гибридный сценарий](media/data-factory-copy-activity-performance/staged-copy-hybrid-scenario.png)

При активации функции промежуточного копирования перемещаемых данных можно настроить их сжатие перед переносом из источника в промежуточное хранилище, а также распаковку перед перемещением из промежуточного хранилища в приемник.

Сейчас промежуточное хранение при копировании данных между двумя локальными хранилищами не поддерживается. Ожидается, что эта возможность будет добавлена в ближайшее время.

### <a name="configuration"></a>Параметр Configuration
С помощью параметра **enableStaging** в разделе действий копирования укажите, следует ли копировать данные в промежуточное хранилище BLOB-объектов перед загрузкой в целевое хранилище данных. Если для параметра **enableStaging** задано значение true, укажите дополнительные свойства, перечисленные в таблице ниже. Если у вас нет промежуточного хранилища, необходимо создать для промежуточного хранения хранилище Azure или службу, связанную с подписанным URL-адресом хранилища.

| Свойство | Описание | Значение по умолчанию | Обязательно |
| --- | --- | --- | --- |
| **enableStaging** |Укажите, следует ли копировать данные в промежуточное хранилище. |Ложь |Нет |
| **linkedServiceName (имя связанной службы)** |Укажите имя связанной службы [AzureStorage](data-factory-azure-blob-connector.md#azure-storage-linked-service) или [AzureStorageSas](data-factory-azure-blob-connector.md#azure-storage-sas-linked-service), которая будет ссылаться на используемый в качестве промежуточного экземпляр хранилища. <br/><br/> Для загрузки данных в хранилище данных SQL с помощью PolyBase нельзя использовать хранилище с подписанным URL-адресом. Его можно использовать в других случаях. |Недоступно |Да, если для параметра **enableStaging** задано значение true |
| **path** |Укажите путь к хранилищу BLOB-объектов, в котором будут храниться промежуточные данные. В противном случае служба создаст контейнер для хранения временных данных. <br/><br/> Укажите путь, только если используется хранилище с подписанным URL-адресом или требуется, чтобы временные данные хранились в определенном месте. |Недоступно |Нет |
| **enableCompression** |Указывает, следует ли сжимать данные перед копированием в место назначения. Этот параметр позволяет уменьшить объем передаваемых данных. |Ложь |Нет |

Ниже приведен пример определения действия копирования со свойствами, описанными в приведенной выше таблице.

```json
"activities":[  
{
    "name": "Sample copy activity",
    "type": "Copy",
    "inputs": [{ "name": "OnpremisesSQLServerInput" }],
    "outputs": [{ "name": "AzureSQLDBOutput" }],
    "typeProperties": {
        "source": {
            "type": "SqlSource",
        },
        "sink": {
            "type": "SqlSink"
        },
        "enableStaging": true,
        "stagingSettings": {
            "linkedServiceName": "MyStagingBlob",
            "path": "stagingcontainer/path",
            "enableCompression": true
        }
    }
}
]
```

### <a name="billing-impact"></a>Принцип выставления счетов
Взимаемая плата зависит от длительности и типа копирования.

* При использовании промежуточного хранилища данных для облачного копирования (копирования данных между облачными хранилищами данных) счет формируется так: [сумма длительности копирования для этапов 1 и 2] x [цена за единицу облачного копирования].
* При использовании промежуточного хранилища данных для гибридного копирования (копирования данных из локального хранилища данных в облачное хранилище данных) счет формируется так: [длительность гибридного копирования] x [цена за единицу гибридного копирования] + [длительность облачного копирования] x [цена за единицу облачного копирования].

## <a name="performance-tuning-steps"></a>Этапы настройки производительности
Мы советуем выполнить следующие действия, чтобы настроить производительность службы фабрики данных при использовании действия копирования.

1. **Определите базовые показатели**. Протестируйте конвейер на этапе разработки с помощью действия копирования на примере репрезентативных данных. Чтобы ограничить объем данных для тестирования, можно использовать [модель среза](data-factory-scheduling-and-execution.md) фабрики данных.

   Соберите показатели времени выполнения и производительности с помощью **приложения для мониторинга и управления**. На домашней странице фабрики данных выберите **Monitor & Manage** (Мониторинг и управление). В представлении в виде дерева выберите **Output dataset** (Выходной набор данных). В списке **Activity Windows** (Окна действий) выберите выполнение действия копирования. В списке **Activity Windows** (Окна действий) содержатся сведения о продолжительности действия копирования и объеме копируемых данных. Сведения о пропускной способности можно узнать в **обозревателе окон действий**. Чтобы узнать больше об этом приложении, ознакомьтесь со статьей [Мониторинг конвейеров фабрики данных Azure и управление ими с помощью нового приложения по мониторингу и управлению](data-factory-monitor-manage-app.md).

   ![СВЕДЕНИЯ О ВЫПОЛНЕННОМ ДЕЙСТВИИ](./media/data-factory-copy-activity-performance/mmapp-activity-run-details.png)

   Далее в этой статье вы можете сравнить показатели производительности и конфигурацию вашего сценария с [базовыми показателями производительности](#performance-reference) действия копирования, полученными в результате наших тестов.
2. **Выполните диагностику состояния производительности и оптимизируйте ее.**Если наблюдаемая производительность не соответствует вашим ожиданиям, необходимо определить ее узкие места. После этого оптимизируйте производительность, чтобы устранить или уменьшить влияние узких мест. В этой статье не приведено полное описание диагностики производительности. Однако ниже даны некоторые общие рекомендации.

   * Функции для повышения производительности:
     * [Параллельное копирование](#parallel-copy)
     * [Облачные единицы перемещения данных](#cloud-data-movement-units)
     * [Промежуточное копирование](#staged-copy)
     * [Масштабируемость шлюза управления данными](data-factory-data-management-gateway-high-availability-scalability.md)
   * [Шлюз управления данными](#considerations-for-data-management-gateway)
   * [Источник](#considerations-for-the-source)
   * [Приемник](#considerations-for-the-sink)
   * [Сериализация или десериализация](#considerations-for-serialization-and-deserialization)
   * [Сжатие](#considerations-for-compression)
   * [Сопоставление столбцов](#considerations-for-column-mapping)
   * [Дополнительные рекомендации](#other-considerations)
3. **Задайте конфигурацию для работы со всеми данными**. Если вас устраивают результаты выполнения и производительность, можно задать определение и активный период конвейера для всего набора данных.

## <a name="considerations-for-data-management-gateway"></a>Рекомендации относительно шлюза управления данными
**Настройка шлюза.** Для размещения шлюза управления данными рекомендуется использовать выделенный компьютер. См. [Рекомендации относительно шлюза управления данными](data-factory-data-management-gateway.md#considerations-for-using-gateway).  

**Мониторинг шлюза и вертикальное и (или) горизонтальное масштабирование.** Один логический шлюз с одним узлом шлюза или несколькими может обслуживать несколько запусков действия копирования одновременно. На компьютере шлюза можно практически в режиме реального времени сделать моментальный снимок использования ресурсов (ЦП, памяти, сети [входящий/исходящий трафик] и т. д.), а также количество одновременно выполняемых заданий и соответствующее ограничение на портале Azure (см. также [Мониторинг шлюза на портале](data-factory-data-management-gateway.md#monitor-gateway-in-the-portal)). При наличии большого объема гибридных данных для переноса с большим количеством параллельных запусков действия копирования или большого объема данных для копирования рассмотрите возможность [вертикального или горизонтального масштабирования шлюза](data-factory-data-management-gateway-high-availability-scalability.md#scale-considerations), чтобы оптимально использовать ресурс или подготовить дополнительные ресурсы для расширения возможностей копирования. 

## <a name="considerations-for-the-source"></a>Рекомендации для источника
### <a name="general"></a>Общие сведения
Убедитесь, что базовое хранилище данных не переполнено другими рабочими нагрузками, выполняемыми в нем или при его задействовании.

Дополнительные сведения о хранилищах данных Майкрософт см. в [разделах о мониторинге и настройке](#performance-reference) для конкретных типов хранилищ данных. В них подробно рассмотрены базовые показатели производительности хранилища данных, способы сокращения времени отклика и повышения пропускной способности.

При копировании данных из хранилища BLOB-объектов в хранилище данных SQL рассмотрите возможность использования функции **PolyBase**, позволяющей повысить производительность. Дополнительные сведения см. в разделе [Загрузка данных в хранилище данных SQL Azure с помощью PolyBase](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse). Пошаговое руководство и пример использования см. в статье [Загрузка 1 ТБ в хранилище данных SQL Azure с помощью фабрики данных Azure [мастер копирования] менее чем за 15 минут](data-factory-load-sql-data-warehouse.md).

### <a name="file-based-data-stores"></a>Файловые хранилища данных
*(Хранилище BLOB-объектов, Data Lake Store, Amazon S3, локальные файловые системы и локальная файловая система HDFS.)*

* **Средний размер файла и их количество**. Действие копирования передает данные в пофайловом режиме. При одинаковом объеме данных общая пропускная способность перемещения данных, которые состоят из большого количества небольших файлов, будет ниже, чем в случае перемещения данных, которые состоят из небольшого количества файлов большего размера. Это происходит из-за времени начальной загрузки каждого файла. Поэтому для получения более высокой пропускной способности по возможности следует объединить небольшие файлы в файлы большего размера.
* **Формат файла и сжатие**. Дополнительные сведения о способах повышения производительности см. в разделах [Рекомендации по сериализации и десериализации](#considerations-for-serialization-and-deserialization) и [Рекомендации по сжатию](#considerations-for-compression).
* Дополнительные сведения о сценарии с использованием **локальной файловой системы**, в котором применяется **шлюз управления данными**, см. в разделе [Рекомендации относительно шлюза управления данными](#considerations-for-data-management-gateway).

### <a name="relational-data-stores"></a>Реляционные хранилища данных
*(База данных SQL, хранилище данных SQL, Amazon Redshift, базы данных SQL Server, а также базы данных Oracle, MySQL, DB2, Teradata, Sybase и PostgreSQL.)*

* **Шаблон данных.**Схема таблицы влияет на пропускную способность копирования. При копировании одинакового общего объема данных большой размер строки обеспечивает лучшую производительность, чем небольшой размер строки. Причина состоит в том, что база данных может более эффективно извлекать меньшее число пакетов данных, которые содержат меньше строк.
* **Запрос или хранимая процедура.**Оптимизируйте логику запроса или хранимой процедуры, указываемую в источнике действия копирования, чтобы более эффективно извлекать данные.
* Дополнительные сведения о **локальных реляционных базах данных**, таких как SQL Server и Oracle, где требуется **шлюз управления данными**, см. в разделе [Рекомендации относительно шлюза управления данными](#considerations-on-data-management-gateway).

## <a name="considerations-for-the-sink"></a>Рекомендации для приемника
### <a name="general"></a>Общие сведения
Убедитесь, что базовое хранилище данных не переполнено другими рабочими нагрузками, выполняемыми в нем или при его задействовании.

Дополнительные сведения о хранилищах данных Microsoft см. в [разделах о мониторинге и настройке](#performance-reference) для конкретных типов хранилищ данных. В них подробно рассмотрены базовые показатели производительности хранилища данных, способы сокращения времени отклика и повышения пропускной способности.

При копировании данных из **хранилища BLOB-объектов** в **хранилище данных SQL** рассмотрите возможность использования функции **PolyBase**, позволяющей повысить производительность. Дополнительные сведения см. в разделе [Загрузка данных в хранилище данных SQL Azure с помощью PolyBase](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse). Пошаговое руководство и пример использования см. в статье [Загрузка 1 ТБ в хранилище данных SQL Azure с помощью фабрики данных Azure [мастер копирования] менее чем за 15 минут](data-factory-load-sql-data-warehouse.md).

### <a name="file-based-data-stores"></a>Файловые хранилища данных
*(Хранилище BLOB-объектов, Data Lake Store, Amazon S3, локальные файловые системы и локальная файловая система HDFS.)*

* **Режим копирования**. При копировании данных из файлового хранилища для действия копирования можно задать три разных режима с помощью свойства **copyBehavior**: сохранение иерархии, преобразование в плоскую структуру или объединение файлов. Сохранение иерархии или преобразование в плоскую структуру практически не оказывает влияния на производительность, в то время как объединение файлов существенно ее ухудшает.
* **Формат файла и сжатие**. Дополнительные сведения о способах повышения производительности см. в разделах [Рекомендации по сериализации и десериализации](#considerations-for-serialization-and-deserialization) и [Рекомендации по сжатию](#considerations-for-compression).
* **Хранилище BLOB-объектов.**В настоящее время оптимизация передачи данных и пропускной способности поддерживается только для блочных BLOB-объектов.
* Дополнительные сведения о сценарии с использованием **локальной файловой системы**, в котором применяется **шлюз управления данными**, см. в разделе [Рекомендации относительно шлюза управления данными](#considerations-for-data-management-gateway).

### <a name="relational-data-stores"></a>Реляционные хранилища данных
*(База данных SQL, хранилище данных SQL, базы данных SQL Server и базы данных Oracle.)*

* **Режим копирования**. В зависимости от свойств, заданных для **sqlSink**, существует несколько вариантов записи данных в базу данных назначения при выполнении действия копирования.
  * По умолчанию служба перемещения данных использует интерфейс API массового копирования для вставки данных в режиме добавления, что обеспечивает лучшую производительность.
  * Если настроить в приемнике хранимую процедуру, данные в базу данных будут записываться в построчном режиме, а не массово. Это существенно снижает производительность. В случае с набором данных большого размера рекомендуется использовать свойство **sqlWriterCleanupScript** , если это применимо.
  * Если настроить свойство **sqlWriterCleanupScript** , при каждом действии копирования для вставки данных служба сначала запустит сценарий, а затем использует интерфейс API массового копирования. Например, чтобы перезаписать всю таблицу последними данными, перед массовой загрузкой новых данных из источника можно указать сценарий для удаления всех записей.
* **Шаблон данных и размер пакета**.
  * Схема таблицы влияет на пропускную способность копирования. Во время копирования данных одинакового объема использование строк большого размера позволяет добиться лучшей производительности, чем при использовании строк небольшого размера. Это связано с тем, что база данных более эффективно сохраняет меньшее количество пакетов данных.
  * Действие копирования вставляет данные в виде последовательности пакетов. Количество строк в пакете можно задать с помощью свойства **writeBatchSize** . Если данные содержатся в строках небольшого размера, можно задать для свойства **writeBatchSize** более высокое значение, чтобы использовать меньшее количество пакетов и тем самым увеличить пропускную способность. Если данные содержатся в строках большого размера, будьте внимательны при увеличении **writeBatchSize**. Высокое значение может привести к сбою копирования из-за перегрузки базы данных.
* Дополнительные сведения о **локальных реляционных базах данных**, таких как SQL Server и Oracle, где требуется **шлюз управления данными**, см. в разделе [Рекомендации относительно шлюза управления данными](#considerations-for-data-management-gateway).

### <a name="nosql-stores"></a>Хранилища NoSQL
*(Хранилище таблиц и Azure Cosmos DB.)*

* Для **хранилища таблиц**:
  * **Секционирование**. Запись данных в секции с чередованием значительно снижает производительность. Отсортируйте исходные данные по ключу секции, чтобы эффективно вставлять данные в секцию за секцией. Можно также настроить логику для записи данных в одну секцию.
* Для **Azure Cosmos DB**:
  * **Размер пакета**. Свойство **writeBatchSize** задает количество параллельных запросов на создание документов в службе Azure Cosmos DB. Если увеличить значение свойства **writeBatchSize** , то производительность повышается, потому что в Azure Cosmos DB начинает уходить больше параллельных запросов. Однако при записи в Azure Cosmos DB необходимо следить за регулированием (может появиться сообщение об ошибке "Высокая частота запросов"). Регулирование могут вызвать различные факторы, в частности размер документа, количество терминов в документах и политика индексирования целевой коллекции. Чтобы добиться более высокой пропускной способности копирования, рекомендуется использовать лучшую коллекцию, например S3.

## <a name="considerations-for-serialization-and-deserialization"></a>Рекомендации по сериализации и десериализации
Сериализация и десериализация могут произойти, если входной или выходной набор данных представляет собой файл. Дополнительные сведения о форматах файлов, поддерживаемых действием копирования, см. в статье [Форматы файлов и сжатия данных, поддерживаемые фабрикой данных Azure](data-factory-supported-file-and-compression-formats.md).

**Режим копирования.**

* При копировании файлов между файловыми хранилищами данных:
  * Если параметры формата файла входного и выходного наборов данных одинаковые, служба перемещения данных выполнит двоичное копирование без сериализации или десериализации. В этом случае пропускная способность будет более высокой, чем в сценарии, когда параметры формата файла источника и приемника отличаются друг от друга.
  * Если входной и выходной наборы данных находятся в текстовом формате и отличаются только типом кодирования, служба перемещения данных выполнит только преобразование кодирования. При этом сериализация и десериализация применяться не будут. По сравнению с двоичным копированием, это совсем незначительно повлияет на производительность.
  * Если входной и выходной наборы данных представлены в разных форматах файлов или имеют разные конфигурации, например отличаются разделителями, то служба перемещения данных десериализует исходные данные для их потоковой передачи, преобразования и сериализации в указанный формат выходных данных. В отличие от предыдущих сценариев, это приведет к более значительному снижению производительности.
* При копировании файлов в хранилище данных, которое не является файловым, или из него (например, из файлового хранилища в реляционное) требуется операция сериализации или десериализации. Этот шаг существенно снижает производительность.

**Формат файла**. Используемый формат файла может повлиять на производительность копирования. К примеру, Avro — это компактный двоичный формат, в котором хранятся метаданные с данными. Этот формат поддерживает экосистема Hadoop для обработки и выполнения запросов. Однако стоимость формата Avro для сериализации или десериализации выше, а пропускная способность копирования ниже по сравнению с текстовым форматом. Формат файла, который необходимо использовать в процессе обработки, следует выбирать, принимая во внимание все элементы — от формы данных, хранимых в исходных хранилищах данных или извлекаемых из внешних систем, лучшего формата для хранения, аналитической обработки и выполнения запросов до формата, в котором следует экспортировать данные в киоски данных для средств создания отчетов и визуализации данных. Иногда формат файла, который не является достаточно оптимальным для производительности операций чтения и записи, может отлично подойти, учитывая общий аналитический процесс.

## <a name="considerations-for-compression"></a>Рекомендации по сжатию
Если входной или выходной набор данных представляет собой файл, для действия копирования можно настроить сжатие или распаковку данных при записи в место назначения. Использование сжатия — это компромисс между количеством операций ввода-вывода и потреблением ЦП, так как для сжатия данных требуются дополнительные вычислительные ресурсы. Однако взамен уменьшается количество сетевых операций ввода-вывода и используемый объем хранилища. В зависимости от данных это может повысить общую пропускную способность копирования.

**Кодек.**Действие копирования поддерживает такие типы сжатия: GZIP, BZIP2 и DEFLATE. Все три типа можно использовать для обработки в Azure HDInsight. Каждый кодек сжатия имеет свои преимущества. Например, кодек BZIP2 обладает минимальной пропускной способностью копирования, но предоставляет лучшую производительность выполнения запросов Hive, так как ее можно разделить для обработки. Кодек GZIP — это наиболее оптимальный вариант, который используется чаще всего. Следует выбрать кодек, который лучше всего подходит для комплексного сценария.

**Уровень.**Для каждого кодека сжатия можно выбрать один из двух параметров — самое быстрое сжатие или оптимальное сжатие. Если использовать параметр самого быстрого сжатия, данные сжимаются как можно быстрее, даже если итоговый файл сжимается не оптимально. Если использовать параметр оптимального сжатия, данные сжимаются дольше, предоставляя минимальный объем данных. Можно испытать оба варианта, чтобы увидеть, который из них обеспечивает лучшую общую производительность в определенном случае.

**Рекомендация**. При копировании данных большого объема между локальным хранилищем и облаком для сжатия можно использовать промежуточное хранилище BLOB-объектов. Промежуточное хранилище эффективно использовать, когда пропускная способность корпоративной сети и служб Azure является ограничивающим фактором и требуется, чтобы входной и выходной наборы данных были в несжатом виде. В частности, можно разбить одно действие копирования на два действия: первое действие копирования будет копировать данные из источника в промежуточный большой двоичный объект в сжатом виде, а второе действие копирования будет копировать сжатые данные из этого объекта и распаковывать их во время записи в приемник.

## <a name="considerations-for-column-mapping"></a>Рекомендации по сопоставлению столбцов
В действии копирования можно задать свойство **columnMappings** для сопоставления всех входных столбцов или их подмножества с выходными столбцами. После считывания данных из источника службе перемещения данных требуется выполнить сопоставление столбцов данных, прежде чем записать их в приемник. Эта дополнительная обработка снижает пропускную способность копирования.

Если данные в источнике доступны для запросов, например при использовании реляционного хранилища (база данных SQL или SQL Server) или хранилища NoSQL (хранилище таблиц или Azure Cosmos DB), вместо использования сопоставления столбцов для свойства **query** можно передать фильтрацию столбцов и логику переупорядочивания. Таким образом, когда служба перемещения данных считывает данные из исходного хранилища, что является более эффективным, осуществляется проецирование.

## <a name="other-considerations"></a>Дополнительные рекомендации
Если размер данных для копирования достаточно большой, можно настроить бизнес-логику для дальнейшего секционирования данных с помощью механизма создания срезов фабрики данных. Затем запланируйте более частое выполнение действия копирования, чтобы уменьшить размер данных для каждого действия копирования.

Необходимо следить за количеством наборов данных и действий копирования, требующих подключения фабрики данных к одному хранилищу данных в одно и то же время. Большое количество одновременно выполняемых заданий копирования может привести к регулированию хранилища данных, что ведет к снижению производительности, внутренним повторным попыткам выполнения действия копирования, а в некоторых случаях — к сбоям выполнения.

## <a name="sample-scenario-copy-from-an-on-premises-sql-server-to-blob-storage"></a>Пример сценария. Копирование из локального SQL Server в хранилище BLOB-объектов
**Сценарий.**Конвейер предназначен для копирования данных с локального сервера SQL Server в хранилище BLOB-объектов в формате CSV. Для ускорения выполнения задания копирования необходимо сжать CSV-файлы в формат BZIP2.

**Тестирование и анализ.**Пропускная способность действия копирования составляет меньше 2 МБ/с, что гораздо меньше, чем в тесте производительности.

**Анализ и оптимизация производительности.**Чтобы устранить проблемы производительности, сначала необходимо рассмотреть процесс обработки и перемещения данных.

1. **Чтение данных.**Шлюз устанавливает подключение с SQL Server и отправляет запрос. SQL Server отвечает, отправляя поток данных в шлюз через интрасеть.
2. **Сериализация и сжатие данных.**Шлюз сериализует поток данных в формат CSV и сжимает данные в поток BZIP2.
3. **Запись данных.**Шлюз отправляет поток BZIP2 в хранилище BLOB-объектов через Интернет.

Как видите, обработка и перемещение данных происходит в последовательном режиме потоковой передачи: SQL Server -> локальная сеть -> шлюз -> глобальная сеть -> хранилище BLOB-объектов. **Общая производительность достигается при минимальной пропускной способности в конвейере.**

![Поток данных](./media/data-factory-copy-activity-performance/case-study-pic-1.png)

Один или несколько следующих факторов могут вызвать узкое место производительности.

* **Источник.**SQL Server отличается низкой пропускной способностью из-за высокой нагрузки.
* **Шлюз управления данными.**
  * **Локальная сеть.**Шлюз находится далеко от компьютера SQL Server и характеризуется низкой пропускной способностью.
  * **Шлюз.**Выполнение следующих операций привело к достижению ограничений нагрузки для шлюза.
    * **Сериализация.**Сериализация потока данных в формат CSV характеризуется низкой пропускной способностью.
    * **Сжатие.**Выбран кодек медленного сжатия (например, BZIP2 со скоростью 2,8 Мбит/с и процессором Core i7).
  * **Глобальная сеть.**Низкая пропускная способность между корпоративной сетью и службами Azure (например, T1 — 1544 Кбит/с, T2 — 6312 Кбит/с).
* **Приемник.**Хранилище BLOB-объектов имеет низкую пропускную способность. (Этот сценарий маловероятный, так как соглашение об уровне обслуживания гарантирует не менее 60 Мбит/с.)

В этом случае сжатие данных в формат BZIP2 может замедлять работу всего конвейера. Этого можно избежать, если перейти на использование кодека сжатия в формат GZIP.

## <a name="sample-scenarios-use-parallel-copy"></a>Примеры сценариев. Использование параллельного копирования
**Сценарий I.** Копирование 1000 файлов размером 1 МБ из локальной файловой системы в хранилище BLOB-объектов.

**Анализ и оптимизация производительности.**Допустим, вы установили шлюз на четырехъядерном компьютере, а фабрика данных использует 16 параллельных копий для одновременного перемещения файлов из файловой системы в хранилище BLOB-объектов. Это приведет к высокой пропускной способности. Можно также явно указать количество параллельных операций копирования. При копировании множества небольших файлов одновременные операции копирования значительно увеличивают пропускную способность за счет более эффективного использования ресурсов.

![Сценарий 1](./media/data-factory-copy-activity-performance/scenario-1.png)

**Сценарий II.**Копирование 20 больших двоичных объектов размером 500 МБ из хранилища BLOB-объектов в Data Lake Store с анализом и настройкой производительности.

**Анализ и оптимизация производительности**. В этом сценарии фабрика данных копирует данные из хранилища BLOB-объектов в Data Lake Store, используя отдельные операции копирования(**parallelCopies** равно 1) и отдельные облачные единицы перемещения данных. Наблюдаемая пропускная способность будет близка к указанной в [разделе с показателями производительности](#performance-reference).   

![Сценарий 2](./media/data-factory-copy-activity-performance/scenario-2.png)

**Сценарий III.**Размер отдельного файла превышает десятки мегабайтов, и общий объем достаточно велик.

**Анализ и оптимизация производительности**. Увеличение значения **parallelCopies** не приведет к повышению производительности копирования ввиду ограничения ресурсов отдельной облачной единицы перемещения данных. Вместо этого следует задать больше облачных единиц перемещения данных, чтобы получить дополнительные ресурсы для перемещения данных. Не указывайте значение для свойства **parallelCopies**. Фабрика данных автоматически обрабатывает параллелизм. В этом случае можно задать для **cloudDataMovementUnits** значение 4. Это повысит пропускную способность примерно в 4 раза.

![Сценарий 3](./media/data-factory-copy-activity-performance/scenario-3.png)

## <a name="reference"></a>Справочные материалы
Ниже приведены справочные материалы по мониторингу и настройке производительности для некоторых поддерживаемых хранилищ данных.

* Служба хранилища Azure (включая хранилище BLOB-объектов и таблиц): [Целевые показатели масштабируемости и производительности службы хранилища Azure](../../storage/common/storage-scalability-targets.md) и [Производительность хранилища Microsoft Azure и контрольный список масштабируемости](../../storage/common/storage-performance-checklist.md).
* База данных SQL Azure: вы можете [наблюдать за производительностью](../../sql-database/sql-database-single-database-monitor.md) и проверять процент использования единиц транзакций базы данных (DTU).
* Хранилище данных SQL Azure: его использование измеряется в единицах использования хранилища данных (DWU). См. статью [Управление вычислительными ресурсами в хранилище данных SQL Azure (обзор)](../../sql-data-warehouse/sql-data-warehouse-manage-compute-overview.md).
* Azure Cosmos DB: [Прекращение использования уровней производительности S1, S2 и S3 в DocumentDB](../../cosmos-db/performance-levels.md).
* Локальный SQL Server: [Мониторинг и настройка производительности](https://msdn.microsoft.com/library/ms189081.aspx)
* Локальный файловый сервер: [Performance tuning for file servers](https://msdn.microsoft.com/library/dn567661.aspx)
