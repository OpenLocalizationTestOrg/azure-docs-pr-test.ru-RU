---
title: "Перемещение данных из базы данных MongoDB с помощью фабрики данных | Документация Майкрософт"
description: "Узнайте, как перемещать данные из базы данных MongoDB с использованием фабрики данных Azure."
services: data-factory
documentationcenter: 
author: linda33wj
manager: jhubbard
editor: monicar
ms.assetid: 10ca7d9a-7715-4446-bf59-2d2876584550
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 01/10/2018
ms.author: jingwang
robots: noindex
ms.openlocfilehash: 20df17ba01cfc18ce751491d154d7401001e706e
ms.sourcegitcommit: 9cc3d9b9c36e4c973dd9c9028361af1ec5d29910
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/23/2018
---
# <a name="move-data-from-mongodb-using-azure-data-factory"></a>Перемещение данных из MongoDB с помощью фабрики данных Azure
> [!div class="op_single_selector" title1="Select the version of Data Factory service you are using:"]
> * [Версия 1 — общедоступная](data-factory-on-premises-mongodb-connector.md)
> * [Версия 2 — предварительная](../connector-mongodb.md)

> [!NOTE]
> Статья относится к версии 1 фабрики данных, которая является общедоступной версией. Если вы используете версию 2 службы фабрики данных, которая находится на этапе предварительной версии, см. статью [Copy data from MongoDB using Azure Data Factory](../connector-mongodb.md) (Копирование данных из MongoDB с помощью фабрики данных Azure).


В этой статье описывается, как с помощью действия копирования в фабрике данных Azure перемещать данные из локальной базы данных MongoDB. Этот документ является продолжением статьи о [действиях перемещения данных](data-factory-data-movement-activities.md), в которой приведены общие сведения о перемещении данных с помощью действия копирования.

Вы можете скопировать данные из локального хранилища данных MongoDB в любой поддерживаемый приемник данных. Список хранилищ данных, которые поддерживаются в качестве приемников для действия копирования, приведен в таблице [Поддерживаемые хранилища данных и форматы](data-factory-data-movement-activities.md#supported-data-stores-and-formats). Сейчас фабрика данных поддерживает только перемещение данных из хранилища данных MongoDB в другие хранилища данных, но не наоборот. 

## <a name="prerequisites"></a>предварительным требованиям
Чтобы служба фабрики данных Azure могла подключаться к локальной базе данных MongoDB, необходимо установить следующие компоненты.

- Поддерживаемые версии MongoDB: 2.4, 2.6, 3.0 и 3.2.
- Шлюз управления данными на том же компьютере, на котором размещена база данных, или на отдельном компьютере во избежание конкуренции за ресурсы. Шлюз управления данными — это программное обеспечение, которое обеспечивает безопасное и управляемое подключение локальных источников данных к облачным службам. Дополнительные сведения о шлюзе управления данными см. в статье [Шлюз управления данными](data-factory-data-management-gateway.md). Пошаговые инструкции по настройке шлюза для перемещения данных с помощью конвейера см. в статье [Перемещение данных между локальными источниками и облаком с помощью шлюза управления данными](data-factory-move-data-between-onprem-and-cloud.md).

    Вместе со шлюзом автоматически устанавливается драйвер ODBC Microsoft MongoDB, который используется для подключения к базе данных MongoDB.

    > [!NOTE]
    > Шлюз используется для подключения к источнику MongoDB, даже если он размещен на виртуальных машинах IaaS Azure. Если вы подключаетесь к экземпляру MongoDB, размещенному в облаке, экземпляр шлюза можно тоже установить на виртуальную машину IaaS.

## <a name="getting-started"></a>Приступая к работе
Вы можете создать конвейер с действием копирования, которое перемещает данные из локального хранилища данных MongoDB, с помощью разных инструментов и интерфейсов API.

Проще всего создать конвейер с помощью **мастера копирования**. В статье [Руководство. Создание конвейера с действием копирования с помощью мастера копирования фабрики данных](data-factory-copy-data-wizard-tutorial.md) приведены краткие пошаговые указания по созданию конвейера с помощью мастера копирования данных.

Также для создания конвейера можно использовать следующие инструменты: **портал Azure**, **Visual Studio**, **Azure PowerShell**, **шаблон Azure Resource Manager**, **API .NET** и **REST API**. Пошаговые инструкции по созданию конвейера с действием копирования см. в [руководстве по действию копирования](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md). 

Независимо от используемого средства или API-интерфейса, для создания конвейера, который перемещает данные из источника данных в приемник, выполняются следующие шаги: 

1. Создайте **связанные службы**, чтобы связать входные и выходные данные с фабрикой данных.
2. Создайте **наборы данных**, которые представляют входные и выходные данные для операции копирования. 
3. Создайте **конвейер** с действием копирования, который принимает входной набор данных и возвращает выходной набор данных. 

Если вы используете мастер, то он автоматически создает определения JSON для сущностей фабрики данных (связанных служб, наборов данных и конвейера). При использовании инструментов и интерфейсов API (за исключением API .NET) вы самостоятельно определяете эти сущности фабрики данных в формате JSON.  Пример определения JSON для сущностей фабрики данных, которые используются для копирования данных из локального хранилища данных MongoDB, приведен в разделе [Пример JSON. Копирование данных из MongoDB в большой двоичный объект Azure](#json-example-copy-data-from-mongodb-to-azure-blob) далее в этой статье. 

Следующие разделы содержат сведения о свойствах JSON, которые используются для определения сущностей фабрики данных, относящихся к источнику MongoDB.

## <a name="linked-service-properties"></a>Свойства связанной службы
В следующей таблице содержится описание элементов JSON, которые относятся к связанной службе **OnPremisesMongoDB** .

| Свойство | ОПИСАНИЕ | Обязательно |
| --- | --- | --- |
| Тип |Для свойства type необходимо задать значение **OnPremisesMongoDb** |Yes |
| server |IP-адрес или имя узла сервера MongoDB |Yes |
| порт |TCP-порт, используемый сервером MongoDB для прослушивания клиентских подключений |Значение по умолчанию — 27017 (необязательно) |
| authenticationType |Укажите тип Basic или Anonymous |Yes |
| Имя пользователя |Учетная запись пользователя для доступа к MongoDB |Да (если используется обычная проверка подлинности) |
| password |Пароль для пользователя |Да (если используется обычная проверка подлинности) |
| authSource |Имя базы данных MongoDB, которое будет использоваться для проверки учетных данных при проверке подлинности |Необязательно (если используется обычная проверка подлинности). По умолчанию используется учетная запись администратора и база данных, указанная с помощью свойства databaseName |
| databaseName |Имя базы данных MongoDB, к которой необходимо получить доступ |Yes |
| gatewayName |Имя шлюза, который обращается к хранилищу данных |Yes |
| encryptedCredential |Учетные данные, зашифрованные шлюзом |Необязательно |

## <a name="dataset-properties"></a>Свойства набора данных
Полный список разделов и свойств, используемых для определения наборов данных, см. в статье [Наборы данных](data-factory-create-datasets.md). Разделы структуры, доступности и политики JSON набора данных одинаковы для всех типов наборов данных (SQL Azure, большие двоичные объекты Azure, таблицы Azure и т. д.).

Раздел **typeProperties** во всех типах наборов данных разный. В нем содержатся сведения о расположении данных в хранилище данных. Раздел typeProperties набора данных типа **MongoDbCollection** содержит следующие свойства.

| Свойство | ОПИСАНИЕ | Обязательно |
| --- | --- | --- |
| collectionName |Имя коллекции в базе данных MongoDB |Да |

## <a name="copy-activity-properties"></a>Свойства действия копирования
Полный список разделов и свойств, используемых для определения действий, см. в статье [Создание конвейеров](data-factory-create-pipelines.md). Свойства (включая имя, описание, входные и выходные таблицы, политику и т. д.) доступны для всех типов действий.

С другой стороны, свойства, доступные в разделе **typeProperties** действия, зависят от конкретного типа действия. Для действия копирования они различаются в зависимости от типов источников и приемников.

Если источник относится к типу **MongoDbSource** , в разделе typeProperties доступны следующие свойства.

| Свойство | ОПИСАНИЕ | Допустимые значения | Обязательно |
| --- | --- | --- | --- |
| query |Используйте пользовательский запрос для чтения данных. |Строка запроса SQL-92. Например, select * from MyTable. |Нет (если для свойства **collectionName** задано значение **dataset**). |



## <a name="json-example-copy-data-from-mongodb-to-azure-blob"></a>Пример JSON. Копирование данных из MongoDB в большой двоичный объект Azure
Ниже приведен пример с определениями JSON, которые можно использовать для создания конвейера с помощью [портала Azure](data-factory-copy-activity-tutorial-using-azure-portal.md), [Visual Studio](data-factory-copy-activity-tutorial-using-visual-studio.md) или [Azure PowerShell](data-factory-copy-activity-tutorial-using-powershell.md). В нем показано, как скопировать данные из локального хранилища данных MongoDB в хранилище BLOB-объектов Azure. Тем не менее данные можно копировать в любой из указанных [здесь](data-factory-data-movement-activities.md#supported-data-stores-and-formats) приемников. Это делается с помощью действия копирования в фабрике данных Azure.

Образец состоит из следующих сущностей фабрики данных.

1. Связанная служба типа [OnPremisesMongoDb](#linked-service-properties).
2. Связанная служба типа [AzureStorage](data-factory-azure-blob-connector.md#linked-service-properties).
3. Входной [набор данных](data-factory-create-datasets.md) типа [MongoDbCollection](#dataset-properties).
4. Выходной [набор данных](data-factory-create-datasets.md) типа [AzureBlob](data-factory-azure-blob-connector.md#dataset-properties).
5. [Конвейер](data-factory-create-pipelines.md) с действием копирования, в котором используются [MongoDbSource](#copy-activity-properties) и [BlobSink](data-factory-azure-blob-connector.md#copy-activity-properties).

В примере данные из результата выполнения запроса к базе данных MongoDB каждый час копируются в большой двоичный объект. Используемые в этих примерах свойства JSON описаны в разделах, следующих за примерами.

Сначала настройте шлюз управления данными. Необходимые инструкции представлены в статье [Шлюз управления данными](data-factory-data-management-gateway.md).

**Связанная служба MongoDB**

```json
{
    "name": "OnPremisesMongoDbLinkedService",
    "properties":
    {
        "type": "OnPremisesMongoDb",
        "typeProperties":
        {
            "authenticationType": "<Basic or Anonymous>",
            "server": "< The IP address or host name of the MongoDB server >",  
            "port": "<The number of the TCP port that the MongoDB server uses to listen for client connections.>",
            "username": "<username>",
            "password": "<password>",
           "authSource": "< The database that you want to use to check your credentials for authentication. >",
            "databaseName": "<database name>",
            "gatewayName": "<mygateway>"
        }
    }
}
```

**Связанная служба хранилища Azure**

```json
{
  "name": "AzureStorageLinkedService",
  "properties": {
    "type": "AzureStorage",
    "typeProperties": {
      "connectionString": "DefaultEndpointsProtocol=https;AccountName=<accountname>;AccountKey=<accountkey>"
    }
  }
}
```

**Входной набор данных MongoDB**. Если для параметра external задать значение true, то фабрика данных воспримет эту таблицу как внешнюю таблицу, которая создана не в результате какого-либо действия в этой службе.

```json
{
     "name":  "MongoDbInputDataset",
    "properties": {
        "type": "MongoDbCollection",
        "linkedServiceName": "OnPremisesMongoDbLinkedService",
        "typeProperties": {
            "collectionName": "<Collection name>"    
        },
        "availability": {
            "frequency": "Hour",
            "interval": 1
        },
        "external": true
    }
}
```

**Выходной набор данных BLOB-объекта Azure**

Данные записываются в новый BLOB-объект каждый час (frequency: hour, interval: 1). Путь к папке BLOB-объекта вычисляется динамически на основе времени начала обрабатываемого среза. В пути к папке используется год, месяц, день и час времени начала.

```json
{
    "name": "AzureBlobOutputDataSet",
    "properties": {
        "type": "AzureBlob",
        "linkedServiceName": "AzureStorageLinkedService",
        "typeProperties": {
            "folderPath": "mycontainer/frommongodb/yearno={Year}/monthno={Month}/dayno={Day}/hourno={Hour}",
            "format": {
                "type": "TextFormat",
                "rowDelimiter": "\n",
                "columnDelimiter": "\t"
            },
            "partitionedBy": [
                {
                    "name": "Year",
                    "value": {
                        "type": "DateTime",
                        "date": "SliceStart",
                        "format": "yyyy"
                    }
                },
                {
                    "name": "Month",
                    "value": {
                        "type": "DateTime",
                        "date": "SliceStart",
                        "format": "MM"
                    }
                },
                {
                    "name": "Day",
                    "value": {
                        "type": "DateTime",
                        "date": "SliceStart",
                        "format": "dd"
                    }
                },
                {
                    "name": "Hour",
                    "value": {
                        "type": "DateTime",
                        "date": "SliceStart",
                        "format": "HH"
                    }
                }
            ]
        },
        "availability": {
            "frequency": "Hour",
            "interval": 1
        }
    }
}
```

**Действие копирования в конвейере с MongoDB в качестве источника и большим двоичным объектом в качестве приемника**

Конвейер содержит действие копирования (Copy), которое использует входной и выходной наборы данных (см. выше) и выполняется каждый час. В определении JSON конвейера для типа **source** установлено значение **MongoDbSource**, а для типа **sink** — значение **BlobSink**. SQL-запрос, указанный для свойства **query** , выбирает для копирования данные за последний час.

```json
{
    "name": "CopyMongoDBToBlob",
    "properties": {
        "description": "pipeline for copy activity",
        "activities": [
            {
                "type": "Copy",
                "typeProperties": {
                    "source": {
                        "type": "MongoDbSource",
                        "query": "$$Text.Format('select * from  MyTable where LastModifiedDate >= {{ts\'{0:yyyy-MM-dd HH:mm:ss}\'}} AND LastModifiedDate < {{ts\'{1:yyyy-MM-dd HH:mm:ss}\'}}', WindowStart, WindowEnd)"
                    },
                    "sink": {
                        "type": "BlobSink",
                        "writeBatchSize": 0,
                        "writeBatchTimeout": "00:00:00"
                    }
                },
                "inputs": [
                    {
                        "name": "MongoDbInputDataset"
                    }
                ],
                "outputs": [
                    {
                        "name": "AzureBlobOutputDataSet"
                    }
                ],
                "policy": {
                    "timeout": "01:00:00",
                    "concurrency": 1
                },
                "scheduler": {
                    "frequency": "Hour",
                    "interval": 1
                },
                "name": "MongoDBToAzureBlob"
            }
        ],
        "start": "2016-06-01T18:00:00Z",
        "end": "2016-06-01T19:00:00Z"
    }
}
```


## <a name="schema-by-data-factory"></a>Схема фабрики данных
Служба фабрики данных Azure определяет схему для коллекции MongoDB, используя последние 100 документов в коллекции. Если эти 100 документов не содержат полной схемы, во время копирования некоторые столбцы могут игнорироваться.

## <a name="type-mapping-for-mongodb"></a>Сопоставление типов для MongoDB
Как упоминалось в статье о [действиях перемещения данных](data-factory-data-movement-activities.md), во время копирования типы источников автоматически преобразовываются в типы приемников. Такое преобразование выполняется в два этапа.

1. Преобразование собственных типов источников в тип .NET.
2. Преобразование типа .NET в собственный тип приемника.

Когда данные перемещаются в MongoDB, для преобразования типов MongoDB в типы .NET используются следующие сопоставления.

| Тип MongoDB | Тип .NET Framework |
| --- | --- |
| Binary |Byte[] |
| Логическое |Логическое |
| Дата |Datetime |
| NumberDouble |Double |
| NumberInt |Int32 |
| NumberLong |Int64 |
| ObjectID |Строка |
| Строка |Строка |
| UUID |Guid |
| Объект. |Преобразованный в плоские столбцы с "_" в качестве вложенного разделителя |

> [!NOTE]
> Дополнительные сведения о поддержке массивов с помощью виртуальных таблиц см. в разделе [Поддержка сложных типов с помощью виртуальных таблиц](#support-for-complex-types-using-virtual-tables) ниже.

В настоящее время не поддерживаются следующие типы MongoDB: DBPointer, JavaScript, мин. и макс. значение ключей, регулярное выражение, символ, метка времени, не определенный.

## <a name="support-for-complex-types-using-virtual-tables"></a>Поддержка сложных типов с помощью виртуальных таблиц
В фабрике данных Azure используется встроенный драйвер ODBC, который позволяет подключаться к базе данных MongoDB и копировать из нее данные. Для сложных типов, таких как массивы или объекты с различными типами данных в документах, драйвер ренормализует данные в соответствующие виртуальные таблицы. В частности, если таблица содержит такие столбцы, драйвер создает следующие виртуальные таблицы.

* **Базовая таблица**, в которой содержатся те же данные, что и в исходной таблице, кроме столбцов сложного типа. Имена базовой таблицы и таблицы, которую она представляет, совпадают.
* **Виртуальная таблица** для каждого столбца сложного типа, в которой представлены вложенные данные в развернутом виде. Виртуальным таблицам присваиваются имена в следующем формате: имя исходной таблицы, разделитель "_", имя массива или объекта.

Виртуальные таблицы ссылаются на данные в исходной таблице, что позволяет драйверу подключаться к денормализованным данным. Дополнительные сведения см. в разделе "Примеры". Доступ к содержимому массивов MongoDB можно получить при помощи отправки запроса и соединения виртуальных таблиц.

Просмотреть список таблиц, в том числе виртуальных, в базе данных MongoDB и содержащихся в них данных можно с помощью [мастера копирования](data-factory-data-movement-activities.md#create-a-pipeline-with-copy-activity) . Он также позволяет создать запрос и просмотреть результат выполнения.

### <a name="example"></a>Пример
Ниже приведен пример таблицы ExampleTable в базе данных MongoDB, содержащей столбец ("Счета") с массивом объектов в каждой ячейке и столбец с массивом данных скалярных типов ("Оценки").

| _№ | Имя клиента | Счета | Уровень обслуживания | Оценки |
| --- | --- | --- | --- | --- |
| 1111 |ABC |[{счет_№:"123", товар:"тостер", цена:"456", скидка:"0,2"}, {счет_№:"124", товар:"печь", цена: "1235", скидка: "0,2"}] |Silver |[5,6] |
| 2222 |XYZ |[{счет_№: "135", товар: "холодильник", цена: "12543", скидка: "0,0"}] |Gold |[1,2] |

Для представления такой одной таблицы драйвер создает несколько виртуальных таблиц. Ниже приведен пример первой базовой виртуальной таблицы ExampleTable. Базовая таблица содержит все данные из исходной таблицы, но данные массивов опущены и развернуты в виртуальных таблицах.

| _№ | Имя клиента | Уровень обслуживания |
| --- | --- | --- |
| 1111 |ABC |Silver |
| 2222 |XYZ |Gold |

В следующих таблицах представлены виртуальные таблицы, соответствующие исходным массивам в примере. Каждая из этих таблиц содержит следующее:

* обратную ссылку на исходный ключевой столбец, соответствующий строке исходного массива (с помощью столбца _№);
* указание на позицию данных в исходном массиве;
* развернутые данные для каждого элемента в массиве.

Таблица ExampleTable_Invoices:

| _№ | ExampleTable_Invoices_dim1_idx | счет_№ | item | price | Скидка |
| --- | --- | --- | --- | --- | --- |
| 1111 |0 |123 |тостер |456 |0,2 |
| 1111 |1 |124 |печь |1235 |0,2 |
| 2222 |0 |135 |холодильник |12543 |0,0 |

Таблица ExampleTable_Ratings:

| _№ | ExampleTable_Ratings_dim1_idx | ExampleTable_Ratings |
| --- | --- | --- |
| 1111 |0 |5 |
| 1111 |1 |6 |
| 2222 |0 |1 |
| 2222 |1 |2 |

## <a name="map-source-to-sink-columns"></a>Сопоставление столбцов источника и приемника
Дополнительные сведения о сопоставлении столбцов в наборе данных, используемом в качестве источника, со столбцами в приемнике см. в [этой статье](data-factory-map-columns.md).

## <a name="repeatable-read-from-relational-sources"></a>Повторяющиеся операции чтения из реляционных источников
При копировании данных из реляционных хранилищ важно помнить о повторяемости, чтобы избежать непредвиденных результатов. В фабрике данных Azure можно вручную повторно выполнить срез. Вы можете также настроить для набора данных политику повтора, чтобы при сбое срез выполнялся повторно. При повторном выполнении среза в любом случае необходимо убедиться в том, что считываются те же данные, независимо от того, сколько раз выполняется срез. Ознакомьтесь с разделом [Повторяющиеся операции чтения из реляционных источников](data-factory-repeatable-copy.md#repeatable-read-from-relational-sources).

## <a name="performance-and-tuning"></a>Производительность и настройка
Ознакомьтесь со статьей [Руководство по настройке производительности действия копирования](data-factory-copy-activity-performance.md), в которой описываются ключевые факторы, влияющие на производительность перемещения данных (действие копирования) в фабрике данных Azure, и различные способы оптимизации этого процесса.

## <a name="next-steps"></a>Дальнейшие действия
Ознакомьтесь со статьей [Перемещение данных между локальными источниками и облаком с помощью шлюза управления данными](data-factory-move-data-between-onprem-and-cloud.md), в которой представлены пошаговые инструкции по созданию конвейера данных, который перемещает данные из локального хранилища в хранилище данных Azure.
