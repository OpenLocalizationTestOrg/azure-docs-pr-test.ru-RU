---
title: "Ветвление в конвейере фабрики данных Azure | Документация Майкрософт"
description: "Узнайте, как контролировать поток данных в фабрике данных Azure с помощью ветвления и создания цепочки действий."
services: data-factory
documentationcenter: 
author: sharonlo101
manager: jhubbard
editor: spelluru
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: get-started-article
ms.date: 01/11/2018
ms.author: shlo
ms.openlocfilehash: de48d61af0e8056a749715343ef821cfc35cb93d
ms.sourcegitcommit: be9a42d7b321304d9a33786ed8e2b9b972a5977e
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/19/2018
---
# <a name="branching-and-chaining-activities-in-a-data-factory-pipeline"></a>Ветвления и создание цепочки действий в конвейере фабрики данных
В этом руководстве создается конвейер фабрики данных, который демонстрирует некоторые функции потока управления. Этот конвейер просто копирует данные из контейнера в хранилище BLOB-объектов Azure в другой контейнер в той же учетной записи хранения. Если действие копирования завершается успешно, конвейер отправляет по электронной почте подробную информацию об успешной операции копирования (например, количество записанных данных). Если происходит сбой действия копирования, конвейер отправляет по электронной почте данные об ошибке копирования (например, текст сообщения об ошибке). В этом руководстве вы научитесь передавать параметры.

> [!NOTE]
> Эта статья относится к версии 2 фабрики данных, которая в настоящее время доступна в предварительной версии. Если вы используете общедоступную версию 1 службы фабрики данных, ознакомьтесь с [документацией по фабрике данных версии 1](v1/data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).

Общий обзор сценария: ![Обзор](media/tutorial-control-flow-portal/overview.png)

В этом руководстве вы выполните следующие шаги:

> [!div class="checklist"]
> * Создадите фабрику данных.
> * Создание связанной службы хранилища Azure.
> * Создание набора данных больших двоичных объектов Azure
> * Создание конвейера, содержащего действия копирования и веб-действие.
> * Отправка выходных данных действий для последующих действий.
> * Использование передачи параметров и системных переменных.
> * Запуск конвейера.
> * Мониторинг конвейера и выполнения действий.

В этом руководстве используется портал Azure. Вы можете использовать другие механизмы для взаимодействия с фабрикой данных Azure (см. раздел "Быстрое начало работы" в оглавлении).

## <a name="prerequisites"></a>предварительным требованиям

* **Подписка Azure**. Если у вас еще нет подписки Azure, создайте [бесплатную](https://azure.microsoft.com/free/) учетную запись Azure, прежде чем начинать работу.
* **Учетная запись хранения Azure.** В этом руководстве в качестве **источника** будет использоваться хранилище BLOB-объектов. Если у вас нет учетной записи хранения Azure, ознакомьтесь с разделом [Создание учетной записи хранения](../storage/common/storage-create-storage-account.md#create-a-storage-account).
* **База данных SQL Azure**. Используйте базу данных как хранилище данных-**приемник**. Если у вас нет базы данных SQL Azure, вы можете создать ее, выполнив шаги из статьи [Создание базы данных SQL Azure на портале Azure](../sql-database/sql-database-get-started-portal.md).

### <a name="create-blob-table"></a>Создание таблицы больших двоичных объектов

1. Запустите Блокнот. Скопируйте следующий текст и сохраните его в файл **input.txt** на диске.

    ```
    John,Doe
    Jane,Doe
    ```
2. Используйте специальные инструменты, например [Обозреватель службы хранилища Azure](http://storageexplorer.com/), чтобы выполнить следующие действия. 
    1. Создайте контейнер **adfv2branch**.
    2. Создайте папку **input** в контейнере **adfv2branch**.
    3. Передайте файл **input.txt** в этот контейнер.

## <a name="create-email-workflow-endpoints"></a>Создание конечных точек рабочего процесса электронной почты
Чтобы инициировать отправку сообщения электронной почты из конвейера, определите рабочий процесс с помощью [Logic Apps](../logic-apps/logic-apps-overview.md). Сведения о создании рабочего процесса приложения логики см. в статье [Создание первого рабочего процесса приложения логики для автоматизации процессов между облачными приложениями и облачными службами](../logic-apps/quickstart-create-first-logic-app-workflow.md). 

### <a name="success-email-workflow"></a>Рабочий процесс успешной отправки сообщения электронной почты 
Создайте рабочий процесс приложения логики с именем `CopySuccessEmail`. Определите триггер рабочего процесса `When an HTTP request is received` и добавьте действие `Office 365 Outlook – Send an email`.

![Рабочий процесс успешной отправки сообщения электронной почты](media/tutorial-control-flow-portal/success-email-workflow.png)

Для триггера запроса укажите в `Request Body JSON Schema` следующий фрагмент кода JSON:

```json
{
    "properties": {
        "dataFactoryName": {
            "type": "string"
        },
        "message": {
            "type": "string"
        },
        "pipelineName": {
            "type": "string"
        },
        "receiver": {
            "type": "string"
        }
    },
    "type": "object"
}
```

В конструкторе приложения логики запрос должен выглядеть так, как на следующем изображении: 

![Запрос в окне конструктора приложений логики](media/tutorial-control-flow-portal/logic-app-designer-request.png)

Для действия **Отправка электронного сообщения** настройте способ форматирования электронного сообщения, используя свойства, переданные в схеме запроса текста JSON. Вот пример: 

![Конструктор приложения логики. Действие отправки электронной почты](media/tutorial-control-flow-portal/send-email-action-2.png)

Сохраните рабочий процесс. Запишите URL-адрес запроса HTTP Post рабочего процесса успешной отправки электронной почты:

```
//Success Request Url
https://prodxxx.eastus.logic.azure.com:443/workflows/000000/triggers/manual/paths/invoke?api-version=2016-10-01&sp=%2Ftriggers%2Fmanual%2Frun&sv=1.0&sig=000000
```

### <a name="fail-email-workflow"></a>Рабочий процесс сбоя отправки сообщения электронной почты 
Повторите этот же процесс, чтобы создать еще один рабочий процесс Logic Apps с именем **CopyFailEmail**. В триггере запроса действие `Request Body JSON schema` такое же. Измените формат сообщения электронной почты, например поле `Subject`, чтобы создать другое сообщение на случай сбоя. Вот пример: 

![Конструктор приложения логики. Рабочий процесс сбоя отправки сообщения электронной почты](media/tutorial-control-flow-portal/fail-email-workflow-2.png)

Сохраните рабочий процесс. Запишите URL-адрес запроса HTTP Post для рабочего процесса успешной отправки электронной почты:

```
//Fail Request Url
https://prodxxx.eastus.logic.azure.com:443/workflows/000000/triggers/manual/paths/invoke?api-version=2016-10-01&sp=%2Ftriggers%2Fmanual%2Frun&sv=1.0&sig=000000
```

Теперь у вас будут два URL-адреса рабочих процессов.

```
//Success Request Url
https://prodxxx.eastus.logic.azure.com:443/workflows/000000/triggers/manual/paths/invoke?api-version=2016-10-01&sp=%2Ftriggers%2Fmanual%2Frun&sv=1.0&sig=000000

//Fail Request Url
https://prodxxx.eastus.logic.azure.com:443/workflows/000000/triggers/manual/paths/invoke?api-version=2016-10-01&sp=%2Ftriggers%2Fmanual%2Frun&sv=1.0&sig=000000
```

## <a name="create-a-data-factory"></a>Создание фабрики данных

1. В меню слева щелкните **Создать**, выберите **Данные+аналитика** и щелкните **Фабрика данных**. 
   
   ![Создать -> Фабрика данных](./media/tutorial-control-flow-portal/new-azure-data-factory-menu.png)
2. На странице **Новая фабрика данных** введите **ADFTutorialDataFactory** в поле **Имя**. 
      
     ![Страница "Новая фабрика данных"](./media/tutorial-control-flow-portal/new-azure-data-factory.png)
 
   Имя фабрики данных Azure должно быть **глобально уникальным**. При возникновении указанной ниже ошибки измените имя фабрики данных (например, на ваше_имя_ADFTutorialDataFactory) и попробуйте создать фабрику данных снова. Ознакомьтесь со статьей [Фабрика данных Azure — правила именования](naming-rules.md), чтобы узнать правила именования для артефактов службы "Фабрика данных".
  
       `Data factory name “ADFTutorialDataFactory” is not available`
3. Выберите **подписку** Azure, в рамках которой вы хотите создать фабрику данных. 
4. Для **группы ресурсов** выполните одно из следующих действий.
     
      - Выберите **Использовать существующую**и укажите существующую группу ресурсов в раскрывающемся списке. 
      - Выберите **Создать новую**и укажите имя группы ресурсов.   
         
        Сведения о группах ресурсов см. в статье, где описывается [использование групп ресурсов для управления ресурсами Azure](../azure-resource-manager/resource-group-overview.md).  
4. Выберите **V2 (Preview)** (V2 (предварительная версия)) для **версии**.
5. Укажите **расположение** фабрики данных. В раскрывающемся списке отображаются только поддерживаемые расположения. Хранилища данных (служба хранилища Azure, база данных SQL Azure и т. д.) и вычисления (HDInsight и т. д.), используемые фабрикой данных, могут располагаться в других регионах.
6. Кроме того, установите флажок **Закрепить на панели мониторинга**.     
7. Нажмите кнопку **Создать**.      
8. На панели мониторинга вы увидите приведенный ниже элемент с состоянием **Deploying data factory** (Развертывание фабрики данных). 

    ![Элемент Deploying data factory (Развертывание фабрики данных)](media/tutorial-control-flow-portal/deploying-data-factory.png)
9. Когда завершится создание, откроется страница **Фабрика данных**, как показано на рисунке ниже.
   
   ![Домашняя страница фабрики данных](./media/tutorial-control-flow-portal/data-factory-home-page.png)
10. Щелкните плитку **Создание и мониторинг**, чтобы открыть на отдельной вкладке пользовательский интерфейс фабрики данных Azure.


## <a name="create-a-pipeline"></a>Создание конвейера
На этом этапе вы создадите конвейер с одним действием копирования и двумя веб-действиями. Для этого конвейера вам потребуются следующие компоненты.

- Параметры конвейера, определяющие доступ на основе наборов данных. 
- Веб-действие для вызова рабочих процессов приложений логики, которые отправляют электронные письма при успешном завершении или при сбое. 
- Связи между разными действиями (после успешного выполнения и сбоя).
- использование выходных данных действия в качестве входных данных для последующего действия.

1. На странице **Начало работы** в пользовательском интерфейсе фабрики данных щелкните плитку **Создать конвейер**.  

   ![Страница "Начало работы"](./media/tutorial-control-flow-portal/get-started-page.png) 
3. В окне свойств для конвейера перейдите на вкладку **Параметры** и нажмите кнопку **Создать**, чтобы добавить три строковых параметра sourceBlobContainer, sinkBlobContainer и reciever. 

    - Параметр **sourceBlobContainer** в конвейере используется в наборе данных для исходного BLOB-объекта.
    - Параметр **sinkBlobContainer** в конвейере используется в наборе данных для целевого BLOB-объекта.
    - Параметр **receiver** используется в конвейере двумя веб-действиями, которые отправляют сообщения электронной почты об успешном выполнении или сбое на адрес электронной почты, указанный в этом параметре.

   ![Меню создания конвейера](./media/tutorial-control-flow-portal/pipeline-parameters.png)
4. На панели элементов **Действия** разверните **Потоки данных** и перетащите действие **Копирование** в область конструктора конвейера. 

   ![Перетаскивание действия копирования](./media/tutorial-control-flow-portal/drag-drop-copy-activity.png)
5. В окне **Свойства** для второго действия **Копирование** в нижней части страницы перейдите на вкладку **Источник** и щелкните **+ Создать**. На этом шаге вы создаете исходный набор данных для действия копирования. 

   ![Исходный набор данных](./media/tutorial-control-flow-portal/new-source-dataset-button.png)
6. В окне **Новый набор данных** выберите **Хранилище BLOB-объектов Azure** и нажмите кнопку **Готово**. 

   ![Выбор хранилища BLOB-объектов Azure](./media/tutorial-control-flow-portal/select-azure-blob-storage.png)
7. Вы увидите новую **вкладку** с именем **AzureBlob1**. Измените имя этого набора данных на **SourceBlobDataset**.

   ![Общие параметры набора данных](./media/tutorial-control-flow-portal/dataset-general-page.png)
8. Перейдите на вкладку **Подключение** в окне **Свойства** и щелкните ссылку создания **связанной службы**. Это действие создает связанную службу, которая свяжет учетную запись хранения Azure с фабрикой данных. 
    
   ![Подключение набора данных — новая связанная служба](./media/tutorial-control-flow-portal/dataset-connection-new-button.png)
9. В окне **New Linked Service** (Новая связанная служба) выполните следующие действия: 

    1. Введите **AzureStorageLinkedService** в поле **Имя**.
    2. Выберите учетную запись хранения Azure в списке **Имя учетной записи хранения**.
    3. Выберите команду **Сохранить**.

   ![Новая связанная служба для службы хранилища Azure](./media/tutorial-control-flow-portal/new-azure-storage-linked-service.png)
12. Введите `@pipeline().parameters.sourceBlobContainer` в качестве имени папки и `emp.txt` в качестве имени файла. Параметр sourceBlobContainer в конвейере позволяет задать для набора данных путь к папке с данными. 

    ![Параметры исходного набора данных](./media/tutorial-control-flow-portal/source-dataset-settings.png)
13. Перейдите на вкладку **Конвейер** или щелкните конвейер в представлении в виде дерева. Убедитесь, что в списке **Source Dataset** (Исходный набор данных) выбрано значение **SourceBlobDataset**. 

   ![Исходный набор данных](./media/tutorial-control-flow-portal/pipeline-source-dataset-selected.png)
13. В окне свойств перейдите на вкладку **Приемник** и нажмите кнопку **+ Создать** в поле **Sink Dataset** (Целевой набор данных). В этом шаге вы создадите целевой набор данных, точно так же, как исходный набор данных ранее. 

    ![Кнопка "Новый целевой набор данных"](./media/tutorial-control-flow-portal/new-sink-dataset-button.png)
14. В окне **Новый набор данных** выберите **Хранилище BLOB-объектов Azure** и нажмите кнопку **Готово**. 
15. На странице настроек **Общие** для набора данных введите **SinkBlobDataset** в поле **Имя**.
16. Перейдите на вкладку **Подключения** и выполните следующие действия: 

    1. Выберите **AzureStorageLinkedService** в списке **Связанная служба**.
    2. Введите имя папки `@pipeline().parameters.sinkBlobContainer`.
    1. Введите имя файла `@CONCAT(pipeline().RunId, '.txt')`. Это выражение использует идентификатор текущего запуска конвейера для создания имени файла. Списки поддерживаемых системных переменных и выражений вы найдете в статьях [Системные переменные, поддерживаемые в фабрике данных Azure](control-flow-system-variables.md) и [Выражения и функции в фабрике данных Azure](control-flow-expression-language-functions.md).

        ![Параметры целевого набора данных](./media/tutorial-control-flow-portal/sink-dataset-settings.png)
17. Перейдите на вкладку **Конвейер** вверху. Разверните **Общие** в панели элементов **Действия** и перетащите действие **Веб** в область конструктора конвейера. Присвойте этому действию имя **SendSuccessEmailActivity**. Веб-действие разрешает выполнять вызов любой конечной точки REST. Дополнительные сведения о действиях см. в статье [Веб-действие в фабрике данных Azure](control-flow-web-activity.md). Этот конвейер использует веб-действие для вызова рабочего процесса электронной почты Logic Apps. 

   ![Перетаскивание первого веб-действия](./media/tutorial-control-flow-portal/success-web-activity-general.png)
18. Перейдите на вкладку **Настройки** из вкладки **Общие** и выполните следующие действия: 
    1. В поле **URL-адрес** укажите URL-адрес для рабочего процесса приложений логики, который отправляет сообщение электронной почты об успешном выполнении.  
    2. Выберите **POST** в поле **Метод**. 
    3. Щелкните ссылку **+ Добавить заголовок** в разделе **Заголовки**. 
    4. Добавьте заголовок с именем **Content-Type** и значением **application/json**. 
    5. Внесите следующий код JSON в поле **Текст**. 

        ```json
        {
            "message": "@{activity('Copy1').output.dataWritten}",
            "dataFactoryName": "@{pipeline().DataFactory}",
            "pipelineName": "@{pipeline().Pipeline}",
            "receiver": "@pipeline().parameters.receiver"
        }
        ```
        Текст сообщения содержит следующие свойства.

        - Сообщение — передает значение `@{activity('Copy1').output.dataWritten`. Обращается к свойству предыдущего действия копирования и передает значение dataWritten. В случае сбоя передает выходные данные ошибки вместо `@{activity('CopyBlobtoBlob').error.message`.
        - Имя фабрики данных — передает значение `@{pipeline().DataFactory}`. Это системная переменная, которая позволяет получить доступ к соответствующему имени фабрики данных. Список поддерживаемых системных переменных см. в статье [Системные переменные, поддерживаемые фабрикой данных Azure](control-flow-system-variables.md).
        - Имя конвейера — передает значение `@{pipeline().Pipeline}`. Это системная переменная, которая позволяет обращаться к соответствующему имени конвейера. 
        - Получатель — передает значение "@pipeline().parameters.receiver"). Получает доступ к параметрам конвейера.
    6. Теперь вкладка **Настройки** должна выглядеть, как на следующем изображении. 

        ![Настройки для первого веб-действия](./media/tutorial-control-flow-portal/web-activity1-settings.png)         
19. Подключите действие **Копирование** к **веб-действию**, перетащив зеленую кнопку рядом с действием копирования в блок веб-действия. 

    ![Соединение действия копирования с первым веб-действием](./media/tutorial-control-flow-portal/connect-copy-web-activity1.png)
20. Перетащите второе **Веб-действие** из панели элементов "Действия" в область конструктора конвейера и задайте для него **Имя** **SendFailureEmailActivity**.

    ![Имя для второго веб-действия](./media/tutorial-control-flow-portal/web-activity2-name.png)
21. Перейдите на вкладку **Настройки** и выполните здесь следующие действия:

    1. В поле **URL-адрес** укажите URL-адрес для рабочего процесса приложений логики, который отправляет сообщение электронной почты об ошибке при выполнении.  
    2. Выберите **POST** в поле **Метод**. 
    3. Щелкните ссылку **+ Добавить заголовок** в разделе **Заголовки**. 
    4. Добавьте заголовок с именем **Content-Type** и значением **application/json**. 
    5. Внесите следующий код JSON в поле **Текст**. 

        ```json
        {
            "message": "@{activity('Copy1').error.message}",
            "dataFactoryName": "@{pipeline().DataFactory}",
            "pipelineName": "@{pipeline().Pipeline}",
            "receiver": "@pipeline().parameters.receiver"
        }
        ```
    6. Теперь вкладка **Настройки** должна выглядеть, как на следующем изображении. 
    
        ![Настройки для второго веб-действия](./media/tutorial-control-flow-portal/web-activity2-settings.png)         
22. Выберите действие **Копирование** в конструкторе конвейера и нажмите кнопку **+->**, затем выберите **Ошибка**.  

    ![Настройки для второго веб-действия](./media/tutorial-control-flow-portal/select-copy-failure-link.png)
23. Перетащите **красную** кнопку, расположенную рядом с действием копирования, на второе веб-действие **SendFailureEmailActivity**. Переставьте действия в области конструктора, чтобы конвейер выглядел примерно так: 

    ![Готовый конвейер с настроенными действиями](./media/tutorial-control-flow-portal/full-pipeline.png)
24. Чтобы проверить работу конвейера, нажмите кнопку **Проверка** на панели инструментов. Закройте окно **Pipeline Validation Output** (Выходные данные проверки конвейера), нажав кнопку **>>**.

    ![Проверка конвейера](./media/tutorial-control-flow-portal/validate-pipeline.png)
24. Чтобы опубликовать сущности (наборы данных, конвейеры, т. д.) в службу фабрики данных, щелкните **Опубликовать**. Дождитесь сообщения **Successfully published** (Публикация выполнена).

    ![Опубликовать](./media/tutorial-control-flow-portal/publish-button.png)
 
## <a name="trigger-a-pipeline-run-that-succeeds"></a>Запуск конвейера, который будет выполнен успешно
1. Чтобы **запустить** конвейер, щелкните **Триггер** на панели инструментов, а затем **Trigger Now** (Запустить сейчас). 

    ![Запуск выполнения конвейера](./media/tutorial-control-flow-portal/trigger-now-menu.png)
2. В окне **Запуск конвейера** выполните следующие действия. 

    1. Введите **adftutorial/adfv2branch/input** в качестве значения для параметра **sourceBlobContainer**. 
    2. Введите **adftutorial/adfv2branch/output** в качестве значения для параметра **sinkBlobContainer**. 
    3. Введите **адрес электронной почты** для **получателя**. 
    4. Нажмите кнопку **Готово**.

        ![Параметры запуска конвейера](./media/tutorial-control-flow-portal/pipeline-run-parameters.png)

## <a name="monitor-the-successful-pipeline-run"></a>Мониторинг успешного выполнения конвейера

1. Чтобы отследить выполнение конвейера, перейдите на вкладку **Мониторинг** слева. Вы увидите здесь запуск конвейера, который вы ранее выполнили вручную. Нажмите кнопку **Обновить**, чтобы обновить этот список. 
    
    ![Успешный запуск конвейера](./media/tutorial-control-flow-portal/monitor-success-pipeline-run.png)
2. Чтобы **просмотреть запуски действий**, связанные с этим запуском конвейера, щелкните первую ссылку в столбце **Действия**. Вы можете переключиться к предыдущему представлению, щелкнув раздел **Конвейеры** вверху страницы. Нажмите кнопку **Обновить**, чтобы обновить этот список. 

    ![Выполнение действия](./media/tutorial-control-flow-portal/activity-runs-success.png)

## <a name="trigger-a-pipeline-run-that-fails"></a>Запуск конвейера, который завершится сбоем
1. Перейдите на вкладку **Правка** слева. 
2. Чтобы **запустить** конвейер, щелкните **Триггер** на панели инструментов, а затем **Trigger Now** (Запустить сейчас). 
3. В окне **Запуск конвейера** выполните следующие действия. 

    1. Введите **adftutorial/dummy/input** в качестве значения для параметра **sourceBlobContainer**. Убедитесь, что папка dummy не существует в контейнере adftutorial. 
    2. Введите **adftutorial/dummy/inputt** в качестве значения для параметра **sinkBlobContainer**. 
    3. Введите **адрес электронной почты** для **получателя**. 
    4. Нажмите кнопку **Готово**

## <a name="monitor-the-failed-pipeline-run"></a>Отслеживание неудачного запуска конвейера.

1. Чтобы отследить выполнение конвейера, перейдите на вкладку **Мониторинг** слева. Вы увидите здесь запуск конвейера, который вы ранее выполнили вручную. Нажмите кнопку **Обновить**, чтобы обновить этот список. 
    
    ![Неудачный запуск конвейера](./media/tutorial-control-flow-portal/monitor-failure-pipeline-run.png)
2. Щелкните ссылку **Ошибка** рядом с запуском конвейера, чтобы просмотреть сведения об этой ошибке. 

    ![Ошибка конвейера](./media/tutorial-control-flow-portal/pipeline-error-message.png)
2. Чтобы **просмотреть запуски действий**, связанные с этим запуском конвейера, щелкните первую ссылку в столбце **Действия**. Нажмите кнопку **Обновить**, чтобы обновить этот список. Обратите внимание, что действие копирования в конвейере завершилось сбоем. Веб-действие успешно выполнено, то есть отправило указанному получателю сообщение электронной почты о сбое. 

    ![Выполнение действия](./media/tutorial-control-flow-portal/activity-runs-failure.png)
4. Щелкните ссылку **Ошибка** в столбце **Действия**, чтобы просмотреть сведения об этой ошибке. 

    ![Ошибка выполнения действия](./media/tutorial-control-flow-portal/activity-run-error.png)

## <a name="next-steps"></a>Дополнительная информация
В этом руководстве вы выполнили следующие шаги: 

> [!div class="checklist"]
> * Создадите фабрику данных.
> * Создание связанной службы хранилища Azure.
> * Создание набора данных больших двоичных объектов Azure
> * Создание конвейера, содержащего действия копирования и веб-действие.
> * Отправка выходных данных действий для последующих действий.
> * Использование передачи параметров и системных переменных.
> * Запуск конвейера.
> * Мониторинг конвейера и выполнения действий.

Теперь вы можете перейти к разделу ключевых концепций, чтобы получить дополнительные сведения о фабрике данных Azure.
> [!div class="nextstepaction"]
>[Конвейеры и действия](concepts-pipelines-activities.md)
