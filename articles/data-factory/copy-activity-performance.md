---
title: "Руководство по настройке производительности действия копирования в фабрике данных Azure | Документация Майкрософт"
description: "Узнайте о ключевых факторах, которые влияют на производительность перемещения данных в фабрике данных Azure при использовании действия копирования."
services: data-factory
documentationcenter: 
author: linda33wj
manager: jhubbard
editor: spelluru
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 01/15/2018
ms.author: jingwang
ms.openlocfilehash: 53f2b59e57d49a409552aebbdb1b0e81ccd5200c
ms.sourcegitcommit: 9cc3d9b9c36e4c973dd9c9028361af1ec5d29910
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/23/2018
---
# <a name="copy-activity-performance-and-tuning-guide"></a>Руководство по настройке производительности действия копирования
> [!div class="op_single_selector" title1="Select the version of Data Factory service you are using:"]
> * [Версия 1 — общедоступная](v1/data-factory-copy-activity-performance.md)
> * [Версия 2 — предварительная](copy-activity-performance.md)


Действие копирования фабрики данных Azure — первоклассное безопасное, надежное и высокопроизводительное решение для загрузки данных. Оно позволяет ежедневно копировать десятки терабайтов данных в самые разнообразные облачные и локальные хранилища данных. Именно высокоскоростная загрузка данных позволяет сосредоточиться на основных проблемах "больших данных": создании решений расширенной аналитики и получении ценной информации из данных.

> [!NOTE]
> Эта статья относится к версии 2 фабрики данных, которая в настоящее время доступна в предварительной версии. Если вы используете общедоступную версию 1 службы фабрики данных, см. статью [Руководство по настройке производительности действия копирования](v1/data-factory-copy-activity-performance.md) для версии 1.

Azure предоставляет набор решений корпоративного уровня для хранения данных, а действие копирования предлагает сильно оптимизированные функции загрузки данных, которые легко установить и настроить. Ниже перечислены возможности отдельного действия копирования.

* Загрузка данных в **хранилище данных SQL Azure** со скоростью **1,2 Гбит/с**.
* Загрузка данных в **хранилище BLOB-объектов Azure** на скорости **1,0 Гбит/с**.
* Загрузка данных в **Azure Data Lake Store** на скорости **1,0 Гбит/с**.

Содержание статьи

* [Контрольные показатели производительности](#performance-reference) для поддерживаемых хранилищ данных (источника и приемника), которые помогут при планировании проекта.
* Функции, которые могут значительно повысить пропускную способность копирования в различных сценариях, в том числе [облачные единицы перемещения данных](#cloud-data-movement-units), [параллельное копирование](#parallel-copy) и [промежуточное копирование](#staged-copy).
* [Руководство по настройке производительности](#performance-tuning-steps) , в котором описывается настройка производительности и ключевые факторы, которые могут влиять на производительность копирования.

> [!NOTE]
> Если вам в целом не знакомо действие копирования, перед чтением этой статьи ознакомьтесь со статьей [Действие копирования в фабрике данных Azure](copy-activity-overview.md).
>

## <a name="performance-reference"></a>Базовые показатели производительности

В качестве справки ниже представлена таблица, в которой отражены показатели пропускной способности **в Мбит/с** для указанных пар источника и приемника, полученные **при выполнении отдельного действия копирования** в ходе внутреннего тестирования. Для сравнения также демонстрируется, как разные параметры [облачных единиц перемещения данных](#cloud-data-movement-units) или [масштабируемости локальной среды выполнения интеграции](concepts-integration-runtime.md#self-hosted-integration-runtime) (несколько узлов) могут помочь определить производительность копирования.

![Матрица производительности](./media/copy-activity-performance/CopyPerfRef.png)

>[!IMPORTANT]
>В фабрике данных Azure версии 2 при выполнении действия копирования в среде выполнения интеграции Azure минимальное допустимое количество облачных единиц перемещения данных равно двум. Если не указано другое, ознакомьтесь со стандартными единицами перемещения данных, используемыми в [облачных единицах перемещения данных](#cloud-data-movement-units).

Примечания:

* Для вычисления пропускной способности используется следующая формула: [размер данных, считанных из источника]/[длительность выполнения действия копирования].
* Контрольные показатели производительности в таблице были измерены с использованием набора данных [TPC-H](http://www.tpc.org/tpch/) для выполнения отдельного действия копирования.
* При использовании хранилищ данных Azure источник и приемник находились в одном регионе Azure.
* Для гибридного перемещения данных (из локальной среды в облако или наоборот) использовался каждый узел локальной среды выполнения интеграции на компьютере, на котором отсутствовало хранилище данных. Конфигурация приведена в следующей таблице. При выполнении одного действия операция копирования потребляла только небольшую часть ресурсов ЦП, памяти и пропускной способности сети на тестовом компьютере.
    <table>
    <tr>
        <td>ЦП</td>
        <td>Intel Xeon E5-2660 v2, 32 ядра с частотой 2,20 ГГц</td>
    </tr>
    <tr>
        <td>Память</td>
        <td>128 ГБ</td>
    </tr>
    <tr>
        <td>Сеть</td>
        <td>Веб-интерфейс: 10 Гбит/с; интерфейс интрасети: 40 Гбит/с</td>
    </tr>
    </table>


> [!TIP]
> Пропускную способность можно повысить, используя больше единиц перемещения данных (DMU), чем максимальное разрешенное количество DMU по умолчанию (32 единицы для выполнения действия копирования из облака в облако). Например, используя 100 DMU, можно достичь скорости копирования данных из большого двоичного объекта Azure в Azure Data Lake Store до **1 Гбит/с**. Подробные сведения об этой функции и поддерживаемый сценарий см. в разделе [Облачные единицы перемещения данных](#cloud-data-movement-units). Чтобы получить дополнительные единицы DMU, отправьте запрос в [службу поддержки Azure](https://azure.microsoft.com/support/).

## <a name="cloud-data-movement-units"></a>Облачные единицы перемещения данных

**Облачная единица перемещения данных** — это мера, представляющая производительность (сочетание выделенных ресурсов ЦП, памяти и сети) одной единицы в фабрике данных. **Эта мера применяется только к [среде выполнения интеграции Azure](concepts-integration-runtime.md#azure-integration-runtime)**, но не для [локальной среды выполнения интеграции](concepts-integration-runtime.md#self-hosted-integration-runtime).

**Минимальное количество облачных единиц перемещения данных для выполнения действия копирования равно двум.** Если не указано другое, в следующей таблице перечислены облачные единицы перемещения данных по умолчанию, используемые в различных сценариях копирования:

| Сценарий копирования | Число облачных единиц перемещения данных по умолчанию, определенное службой |
|:--- |:--- |
| Копирование данных между файловыми хранилищами | От 4 до 32, в зависимости от числа и размеров файлов. |
| Все остальные сценарии копирования | 4. |

Это значение по умолчанию можно переопределить, указав значение для свойства **cloudDataMovementUnits**, как показано ниже. **Допустимые значения** свойства **cloudDataMovementUnits**: 2, 4, 8, 16, 32. **Фактическое число облачных единиц перемещения данных** , используемых во время выполнения операции копирования, меньше или равно заданному значению, в зависимости от шаблона данных. Сведения о том, как можно повысить уровень производительности, настроив дополнительные единицы для определенного источника и приемника, см. в [справочнике по производительности](#performance-reference).

При отслеживании выполнения действия можно увидеть используемые облачные единицы перемещения данных каждого выполнения в выходных данных действия копирования. Дополнительные сведения см. в разделе [Мониторинг](copy-activity-overview.md#monitoring).

> [!NOTE]
> Если вам требуется больше облачных единиц перемещения данных, чтобы повысить пропускную способность, обратитесь в [службу поддержки Azure](https://azure.microsoft.com/support/). В настоящее время 8 и более облачных единиц перемещения данных поддерживаются только при **копировании нескольких файлов из хранилища BLOB-объектов, Data Lake Store, Amazon S3, облака FTP или облака SFTP в любые другие облачные хранилища данных**.
>

**Пример.**

```json
"activities":[
    {
        "name": "Sample copy activity",
        "type": "Copy",
        "inputs": [...],
        "outputs": [...],
        "typeProperties": {
            "source": {
                "type": "BlobSource",
            },
            "sink": {
                "type": "AzureDataLakeStoreSink"
            },
            "cloudDataMovementUnits": 32
        }
    }
]
```

### <a name="cloud-data-movement-units-billing-impact"></a>Принцип выставления счетов за облачные единицы перемещения данных

**Важно** помнить, что оплата взимается на основе общего времени операции копирования. Вам будет выставляться счет за общее время выполнения при использовании облачных единиц перемещения данных. Если задание копирования обычно занимало один час и две облачные единицы, а теперь на это требуется 15 минут и восемь облачных единиц, то стоимость практически не изменится.

## <a name="parallel-copy"></a>Параллельное копирование

Можно использовать свойство **parallelCopies** , чтобы задать параллелизм для действия копирования. Считайте это свойство максимальным числом потоков в рамках действия копирования, которые могут параллельно считывать данные из источника или записывать их в хранилища данных-приемники.

Для каждого выполнения действия копирования фабрика данных определяет количество параллельных копий для копирования данных из исходного хранилища данных в целевое хранилище данных. Количество параллельных копий по умолчанию зависит от типов используемых источника и приемника.

| Сценарий копирования | Число параллельных копий по умолчанию, определенное службой |
| --- | --- |
| Копирование данных между файловыми хранилищами |От 1 до 64. Зависит от размера файлов и числа облачных единиц перемещения данных, используемых для копирования данных между двумя облачными хранилищами данных или в пределах физической конфигурации компьютера, где выполняется локальная среда выполнения интеграции. |
| Копирование данных из любого хранилища данных в хранилище таблиц Azure |4. |
| Все остальные сценарии копирования |1 |

Обычно поведение по умолчанию должно обеспечить оптимальную пропускную способность. Тем не менее, чтобы управлять загрузкой компьютеров, на которых размещены хранилища данных, или настроить производительность копирования, можно переопределить значение по умолчанию и указать значение свойства **parallelCopies** . Значение должно быть целым числом больше или равно 1. Во время выполнения действие копирования выберет значение, которое меньше или равно заданному значению, чтобы обеспечить оптимальную производительность.

```json
"activities":[
    {
        "name": "Sample copy activity",
        "type": "Copy",
        "inputs": [...],
        "outputs": [...],
        "typeProperties": {
            "source": {
                "type": "BlobSource",
            },
            "sink": {
                "type": "AzureDataLakeStoreSink"
            },
            "parallelCopies": 32
        }
    }
]
```

Примечания:

* При копировании данных из одного файлового хранилища в другое свойство **parallelCopies** определяет параллелизм на уровне файла. Фрагментирование в пределах файла выполняется автоматически и прозрачно, при этом для определенного типа исходного хранилища данных используется самый подходящий размер блока. Таким образом, данные могут отправляться одновременно и независимо от parallelCopies. Фактическое число параллельных копий, используемых службой перемещения данных для копирования во время выполнения, не превышает количество файлов. Если режим копирования — **mergeFile**, то при копировании параллелизм на уровне файла не будет использоваться.
* При указании значения свойства **parallelCopies** следует учитывать, что это повлечет увеличение нагрузки на источник и приемник данных, а также на локальную среду выполнения интеграции, если она используется для действия копирования, например для гибридного копирования. Это особенно актуально при наличии нескольких действий или параллельных выполнений одинаковых действий с одним и тем же хранилищем данных. Если вы заметите, что хранилище данных или локальная среда выполнения интеграции перегружены, уменьшите значение **parallelCopies**, чтобы снизить загрузку.
* При копировании данных из нефайлового хранилища в файловое служба перемещения данных игнорирует свойство **parallelCopies** . В этом случае параллелизм не применяется, даже если задан соответствующий параметр.
* Свойство **parallelCopies** не связано с **cloudDataMovementUnits**. Первое из них подсчитывается для всех единиц перемещения облачных данных.

## <a name="staged-copy"></a>промежуточное копирование

При копировании данных из источника в приемник можно использовать хранилище BLOB-объектов в качестве промежуточного пространства для хранения. Промежуточное хранилище очень удобно в следующих ситуациях.

- **Вы хотите принимать данные из различных расположений в хранилище данных SQL с помощью PolyBase**. Хранилище данных SQL использует функцию PolyBase, которая обеспечивает высокую пропускную способность при загрузке больших объемов данных в хранилище SQL. Тем не менее исходные данные должны находиться в хранилище BLOB-объектов или Azure Data Lake Store и соответствовать дополнительным требованиям. При загрузке данных не из хранилища BLOB-объектов или Azure Data Lake Store можно активировать копирование через промежуточное хранилище BLOB-объектов. В этом случае фабрика данных выполняет необходимые преобразования данных, чтобы обеспечить их соответствие требованиям PolyBase. Затем она эффективно загружает данные в хранилище данных SQL с помощью PolyBase. Дополнительные сведения см. в разделе [Загрузка данных в хранилище данных SQL Azure с помощью PolyBase](connector-azure-sql-data-warehouse.md#use-polybase-to-load-data-into-azure-sql-data-warehouse).
- **Иногда для гибридного перемещения данных (т. е. для копирования данных из локального в облачное хранилище данных) требуется некоторое время из-за низкой скорости сетевого подключения**. Для повышения производительности вы можете использовать промежуточное копирование для сжатия данных в локальном хранилище, чтобы передача в промежуточное хранилище в облаке занимала меньше времени. Затем распакуйте данные в промежуточном хранилище, прежде чем загрузить их в целевое расположение.
- **В соответствии с корпоративными политиками ИТ в брандмауэре не рекомендуется открывать порты, отличные от 80 и 443**. Например, при копировании данных из локального хранилища в приемник базы данных SQL Azure или приемник хранилища данных SQL Azure необходимо активировать исходящие TCP-подключения через порт 1433 для брандмауэра Windows и корпоративного брандмауэра. В этом случае при промежуточном копировании можно воспользоваться преимуществами локальной среды выполнения интеграции, чтобы сначала скопировать данные в промежуточный экземпляр хранилища BLOB-объектов по протоколу HTTP или HTTPS через порт 443, а уже оттуда загрузить данные в базу данных SQL и хранилище данных SQL. В таком сценарии не нужно включать порт 1433.

### <a name="how-staged-copy-works"></a>Принцип промежуточного копирования

Если активировать функцию промежуточного копирования, сначала данные копируются из исходного хранилища в промежуточное хранилище BLOB-объектов (собственное). Оттуда данные копируются в приемник данных. Фабрика данных автоматически управляет этой двухэтапной процедурой. По окончании перемещения данных фабрика данных удаляет временные данные из промежуточного хранилища.

![промежуточное копирование](media/copy-activity-performance/staged-copy.png)

При активации функции промежуточного копирования перемещаемых данных можно настроить их сжатие перед переносом из источника в промежуточное хранилище, а также распаковку перед перемещением из промежуточного хранилища в приемник.

Сейчас промежуточное хранение при копировании данных между двумя локальными хранилищами не поддерживается.

### <a name="configuration"></a>Параметр Configuration

С помощью параметра **enableStaging** в разделе действий копирования укажите, следует ли копировать данные в промежуточное хранилище BLOB-объектов перед загрузкой в целевое хранилище данных. Если для параметра **enableStaging** задано значение `TRUE`, укажите дополнительные свойства, перечисленные в таблице ниже. Если у вас нет промежуточного хранилища, необходимо создать для промежуточного хранения хранилище Azure или службу, связанную с подписанным URL-адресом хранилища.

| Свойство | Описание | Значение по умолчанию | Обязательно |
| --- | --- | --- | --- |
| **enableStaging** |Укажите, следует ли копировать данные в промежуточное хранилище. |Ложь |Нет |
| **linkedServiceName (имя связанной службы)** |Укажите имя связанной службы [AzureStorage](connector-azure-blob-storage.md#linked-service-properties), которая будет ссылаться на используемый в качестве промежуточного экземпляр хранилища. <br/><br/> Для загрузки данных в хранилище данных SQL с помощью PolyBase нельзя использовать хранилище с подписанным URL-адресом. Его можно использовать в других случаях. |Недоступно |Да, если для параметра **enableStaging** задано значение true |
| **path** |Укажите путь к хранилищу BLOB-объектов, в котором будут храниться промежуточные данные. В противном случае служба создаст контейнер для хранения временных данных. <br/><br/> Укажите путь, только если используется хранилище с подписанным URL-адресом или требуется, чтобы временные данные хранились в определенном месте. |Недоступно |Нет |
| **enableCompression** |Указывает, следует ли сжимать данные перед копированием в место назначения. Этот параметр позволяет уменьшить объем передаваемых данных. |Ложь |Нет |

Ниже приведен пример определения действия копирования со свойствами, описанными в приведенной выше таблице.

```json
"activities":[
    {
        "name": "Sample copy activity",
        "type": "Copy",
        "inputs": [...],
        "outputs": [...],
        "typeProperties": {
            "source": {
                "type": "SqlSource",
            },
            "sink": {
                "type": "SqlSink"
            },
            "enableStaging": true,
            "stagingSettings": {
                "linkedServiceName": {
                    "referenceName": "MyStagingBlob",
                    "type": "LinkedServiceReference"
                },
                "path": "stagingcontainer/path",
                "enableCompression": true
            }
        }
    }
]
```

### <a name="staged-copy-billing-impact"></a>Принцип выставления счетов за промежуточное копирование

Взимаемая плата зависит от длительности и типа копирования.

* При использовании промежуточного хранилища данных для облачного копирования (копирования данных между облачными хранилищами данных, выполняемые интегрированной средой выполнения Azure) счет формируется так: [сумма длительности копирования для этапов 1 и 2] x [цена за единицу облачного копирования].
* При использовании промежуточного хранилища данных для гибридного копирования (копирования данных из локального хранилища данных в облачное хранилище данных (один этап выполняется локальной средой выполнения интеграции)) счет формируется так: [длительность гибридного копирования] x [цена за единицу гибридного копирования] + [длительность облачного копирования] x [цена за единицу облачного копирования].

## <a name="performance-tuning-steps"></a>Этапы настройки производительности

Мы советуем выполнить следующие действия, чтобы настроить производительность службы фабрики данных при использовании действия копирования.

1. **Определите базовые показатели**. Протестируйте конвейер на этапе разработки с помощью действия копирования на примере репрезентативных данных. Сведения о процессе выполнения и характеристики производительности см. в разделе [Мониторинг](copy-activity-overview.md#monitoring).

2. **Выполните диагностику состояния производительности и оптимизируйте ее.**Если наблюдаемая производительность не соответствует вашим ожиданиям, необходимо определить ее узкие места. После этого оптимизируйте производительность, чтобы устранить или уменьшить влияние узких мест. В этой статье не приведено полное описание диагностики производительности. Однако ниже даны некоторые общие рекомендации.

   * Функции для повышения производительности:
     * [Параллельное копирование](#parallel-copy)
     * [Облачные единицы перемещения данных](#cloud-data-movement-units)
     * [Промежуточное копирование](#staged-copy)
     * [Масштабируемость локальной среды выполнения интеграции](concepts-integration-runtime.md#self-hosted-integration-runtime)
   * [Локальная среда выполнения интеграции](#considerations-for-self-hosted-integration-runtime)
   * [Источник](#considerations-for-the-source)
   * [Приемник](#considerations-for-the-sink)
   * [Сериализация или десериализация](#considerations-for-serialization-and-deserialization)
   * [Сжатие](#considerations-for-compression)
   * [Сопоставление столбцов](#considerations-for-column-mapping)
   * [Дополнительные рекомендации](#other-considerations)

3. **Задайте конфигурацию для работы со всеми данными**. Если вас устраивают результаты выполнения и производительность, можно задать определение и конвейер для всего набора данных.

## <a name="considerations-for-self-hosted-integration-runtime"></a>Рекомендации для локальной среды выполнения интеграции

Если действие копирования выполняется в локальной среде выполнения интеграции, обратите внимание на следующее:

**Настройка.** Для размещения среды выполнения интеграции рекомендуется использовать выделенный компьютер. Дополнительные сведения см. в статье [Integration runtime in Azure Data Factory](concepts-integration-runtime.md) (Среда выполнения интеграции в фабрике данных Azure).

**Горизонтальное масштабирование.** Одна логическая локальная среда выполнения интеграции с одним или несколькими узлами может обслуживать несколько запусков действия копирования одновременно. При наличии большого объема гибридных данных для переноса с большим количеством параллельных запусков действия копирования или большого объема данных для копирования рассмотрите возможность [горизонтального масштабирования локальной среды выполнения интеграции](create-self-hosted-integration-runtime.md#high-availability-and-scalability), чтобы подготовить дополнительные ресурсы для расширения возможностей копирования.

## <a name="considerations-for-the-source"></a>Рекомендации для источника

### <a name="general"></a>Общие сведения

Убедитесь, что базовое хранилище данных не переполнено другими рабочими нагрузками, выполняемыми в нем или при его задействовании.

Дополнительные сведения о хранилищах данных Майкрософт см. в [разделах о мониторинге и настройке](#performance-reference) для конкретных типов хранилищ данных. В них подробно рассмотрены базовые показатели производительности хранилища данных, способы сокращения времени отклика и повышения пропускной способности.

* При копировании данных **из хранилища BLOB-объектов в хранилище данных SQL** рассмотрите возможность использования функции **PolyBase**, позволяющей повысить производительность. Дополнительные сведения см. в разделе [Загрузка данных в хранилище данных SQL Azure с помощью PolyBase](connector-azure-sql-data-warehouse.md#use-polybase-to-load-data-into-azure-sql-data-warehouse).
* При копировании данных **из HDFS в хранилище BLOB-объектов Azure или Azure Data Lake Store** рассмотрите возможность использования функции **DistCp**, позволяющей повысить производительность. Дополнительные сведения см. в разделе [Использование DistCp для копирования данных из HDFS](connector-hdfs.md#use-distcp-to-copy-data-from-hdfs).
* При копировании данных **из Redshift в хранилище данных SQL Azure, хранилище BLOB-объектов Azure или в Azure Data Lake Store** рассмотрите возможность использования функции **UNLOAD**, позволяющей повысить производительность. Дополнительные сведения см. в разделе [Копирование данных из Amazon Redshift с помощью UNLOAD](connector-amazon-redshift.md#use-unload-to-copy-data-from-amazon-redshift).

### <a name="file-based-data-stores"></a>Файловые хранилища данных

* **Средний размер файла и их количество**. Действие копирования передает данные в пофайловом режиме. При одинаковом объеме данных общая пропускная способность перемещения данных, которые состоят из большого количества небольших файлов, будет ниже, чем в случае перемещения данных, которые состоят из небольшого количества файлов большего размера. Это происходит из-за времени начальной загрузки каждого файла. Поэтому для получения более высокой пропускной способности по возможности следует объединить небольшие файлы в файлы большего размера.
* **Формат файла и сжатие**. Дополнительные сведения о способах повышения производительности см. в разделах [Рекомендации по сериализации и десериализации](#considerations-for-serialization-and-deserialization) и [Рекомендации по сжатию](#considerations-for-compression).

### <a name="relational-data-stores"></a>Реляционные хранилища данных

* **Шаблон данных.**Схема таблицы влияет на пропускную способность копирования. При копировании одинакового общего объема данных большой размер строки обеспечивает лучшую производительность, чем небольшой размер строки. Причина состоит в том, что база данных может более эффективно извлекать меньшее число пакетов данных, которые содержат меньше строк.
* **Запрос или хранимая процедура.**Оптимизируйте логику запроса или хранимой процедуры, указываемую в источнике действия копирования, чтобы более эффективно извлекать данные.

## <a name="considerations-for-the-sink"></a>Рекомендации для приемника

### <a name="general"></a>Общие сведения

Убедитесь, что базовое хранилище данных не переполнено другими рабочими нагрузками, выполняемыми в нем или при его задействовании.

Дополнительные сведения о хранилищах данных Microsoft см. в [разделах о мониторинге и настройке](#performance-reference) для конкретных типов хранилищ данных. В них подробно рассмотрены базовые показатели производительности хранилища данных, способы сокращения времени отклика и повышения пропускной способности.

* При копировании данных **из хранилища BLOB-объектов в хранилище данных SQL** рассмотрите возможность использования функции **PolyBase**, позволяющей повысить производительность. Дополнительные сведения см. в разделе [Загрузка данных в хранилище данных SQL Azure с помощью PolyBase](connector-azure-sql-data-warehouse.md#use-polybase-to-load-data-into-azure-sql-data-warehouse).
* При копировании данных **из HDFS в хранилище BLOB-объектов Azure или Azure Data Lake Store** рассмотрите возможность использования функции **DistCp**, позволяющей повысить производительность. Дополнительные сведения см. в разделе [Использование DistCp для копирования данных из HDFS](connector-hdfs.md#use-distcp-to-copy-data-from-hdfs).
* При копировании данных **из Redshift в хранилище данных SQL Azure, хранилище BLOB-объектов Azure или в Azure Data Lake Store** рассмотрите возможность использования функции **UNLOAD**, позволяющей повысить производительность. Дополнительные сведения см. в разделе [Копирование данных из Amazon Redshift с помощью UNLOAD](connector-amazon-redshift.md#use-unload-to-copy-data-from-amazon-redshift).

### <a name="file-based-data-stores"></a>Файловые хранилища данных

* **Режим копирования**. При копировании данных из файлового хранилища для действия копирования можно задать три разных режима с помощью свойства **copyBehavior**: сохранение иерархии, преобразование в плоскую структуру или объединение файлов. Сохранение иерархии или преобразование в плоскую структуру практически не оказывает влияния на производительность, в то время как объединение файлов существенно ее ухудшает.
* **Формат файла и сжатие**. Дополнительные сведения о способах повышения производительности см. в разделах [Рекомендации по сериализации и десериализации](#considerations-for-serialization-and-deserialization) и [Рекомендации по сжатию](#considerations-for-compression).

### <a name="relational-data-stores"></a>Реляционные хранилища данных

* **Режим копирования**. В зависимости от свойств, заданных для **sqlSink**, существует несколько вариантов записи данных в базу данных назначения при выполнении действия копирования.
  * По умолчанию служба перемещения данных использует интерфейс API массового копирования для вставки данных в режиме добавления, что обеспечивает лучшую производительность.
  * Если настроить в приемнике хранимую процедуру, данные в базу данных будут записываться в построчном режиме, а не массово. Это существенно снижает производительность. В случае с набором данных большого размера рекомендуется использовать свойство **preCopyScript**, если это применимо.
  * Если настроить свойство **preCopyScript**, при каждом действии копирования для вставки данных служба сначала запустит сценарий, а затем использует интерфейс API массового копирования. Например, чтобы перезаписать всю таблицу последними данными, перед массовой загрузкой новых данных из источника можно указать сценарий для удаления всех записей.
* **Шаблон данных и размер пакета**.
  * Схема таблицы влияет на пропускную способность копирования. Во время копирования данных одинакового объема использование строк большого размера позволяет добиться лучшей производительности, чем при использовании строк небольшого размера. Это связано с тем, что база данных более эффективно сохраняет меньшее количество пакетов данных.
  * Действие копирования вставляет данные в виде последовательности пакетов. Количество строк в пакете можно задать с помощью свойства **writeBatchSize** . Если данные содержатся в строках небольшого размера, можно задать для свойства **writeBatchSize** более высокое значение, чтобы использовать меньшее количество пакетов и тем самым увеличить пропускную способность. Если данные содержатся в строках большого размера, будьте внимательны при увеличении **writeBatchSize**. Высокое значение может привести к сбою копирования из-за перегрузки базы данных.

### <a name="nosql-stores"></a>Хранилища NoSQL

* Для **хранилища таблиц**:
  * **Секционирование**. Запись данных в секции с чередованием значительно снижает производительность. Отсортируйте исходные данные по ключу секции, чтобы эффективно вставлять данные в секцию за секцией. Можно также настроить логику для записи данных в одну секцию.

## <a name="considerations-for-serialization-and-deserialization"></a>Рекомендации по сериализации и десериализации

Сериализация и десериализация могут произойти, если входной или выходной набор данных представляет собой файл. Дополнительные сведения о форматах файлов, поддерживаемых действием копирования, см. в статье [Форматы файлов и сжатия данных, поддерживаемые фабрикой данных Azure](supported-file-formats-and-compression-codecs.md).

**Режим копирования.**

* При копировании файлов между файловыми хранилищами данных:
  * Если параметры формата файла входного и выходного наборов данных одинаковые, служба перемещения данных выполнит **двоичное копирование** без сериализации или десериализации. В этом случае пропускная способность будет более высокой, чем в сценарии, когда параметры формата файла источника и приемника отличаются друг от друга.
  * Если входной и выходной наборы данных находятся в текстовом формате и отличаются только типом кодирования, служба перемещения данных выполнит только преобразование кодирования. При этом сериализация и десериализация применяться не будут. По сравнению с двоичным копированием, это совсем незначительно повлияет на производительность.
  * Если входной и выходной наборы данных представлены в разных форматах файлов или имеют разные конфигурации, например отличаются разделителями, то служба перемещения данных десериализует исходные данные для их потоковой передачи, преобразования и сериализации в указанный формат выходных данных. В отличие от предыдущих сценариев, это приведет к более значительному снижению производительности.
* При копировании файлов в хранилище данных, которое не является файловым, или из него (например, из файлового хранилища в реляционное) требуется операция сериализации или десериализации. Этот шаг существенно снижает производительность.

**Формат файла**. Используемый формат файла может повлиять на производительность копирования. К примеру, Avro — это компактный двоичный формат, в котором хранятся метаданные с данными. Этот формат поддерживает экосистема Hadoop для обработки и выполнения запросов. Однако стоимость формата Avro для сериализации или десериализации выше, а пропускная способность копирования ниже по сравнению с текстовым форматом. Формат файла, который необходимо использовать в процессе обработки, следует выбирать, принимая во внимание все элементы — от формы данных, хранимых в исходных хранилищах данных или извлекаемых из внешних систем, лучшего формата для хранения, аналитической обработки и выполнения запросов до формата, в котором следует экспортировать данные в киоски данных для средств создания отчетов и визуализации данных. Иногда формат файла, который не является достаточно оптимальным для производительности операций чтения и записи, может отлично подойти, учитывая общий аналитический процесс.

## <a name="considerations-for-compression"></a>Рекомендации по сжатию

Если входной или выходной набор данных представляет собой файл, для действия копирования можно настроить сжатие или распаковку данных при записи в место назначения. Использование сжатия — это компромисс между количеством операций ввода-вывода и потреблением ЦП, так как для сжатия данных требуются дополнительные вычислительные ресурсы. Однако взамен уменьшается количество сетевых операций ввода-вывода и используемый объем хранилища. В зависимости от данных это может повысить общую пропускную способность копирования.

**Кодек.** Каждый кодек сжатия имеет свои преимущества. Например, кодек BZIP2 обладает минимальной пропускной способностью копирования, но предоставляет лучшую производительность выполнения запросов Hive, так как ее можно разделить для обработки. Кодек GZIP — это наиболее оптимальный вариант, который используется чаще всего. Следует выбрать кодек, который лучше всего подходит для комплексного сценария.

**Уровень.**Для каждого кодека сжатия можно выбрать один из двух параметров — самое быстрое сжатие или оптимальное сжатие. Если использовать параметр самого быстрого сжатия, данные сжимаются как можно быстрее, даже если итоговый файл сжимается не оптимально. Если использовать параметр оптимального сжатия, данные сжимаются дольше, предоставляя минимальный объем данных. Можно испытать оба варианта, чтобы увидеть, который из них обеспечивает лучшую общую производительность в определенном случае.

**Рекомендация.** При копировании данных большого объема между локальным хранилищем и облаком для сжатия можно воспользоваться [промежуточным копированием](#staged-copy) с включенным сжатием данных. Промежуточное хранилище эффективно использовать, когда пропускная способность корпоративной сети и служб Azure является ограничивающим фактором и требуется, чтобы входной и выходной наборы данных были в несжатом виде.

## <a name="considerations-for-column-mapping"></a>Рекомендации по сопоставлению столбцов

В действии копирования можно задать свойство **columnMappings** для сопоставления всех входных столбцов или их подмножества с выходными столбцами. После считывания данных из источника службе перемещения данных требуется выполнить сопоставление столбцов данных, прежде чем записать их в приемник. Эта дополнительная обработка снижает пропускную способность копирования.

Если данные в источнике доступны для запросов, например при использовании реляционного хранилища (база данных SQL или SQL Server) или хранилища NoSQL (хранилище таблиц или Azure Cosmos DB), вместо использования сопоставления столбцов для свойства **query** можно передать фильтрацию столбцов и логику переупорядочивания. Таким образом, когда служба перемещения данных считывает данные из исходного хранилища, что является более эффективным, осуществляется проецирование.

Дополнительные сведения см. в статье [Сопоставление схем в действии копирования](copy-activity-schema-and-type-mapping.md).

## <a name="other-considerations"></a>Дополнительные рекомендации

Если размер данных для копирования достаточно большой, можно настроить бизнес-логику для дальнейшего секционирования данных и запланировать более частое выполнение действия копирования, чтобы уменьшить размер данных для каждого действия копирования.

Необходимо следить за количеством наборов данных и действий копирования, требующих подключения фабрики данных к одному хранилищу данных в одно и то же время. Большое количество одновременно выполняемых заданий копирования может привести к регулированию хранилища данных, что ведет к снижению производительности, внутренним повторным попыткам выполнения действия копирования, а в некоторых случаях — к сбоям выполнения.

## <a name="sample-scenario-copy-from-an-on-premises-sql-server-to-blob-storage"></a>Пример сценария. Копирование из локального SQL Server в хранилище BLOB-объектов

**Сценарий.**Конвейер предназначен для копирования данных с локального сервера SQL Server в хранилище BLOB-объектов в формате CSV. Для ускорения выполнения задания копирования необходимо сжать CSV-файлы в формат BZIP2.

**Тестирование и анализ.**Пропускная способность действия копирования составляет меньше 2 МБ/с, что гораздо меньше, чем в тесте производительности.

**Анализ и оптимизация производительности.**Чтобы устранить проблемы производительности, сначала необходимо рассмотреть процесс обработки и перемещения данных.

1. **Чтение данных.** Среда выполнения интеграции устанавливает подключение с SQL Server и отправляет запрос. SQL Server отвечает, отправляя поток данных в эту среду через интрасеть.
2. **Сериализация и сжатие данных.** Среда выполнения интеграции сериализует поток данных в формат CSV и сжимает данные в поток BZIP2.
3. **Запись данных.** Среда выполнения интеграции отправляет поток BZIP2 в хранилище BLOB-объектов через Интернет.

Как видите, обработка и перемещение данных происходит в последовательном режиме потоковой передачи: SQL Server > локальная сеть > среда выполнения интеграции > глобальная сеть > хранилище BLOB-объектов. **Общая производительность достигается при минимальной пропускной способности в конвейере.**

![Поток данных](./media/copy-activity-performance/case-study-pic-1.png)

Один или несколько следующих факторов могут вызвать узкое место производительности.

* **Источник.**SQL Server отличается низкой пропускной способностью из-за высокой нагрузки.
* **Локальная среда выполнения интеграции**:
  * **Локальная сеть.** Среда выполнения интеграции находится далеко от компьютера SQL Server и характеризуется низкой пропускной способностью.
  * **Среда выполнения интеграции.** Выполнение следующих операций привело к достижению ограничений нагрузки для среды выполнения интеграции.
    * **Сериализация.**Сериализация потока данных в формат CSV характеризуется низкой пропускной способностью.
    * **Сжатие.**Выбран кодек медленного сжатия (например, BZIP2 со скоростью 2,8 Мбит/с и процессором Core i7).
  * **Глобальная сеть.**Низкая пропускная способность между корпоративной сетью и службами Azure (например, T1 — 1544 Кбит/с, T2 — 6312 Кбит/с).
* **Приемник.**Хранилище BLOB-объектов имеет низкую пропускную способность. (Этот сценарий маловероятный, так как соглашение об уровне обслуживания гарантирует не менее 60 Мбит/с.)

В этом случае сжатие данных в формат BZIP2 может замедлять работу всего конвейера. Этого можно избежать, если перейти на использование кодека сжатия в формат GZIP.

## <a name="reference"></a>Справочные материалы

Ниже приведены справочные материалы по мониторингу и настройке производительности для некоторых поддерживаемых хранилищ данных.

* Служба хранилища Azure (включая хранилище BLOB-объектов и таблиц): [Целевые показатели масштабируемости и производительности службы хранилища Azure](../storage/common/storage-scalability-targets.md) и [Производительность хранилища Microsoft Azure и контрольный список масштабируемости](../storage/common/storage-performance-checklist.md).
* База данных SQL Azure: вы можете [наблюдать за производительностью](../sql-database/sql-database-single-database-monitor.md) и проверять процент использования единиц транзакций базы данных (DTU).
* Хранилище данных SQL Azure: его использование измеряется в единицах использования хранилища данных (DWU). См. статью [Управление вычислительными ресурсами в хранилище данных SQL Azure (обзор)](../sql-data-warehouse/sql-data-warehouse-manage-compute-overview.md).
* Azure Cosmos DB: [Прекращение использования уровней производительности S1, S2 и S3 в DocumentDB](../cosmos-db/performance-levels.md).
* Локальный SQL Server: [Мониторинг и настройка производительности](https://msdn.microsoft.com/library/ms189081.aspx)
* Локальный файловый сервер: [Performance tuning for file servers](https://msdn.microsoft.com/library/dn567661.aspx)

## <a name="next-steps"></a>Дополнительная информация
См. другие статьи о действиях копирования:

- [Действие копирования в фабрике данных Azure](copy-activity-overview.md)
- [Сопоставление схем в действии копирования](copy-activity-schema-and-type-mapping.md)
- [Отказоустойчивость действия копирования в фабрике данных Azure](copy-activity-fault-tolerance.md)
