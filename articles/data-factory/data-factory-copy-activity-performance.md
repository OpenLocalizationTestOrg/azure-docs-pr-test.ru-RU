---
title: "Руководство по настройке производительности действия копирования | Документация Майкрософт"
description: "Узнайте о ключевых факторах, которые влияют на производительность перемещения данных в фабрике данных Azure при использовании действия копирования."
services: data-factory
documentationcenter: 
author: linda33wj
manager: jhubbard
editor: monicar
ms.assetid: 4b9a6a4f-8cf5-4e0a-a06f-8133a2b7bc58
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 08/10/2017
ms.author: jingwang
ms.openlocfilehash: 2779655aee3af3a351b30f18b4c9d9918e9f2210
ms.sourcegitcommit: 18ad9bc049589c8e44ed277f8f43dcaa483f3339
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 08/29/2017
---
# <a name="copy-activity-performance-and-tuning-guide"></a><span data-ttu-id="06cb5-103">Руководство по настройке производительности действия копирования</span><span class="sxs-lookup"><span data-stu-id="06cb5-103">Copy Activity performance and tuning guide</span></span>
<span data-ttu-id="06cb5-104">Действие копирования фабрики данных Azure — первоклассное безопасное, надежное и высокопроизводительное решение для загрузки данных.</span><span class="sxs-lookup"><span data-stu-id="06cb5-104">Azure Data Factory Copy Activity delivers a first-class secure, reliable, and high-performance data loading solution.</span></span> <span data-ttu-id="06cb5-105">Оно позволяет ежедневно копировать десятки терабайтов данных в самые разнообразные облачные и локальные хранилища данных.</span><span class="sxs-lookup"><span data-stu-id="06cb5-105">It enables you to copy tens of terabytes of data every day across a rich variety of cloud and on-premises data stores.</span></span> <span data-ttu-id="06cb5-106">Именно высокоскоростная загрузка данных позволяет сосредоточиться на основных проблемах "больших данных": создании решений расширенной аналитики и получении ценной информации из данных.</span><span class="sxs-lookup"><span data-stu-id="06cb5-106">Blazing-fast data loading performance is key to ensure you can focus on the core “big data” problem: building advanced analytics solutions and getting deep insights from all that data.</span></span>

<span data-ttu-id="06cb5-107">Azure предоставляет набор решений корпоративного уровня для хранения данных, а действие копирования предлагает сильно оптимизированные функции загрузки данных, которые легко установить и настроить.</span><span class="sxs-lookup"><span data-stu-id="06cb5-107">Azure provides a set of enterprise-grade data storage and data warehouse solutions, and Copy Activity offers a highly optimized data loading experience that is easy to configure and set up.</span></span> <span data-ttu-id="06cb5-108">Ниже перечислены возможности отдельного действия копирования.</span><span class="sxs-lookup"><span data-stu-id="06cb5-108">With just a single copy activity, you can achieve:</span></span>

* <span data-ttu-id="06cb5-109">Загрузка данных в **хранилище данных SQL Azure** со скоростью **1,2 Гбит/с**.</span><span class="sxs-lookup"><span data-stu-id="06cb5-109">Loading data into **Azure SQL Data Warehouse** at **1.2 GBps**.</span></span> <span data-ttu-id="06cb5-110">Пошаговое руководство и пример использования см. в статье [Загрузка 1 ТБ в хранилище данных SQL Azure с помощью фабрики данных Azure [мастер копирования] менее чем за 15 минут](data-factory-load-sql-data-warehouse.md).</span><span class="sxs-lookup"><span data-stu-id="06cb5-110">For a walkthrough with a use case, see [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span></span>
* <span data-ttu-id="06cb5-111">Загрузка данных в **хранилище BLOB-объектов Azure** на скорости **1,0 Гбит/с**.</span><span class="sxs-lookup"><span data-stu-id="06cb5-111">Loading data into **Azure Blob storage** at **1.0 GBps**</span></span>
* <span data-ttu-id="06cb5-112">Загрузка данных в **Azure Data Lake Store** на скорости **1,0 Гбит/с**.</span><span class="sxs-lookup"><span data-stu-id="06cb5-112">Loading data into **Azure Data Lake Store** at **1.0 GBps**</span></span>

<span data-ttu-id="06cb5-113">Содержание статьи</span><span class="sxs-lookup"><span data-stu-id="06cb5-113">This article describes:</span></span>

* <span data-ttu-id="06cb5-114">[Контрольные показатели производительности](#performance-reference) для поддерживаемых хранилищ данных (источника и приемника), которые помогут при планировании проекта.</span><span class="sxs-lookup"><span data-stu-id="06cb5-114">[Performance reference numbers](#performance-reference) for supported source and sink data stores to help you plan your project;</span></span>
* <span data-ttu-id="06cb5-115">Функции, которые могут значительно повысить пропускную способность копирования в различных сценариях, в том числе [облачные единицы перемещения данных](#cloud-data-movement-units), [параллельное копирование](#parallel-copy) и [промежуточное копирование](#staged-copy).</span><span class="sxs-lookup"><span data-stu-id="06cb5-115">Features that can boost the copy throughput in different scenarios, including [cloud data movement units](#cloud-data-movement-units), [parallel copy](#parallel-copy), and [staged Copy](#staged-copy);</span></span>
* <span data-ttu-id="06cb5-116">[Руководство по настройке производительности](#performance-tuning-steps) , в котором описывается настройка производительности и ключевые факторы, которые могут влиять на производительность копирования.</span><span class="sxs-lookup"><span data-stu-id="06cb5-116">[Performance tuning guidance](#performance-tuning-steps) on how to tune the performance and the key factors that can impact copy performance.</span></span>

> [!NOTE]
> <span data-ttu-id="06cb5-117">Если вам в целом не знакомо действие копирования, перед чтением этой статьи ознакомьтесь со статьей [Перемещение данных с помощью действия копирования](data-factory-data-movement-activities.md) .</span><span class="sxs-lookup"><span data-stu-id="06cb5-117">If you are not familiar with Copy Activity in general, see [Move data by using Copy Activity](data-factory-data-movement-activities.md) before reading this article.</span></span>
>

## <a name="performance-reference"></a><span data-ttu-id="06cb5-118">Базовые показатели производительности</span><span class="sxs-lookup"><span data-stu-id="06cb5-118">Performance reference</span></span>

<span data-ttu-id="06cb5-119">В качестве справки ниже представлена таблица, в которой отражены показатели пропускной способности (в Мбит/с) для указанных пар источника и приемника, подученные в ходе внутреннего тестирования.</span><span class="sxs-lookup"><span data-stu-id="06cb5-119">As a reference, below table shows the copy throughput number in MBps for the given source and sink pairs based on in-house testing.</span></span> <span data-ttu-id="06cb5-120">Для сравнения также демонстрируется, как разные параметры [облачных единиц перемещения данных](#cloud-data-movement-units) или [масштабируемости шлюза управления данными](data-factory-data-management-gateway-high-availability-scalability.md) (несколько узлов шлюза) могут помочь определить производительность копирования.</span><span class="sxs-lookup"><span data-stu-id="06cb5-120">For comparison, it also demonstrates how different settings of [cloud data movement units](#cloud-data-movement-units) or [Data Management Gateway scalability](data-factory-data-management-gateway-high-availability-scalability.md) (multiple gateway nodes) can help on copy performance.</span></span>

![Матрица производительности](./media/data-factory-copy-activity-performance/CopyPerfRef.png)


<span data-ttu-id="06cb5-122">**Примечания:**</span><span class="sxs-lookup"><span data-stu-id="06cb5-122">**Points to note:**</span></span>
* <span data-ttu-id="06cb5-123">Для вычисления пропускной способности используется следующая формула: [размер данных, считанных из источника]/[длительность выполнения действия копирования].</span><span class="sxs-lookup"><span data-stu-id="06cb5-123">Throughput is calculated by using the following formula: [size of data read from source]/[Copy Activity run duration].</span></span>
* <span data-ttu-id="06cb5-124">Контрольные показатели производительности в таблице были измерены с использованием набора данных [TPC-H](http://www.tpc.org/tpch/) для выполнения отдельного действия копирования.</span><span class="sxs-lookup"><span data-stu-id="06cb5-124">The performance reference numbers in the table were measured using [TPC-H](http://www.tpc.org/tpch/) data set in a single copy activity run.</span></span>
* <span data-ttu-id="06cb5-125">При использовании хранилищ данных Azure источник и приемник находились в одном регионе Azure.</span><span class="sxs-lookup"><span data-stu-id="06cb5-125">In Azure data stores, the source and sink are in the same Azure region.</span></span>
* <span data-ttu-id="06cb5-126">Для гибридного перемещения данных (из локальной среды в облако или наоборот) использовался один экземпляр шлюза на компьютере, на котором не находилось локальное хранилище данных. Конфигурация приведена в следующей таблице.</span><span class="sxs-lookup"><span data-stu-id="06cb5-126">For hybrid copy between on-premises and cloud data stores, each gateway node was running on a machine that was separate from the on-premises data store with below specification.</span></span> <span data-ttu-id="06cb5-127">При выполнении одного действия в шлюзе операция копирования потребляла только небольшую часть ресурсов ЦП, памяти и пропускной способности сети на тестовом компьютере.</span><span class="sxs-lookup"><span data-stu-id="06cb5-127">When a single activity was running on gateway, the copy operation consumed only a small portion of the test machine's CPU, memory, or network bandwidth.</span></span> <span data-ttu-id="06cb5-128">Подробнее см.в разделе [Рекомендации относительно шлюза управления данными](#considerations-for-data-management-gateway).</span><span class="sxs-lookup"><span data-stu-id="06cb5-128">Learn more from [consideration for Data Management Gateway](#considerations-for-data-management-gateway).</span></span>
    <table>
    <tr>
        <td><span data-ttu-id="06cb5-129">ЦП</span><span class="sxs-lookup"><span data-stu-id="06cb5-129">CPU</span></span></td>
        <td><span data-ttu-id="06cb5-130">Intel Xeon E5-2660 v2, 32 ядра с частотой 2,20 ГГц</span><span class="sxs-lookup"><span data-stu-id="06cb5-130">32 cores 2.20 GHz Intel Xeon E5-2660 v2</span></span></td>
    </tr>
    <tr>
        <td><span data-ttu-id="06cb5-131">Память</span><span class="sxs-lookup"><span data-stu-id="06cb5-131">Memory</span></span></td>
        <td><span data-ttu-id="06cb5-132">128 ГБ</span><span class="sxs-lookup"><span data-stu-id="06cb5-132">128 GB</span></span></td>
    </tr>
    <tr>
        <td><span data-ttu-id="06cb5-133">Сеть</span><span class="sxs-lookup"><span data-stu-id="06cb5-133">Network</span></span></td>
        <td><span data-ttu-id="06cb5-134">Веб-интерфейс: 10 Гбит/с; интерфейс интрасети: 40 Гбит/с</span><span class="sxs-lookup"><span data-stu-id="06cb5-134">Internet interface: 10 Gbps; intranet interface: 40 Gbps</span></span></td>
    </tr>
    </table>


> [!TIP]
> <span data-ttu-id="06cb5-135">Пропускную способность можно повысить, используя больше единиц перемещения данных (DMU), чем максимальное количество DMU по умолчанию (32 единицы для выполнения действия копирования из облака в облако).</span><span class="sxs-lookup"><span data-stu-id="06cb5-135">You can achieve higher throughput by leveraging more data movement units (DMUs) than the default maximum DMUs, which is 32 for a cloud-to-cloud copy activity run.</span></span> <span data-ttu-id="06cb5-136">Например, используя 100 DMU, можно достичь скорости копирования данных из большого двоичного объекта Azure в Azure Data Lake Store до **1 Гбит/с**.</span><span class="sxs-lookup"><span data-stu-id="06cb5-136">For example, with 100 DMUs, you can achieve copying data from Azure Blob into Azure Data Lake Store at **1.0GBps**.</span></span> <span data-ttu-id="06cb5-137">Подробные сведения об этой функции и поддерживаемый сценарий см. в разделе [Облачные единицы перемещения данных](#cloud-data-movement-units).</span><span class="sxs-lookup"><span data-stu-id="06cb5-137">See the [Cloud data movement units](#cloud-data-movement-units) section for details about this feature and the supported scenario.</span></span> <span data-ttu-id="06cb5-138">Чтобы получить дополнительные единицы DMU, отправьте запрос в [службу поддержки Azure](https://azure.microsoft.com/support/).</span><span class="sxs-lookup"><span data-stu-id="06cb5-138">Contact [Azure support](https://azure.microsoft.com/support/) to request more DMUs.</span></span>

## <a name="parallel-copy"></a><span data-ttu-id="06cb5-139">Параллельное копирование</span><span class="sxs-lookup"><span data-stu-id="06cb5-139">Parallel copy</span></span>
<span data-ttu-id="06cb5-140">Данные можно считывать из источника или записывать в приемник **одновременно с выполнением действия копирования**.</span><span class="sxs-lookup"><span data-stu-id="06cb5-140">You can read data from the source or write data to the destination **in parallel within a Copy Activity run**.</span></span> <span data-ttu-id="06cb5-141">Эта функция повышает пропускную способность операции копирования и сокращает продолжительность перемещения данных.</span><span class="sxs-lookup"><span data-stu-id="06cb5-141">This feature enhances the throughput of a copy operation and reduces the time it takes to move data.</span></span>

<span data-ttu-id="06cb5-142">Этот параметр отличается от свойства **concurrency** в определении действия.</span><span class="sxs-lookup"><span data-stu-id="06cb5-142">This setting is different from the **concurrency** property in the activity definition.</span></span> <span data-ttu-id="06cb5-143">Свойство **concurrency** определяет число **одновременных действий копирования**, выполняемых для обработки данных из разных окон действий (01:00–02:00, 02:00–03:00, 03:00–04:00 и т. д.).</span><span class="sxs-lookup"><span data-stu-id="06cb5-143">The **concurrency** property determines the number of **concurrent Copy Activity runs** to process data from different activity windows (1 AM to 2 AM, 2 AM to 3 AM, 3 AM to 4 AM, and so on).</span></span> <span data-ttu-id="06cb5-144">Это эффективно в случаях значительной загрузки.</span><span class="sxs-lookup"><span data-stu-id="06cb5-144">This capability is helpful when you perform a historical load.</span></span> <span data-ttu-id="06cb5-145">Возможность параллельного копирования относится к **выполнению одного действия**.</span><span class="sxs-lookup"><span data-stu-id="06cb5-145">The parallel copy capability applies to a **single activity run**.</span></span>

<span data-ttu-id="06cb5-146">Рассмотрим пример сценария:</span><span class="sxs-lookup"><span data-stu-id="06cb5-146">Let's look at a sample scenario.</span></span> <span data-ttu-id="06cb5-147">представим, что требуется обработать несколько срезов, полученных в прошлом.</span><span class="sxs-lookup"><span data-stu-id="06cb5-147">In the following example, multiple slices from the past need to be processed.</span></span> <span data-ttu-id="06cb5-148">Фабрика данных запускает экземпляр действия копирования (выполнение действия) для каждого среза.</span><span class="sxs-lookup"><span data-stu-id="06cb5-148">Data Factory runs an instance of Copy Activity (an activity run) for each slice:</span></span>

* <span data-ttu-id="06cb5-149">Срез данных из первого окна действий (01:00–02:00) == > выполнение действия 1.</span><span class="sxs-lookup"><span data-stu-id="06cb5-149">The data slice from the first activity window (1 AM to 2 AM) ==> Activity run 1</span></span>
* <span data-ttu-id="06cb5-150">Срез данных из второго окна действий (02:00–03:00) == > выполнение действия 2.</span><span class="sxs-lookup"><span data-stu-id="06cb5-150">The data slice from the second activity window (2 AM to 3 AM) ==> Activity run 2</span></span>
* <span data-ttu-id="06cb5-151">Срез данных из второго окна действий (03:00–04:00) == > выполнение действия 3.</span><span class="sxs-lookup"><span data-stu-id="06cb5-151">The data slice from the second activity window (3 AM to 4 AM) ==> Activity run 3</span></span>

<span data-ttu-id="06cb5-152">И т. д.</span><span class="sxs-lookup"><span data-stu-id="06cb5-152">And so on.</span></span>

<span data-ttu-id="06cb5-153">Значение 2 параметра **concurrency** в этом примере позволяет **выполнению действия 1** и **выполнению действия 2** копировать данные из двух окон действий **одновременно**, что повышает производительность перемещения данных.</span><span class="sxs-lookup"><span data-stu-id="06cb5-153">In this example, when the **concurrency** value is set to 2, **Activity run 1** and **Activity run 2** copy data from two activity windows **concurrently** to improve data movement performance.</span></span> <span data-ttu-id="06cb5-154">Тем не менее если в рамках выполнения действия 1 необходимо переместить несколько файлов, служба перемещения данных копирует файлы из источника в приемник по одному.</span><span class="sxs-lookup"><span data-stu-id="06cb5-154">However, if multiple files are associated with Activity run 1, the data movement service copies files from the source to the destination one file at a time.</span></span>

### <a name="cloud-data-movement-units"></a><span data-ttu-id="06cb5-155">Облачные единицы перемещения данных</span><span class="sxs-lookup"><span data-stu-id="06cb5-155">Cloud data movement units</span></span>
<span data-ttu-id="06cb5-156">**Облачная единица перемещения данных** — это мера, представляющая производительность (сочетание выделенных ресурсов ЦП, памяти и сети) одной единицы в фабрике данных.</span><span class="sxs-lookup"><span data-stu-id="06cb5-156">A **cloud data movement unit (DMU)** is a measure that represents the power (a combination of CPU, memory, and network resource allocation) of a single unit in Data Factory.</span></span> <span data-ttu-id="06cb5-157">Эта мера используется для операции копирования из облака в облако, но не для гибридного копирования.</span><span class="sxs-lookup"><span data-stu-id="06cb5-157">A DMU might be used in a cloud-to-cloud copy operation, but not in a hybrid copy.</span></span>

<span data-ttu-id="06cb5-158">По умолчанию фабрика данных использует одну облачную единицу перемещения данных для одного выполнения действия копирования.</span><span class="sxs-lookup"><span data-stu-id="06cb5-158">By default, Data Factory uses a single cloud DMU to perform a single Copy Activity run.</span></span> <span data-ttu-id="06cb5-159">Это значение по умолчанию можно переопределить, указав значение для свойства **cloudDataMovementUnits**, как показано ниже.</span><span class="sxs-lookup"><span data-stu-id="06cb5-159">To override this default, specify a value for the **cloudDataMovementUnits** property as follows.</span></span> <span data-ttu-id="06cb5-160">Сведения о том, как можно повысить уровень производительности, настроив дополнительные единицы для определенного источника и приемника, см. в [справочнике по производительности](#performance-reference).</span><span class="sxs-lookup"><span data-stu-id="06cb5-160">For information about the level of performance gain you might get when you configure more units for a specific copy source and sink, see the [performance reference](#performance-reference).</span></span>

```json
"activities":[  
    {
        "name": "Sample copy activity",
        "description": "",
        "type": "Copy",
        "inputs": [{ "name": "InputDataset" }],
        "outputs": [{ "name": "OutputDataset" }],
        "typeProperties": {
            "source": {
                "type": "BlobSource",
            },
            "sink": {
                "type": "AzureDataLakeStoreSink"
            },
            "cloudDataMovementUnits": 32
        }
    }
]
```
<span data-ttu-id="06cb5-161">**Допустимые значения** свойства **cloudDataMovementUnits**: 1 (по умолчанию), 2, 4, 8, 16, 32.</span><span class="sxs-lookup"><span data-stu-id="06cb5-161">The **allowed values** for the **cloudDataMovementUnits** property are 1 (default), 2, 4, 8, 16, 32.</span></span> <span data-ttu-id="06cb5-162">**Фактическое число облачных единиц перемещения данных** , используемых во время выполнения операции копирования, меньше или равно заданному значению, в зависимости от шаблона данных.</span><span class="sxs-lookup"><span data-stu-id="06cb5-162">The **actual number of cloud DMUs** that the copy operation uses at run time is equal to or less than the configured value, depending on your data pattern.</span></span>

> [!NOTE]
> <span data-ttu-id="06cb5-163">Если вам требуется больше облачных единиц перемещения данных, чтобы повысить пропускную способность, обратитесь в [службу поддержки Azure](https://azure.microsoft.com/support/).</span><span class="sxs-lookup"><span data-stu-id="06cb5-163">If you need more cloud DMUs for a higher throughput, contact [Azure support](https://azure.microsoft.com/support/).</span></span> <span data-ttu-id="06cb5-164">В настоящее время 8 и более облачных единиц перемещения данных поддерживаются только при **копировании нескольких файлов из хранилища BLOB-объектов, Data Lake Store, Amazon S3, облака FTP или облака SFTP в хранилище BLOB-объектов, Data Lake Store или базу данных SQL Azure**.</span><span class="sxs-lookup"><span data-stu-id="06cb5-164">Setting of 8 and above currently works only when you **copy multiple files from Blob storage/Data Lake Store/Amazon S3/cloud FTP/cloud SFTP to Blob storage/Data Lake Store/Azure SQL Database**.</span></span>
>

### <a name="parallelcopies"></a><span data-ttu-id="06cb5-165">parallelCopies</span><span class="sxs-lookup"><span data-stu-id="06cb5-165">parallelCopies</span></span>
<span data-ttu-id="06cb5-166">Можно использовать свойство **parallelCopies** , чтобы задать параллелизм для действия копирования.</span><span class="sxs-lookup"><span data-stu-id="06cb5-166">You can use the **parallelCopies** property to indicate the parallelism that you want Copy Activity to use.</span></span> <span data-ttu-id="06cb5-167">Считайте это свойство максимальным числом потоков в рамках действия копирования, которые могут параллельно считывать данные из источника или записывать их в хранилища данных-приемники.</span><span class="sxs-lookup"><span data-stu-id="06cb5-167">You can think of this property as the maximum number of threads within Copy Activity that can read from your source or write to your sink data stores in parallel.</span></span>

<span data-ttu-id="06cb5-168">Для каждого выполнения действия копирования фабрика данных определяет количество параллельных копий для копирования данных из исходного хранилища данных в целевое хранилище данных.</span><span class="sxs-lookup"><span data-stu-id="06cb5-168">For each Copy Activity run, Data Factory determines the number of parallel copies to use to copy data from the source data store and to the destination data store.</span></span> <span data-ttu-id="06cb5-169">Количество параллельных копий по умолчанию зависит от типов используемых источника и приемника.</span><span class="sxs-lookup"><span data-stu-id="06cb5-169">The default number of parallel copies that it uses depends on the type of source and sink that you are using.</span></span>  

| <span data-ttu-id="06cb5-170">Источник и приемник</span><span class="sxs-lookup"><span data-stu-id="06cb5-170">Source and sink</span></span> | <span data-ttu-id="06cb5-171">Число параллельных копий по умолчанию, определенное службой</span><span class="sxs-lookup"><span data-stu-id="06cb5-171">Default parallel copy count determined by service</span></span> |
| --- | --- |
| <span data-ttu-id="06cb5-172">Копирование данных из одного файлового хранилища данных в другое (хранилище BLOB-объектов, Data Lake Store, Amazon S3, локальная файловая система, локальная файловая система HDFS).</span><span class="sxs-lookup"><span data-stu-id="06cb5-172">Copy data between file-based stores (Blob storage; Data Lake Store; Amazon S3; an on-premises file system; an on-premises HDFS)</span></span> |<span data-ttu-id="06cb5-173">От 1 до 32.</span><span class="sxs-lookup"><span data-stu-id="06cb5-173">Between 1 and 32.</span></span> <span data-ttu-id="06cb5-174">Зависит от размера файлов и числа облачных единиц перемещения данных, используемых для копирования данных между двумя облачными хранилищами данных или в пределах физической конфигурации компьютера шлюза, используемого для гибридного копирования (копирования данных из локального хранилища данных и в него).</span><span class="sxs-lookup"><span data-stu-id="06cb5-174">Depends on the size of the files and the number of cloud data movement units (DMUs) used to copy data between two cloud data stores, or the physical configuration of the Gateway machine used for a hybrid copy (to copy data to or from an on-premises data store).</span></span> |
| <span data-ttu-id="06cb5-175">Копирование данных из **любого хранилища данных в хранилище таблиц Azure**</span><span class="sxs-lookup"><span data-stu-id="06cb5-175">Copy data from **any source data store to Azure Table storage**</span></span> |<span data-ttu-id="06cb5-176">4.</span><span class="sxs-lookup"><span data-stu-id="06cb5-176">4</span></span> |
| <span data-ttu-id="06cb5-177">Все прочие сочетания источника и приемника</span><span class="sxs-lookup"><span data-stu-id="06cb5-177">All other source and sink pairs</span></span> |<span data-ttu-id="06cb5-178">1</span><span class="sxs-lookup"><span data-stu-id="06cb5-178">1</span></span> |

<span data-ttu-id="06cb5-179">Обычно поведение по умолчанию должно обеспечить оптимальную пропускную способность.</span><span class="sxs-lookup"><span data-stu-id="06cb5-179">Usually, the default behavior should give you the best throughput.</span></span> <span data-ttu-id="06cb5-180">Тем не менее, чтобы управлять загрузкой компьютеров, на которых размещены хранилища данных, или настроить производительность копирования, можно переопределить значение по умолчанию и указать значение свойства **parallelCopies** .</span><span class="sxs-lookup"><span data-stu-id="06cb5-180">However, to control the load on machines that host your data stores, or to tune copy performance, you may choose to override the default value and specify a value for the **parallelCopies** property.</span></span> <span data-ttu-id="06cb5-181">Значение должно быть от 1 до 32 (включая оба числа).</span><span class="sxs-lookup"><span data-stu-id="06cb5-181">The value must be between 1 and 32 (both inclusive).</span></span> <span data-ttu-id="06cb5-182">Во время выполнения действие копирования выберет значение, которое меньше или равно заданному значению, чтобы обеспечить оптимальную производительность.</span><span class="sxs-lookup"><span data-stu-id="06cb5-182">At run time, for the best performance, Copy Activity uses a value that is less than or equal to the value that you set.</span></span>

```json
"activities":[  
    {
        "name": "Sample copy activity",
        "description": "",
        "type": "Copy",
        "inputs": [{ "name": "InputDataset" }],
        "outputs": [{ "name": "OutputDataset" }],
        "typeProperties": {
            "source": {
                "type": "BlobSource",
            },
            "sink": {
                "type": "AzureDataLakeStoreSink"
            },
            "parallelCopies": 8
        }
    }
]
```
<span data-ttu-id="06cb5-183">Примечания:</span><span class="sxs-lookup"><span data-stu-id="06cb5-183">Points to note:</span></span>

* <span data-ttu-id="06cb5-184">При копировании данных из одного файлового хранилища в другое свойство **parallelCopies** определяет параллелизм на уровне файла.</span><span class="sxs-lookup"><span data-stu-id="06cb5-184">When you copy data between file-based stores, the **parallelCopies** determine the parallelism at the file level.</span></span> <span data-ttu-id="06cb5-185">Фрагментирование в пределах файла выполняется автоматически и прозрачно, при этом для определенного типа исходного хранилища данных используется самый подходящий размер блока. Таким образом, данные могут отправляться одновременно и независимо от parallelCopies.</span><span class="sxs-lookup"><span data-stu-id="06cb5-185">The chunking within a single file would happen underneath automatically and transparently, and it's designed to use the best suitable chunk size for a given source data store type to load data in parallel and orthogonal to parallelCopies.</span></span> <span data-ttu-id="06cb5-186">Фактическое число параллельных копий, используемых службой перемещения данных для копирования во время выполнения, не превышает количество файлов.</span><span class="sxs-lookup"><span data-stu-id="06cb5-186">The actual number of parallel copies the data movement service uses for the copy operation at run time is no more than the number of files you have.</span></span> <span data-ttu-id="06cb5-187">Если режим копирования — **mergeFile**, то при копировании параллелизм на уровне файла не будет использоваться.</span><span class="sxs-lookup"><span data-stu-id="06cb5-187">If the copy behavior is **mergeFile**, Copy Activity cannot take advantage of file-level parallelism.</span></span>
* <span data-ttu-id="06cb5-188">При указании значения свойства **parallelCopies** следует учитывать, что это повлечет увеличение нагрузки на хранилище данных источника и приемника, а также на шлюз, если это гибридное копирование.</span><span class="sxs-lookup"><span data-stu-id="06cb5-188">When you specify a value for the **parallelCopies** property, consider the load increase on your source and sink data stores, and to gateway if it is a hybrid copy.</span></span> <span data-ttu-id="06cb5-189">Это особенно актуально при наличии нескольких действий или параллельных выполнений одинаковых действий с одним и тем же хранилищем данных.</span><span class="sxs-lookup"><span data-stu-id="06cb5-189">This happens especially when you have multiple activities or concurrent runs of the same activities that run against the same data store.</span></span> <span data-ttu-id="06cb5-190">Если вы заметите, что хранилище данных или шлюз перегружены, уменьшите значение **parallelCopies** , чтобы снизить загрузку.</span><span class="sxs-lookup"><span data-stu-id="06cb5-190">If you notice that either the data store or Gateway is overwhelmed with the load, decrease the **parallelCopies** value to relieve the load.</span></span>
* <span data-ttu-id="06cb5-191">При копировании данных из нефайлового хранилища в файловое служба перемещения данных игнорирует свойство **parallelCopies** .</span><span class="sxs-lookup"><span data-stu-id="06cb5-191">When you copy data from stores that are not file-based to stores that are file-based, the data movement service ignores the **parallelCopies** property.</span></span> <span data-ttu-id="06cb5-192">В этом случае параллелизм не применяется, даже если задан соответствующий параметр.</span><span class="sxs-lookup"><span data-stu-id="06cb5-192">Even if parallelism is specified, it's not applied in this case.</span></span>

> [!NOTE]
> <span data-ttu-id="06cb5-193">Чтобы применить функцию **parallelCopies** при гибридном копировании, необходимо использовать шлюз управления данными версии не ниже 1.11.</span><span class="sxs-lookup"><span data-stu-id="06cb5-193">You must use Data Management Gateway version 1.11 or later to use the **parallelCopies** feature when you do a hybrid copy.</span></span>
>
>

<span data-ttu-id="06cb5-194">Чтобы эффективного использовать эти два свойства и повысить пропускную способность перемещения данных, ознакомьтесь с [примерами использования](#case-study-use-parallel-copy).</span><span class="sxs-lookup"><span data-stu-id="06cb5-194">To better use these two properties, and to enhance your data movement throughput, see the [sample use cases](#case-study-use-parallel-copy).</span></span> <span data-ttu-id="06cb5-195">Чтобы воспользоваться преимуществами поведения по умолчанию, настраивать свойство **parallelCopies** не требуется.</span><span class="sxs-lookup"><span data-stu-id="06cb5-195">You don't need to configure **parallelCopies** to take advantage of the default behavior.</span></span> <span data-ttu-id="06cb5-196">Если вы зададите для свойства **parallelCopies** невысокое значение, несколько облачных единиц перемещения данных не будут использоваться полностью.</span><span class="sxs-lookup"><span data-stu-id="06cb5-196">If you do configure and **parallelCopies** is too small, multiple cloud DMUs might not be fully utilized.</span></span>  

### <a name="billing-impact"></a><span data-ttu-id="06cb5-197">Принцип выставления счетов</span><span class="sxs-lookup"><span data-stu-id="06cb5-197">Billing impact</span></span>
<span data-ttu-id="06cb5-198">**Важно** помнить, что оплата взимается на основе общего времени операции копирования.</span><span class="sxs-lookup"><span data-stu-id="06cb5-198">It's **important** to remember that you are charged based on the total time of the copy operation.</span></span> <span data-ttu-id="06cb5-199">Если задание копирования обычно занимало один час и одну облачную единицу, а теперь на это требуется 15 минут и четыре облачные единицы, то стоимость практически не изменится.</span><span class="sxs-lookup"><span data-stu-id="06cb5-199">If a copy job used to take one hour with one cloud unit and now it takes 15 minutes with four cloud units, the overall bill remains almost the same.</span></span> <span data-ttu-id="06cb5-200">Допустим, используются четыре облачные единицы.</span><span class="sxs-lookup"><span data-stu-id="06cb5-200">For example, you use four cloud units.</span></span> <span data-ttu-id="06cb5-201">Для первой и второй облачных единиц требуется по 10 минут, для третьей и четвертой — по 5 минут, и все это в пределах одного выполнения действия копирования.</span><span class="sxs-lookup"><span data-stu-id="06cb5-201">The first cloud unit spends 10 minutes, the second one, 10 minutes, the third one, 5 minutes, and the fourth one, 5 minutes, all in one Copy Activity run.</span></span> <span data-ttu-id="06cb5-202">Плата взимается за общее время копирования (перемещения данных), что составляет 30 минут (10 + 10 + 5 + 5).</span><span class="sxs-lookup"><span data-stu-id="06cb5-202">You are charged for the total copy (data movement) time, which is 10 + 10 + 5 + 5 = 30 minutes.</span></span> <span data-ttu-id="06cb5-203">Использование свойства **parallelCopies** не влияет на выставление счетов.</span><span class="sxs-lookup"><span data-stu-id="06cb5-203">Using **parallelCopies** does not affect billing.</span></span>

## <a name="staged-copy"></a><span data-ttu-id="06cb5-204">промежуточное копирование</span><span class="sxs-lookup"><span data-stu-id="06cb5-204">Staged copy</span></span>
<span data-ttu-id="06cb5-205">При копировании данных из источника в приемник можно использовать хранилище BLOB-объектов в качестве промежуточного пространства для хранения.</span><span class="sxs-lookup"><span data-stu-id="06cb5-205">When you copy data from a source data store to a sink data store, you might choose to use Blob storage as an interim staging store.</span></span> <span data-ttu-id="06cb5-206">Промежуточное хранилище очень удобно в следующих ситуациях.</span><span class="sxs-lookup"><span data-stu-id="06cb5-206">Staging is especially useful in the following cases:</span></span>

1. <span data-ttu-id="06cb5-207">**Вы хотите принимать данные из различных расположений в хранилище данных SQL с помощью PolyBase**.</span><span class="sxs-lookup"><span data-stu-id="06cb5-207">**You want to ingest data from various data stores into SQL Data Warehouse via PolyBase**.</span></span> <span data-ttu-id="06cb5-208">Хранилище данных SQL использует функцию PolyBase, которая обеспечивает высокую пропускную способность при загрузке больших объемов данных в хранилище SQL.</span><span class="sxs-lookup"><span data-stu-id="06cb5-208">SQL Data Warehouse uses PolyBase as a high-throughput mechanism to load a large amount of data into SQL Data Warehouse.</span></span> <span data-ttu-id="06cb5-209">Тем не менее исходные данные должны находиться в хранилище BLOB-объектов и соответствовать дополнительным требованиям.</span><span class="sxs-lookup"><span data-stu-id="06cb5-209">However, the source data must be in Blob storage, and it must meet additional criteria.</span></span> <span data-ttu-id="06cb5-210">При загрузке данных не из хранилища BLOB-объектов можно активировать копирование через промежуточное хранилище BLOB-объектов.</span><span class="sxs-lookup"><span data-stu-id="06cb5-210">When you load data from a data store other than Blob storage, you can activate data copying via interim staging Blob storage.</span></span> <span data-ttu-id="06cb5-211">В этом случае фабрика данных выполняет необходимые преобразования данных, чтобы обеспечить их соответствие требованиям PolyBase.</span><span class="sxs-lookup"><span data-stu-id="06cb5-211">In that case, Data Factory performs the required data transformations to ensure that it meets the requirements of PolyBase.</span></span> <span data-ttu-id="06cb5-212">Затем она загружает данные в хранилище данных SQL с помощью PolyBase.</span><span class="sxs-lookup"><span data-stu-id="06cb5-212">Then it uses PolyBase to load data into SQL Data Warehouse.</span></span> <span data-ttu-id="06cb5-213">Дополнительные сведения см. в разделе [Загрузка данных в хранилище данных SQL Azure с помощью PolyBase](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse).</span><span class="sxs-lookup"><span data-stu-id="06cb5-213">For more details, see [Use PolyBase to load data into Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse).</span></span> <span data-ttu-id="06cb5-214">Пошаговое руководство и пример использования см. в статье [Загрузка 1 ТБ в хранилище данных SQL Azure с помощью фабрики данных Azure [мастер копирования] менее чем за 15 минут](data-factory-load-sql-data-warehouse.md).</span><span class="sxs-lookup"><span data-stu-id="06cb5-214">For a walkthrough with a use case, see [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span></span>
2. <span data-ttu-id="06cb5-215">**Иногда для гибридного перемещения данных (т. е. для копирования данных между локальным и облачным хранилищами данных) требуется некоторое время из-за низкой скорости сетевого подключения**.</span><span class="sxs-lookup"><span data-stu-id="06cb5-215">**Sometimes it takes a while to perform a hybrid data movement (that is, to copy between an on-premises data store and a cloud data store) over a slow network connection**.</span></span> <span data-ttu-id="06cb5-216">Чтобы передача в промежуточное хранилище в облаке занимала меньше времени, можно сжать данные в локальном хранилище.</span><span class="sxs-lookup"><span data-stu-id="06cb5-216">To improve performance, you can compress the data on-premises so that it takes less time to move data to the staging data store in the cloud.</span></span> <span data-ttu-id="06cb5-217">Затем данные в промежуточном хранилище распаковываются и загружаются в целевое расположение.</span><span class="sxs-lookup"><span data-stu-id="06cb5-217">Then you can decompress the data in the staging store before you load it into the destination data store.</span></span>
3. <span data-ttu-id="06cb5-218">**В соответствии с корпоративными политиками ИТ в брандмауэре не рекомендуется открывать порты, отличные от 80 и 443**.</span><span class="sxs-lookup"><span data-stu-id="06cb5-218">**You don't want to open ports other than port 80 and port 443 in your firewall, because of corporate IT policies**.</span></span> <span data-ttu-id="06cb5-219">Например, при копировании данных из локального хранилища в приемник базы данных SQL Azure или приемник хранилища данных SQL Azure необходимо активировать исходящие TCP-подключения через порт 1433 для брандмауэра Windows и корпоративного брандмауэра.</span><span class="sxs-lookup"><span data-stu-id="06cb5-219">For example, when you copy data from an on-premises data store to an Azure SQL Database sink or an Azure SQL Data Warehouse sink, you need to activate outbound TCP communication on port 1433 for both the Windows firewall and your corporate firewall.</span></span> <span data-ttu-id="06cb5-220">В этом случае можно использовать преимущества шлюза, чтобы сначала скопировать данные в промежуточный экземпляр хранилища BLOB-объектов по протоколу HTTP или HTTPS через порт 443,</span><span class="sxs-lookup"><span data-stu-id="06cb5-220">In this scenario, take advantage of the gateway to first copy data to a Blob storage staging instance over HTTP or HTTPS on port 443.</span></span> <span data-ttu-id="06cb5-221">а уже оттуда загрузить данные в базу данных SQL или хранилище данных SQL.</span><span class="sxs-lookup"><span data-stu-id="06cb5-221">Then, load the data into SQL Database or SQL Data Warehouse from Blob storage staging.</span></span> <span data-ttu-id="06cb5-222">В таком сценарии не нужно включать порт 1433.</span><span class="sxs-lookup"><span data-stu-id="06cb5-222">In this flow, you don't need to enable port 1433.</span></span>

### <a name="how-staged-copy-works"></a><span data-ttu-id="06cb5-223">Принцип промежуточного копирования</span><span class="sxs-lookup"><span data-stu-id="06cb5-223">How staged copy works</span></span>
<span data-ttu-id="06cb5-224">Если активировать функцию промежуточного копирования, сначала данные копируются из исходного хранилища в промежуточное (собственное).</span><span class="sxs-lookup"><span data-stu-id="06cb5-224">When you activate the staging feature, first the data is copied from the source data store to the staging data store (bring your own).</span></span> <span data-ttu-id="06cb5-225">Оттуда данные копируются в приемник данных.</span><span class="sxs-lookup"><span data-stu-id="06cb5-225">Next, the data is copied from the staging data store to the sink data store.</span></span> <span data-ttu-id="06cb5-226">Фабрика данных автоматически управляет этой двухэтапной процедурой.</span><span class="sxs-lookup"><span data-stu-id="06cb5-226">Data Factory automatically manages the two-stage flow for you.</span></span> <span data-ttu-id="06cb5-227">По окончании перемещения данных фабрика данных удаляет временные данные из промежуточного хранилища.</span><span class="sxs-lookup"><span data-stu-id="06cb5-227">Data Factory also cleans up temporary data from the staging storage after the data movement is complete.</span></span>

<span data-ttu-id="06cb5-228">В случае облачного копирования (источник и приемник данных находятся в облаке) шлюз не используется.</span><span class="sxs-lookup"><span data-stu-id="06cb5-228">In the cloud copy scenario (both source and sink data stores are in the cloud), gateway is not used.</span></span> <span data-ttu-id="06cb5-229">Операции копирования выполняет служба фабрики данных.</span><span class="sxs-lookup"><span data-stu-id="06cb5-229">The Data Factory service performs the copy operations.</span></span>

![Промежуточное копирование: облачный сценарий](media/data-factory-copy-activity-performance/staged-copy-cloud-scenario.png)

<span data-ttu-id="06cb5-231">В сценарии гибридного копирования (источник размещен в локальной среде, а приемник — в облаке) шлюз перемещает данные из источника в промежуточное хранилище данных.</span><span class="sxs-lookup"><span data-stu-id="06cb5-231">In the hybrid copy scenario (source is on-premises and sink is in the cloud), the gateway moves data from the source data store to a staging data store.</span></span> <span data-ttu-id="06cb5-232">Оттуда служба фабрики данных перемещает данные в приемник.</span><span class="sxs-lookup"><span data-stu-id="06cb5-232">Data Factory service moves data from the staging data store to the sink data store.</span></span> <span data-ttu-id="06cb5-233">Копирование данных из облачного хранилища данных в локальное с использованием промежуточного хранилища данных также поддерживается при обратном процессе.</span><span class="sxs-lookup"><span data-stu-id="06cb5-233">Copying data from a cloud data store to an on-premises data store via staging also is supported with the reversed flow.</span></span>

![Промежуточное копирование: гибридный сценарий](media/data-factory-copy-activity-performance/staged-copy-hybrid-scenario.png)

<span data-ttu-id="06cb5-235">При активации функции промежуточного копирования перемещаемых данных можно настроить их сжатие перед переносом из источника в промежуточное хранилище, а также распаковку перед перемещением из промежуточного хранилища в приемник.</span><span class="sxs-lookup"><span data-stu-id="06cb5-235">When you activate data movement by using a staging store, you can specify whether you want the data to be compressed before moving data from the source data store to an interim or staging data store, and then decompressed before moving data from an interim or staging data store to the sink data store.</span></span>

<span data-ttu-id="06cb5-236">Сейчас промежуточное хранение при копировании данных между двумя локальными хранилищами не поддерживается.</span><span class="sxs-lookup"><span data-stu-id="06cb5-236">Currently, you can't copy data between two on-premises data stores by using a staging store.</span></span> <span data-ttu-id="06cb5-237">Ожидается, что эта возможность будет добавлена в ближайшее время.</span><span class="sxs-lookup"><span data-stu-id="06cb5-237">We expect this option to be available soon.</span></span>

### <a name="configuration"></a><span data-ttu-id="06cb5-238">Конфигурация</span><span class="sxs-lookup"><span data-stu-id="06cb5-238">Configuration</span></span>
<span data-ttu-id="06cb5-239">С помощью параметра **enableStaging** в разделе действий копирования укажите, следует ли копировать данные в промежуточное хранилище BLOB-объектов перед загрузкой в целевое хранилище данных.</span><span class="sxs-lookup"><span data-stu-id="06cb5-239">Configure the **enableStaging** setting in Copy Activity to specify whether you want the data to be staged in Blob storage before you load it into a destination data store.</span></span> <span data-ttu-id="06cb5-240">Если для параметра **enableStaging** задано значение true, укажите дополнительные свойства, перечисленные в таблице ниже.</span><span class="sxs-lookup"><span data-stu-id="06cb5-240">When you set **enableStaging** to TRUE, specify the additional properties listed in the next table.</span></span> <span data-ttu-id="06cb5-241">Если у вас нет промежуточного хранилища, необходимо создать для промежуточного хранения хранилище Azure или службу, связанную с подписанным URL-адресом хранилища.</span><span class="sxs-lookup"><span data-stu-id="06cb5-241">If you don’t have one, you also need to create an Azure Storage or Storage shared access signature-linked service for staging.</span></span>

| <span data-ttu-id="06cb5-242">Свойство</span><span class="sxs-lookup"><span data-stu-id="06cb5-242">Property</span></span> | <span data-ttu-id="06cb5-243">Описание</span><span class="sxs-lookup"><span data-stu-id="06cb5-243">Description</span></span> | <span data-ttu-id="06cb5-244">Значение по умолчанию</span><span class="sxs-lookup"><span data-stu-id="06cb5-244">Default value</span></span> | <span data-ttu-id="06cb5-245">Обязательно</span><span class="sxs-lookup"><span data-stu-id="06cb5-245">Required</span></span> |
| --- | --- | --- | --- |
| <span data-ttu-id="06cb5-246">**enableStaging**</span><span class="sxs-lookup"><span data-stu-id="06cb5-246">**enableStaging**</span></span> |<span data-ttu-id="06cb5-247">Укажите, следует ли копировать данные в промежуточное хранилище.</span><span class="sxs-lookup"><span data-stu-id="06cb5-247">Specify whether you want to copy data via an interim staging store.</span></span> |<span data-ttu-id="06cb5-248">Ложь</span><span class="sxs-lookup"><span data-stu-id="06cb5-248">False</span></span> |<span data-ttu-id="06cb5-249">Нет</span><span class="sxs-lookup"><span data-stu-id="06cb5-249">No</span></span> |
| <span data-ttu-id="06cb5-250">**linkedServiceName (имя связанной службы)**</span><span class="sxs-lookup"><span data-stu-id="06cb5-250">**linkedServiceName**</span></span> |<span data-ttu-id="06cb5-251">Укажите имя связанной службы [AzureStorage](data-factory-azure-blob-connector.md#azure-storage-linked-service) или [AzureStorageSas](data-factory-azure-blob-connector.md#azure-storage-sas-linked-service), которая будет ссылаться на используемый в качестве промежуточного экземпляр хранилища.</span><span class="sxs-lookup"><span data-stu-id="06cb5-251">Specify the name of an [AzureStorage](data-factory-azure-blob-connector.md#azure-storage-linked-service) or [AzureStorageSas](data-factory-azure-blob-connector.md#azure-storage-sas-linked-service) linked service, which refers to the instance of Storage that you use as an interim staging store.</span></span> <br/><br/> <span data-ttu-id="06cb5-252">Для загрузки данных в хранилище данных SQL с помощью PolyBase нельзя использовать хранилище с подписанным URL-адресом.</span><span class="sxs-lookup"><span data-stu-id="06cb5-252">You cannot use Storage with a shared access signature to load data into SQL Data Warehouse via PolyBase.</span></span> <span data-ttu-id="06cb5-253">Его можно использовать в других случаях.</span><span class="sxs-lookup"><span data-stu-id="06cb5-253">You can use it in all other scenarios.</span></span> |<span data-ttu-id="06cb5-254">Недоступно</span><span class="sxs-lookup"><span data-stu-id="06cb5-254">N/A</span></span> |<span data-ttu-id="06cb5-255">Да, если для параметра **enableStaging** задано значение true</span><span class="sxs-lookup"><span data-stu-id="06cb5-255">Yes, when **enableStaging** is set to TRUE</span></span> |
| <span data-ttu-id="06cb5-256">**path**</span><span class="sxs-lookup"><span data-stu-id="06cb5-256">**path**</span></span> |<span data-ttu-id="06cb5-257">Укажите путь к хранилищу BLOB-объектов, в котором будут храниться промежуточные данные.</span><span class="sxs-lookup"><span data-stu-id="06cb5-257">Specify the Blob storage path that you want to contain the staged data.</span></span> <span data-ttu-id="06cb5-258">В противном случае служба создаст контейнер для хранения временных данных.</span><span class="sxs-lookup"><span data-stu-id="06cb5-258">If you do not provide a path, the service creates a container to store temporary data.</span></span> <br/><br/> <span data-ttu-id="06cb5-259">Укажите путь, только если используется хранилище с подписанным URL-адресом или требуется, чтобы временные данные хранились в определенном месте.</span><span class="sxs-lookup"><span data-stu-id="06cb5-259">Specify a path only if you use Storage with a shared access signature, or you require temporary data to be in a specific location.</span></span> |<span data-ttu-id="06cb5-260">Недоступно</span><span class="sxs-lookup"><span data-stu-id="06cb5-260">N/A</span></span> |<span data-ttu-id="06cb5-261">Нет</span><span class="sxs-lookup"><span data-stu-id="06cb5-261">No</span></span> |
| <span data-ttu-id="06cb5-262">**enableCompression**</span><span class="sxs-lookup"><span data-stu-id="06cb5-262">**enableCompression**</span></span> |<span data-ttu-id="06cb5-263">Указывает, следует ли сжимать данные перед копированием в место назначения.</span><span class="sxs-lookup"><span data-stu-id="06cb5-263">Specifies whether data should be compressed before it is copied to the destination.</span></span> <span data-ttu-id="06cb5-264">Этот параметр позволяет уменьшить объем передаваемых данных.</span><span class="sxs-lookup"><span data-stu-id="06cb5-264">This setting reduces the volume of data being transferred.</span></span> |<span data-ttu-id="06cb5-265">Ложь</span><span class="sxs-lookup"><span data-stu-id="06cb5-265">False</span></span> |<span data-ttu-id="06cb5-266">Нет</span><span class="sxs-lookup"><span data-stu-id="06cb5-266">No</span></span> |

<span data-ttu-id="06cb5-267">Ниже приведен пример определения действия копирования со свойствами, описанными в приведенной выше таблице.</span><span class="sxs-lookup"><span data-stu-id="06cb5-267">Here's a sample definition of Copy Activity with the properties that are described in the preceding table:</span></span>

```json
"activities":[  
{
    "name": "Sample copy activity",
    "type": "Copy",
    "inputs": [{ "name": "OnpremisesSQLServerInput" }],
    "outputs": [{ "name": "AzureSQLDBOutput" }],
    "typeProperties": {
        "source": {
            "type": "SqlSource",
        },
        "sink": {
            "type": "SqlSink"
        },
        "enableStaging": true,
        "stagingSettings": {
            "linkedServiceName": "MyStagingBlob",
            "path": "stagingcontainer/path",
            "enableCompression": true
        }
    }
}
]
```

### <a name="billing-impact"></a><span data-ttu-id="06cb5-268">Принцип выставления счетов</span><span class="sxs-lookup"><span data-stu-id="06cb5-268">Billing impact</span></span>
<span data-ttu-id="06cb5-269">Взимаемая плата зависит от длительности и типа копирования.</span><span class="sxs-lookup"><span data-stu-id="06cb5-269">You are charged based on two steps: copy duration and copy type.</span></span>

* <span data-ttu-id="06cb5-270">При использовании промежуточного хранилища данных для облачного копирования (копирования данных между облачными хранилищами данных) счет формируется так: [сумма длительности копирования для этапов 1 и 2] x [цена за единицу облачного копирования].</span><span class="sxs-lookup"><span data-stu-id="06cb5-270">When you use staging during a cloud copy (copying data from a cloud data store to another cloud data store), you are charged the [sum of copy duration for step 1 and step 2] x [cloud copy unit price].</span></span>
* <span data-ttu-id="06cb5-271">При использовании промежуточного хранилища данных для гибридного копирования (копирования данных из локального хранилища данных в облачное хранилище данных) счет формируется так: [длительность гибридного копирования] x [цена за единицу гибридного копирования] + [длительность облачного копирования] x [цена за единицу облачного копирования].</span><span class="sxs-lookup"><span data-stu-id="06cb5-271">When you use staging during a hybrid copy (copying data from an on-premises data store to a cloud data store), you are charged for [hybrid copy duration] x [hybrid copy unit price] + [cloud copy duration] x [cloud copy unit price].</span></span>

## <a name="performance-tuning-steps"></a><span data-ttu-id="06cb5-272">Этапы настройки производительности</span><span class="sxs-lookup"><span data-stu-id="06cb5-272">Performance tuning steps</span></span>
<span data-ttu-id="06cb5-273">Мы советуем выполнить следующие действия, чтобы настроить производительность службы фабрики данных при использовании действия копирования.</span><span class="sxs-lookup"><span data-stu-id="06cb5-273">We suggest that you take these steps to tune the performance of your Data Factory service with Copy Activity:</span></span>

1. <span data-ttu-id="06cb5-274">**Определите базовые показатели**.</span><span class="sxs-lookup"><span data-stu-id="06cb5-274">**Establish a baseline**.</span></span> <span data-ttu-id="06cb5-275">Протестируйте конвейер на этапе разработки с помощью действия копирования на примере репрезентативных данных.</span><span class="sxs-lookup"><span data-stu-id="06cb5-275">During the development phase, test your pipeline by using Copy Activity against a representative data sample.</span></span> <span data-ttu-id="06cb5-276">Чтобы ограничить объем данных для тестирования, можно использовать [модель среза](data-factory-scheduling-and-execution.md) фабрики данных.</span><span class="sxs-lookup"><span data-stu-id="06cb5-276">You can use the Data Factory [slicing model](data-factory-scheduling-and-execution.md) to limit the amount of data you work with.</span></span>

   <span data-ttu-id="06cb5-277">Соберите показатели времени выполнения и производительности с помощью **приложения для мониторинга и управления**.</span><span class="sxs-lookup"><span data-stu-id="06cb5-277">Collect execution time and performance characteristics by using the **Monitoring and Management App**.</span></span> <span data-ttu-id="06cb5-278">На домашней странице фабрики данных выберите **Monitor & Manage** (Мониторинг и управление).</span><span class="sxs-lookup"><span data-stu-id="06cb5-278">Choose **Monitor & Manage** on your Data Factory home page.</span></span> <span data-ttu-id="06cb5-279">В представлении в виде дерева выберите **Output dataset** (Выходной набор данных).</span><span class="sxs-lookup"><span data-stu-id="06cb5-279">In the tree view, choose the **output dataset**.</span></span> <span data-ttu-id="06cb5-280">В списке **Activity Windows** (Окна действий) выберите выполнение действия копирования.</span><span class="sxs-lookup"><span data-stu-id="06cb5-280">In the **Activity Windows** list, choose the Copy Activity run.</span></span> <span data-ttu-id="06cb5-281">В списке **Activity Windows** (Окна действий) содержатся сведения о продолжительности действия копирования и объеме копируемых данных.</span><span class="sxs-lookup"><span data-stu-id="06cb5-281">**Activity Windows** lists the Copy Activity duration and the size of the data that's copied.</span></span> <span data-ttu-id="06cb5-282">Сведения о пропускной способности можно узнать в **обозревателе окон действий**.</span><span class="sxs-lookup"><span data-stu-id="06cb5-282">The throughput is listed in **Activity Window Explorer**.</span></span> <span data-ttu-id="06cb5-283">Чтобы узнать больше об этом приложении, ознакомьтесь со статьей [Мониторинг конвейеров фабрики данных Azure и управление ими с помощью нового приложения по мониторингу и управлению](data-factory-monitor-manage-app.md).</span><span class="sxs-lookup"><span data-stu-id="06cb5-283">To learn more about the app, see [Monitor and manage Azure Data Factory pipelines by using the Monitoring and Management App](data-factory-monitor-manage-app.md).</span></span>

   ![СВЕДЕНИЯ О ВЫПОЛНЕННОМ ДЕЙСТВИИ](./media/data-factory-copy-activity-performance/mmapp-activity-run-details.png)

   <span data-ttu-id="06cb5-285">Далее в этой статье вы можете сравнить показатели производительности и конфигурацию вашего сценария с [базовыми показателями производительности](#performance-reference) действия копирования, полученными в результате наших тестов.</span><span class="sxs-lookup"><span data-stu-id="06cb5-285">Later in the article, you can compare the performance and configuration of your scenario to Copy Activity’s [performance reference](#performance-reference) from our tests.</span></span>
2. <span data-ttu-id="06cb5-286">**Выполните диагностику состояния производительности и оптимизируйте ее.**Если наблюдаемая производительность не соответствует вашим ожиданиям, необходимо определить ее узкие места.</span><span class="sxs-lookup"><span data-stu-id="06cb5-286">**Diagnose and optimize performance**.</span></span> <span data-ttu-id="06cb5-287">После этого оптимизируйте производительность, чтобы устранить или уменьшить влияние узких мест.</span><span class="sxs-lookup"><span data-stu-id="06cb5-287">If the performance you observe doesn't meet your expectations, you need to identify performance bottlenecks.</span></span> <span data-ttu-id="06cb5-288">В этой статье не приведено полное описание диагностики производительности.</span><span class="sxs-lookup"><span data-stu-id="06cb5-288">Then, optimize performance to remove or reduce the effect of bottlenecks.</span></span> <span data-ttu-id="06cb5-289">Однако ниже даны некоторые общие рекомендации.</span><span class="sxs-lookup"><span data-stu-id="06cb5-289">A full description of performance diagnosis is beyond the scope of this article, but here are some common considerations:</span></span>

   * <span data-ttu-id="06cb5-290">Функции для повышения производительности:</span><span class="sxs-lookup"><span data-stu-id="06cb5-290">Performance features:</span></span>
     * [<span data-ttu-id="06cb5-291">Параллельное копирование</span><span class="sxs-lookup"><span data-stu-id="06cb5-291">Parallel copy</span></span>](#parallel-copy)
     * [<span data-ttu-id="06cb5-292">Облачные единицы перемещения данных</span><span class="sxs-lookup"><span data-stu-id="06cb5-292">Cloud data movement units</span></span>](#cloud-data-movement-units)
     * [<span data-ttu-id="06cb5-293">Промежуточное копирование</span><span class="sxs-lookup"><span data-stu-id="06cb5-293">Staged copy</span></span>](#staged-copy)
     * [<span data-ttu-id="06cb5-294">Масштабируемость шлюза управления данными</span><span class="sxs-lookup"><span data-stu-id="06cb5-294">Data Management Gateway scalability</span></span>](data-factory-data-management-gateway-high-availability-scalability.md)
   * [<span data-ttu-id="06cb5-295">Шлюз управления данными</span><span class="sxs-lookup"><span data-stu-id="06cb5-295">Data Management Gateway</span></span>](#considerations-for-data-management-gateway)
   * [<span data-ttu-id="06cb5-296">Источник</span><span class="sxs-lookup"><span data-stu-id="06cb5-296">Source</span></span>](#considerations-for-the-source)
   * [<span data-ttu-id="06cb5-297">Приемник</span><span class="sxs-lookup"><span data-stu-id="06cb5-297">Sink</span></span>](#considerations-for-the-sink)
   * [<span data-ttu-id="06cb5-298">Сериализация или десериализация</span><span class="sxs-lookup"><span data-stu-id="06cb5-298">Serialization and deserialization</span></span>](#considerations-for-serialization-and-deserialization)
   * [<span data-ttu-id="06cb5-299">Сжатие</span><span class="sxs-lookup"><span data-stu-id="06cb5-299">Compression</span></span>](#considerations-for-compression)
   * [<span data-ttu-id="06cb5-300">Сопоставление столбцов</span><span class="sxs-lookup"><span data-stu-id="06cb5-300">Column mapping</span></span>](#considerations-for-column-mapping)
   * [<span data-ttu-id="06cb5-301">Дополнительные рекомендации</span><span class="sxs-lookup"><span data-stu-id="06cb5-301">Other considerations</span></span>](#other-considerations)
3. <span data-ttu-id="06cb5-302">**Задайте конфигурацию для работы со всеми данными**.</span><span class="sxs-lookup"><span data-stu-id="06cb5-302">**Expand the configuration to your entire data set**.</span></span> <span data-ttu-id="06cb5-303">Если вас устраивают результаты выполнения и производительность, можно задать определение и активный период конвейера для всего набора данных.</span><span class="sxs-lookup"><span data-stu-id="06cb5-303">When you're satisfied with the execution results and performance, you can expand the definition and pipeline active period to cover your entire data set.</span></span>

## <a name="considerations-for-data-management-gateway"></a><span data-ttu-id="06cb5-304">Рекомендации относительно шлюза управления данными</span><span class="sxs-lookup"><span data-stu-id="06cb5-304">Considerations for Data Management Gateway</span></span>
<span data-ttu-id="06cb5-305">**Настройка шлюза.** Для размещения шлюза управления данными рекомендуется использовать выделенный компьютер.</span><span class="sxs-lookup"><span data-stu-id="06cb5-305">**Gateway setup**: We recommend that you use a dedicated machine to host Data Management Gateway.</span></span> <span data-ttu-id="06cb5-306">См. [Рекомендации относительно шлюза управления данными](data-factory-data-management-gateway.md#considerations-for-using-gateway).</span><span class="sxs-lookup"><span data-stu-id="06cb5-306">See [Considerations for using Data Management Gateway](data-factory-data-management-gateway.md#considerations-for-using-gateway).</span></span>  

<span data-ttu-id="06cb5-307">**Мониторинг шлюза и вертикальное и (или) горизонтальное масштабирование.** Один логический шлюз с одним узлом шлюза или несколькими может обслуживать несколько запусков действия копирования одновременно.</span><span class="sxs-lookup"><span data-stu-id="06cb5-307">**Gateway monitoring and scale-up/out**: A single logical gateway with one or more gateway nodes can serve multiple Copy Activity runs at the same time concurrently.</span></span> <span data-ttu-id="06cb5-308">На компьютере шлюза можно практически в режиме реального времени сделать моментальный снимок использования ресурсов (ЦП, памяти, сети [входящий/исходящий трафик] и т. д.), а также количество одновременно выполняемых заданий и соответствующее ограничение на портале Azure (см. также [Мониторинг шлюза на портале](data-factory-data-management-gateway.md#monitor-gateway-in-the-portal)).</span><span class="sxs-lookup"><span data-stu-id="06cb5-308">You can view near-real time snapshot of resource utilization (CPU, memory, network(in/out), etc.) on a gateway machine as well as the number of concurrent jobs running versus limit in the Azure portal, see [Monitor gateway in the portal](data-factory-data-management-gateway.md#monitor-gateway-in-the-portal).</span></span> <span data-ttu-id="06cb5-309">При наличии большого объема гибридных данных для переноса с большим количеством параллельных запусков действия копирования или большого объема данных для копирования рассмотрите возможность [вертикального или горизонтального масштабирования шлюза](data-factory-data-management-gateway-high-availability-scalability.md#scale-considerations), чтобы оптимально использовать ресурс или подготовить дополнительные ресурсы для расширения возможностей копирования.</span><span class="sxs-lookup"><span data-stu-id="06cb5-309">If you have heavy need on hybrid data movement either with large number of concurrent copy activity runs or with large volume of data to copy, consider to [scale up or scale out gateway](data-factory-data-management-gateway-high-availability-scalability.md#scale-considerations) so as to better utilize your resource or to provision more resource to empower copy.</span></span> 

## <a name="considerations-for-the-source"></a><span data-ttu-id="06cb5-310">Рекомендации для источника</span><span class="sxs-lookup"><span data-stu-id="06cb5-310">Considerations for the source</span></span>
### <a name="general"></a><span data-ttu-id="06cb5-311">Общие сведения</span><span class="sxs-lookup"><span data-stu-id="06cb5-311">General</span></span>
<span data-ttu-id="06cb5-312">Убедитесь, что базовое хранилище данных не переполнено другими рабочими нагрузками, выполняемыми в нем или при его задействовании.</span><span class="sxs-lookup"><span data-stu-id="06cb5-312">Be sure that the underlying data store is not overwhelmed by other workloads that are running on or against it.</span></span>

<span data-ttu-id="06cb5-313">Дополнительные сведения о хранилищах данных Майкрософт см. в [разделах о мониторинге и настройке](#performance-reference) для конкретных типов хранилищ данных. В них подробно рассмотрены базовые показатели производительности хранилища данных, способы сокращения времени отклика и повышения пропускной способности.</span><span class="sxs-lookup"><span data-stu-id="06cb5-313">For Microsoft data stores, see [monitoring and tuning topics](#performance-reference) that are specific to data stores, and help you understand data store performance characteristics, minimize response times, and maximize throughput.</span></span>

<span data-ttu-id="06cb5-314">При копировании данных из хранилища BLOB-объектов в хранилище данных SQL рассмотрите возможность использования функции **PolyBase**, позволяющей повысить производительность.</span><span class="sxs-lookup"><span data-stu-id="06cb5-314">If you copy data from Blob storage to SQL Data Warehouse, consider using **PolyBase** to boost performance.</span></span> <span data-ttu-id="06cb5-315">Дополнительные сведения см. в разделе [Загрузка данных в хранилище данных SQL Azure с помощью PolyBase](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse).</span><span class="sxs-lookup"><span data-stu-id="06cb5-315">See [Use PolyBase to load data into Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse) for details.</span></span> <span data-ttu-id="06cb5-316">Пошаговое руководство и пример использования см. в статье [Загрузка 1 ТБ в хранилище данных SQL Azure с помощью фабрики данных Azure [мастер копирования] менее чем за 15 минут](data-factory-load-sql-data-warehouse.md).</span><span class="sxs-lookup"><span data-stu-id="06cb5-316">For a walkthrough with a use case, see [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span></span>

### <a name="file-based-data-stores"></a><span data-ttu-id="06cb5-317">Файловые хранилища данных</span><span class="sxs-lookup"><span data-stu-id="06cb5-317">File-based data stores</span></span>
<span data-ttu-id="06cb5-318">*(Хранилище BLOB-объектов, Data Lake Store, Amazon S3, локальные файловые системы и локальная файловая система HDFS.)*</span><span class="sxs-lookup"><span data-stu-id="06cb5-318">*(Includes Blob storage, Data Lake Store, Amazon S3, on-premises file systems, and on-premises HDFS)*</span></span>

* <span data-ttu-id="06cb5-319">**Средний размер файла и их количество**. Действие копирования передает данные в пофайловом режиме.</span><span class="sxs-lookup"><span data-stu-id="06cb5-319">**Average file size and file count**: Copy Activity transfers data one file at a time.</span></span> <span data-ttu-id="06cb5-320">При одинаковом объеме данных общая пропускная способность перемещения данных, которые состоят из большого количества небольших файлов, будет ниже, чем в случае перемещения данных, которые состоят из небольшого количества файлов большего размера. Это происходит из-за времени начальной загрузки каждого файла.</span><span class="sxs-lookup"><span data-stu-id="06cb5-320">With the same amount of data to be moved, the overall throughput is lower if the data consists of many small files rather than a few large files due to the bootstrap phase for each file.</span></span> <span data-ttu-id="06cb5-321">Поэтому для получения более высокой пропускной способности по возможности следует объединить небольшие файлы в файлы большего размера.</span><span class="sxs-lookup"><span data-stu-id="06cb5-321">Therefore, if possible, combine small files into larger files to gain higher throughput.</span></span>
* <span data-ttu-id="06cb5-322">**Формат файла и сжатие**. Дополнительные сведения о способах повышения производительности см. в разделах [Рекомендации по сериализации и десериализации](#considerations-for-serialization-and-deserialization) и [Рекомендации по сжатию](#considerations-for-compression).</span><span class="sxs-lookup"><span data-stu-id="06cb5-322">**File format and compression**: For more ways to improve performance, see the [Considerations for serialization and deserialization](#considerations-for-serialization-and-deserialization) and [Considerations for compression](#considerations-for-compression) sections.</span></span>
* <span data-ttu-id="06cb5-323">Дополнительные сведения о сценарии с использованием **локальной файловой системы**, в котором применяется **шлюз управления данными**, см. в разделе [Рекомендации относительно шлюза управления данными](#considerations-for-data-management-gateway).</span><span class="sxs-lookup"><span data-stu-id="06cb5-323">For the **on-premises file system** scenario, in which **Data Management Gateway** is required, see the [Considerations for Data Management Gateway](#considerations-for-data-management-gateway) section.</span></span>

### <a name="relational-data-stores"></a><span data-ttu-id="06cb5-324">Реляционные хранилища данных</span><span class="sxs-lookup"><span data-stu-id="06cb5-324">Relational data stores</span></span>
<span data-ttu-id="06cb5-325">*(База данных SQL, хранилище данных SQL, Amazon Redshift, базы данных SQL Server, а также базы данных Oracle, MySQL, DB2, Teradata, Sybase и PostgreSQL.)*</span><span class="sxs-lookup"><span data-stu-id="06cb5-325">*(Includes SQL Database; SQL Data Warehouse; Amazon Redshift; SQL Server databases; and Oracle, MySQL, DB2, Teradata, Sybase, and PostgreSQL databases, etc.)*</span></span>

* <span data-ttu-id="06cb5-326">**Шаблон данных.**Схема таблицы влияет на пропускную способность копирования.</span><span class="sxs-lookup"><span data-stu-id="06cb5-326">**Data pattern**: Your table schema affects copy throughput.</span></span> <span data-ttu-id="06cb5-327">При копировании одинакового общего объема данных большой размер строки обеспечивает лучшую производительность, чем небольшой размер строки.</span><span class="sxs-lookup"><span data-stu-id="06cb5-327">A large row size gives you a better performance than small row size, to copy the same amount of data.</span></span> <span data-ttu-id="06cb5-328">Причина состоит в том, что база данных может более эффективно извлекать меньшее число пакетов данных, которые содержат меньше строк.</span><span class="sxs-lookup"><span data-stu-id="06cb5-328">The reason is that the database can more efficiently retrieve fewer batches of data that contain fewer rows.</span></span>
* <span data-ttu-id="06cb5-329">**Запрос или хранимая процедура.**Оптимизируйте логику запроса или хранимой процедуры, указываемую в источнике действия копирования, чтобы более эффективно извлекать данные.</span><span class="sxs-lookup"><span data-stu-id="06cb5-329">**Query or stored procedure**: Optimize the logic of the query or stored procedure you specify in the Copy Activity source to fetch data more efficiently.</span></span>
* <span data-ttu-id="06cb5-330">Дополнительные сведения о **локальных реляционных базах данных**, таких как SQL Server и Oracle, где требуется **шлюз управления данными**, см. в разделе [Рекомендации относительно шлюза управления данными](#considerations-on-data-management-gateway).</span><span class="sxs-lookup"><span data-stu-id="06cb5-330">For **on-premises relational databases**, such as SQL Server and Oracle, which require the use of **Data Management Gateway**, see the [Considerations for Data Management Gateway](#considerations-on-data-management-gateway) section.</span></span>

## <a name="considerations-for-the-sink"></a><span data-ttu-id="06cb5-331">Рекомендации для приемника</span><span class="sxs-lookup"><span data-stu-id="06cb5-331">Considerations for the sink</span></span>
### <a name="general"></a><span data-ttu-id="06cb5-332">Общие сведения</span><span class="sxs-lookup"><span data-stu-id="06cb5-332">General</span></span>
<span data-ttu-id="06cb5-333">Убедитесь, что базовое хранилище данных не переполнено другими рабочими нагрузками, выполняемыми в нем или при его задействовании.</span><span class="sxs-lookup"><span data-stu-id="06cb5-333">Be sure that the underlying data store is not overwhelmed by other workloads that are running on or against it.</span></span>

<span data-ttu-id="06cb5-334">Дополнительные сведения о хранилищах данных Microsoft см. в [разделах о мониторинге и настройке](#performance-reference) для конкретных типов хранилищ данных.</span><span class="sxs-lookup"><span data-stu-id="06cb5-334">For Microsoft data stores, refer to [monitoring and tuning topics](#performance-reference) that are specific to data stores.</span></span> <span data-ttu-id="06cb5-335">В них подробно рассмотрены базовые показатели производительности хранилища данных, способы сокращения времени отклика и повышения пропускной способности.</span><span class="sxs-lookup"><span data-stu-id="06cb5-335">These topics can help you understand data store performance characteristics and how to minimize response times and maximize throughput.</span></span>

<span data-ttu-id="06cb5-336">При копировании данных из **хранилища BLOB-объектов** в **хранилище данных SQL** рассмотрите возможность использования функции **PolyBase**, позволяющей повысить производительность.</span><span class="sxs-lookup"><span data-stu-id="06cb5-336">If you are copying data from **Blob storage** to **SQL Data Warehouse**, consider using **PolyBase** to boost performance.</span></span> <span data-ttu-id="06cb5-337">Дополнительные сведения см. в разделе [Загрузка данных в хранилище данных SQL Azure с помощью PolyBase](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse).</span><span class="sxs-lookup"><span data-stu-id="06cb5-337">See [Use PolyBase to load data into Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse) for details.</span></span> <span data-ttu-id="06cb5-338">Пошаговое руководство и пример использования см. в статье [Загрузка 1 ТБ в хранилище данных SQL Azure с помощью фабрики данных Azure [мастер копирования] менее чем за 15 минут](data-factory-load-sql-data-warehouse.md).</span><span class="sxs-lookup"><span data-stu-id="06cb5-338">For a walkthrough with a use case, see [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span></span>

### <a name="file-based-data-stores"></a><span data-ttu-id="06cb5-339">Файловые хранилища данных</span><span class="sxs-lookup"><span data-stu-id="06cb5-339">File-based data stores</span></span>
<span data-ttu-id="06cb5-340">*(Хранилище BLOB-объектов, Data Lake Store, Amazon S3, локальные файловые системы и локальная файловая система HDFS.)*</span><span class="sxs-lookup"><span data-stu-id="06cb5-340">*(Includes Blob storage, Data Lake Store, Amazon S3, on-premises file systems, and on-premises HDFS)*</span></span>

* <span data-ttu-id="06cb5-341">**Режим копирования**. При копировании данных из файлового хранилища для действия копирования можно задать три разных режима с помощью свойства **copyBehavior**:</span><span class="sxs-lookup"><span data-stu-id="06cb5-341">**Copy behavior**: If you copy data from a different file-based data store, Copy Activity has three options via the **copyBehavior** property.</span></span> <span data-ttu-id="06cb5-342">сохранение иерархии, преобразование в плоскую структуру или объединение файлов.</span><span class="sxs-lookup"><span data-stu-id="06cb5-342">It preserves hierarchy, flattens hierarchy, or merges files.</span></span> <span data-ttu-id="06cb5-343">Сохранение иерархии или преобразование в плоскую структуру практически не оказывает влияния на производительность, в то время как объединение файлов существенно ее ухудшает.</span><span class="sxs-lookup"><span data-stu-id="06cb5-343">Either preserving or flattening hierarchy has little or no performance overhead, but merging files causes performance overhead to increase.</span></span>
* <span data-ttu-id="06cb5-344">**Формат файла и сжатие**. Дополнительные сведения о способах повышения производительности см. в разделах [Рекомендации по сериализации и десериализации](#considerations-for-serialization-and-deserialization) и [Рекомендации по сжатию](#considerations-for-compression).</span><span class="sxs-lookup"><span data-stu-id="06cb5-344">**File format and compression**: See the [Considerations for serialization and deserialization](#considerations-for-serialization-and-deserialization) and [Considerations for compression](#considerations-for-compression) sections for more ways to improve performance.</span></span>
* <span data-ttu-id="06cb5-345">**Хранилище BLOB-объектов.**В настоящее время оптимизация передачи данных и пропускной способности поддерживается только для блочных BLOB-объектов.</span><span class="sxs-lookup"><span data-stu-id="06cb5-345">**Blob storage**: Currently, Blob storage supports only block blobs for optimized data transfer and throughput.</span></span>
* <span data-ttu-id="06cb5-346">Дополнительные сведения о сценарии с использованием **локальной файловой системы**, в котором применяется **шлюз управления данными**, см. в разделе [Рекомендации относительно шлюза управления данными](#considerations-for-data-management-gateway).</span><span class="sxs-lookup"><span data-stu-id="06cb5-346">For **on-premises file systems** scenarios that require the use of **Data Management Gateway**, see the [Considerations for Data Management Gateway](#considerations-for-data-management-gateway) section.</span></span>

### <a name="relational-data-stores"></a><span data-ttu-id="06cb5-347">Реляционные хранилища данных</span><span class="sxs-lookup"><span data-stu-id="06cb5-347">Relational data stores</span></span>
<span data-ttu-id="06cb5-348">*(База данных SQL, хранилище данных SQL, базы данных SQL Server и базы данных Oracle.)*</span><span class="sxs-lookup"><span data-stu-id="06cb5-348">*(Includes SQL Database, SQL Data Warehouse, SQL Server databases, and Oracle databases)*</span></span>

* <span data-ttu-id="06cb5-349">**Режим копирования**. В зависимости от свойств, заданных для **sqlSink**, существует несколько вариантов записи данных в базу данных назначения при выполнении действия копирования.</span><span class="sxs-lookup"><span data-stu-id="06cb5-349">**Copy behavior**: Depending on the properties you've set for **sqlSink**, Copy Activity writes data to the destination database in different ways.</span></span>
  * <span data-ttu-id="06cb5-350">По умолчанию служба перемещения данных использует интерфейс API массового копирования для вставки данных в режиме добавления, что обеспечивает лучшую производительность.</span><span class="sxs-lookup"><span data-stu-id="06cb5-350">By default, the data movement service uses the Bulk Copy API to insert data in append mode, which provides the best performance.</span></span>
  * <span data-ttu-id="06cb5-351">Если настроить в приемнике хранимую процедуру, данные в базу данных будут записываться в построчном режиме, а не массово.</span><span class="sxs-lookup"><span data-stu-id="06cb5-351">If you configure a stored procedure in the sink, the database applies the data one row at a time instead of as a bulk load.</span></span> <span data-ttu-id="06cb5-352">Это существенно снижает производительность.</span><span class="sxs-lookup"><span data-stu-id="06cb5-352">Performance drops significantly.</span></span> <span data-ttu-id="06cb5-353">В случае с набором данных большого размера рекомендуется использовать свойство **sqlWriterCleanupScript** , если это применимо.</span><span class="sxs-lookup"><span data-stu-id="06cb5-353">If your data set is large, when applicable, consider switching to using the **sqlWriterCleanupScript** property.</span></span>
  * <span data-ttu-id="06cb5-354">Если настроить свойство **sqlWriterCleanupScript** , при каждом действии копирования для вставки данных служба сначала запустит сценарий, а затем использует интерфейс API массового копирования.</span><span class="sxs-lookup"><span data-stu-id="06cb5-354">If you configure the **sqlWriterCleanupScript** property for each Copy Activity run, the service triggers the script, and then you use the Bulk Copy API to insert the data.</span></span> <span data-ttu-id="06cb5-355">Например, чтобы перезаписать всю таблицу последними данными, перед массовой загрузкой новых данных из источника можно указать сценарий для удаления всех записей.</span><span class="sxs-lookup"><span data-stu-id="06cb5-355">For example, to overwrite the entire table with the latest data, you can specify a script to first delete all records before bulk-loading the new data from the source.</span></span>
* <span data-ttu-id="06cb5-356">**Шаблон данных и размер пакета**.</span><span class="sxs-lookup"><span data-stu-id="06cb5-356">**Data pattern and batch size**:</span></span>
  * <span data-ttu-id="06cb5-357">Схема таблицы влияет на пропускную способность копирования.</span><span class="sxs-lookup"><span data-stu-id="06cb5-357">Your table schema affects copy throughput.</span></span> <span data-ttu-id="06cb5-358">Во время копирования данных одинакового объема использование строк большого размера позволяет добиться лучшей производительности, чем при использовании строк небольшого размера. Это связано с тем, что база данных более эффективно сохраняет меньшее количество пакетов данных.</span><span class="sxs-lookup"><span data-stu-id="06cb5-358">To copy the same amount of data, a large row size gives you better performance than a small row size because the database can more efficiently commit fewer batches of data.</span></span>
  * <span data-ttu-id="06cb5-359">Действие копирования вставляет данные в виде последовательности пакетов.</span><span class="sxs-lookup"><span data-stu-id="06cb5-359">Copy Activity inserts data in a series of batches.</span></span> <span data-ttu-id="06cb5-360">Количество строк в пакете можно задать с помощью свойства **writeBatchSize** .</span><span class="sxs-lookup"><span data-stu-id="06cb5-360">You can set the number of rows in a batch by using the **writeBatchSize** property.</span></span> <span data-ttu-id="06cb5-361">Если данные содержатся в строках небольшого размера, можно задать для свойства **writeBatchSize** более высокое значение, чтобы использовать меньшее количество пакетов и тем самым увеличить пропускную способность.</span><span class="sxs-lookup"><span data-stu-id="06cb5-361">If your data has small rows, you can set the **writeBatchSize** property with a higher value to benefit from lower batch overhead and higher throughput.</span></span> <span data-ttu-id="06cb5-362">Если данные содержатся в строках большого размера, будьте внимательны при увеличении **writeBatchSize**.</span><span class="sxs-lookup"><span data-stu-id="06cb5-362">If the row size of your data is large, be careful when you increase **writeBatchSize**.</span></span> <span data-ttu-id="06cb5-363">Высокое значение может привести к сбою копирования из-за перегрузки базы данных.</span><span class="sxs-lookup"><span data-stu-id="06cb5-363">A high value might lead to a copy failure caused by overloading the database.</span></span>
* <span data-ttu-id="06cb5-364">Дополнительные сведения о **локальных реляционных базах данных**, таких как SQL Server и Oracle, где требуется **шлюз управления данными**, см. в разделе [Рекомендации относительно шлюза управления данными](#considerations-for-data-management-gateway).</span><span class="sxs-lookup"><span data-stu-id="06cb5-364">For **on-premises relational databases** like SQL Server and Oracle, which require the use of **Data Management Gateway**, see the [Considerations for Data Management Gateway](#considerations-for-data-management-gateway) section.</span></span>

### <a name="nosql-stores"></a><span data-ttu-id="06cb5-365">Хранилища NoSQL</span><span class="sxs-lookup"><span data-stu-id="06cb5-365">NoSQL stores</span></span>
<span data-ttu-id="06cb5-366">*(Хранилище таблиц и Azure Cosmos DB.)*</span><span class="sxs-lookup"><span data-stu-id="06cb5-366">*(Includes Table storage and Azure Cosmos DB )*</span></span>

* <span data-ttu-id="06cb5-367">Для **хранилища таблиц**:</span><span class="sxs-lookup"><span data-stu-id="06cb5-367">For **Table storage**:</span></span>
  * <span data-ttu-id="06cb5-368">**Секционирование**. Запись данных в секции с чередованием значительно снижает производительность.</span><span class="sxs-lookup"><span data-stu-id="06cb5-368">**Partition**: Writing data to interleaved partitions dramatically degrades performance.</span></span> <span data-ttu-id="06cb5-369">Отсортируйте исходные данные по ключу секции, чтобы эффективно вставлять данные в секцию за секцией. Можно также настроить логику для записи данных в одну секцию.</span><span class="sxs-lookup"><span data-stu-id="06cb5-369">Sort your source data by partition key so that the data is inserted efficiently into one partition after another, or adjust the logic to write the data to a single partition.</span></span>
* <span data-ttu-id="06cb5-370">Для **Azure Cosmos DB**:</span><span class="sxs-lookup"><span data-stu-id="06cb5-370">For **Azure Cosmos DB**:</span></span>
  * <span data-ttu-id="06cb5-371">**Размер пакета**. Свойство **writeBatchSize** задает количество параллельных запросов на создание документов в службе Azure Cosmos DB.</span><span class="sxs-lookup"><span data-stu-id="06cb5-371">**Batch size**: The **writeBatchSize** property sets the number of parallel requests to the Azure Cosmos DB service to create documents.</span></span> <span data-ttu-id="06cb5-372">Если увеличить значение свойства **writeBatchSize** , то производительность повышается, потому что в Azure Cosmos DB начинает уходить больше параллельных запросов.</span><span class="sxs-lookup"><span data-stu-id="06cb5-372">You can expect better performance when you increase **writeBatchSize** because more parallel requests are sent to Azure Cosmos DB.</span></span> <span data-ttu-id="06cb5-373">Однако при записи в Azure Cosmos DB необходимо следить за регулированием (может появиться сообщение об ошибке "Высокая частота запросов").</span><span class="sxs-lookup"><span data-stu-id="06cb5-373">However, watch for throttling when you write to Azure Cosmos DB (the error message is "Request rate is large").</span></span> <span data-ttu-id="06cb5-374">Регулирование могут вызвать различные факторы, в частности размер документа, количество терминов в документах и политика индексирования целевой коллекции.</span><span class="sxs-lookup"><span data-stu-id="06cb5-374">Various factors can cause throttling, including document size, the number of terms in the documents, and the target collection's indexing policy.</span></span> <span data-ttu-id="06cb5-375">Чтобы добиться более высокой пропускной способности копирования, рекомендуется использовать лучшую коллекцию, например S3.</span><span class="sxs-lookup"><span data-stu-id="06cb5-375">To achieve higher copy throughput, consider using a better collection, for example, S3.</span></span>

## <a name="considerations-for-serialization-and-deserialization"></a><span data-ttu-id="06cb5-376">Рекомендации по сериализации и десериализации</span><span class="sxs-lookup"><span data-stu-id="06cb5-376">Considerations for serialization and deserialization</span></span>
<span data-ttu-id="06cb5-377">Сериализация и десериализация могут произойти, если входной или выходной набор данных представляет собой файл.</span><span class="sxs-lookup"><span data-stu-id="06cb5-377">Serialization and deserialization can occur when your input data set or output data set is a file.</span></span> <span data-ttu-id="06cb5-378">Дополнительные сведения о форматах файлов, поддерживаемых действием копирования, см. в статье [Форматы файлов и сжатия данных, поддерживаемые фабрикой данных Azure](data-factory-supported-file-and-compression-formats.md).</span><span class="sxs-lookup"><span data-stu-id="06cb5-378">See [Supported file and compression formats](data-factory-supported-file-and-compression-formats.md) with details on supported file formats by Copy Activity.</span></span>

<span data-ttu-id="06cb5-379">**Режим копирования.**</span><span class="sxs-lookup"><span data-stu-id="06cb5-379">**Copy behavior**:</span></span>

* <span data-ttu-id="06cb5-380">При копировании файлов между файловыми хранилищами данных:</span><span class="sxs-lookup"><span data-stu-id="06cb5-380">Copying files between file-based data stores:</span></span>
  * <span data-ttu-id="06cb5-381">Если параметры формата файла входного и выходного наборов данных одинаковые, служба перемещения данных выполнит двоичное копирование без сериализации или десериализации.</span><span class="sxs-lookup"><span data-stu-id="06cb5-381">When input and output data sets both have the same or no file format settings, the data movement service executes a binary copy without any serialization or deserialization.</span></span> <span data-ttu-id="06cb5-382">В этом случае пропускная способность будет более высокой, чем в сценарии, когда параметры формата файла источника и приемника отличаются друг от друга.</span><span class="sxs-lookup"><span data-stu-id="06cb5-382">You see a higher throughput compared to the scenario, in which the source and sink file format settings are different from each other.</span></span>
  * <span data-ttu-id="06cb5-383">Если входной и выходной наборы данных находятся в текстовом формате и отличаются только типом кодирования, служба перемещения данных выполнит только преобразование кодирования.</span><span class="sxs-lookup"><span data-stu-id="06cb5-383">When input and output data sets both are in text format and only the encoding type is different, the data movement service only does encoding conversion.</span></span> <span data-ttu-id="06cb5-384">При этом сериализация и десериализация применяться не будут. По сравнению с двоичным копированием, это совсем незначительно повлияет на производительность.</span><span class="sxs-lookup"><span data-stu-id="06cb5-384">It doesn't do any serialization and deserialization, which causes some performance overhead compared to a binary copy.</span></span>
  * <span data-ttu-id="06cb5-385">Если входной и выходной наборы данных представлены в разных форматах файлов или имеют разные конфигурации, например отличаются разделителями, то служба перемещения данных десериализует исходные данные для их потоковой передачи, преобразования и сериализации в указанный формат выходных данных.</span><span class="sxs-lookup"><span data-stu-id="06cb5-385">When input and output data sets both have different file formats or different configurations, like delimiters, the data movement service deserializes source data to stream, transform, and then serialize it into the output format you indicated.</span></span> <span data-ttu-id="06cb5-386">В отличие от предыдущих сценариев, это приведет к более значительному снижению производительности.</span><span class="sxs-lookup"><span data-stu-id="06cb5-386">This operation results in a much more significant performance overhead compared to other scenarios.</span></span>
* <span data-ttu-id="06cb5-387">При копировании файлов в хранилище данных, которое не является файловым, или из него (например, из файлового хранилища в реляционное) требуется операция сериализации или десериализации.</span><span class="sxs-lookup"><span data-stu-id="06cb5-387">When you copy files to/from a data store that is not file-based (for example, from a file-based store to a relational store), the serialization or deserialization step is required.</span></span> <span data-ttu-id="06cb5-388">Этот шаг существенно снижает производительность.</span><span class="sxs-lookup"><span data-stu-id="06cb5-388">This step results in significant performance overhead.</span></span>

<span data-ttu-id="06cb5-389">**Формат файла**. Используемый формат файла может повлиять на производительность копирования.</span><span class="sxs-lookup"><span data-stu-id="06cb5-389">**File format**: The file format you choose might affect copy performance.</span></span> <span data-ttu-id="06cb5-390">К примеру, Avro — это компактный двоичный формат, в котором хранятся метаданные с данными.</span><span class="sxs-lookup"><span data-stu-id="06cb5-390">For example, Avro is a compact binary format that stores metadata with data.</span></span> <span data-ttu-id="06cb5-391">Этот формат поддерживает экосистема Hadoop для обработки и выполнения запросов.</span><span class="sxs-lookup"><span data-stu-id="06cb5-391">It has broad support in the Hadoop ecosystem for processing and querying.</span></span> <span data-ttu-id="06cb5-392">Однако стоимость формата Avro для сериализации или десериализации выше, а пропускная способность копирования ниже по сравнению с текстовым форматом.</span><span class="sxs-lookup"><span data-stu-id="06cb5-392">However, Avro is more expensive for serialization and deserialization, which results in lower copy throughput compared to text format.</span></span> <span data-ttu-id="06cb5-393">Формат файла, который необходимо использовать в процессе обработки, следует выбирать, принимая во внимание все элементы —</span><span class="sxs-lookup"><span data-stu-id="06cb5-393">Make your choice of file format throughout the processing flow holistically.</span></span> <span data-ttu-id="06cb5-394">от формы данных, хранимых в исходных хранилищах данных или извлекаемых из внешних систем, лучшего формата для хранения, аналитической обработки и выполнения запросов до формата, в котором следует экспортировать данные в киоски данных для средств создания отчетов и визуализации данных.</span><span class="sxs-lookup"><span data-stu-id="06cb5-394">Start with what form the data is stored in, source data stores or to be extracted from external systems; the best format for storage, analytical processing, and querying; and in what format the data should be exported into data marts for reporting and visualization tools.</span></span> <span data-ttu-id="06cb5-395">Иногда формат файла, который не является достаточно оптимальным для производительности операций чтения и записи, может отлично подойти, учитывая общий аналитический процесс.</span><span class="sxs-lookup"><span data-stu-id="06cb5-395">Sometimes a file format that is suboptimal for read and write performance might be a good choice when you consider the overall analytical process.</span></span>

## <a name="considerations-for-compression"></a><span data-ttu-id="06cb5-396">Рекомендации по сжатию</span><span class="sxs-lookup"><span data-stu-id="06cb5-396">Considerations for compression</span></span>
<span data-ttu-id="06cb5-397">Если входной или выходной набор данных представляет собой файл, для действия копирования можно настроить сжатие или распаковку данных при записи в место назначения.</span><span class="sxs-lookup"><span data-stu-id="06cb5-397">When your input or output data set is a file, you can set Copy Activity to perform compression or decompression as it writes data to the destination.</span></span> <span data-ttu-id="06cb5-398">Использование сжатия — это компромисс между количеством операций ввода-вывода и потреблением ЦП,</span><span class="sxs-lookup"><span data-stu-id="06cb5-398">When you choose compression, you make a tradeoff between input/output (I/O) and CPU.</span></span> <span data-ttu-id="06cb5-399">так как для сжатия данных требуются дополнительные вычислительные ресурсы.</span><span class="sxs-lookup"><span data-stu-id="06cb5-399">Compressing the data costs extra in compute resources.</span></span> <span data-ttu-id="06cb5-400">Однако взамен уменьшается количество сетевых операций ввода-вывода и используемый объем хранилища.</span><span class="sxs-lookup"><span data-stu-id="06cb5-400">But in return, it reduces network I/O and storage.</span></span> <span data-ttu-id="06cb5-401">В зависимости от данных это может повысить общую пропускную способность копирования.</span><span class="sxs-lookup"><span data-stu-id="06cb5-401">Depending on your data, you may see a boost in overall copy throughput.</span></span>

<span data-ttu-id="06cb5-402">**Кодек.**Действие копирования поддерживает такие типы сжатия: GZIP, BZIP2 и DEFLATE.</span><span class="sxs-lookup"><span data-stu-id="06cb5-402">**Codec**: Copy Activity supports gzip, bzip2, and Deflate compression types.</span></span> <span data-ttu-id="06cb5-403">Все три типа можно использовать для обработки в Azure HDInsight.</span><span class="sxs-lookup"><span data-stu-id="06cb5-403">Azure HDInsight can consume all three types for processing.</span></span> <span data-ttu-id="06cb5-404">Каждый кодек сжатия имеет свои преимущества.</span><span class="sxs-lookup"><span data-stu-id="06cb5-404">Each compression codec has advantages.</span></span> <span data-ttu-id="06cb5-405">Например, кодек BZIP2 обладает минимальной пропускной способностью копирования, но предоставляет лучшую производительность выполнения запросов Hive, так как ее можно разделить для обработки.</span><span class="sxs-lookup"><span data-stu-id="06cb5-405">For example, bzip2 has the lowest copy throughput, but you get the best Hive query performance with bzip2 because you can split it for processing.</span></span> <span data-ttu-id="06cb5-406">Кодек GZIP — это наиболее оптимальный вариант, который используется чаще всего.</span><span class="sxs-lookup"><span data-stu-id="06cb5-406">Gzip is the most balanced option, and it is used the most often.</span></span> <span data-ttu-id="06cb5-407">Следует выбрать кодек, который лучше всего подходит для комплексного сценария.</span><span class="sxs-lookup"><span data-stu-id="06cb5-407">Choose the codec that best suits your end-to-end scenario.</span></span>

<span data-ttu-id="06cb5-408">**Уровень.**Для каждого кодека сжатия можно выбрать один из двух параметров — самое быстрое сжатие или оптимальное сжатие.</span><span class="sxs-lookup"><span data-stu-id="06cb5-408">**Level**: You can choose from two options for each compression codec: fastest compressed and optimally compressed.</span></span> <span data-ttu-id="06cb5-409">Если использовать параметр самого быстрого сжатия, данные сжимаются как можно быстрее, даже если итоговый файл сжимается не оптимально.</span><span class="sxs-lookup"><span data-stu-id="06cb5-409">The fastest compressed option compresses the data as quickly as possible, even if the resulting file is not optimally compressed.</span></span> <span data-ttu-id="06cb5-410">Если использовать параметр оптимального сжатия, данные сжимаются дольше, предоставляя минимальный объем данных.</span><span class="sxs-lookup"><span data-stu-id="06cb5-410">The optimally compressed option spends more time on compression and yields a minimal amount of data.</span></span> <span data-ttu-id="06cb5-411">Можно испытать оба варианта, чтобы увидеть, который из них обеспечивает лучшую общую производительность в определенном случае.</span><span class="sxs-lookup"><span data-stu-id="06cb5-411">You can test both options to see which provides better overall performance in your case.</span></span>

<span data-ttu-id="06cb5-412">**Рекомендация**. При копировании данных большого объема между локальным хранилищем и облаком для сжатия можно использовать промежуточное хранилище BLOB-объектов.</span><span class="sxs-lookup"><span data-stu-id="06cb5-412">**A consideration**: To copy a large amount of data between an on-premises store and the cloud, consider using interim blob storage with compression.</span></span> <span data-ttu-id="06cb5-413">Промежуточное хранилище эффективно использовать, когда пропускная способность корпоративной сети и служб Azure является ограничивающим фактором и требуется, чтобы входной и выходной наборы данных были в несжатом виде.</span><span class="sxs-lookup"><span data-stu-id="06cb5-413">Using interim storage is helpful when the bandwidth of your corporate network and your Azure services is the limiting factor, and you want the input data set and output data set both to be in uncompressed form.</span></span> <span data-ttu-id="06cb5-414">В частности, можно разбить одно действие копирования на два действия:</span><span class="sxs-lookup"><span data-stu-id="06cb5-414">More specifically, you can break a single copy activity into two copy activities.</span></span> <span data-ttu-id="06cb5-415">первое действие копирования будет копировать данные из источника в промежуточный большой двоичный объект в сжатом виде,</span><span class="sxs-lookup"><span data-stu-id="06cb5-415">The first copy activity copies from the source to an interim or staging blob in compressed form.</span></span> <span data-ttu-id="06cb5-416">а второе действие копирования будет копировать сжатые данные из этого объекта и распаковывать их во время записи в приемник.</span><span class="sxs-lookup"><span data-stu-id="06cb5-416">The second copy activity copies the compressed data from staging, and then decompresses while it writes to the sink.</span></span>

## <a name="considerations-for-column-mapping"></a><span data-ttu-id="06cb5-417">Рекомендации по сопоставлению столбцов</span><span class="sxs-lookup"><span data-stu-id="06cb5-417">Considerations for column mapping</span></span>
<span data-ttu-id="06cb5-418">В действии копирования можно задать свойство **columnMappings** для сопоставления всех входных столбцов или их подмножества с выходными столбцами.</span><span class="sxs-lookup"><span data-stu-id="06cb5-418">You can set the **columnMappings** property in Copy Activity to map all or a subset of the input columns to the output columns.</span></span> <span data-ttu-id="06cb5-419">После считывания данных из источника службе перемещения данных требуется выполнить сопоставление столбцов данных, прежде чем записать их в приемник.</span><span class="sxs-lookup"><span data-stu-id="06cb5-419">After the data movement service reads the data from the source, it needs to perform column mapping on the data before it writes the data to the sink.</span></span> <span data-ttu-id="06cb5-420">Эта дополнительная обработка снижает пропускную способность копирования.</span><span class="sxs-lookup"><span data-stu-id="06cb5-420">This extra processing reduces copy throughput.</span></span>

<span data-ttu-id="06cb5-421">Если данные в источнике доступны для запросов, например при использовании реляционного хранилища (база данных SQL или SQL Server) или хранилища NoSQL (хранилище таблиц или Azure Cosmos DB), вместо использования сопоставления столбцов для свойства **query** можно передать фильтрацию столбцов и логику переупорядочивания.</span><span class="sxs-lookup"><span data-stu-id="06cb5-421">If your source data store is queryable, for example, if it's a relational store like SQL Database or SQL Server, or if it's a NoSQL store like Table storage or Azure Cosmos DB, consider pushing the column filtering and reordering logic to the **query** property instead of using column mapping.</span></span> <span data-ttu-id="06cb5-422">Таким образом, когда служба перемещения данных считывает данные из исходного хранилища, что является более эффективным, осуществляется проецирование.</span><span class="sxs-lookup"><span data-stu-id="06cb5-422">This way, the projection occurs while the data movement service reads data from the source data store, where it is much more efficient.</span></span>

## <a name="other-considerations"></a><span data-ttu-id="06cb5-423">Дополнительные рекомендации</span><span class="sxs-lookup"><span data-stu-id="06cb5-423">Other considerations</span></span>
<span data-ttu-id="06cb5-424">Если размер данных для копирования достаточно большой, можно настроить бизнес-логику для дальнейшего секционирования данных с помощью механизма создания срезов фабрики данных.</span><span class="sxs-lookup"><span data-stu-id="06cb5-424">If the size of data you want to copy is large, you can adjust your business logic to further partition the data using the slicing mechanism in Data Factory.</span></span> <span data-ttu-id="06cb5-425">Затем запланируйте более частое выполнение действия копирования, чтобы уменьшить размер данных для каждого действия копирования.</span><span class="sxs-lookup"><span data-stu-id="06cb5-425">Then, schedule Copy Activity to run more frequently to reduce the data size for each Copy Activity run.</span></span>

<span data-ttu-id="06cb5-426">Необходимо следить за количеством наборов данных и действий копирования, требующих подключения фабрики данных к одному хранилищу данных в одно и то же время.</span><span class="sxs-lookup"><span data-stu-id="06cb5-426">Be cautious about the number of data sets and copy activities requiring Data Factory to connector to the same data store at the same time.</span></span> <span data-ttu-id="06cb5-427">Большое количество одновременно выполняемых заданий копирования может привести к регулированию хранилища данных, что ведет к снижению производительности, внутренним повторным попыткам выполнения действия копирования, а в некоторых случаях — к сбоям выполнения.</span><span class="sxs-lookup"><span data-stu-id="06cb5-427">Many concurrent copy jobs might throttle a data store and lead to degraded performance, copy job internal retries, and in some cases, execution failures.</span></span>

## <a name="sample-scenario-copy-from-an-on-premises-sql-server-to-blob-storage"></a><span data-ttu-id="06cb5-428">Пример сценария. Копирование из локального SQL Server в хранилище BLOB-объектов</span><span class="sxs-lookup"><span data-stu-id="06cb5-428">Sample scenario: Copy from an on-premises SQL Server to Blob storage</span></span>
<span data-ttu-id="06cb5-429">**Сценарий.**Конвейер предназначен для копирования данных с локального сервера SQL Server в хранилище BLOB-объектов в формате CSV.</span><span class="sxs-lookup"><span data-stu-id="06cb5-429">**Scenario**: A pipeline is built to copy data from an on-premises SQL Server to Blob storage in CSV format.</span></span> <span data-ttu-id="06cb5-430">Для ускорения выполнения задания копирования необходимо сжать CSV-файлы в формат BZIP2.</span><span class="sxs-lookup"><span data-stu-id="06cb5-430">To make the copy job faster, the CSV files should be compressed into bzip2 format.</span></span>

<span data-ttu-id="06cb5-431">**Тестирование и анализ.**Пропускная способность действия копирования составляет меньше 2 МБ/с, что гораздо меньше, чем в тесте производительности.</span><span class="sxs-lookup"><span data-stu-id="06cb5-431">**Test and analysis**: The throughput of Copy Activity is less than 2 MBps, which is much slower than the performance benchmark.</span></span>

<span data-ttu-id="06cb5-432">**Анализ и оптимизация производительности.**Чтобы устранить проблемы производительности, сначала необходимо рассмотреть процесс обработки и перемещения данных.</span><span class="sxs-lookup"><span data-stu-id="06cb5-432">**Performance analysis and tuning**: To troubleshoot the performance issue, let’s look at how the data is processed and moved.</span></span>

1. <span data-ttu-id="06cb5-433">**Чтение данных.**Шлюз устанавливает подключение с SQL Server и отправляет запрос.</span><span class="sxs-lookup"><span data-stu-id="06cb5-433">**Read data**: Gateway opens a connection to SQL Server and sends the query.</span></span> <span data-ttu-id="06cb5-434">SQL Server отвечает, отправляя поток данных в шлюз через интрасеть.</span><span class="sxs-lookup"><span data-stu-id="06cb5-434">SQL Server responds by sending the data stream to Gateway via the intranet.</span></span>
2. <span data-ttu-id="06cb5-435">**Сериализация и сжатие данных.**Шлюз сериализует поток данных в формат CSV и сжимает данные в поток BZIP2.</span><span class="sxs-lookup"><span data-stu-id="06cb5-435">**Serialize and compress data**: Gateway serializes the data stream to CSV format, and compresses the data to a bzip2 stream.</span></span>
3. <span data-ttu-id="06cb5-436">**Запись данных.**Шлюз отправляет поток BZIP2 в хранилище BLOB-объектов через Интернет.</span><span class="sxs-lookup"><span data-stu-id="06cb5-436">**Write data**: Gateway uploads the bzip2 stream to Blob storage via the Internet.</span></span>

<span data-ttu-id="06cb5-437">Как видите, обработка и перемещение данных происходит в последовательном режиме потоковой передачи: SQL Server -> локальная сеть -> шлюз -> глобальная сеть -> хранилище BLOB-объектов.</span><span class="sxs-lookup"><span data-stu-id="06cb5-437">As you can see, the data is being processed and moved in a streaming sequential manner: SQL Server > LAN > Gateway > WAN > Blob storage.</span></span> <span data-ttu-id="06cb5-438">**Общая производительность достигается при минимальной пропускной способности в конвейере.**</span><span class="sxs-lookup"><span data-stu-id="06cb5-438">**The overall performance is gated by the minimum throughput across the pipeline**.</span></span>

![Поток данных](./media/data-factory-copy-activity-performance/case-study-pic-1.png)

<span data-ttu-id="06cb5-440">Один или несколько следующих факторов могут вызвать узкое место производительности.</span><span class="sxs-lookup"><span data-stu-id="06cb5-440">One or more of the following factors might cause the performance bottleneck:</span></span>

* <span data-ttu-id="06cb5-441">**Источник.**SQL Server отличается низкой пропускной способностью из-за высокой нагрузки.</span><span class="sxs-lookup"><span data-stu-id="06cb5-441">**Source**: SQL Server itself has low throughput because of heavy loads.</span></span>
* <span data-ttu-id="06cb5-442">**Шлюз управления данными.**</span><span class="sxs-lookup"><span data-stu-id="06cb5-442">**Data Management Gateway**:</span></span>
  * <span data-ttu-id="06cb5-443">**Локальная сеть.**Шлюз находится далеко от компьютера SQL Server и характеризуется низкой пропускной способностью.</span><span class="sxs-lookup"><span data-stu-id="06cb5-443">**LAN**: Gateway is located far from the SQL Server machine and has a low-bandwidth connection.</span></span>
  * <span data-ttu-id="06cb5-444">**Шлюз.**Выполнение следующих операций привело к достижению ограничений нагрузки для шлюза.</span><span class="sxs-lookup"><span data-stu-id="06cb5-444">**Gateway**: Gateway has reached its load limitations to perform the following operations:</span></span>
    * <span data-ttu-id="06cb5-445">**Сериализация.**Сериализация потока данных в формат CSV характеризуется низкой пропускной способностью.</span><span class="sxs-lookup"><span data-stu-id="06cb5-445">**Serialization**: Serializing the data stream to CSV format has slow throughput.</span></span>
    * <span data-ttu-id="06cb5-446">**Сжатие.**Выбран кодек медленного сжатия (например, BZIP2 со скоростью 2,8 Мбит/с и процессором Core i7).</span><span class="sxs-lookup"><span data-stu-id="06cb5-446">**Compression**: You chose a slow compression codec (for example, bzip2, which is 2.8 MBps with Core i7).</span></span>
  * <span data-ttu-id="06cb5-447">**Глобальная сеть.**Низкая пропускная способность между корпоративной сетью и службами Azure (например, T1 — 1544 Кбит/с, T2 — 6312 Кбит/с).</span><span class="sxs-lookup"><span data-stu-id="06cb5-447">**WAN**: The bandwidth between the corporate network and your Azure services is low (for example, T1 = 1,544 kbps; T2 = 6,312 kbps).</span></span>
* <span data-ttu-id="06cb5-448">**Приемник.**Хранилище BLOB-объектов имеет низкую пропускную способность.</span><span class="sxs-lookup"><span data-stu-id="06cb5-448">**Sink**: Blob storage has low throughput.</span></span> <span data-ttu-id="06cb5-449">(Этот сценарий маловероятный, так как соглашение об уровне обслуживания гарантирует не менее 60 Мбит/с.)</span><span class="sxs-lookup"><span data-stu-id="06cb5-449">(This scenario is unlikely because its SLA guarantees a minimum of 60 MBps.)</span></span>

<span data-ttu-id="06cb5-450">В этом случае сжатие данных в формат BZIP2 может замедлять работу всего конвейера.</span><span class="sxs-lookup"><span data-stu-id="06cb5-450">In this case, bzip2 data compression might be slowing down the entire pipeline.</span></span> <span data-ttu-id="06cb5-451">Этого можно избежать, если перейти на использование кодека сжатия в формат GZIP.</span><span class="sxs-lookup"><span data-stu-id="06cb5-451">Switching to a gzip compression codec might ease this bottleneck.</span></span>

## <a name="sample-scenarios-use-parallel-copy"></a><span data-ttu-id="06cb5-452">Примеры сценариев. Использование параллельного копирования</span><span class="sxs-lookup"><span data-stu-id="06cb5-452">Sample scenarios: Use parallel copy</span></span>
<span data-ttu-id="06cb5-453">**Сценарий I.** Копирование 1000 файлов размером 1 МБ из локальной файловой системы в хранилище BLOB-объектов.</span><span class="sxs-lookup"><span data-stu-id="06cb5-453">**Scenario I:** Copy 1,000 1-MB files from the on-premises file system to Blob storage.</span></span>

<span data-ttu-id="06cb5-454">**Анализ и оптимизация производительности.**Допустим, вы установили шлюз на четырехъядерном компьютере, а фабрика данных использует 16 параллельных копий для одновременного перемещения файлов из файловой системы в хранилище BLOB-объектов.</span><span class="sxs-lookup"><span data-stu-id="06cb5-454">**Analysis and performance tuning**: For an example, if you have installed gateway on a quad core machine, Data Factory uses 16 parallel copies to move files from the file system to Blob storage concurrently.</span></span> <span data-ttu-id="06cb5-455">Это приведет к высокой пропускной способности.</span><span class="sxs-lookup"><span data-stu-id="06cb5-455">This parallel execution should result in high throughput.</span></span> <span data-ttu-id="06cb5-456">Можно также явно указать количество параллельных операций копирования.</span><span class="sxs-lookup"><span data-stu-id="06cb5-456">You also can explicitly specify the parallel copies count.</span></span> <span data-ttu-id="06cb5-457">При копировании множества небольших файлов одновременные операции копирования значительно увеличивают пропускную способность за счет более эффективного использования ресурсов.</span><span class="sxs-lookup"><span data-stu-id="06cb5-457">When you copy many small files, parallel copies dramatically help throughput by using resources more effectively.</span></span>

![Сценарий 1](./media/data-factory-copy-activity-performance/scenario-1.png)

<span data-ttu-id="06cb5-459">**Сценарий II.**Копирование 20 больших двоичных объектов размером 500 МБ из хранилища BLOB-объектов в Data Lake Store с анализом и настройкой производительности.</span><span class="sxs-lookup"><span data-stu-id="06cb5-459">**Scenario II**: Copy 20 blobs of 500 MB each from Blob storage to Data Lake Store Analytics, and then tune performance.</span></span>

<span data-ttu-id="06cb5-460">**Анализ и оптимизация производительности**. В этом сценарии фабрика данных копирует данные из хранилища BLOB-объектов в Data Lake Store, используя отдельные операции копирования(**parallelCopies** равно 1) и отдельные облачные единицы перемещения данных.</span><span class="sxs-lookup"><span data-stu-id="06cb5-460">**Analysis and performance tuning**: In this scenario, Data Factory copies the data from Blob storage to Data Lake Store by using single-copy (**parallelCopies** set to 1) and single-cloud data movement units.</span></span> <span data-ttu-id="06cb5-461">Наблюдаемая пропускная способность будет близка к указанной в [разделе с показателями производительности](#performance-reference).</span><span class="sxs-lookup"><span data-stu-id="06cb5-461">The throughput you observe will be close to that described in the [performance reference section](#performance-reference).</span></span>   

![Сценарий 2](./media/data-factory-copy-activity-performance/scenario-2.png)

<span data-ttu-id="06cb5-463">**Сценарий III.**Размер отдельного файла превышает десятки мегабайтов, и общий объем достаточно велик.</span><span class="sxs-lookup"><span data-stu-id="06cb5-463">**Scenario III**: Individual file size is greater than dozens of MBs and total volume is large.</span></span>

<span data-ttu-id="06cb5-464">**Анализ и оптимизация производительности**. Увеличение значения **parallelCopies** не приведет к повышению производительности копирования ввиду ограничения ресурсов отдельной облачной единицы перемещения данных.</span><span class="sxs-lookup"><span data-stu-id="06cb5-464">**Analysis and performance turning**: Increasing **parallelCopies** doesn't result in better copy performance because of the resource limitations of a single-cloud DMU.</span></span> <span data-ttu-id="06cb5-465">Вместо этого следует задать больше облачных единиц перемещения данных, чтобы получить дополнительные ресурсы для перемещения данных.</span><span class="sxs-lookup"><span data-stu-id="06cb5-465">Instead, you should specify more cloud DMUs to get more resources to perform the data movement.</span></span> <span data-ttu-id="06cb5-466">Не указывайте значение для свойства **parallelCopies**.</span><span class="sxs-lookup"><span data-stu-id="06cb5-466">Do not specify a value for the **parallelCopies** property.</span></span> <span data-ttu-id="06cb5-467">Фабрика данных автоматически обрабатывает параллелизм.</span><span class="sxs-lookup"><span data-stu-id="06cb5-467">Data Factory handles the parallelism for you.</span></span> <span data-ttu-id="06cb5-468">В этом случае можно задать для **cloudDataMovementUnits** значение 4. Это повысит пропускную способность примерно в 4 раза.</span><span class="sxs-lookup"><span data-stu-id="06cb5-468">In this case, if you set **cloudDataMovementUnits** to 4, a throughput of about four times occurs.</span></span>

![Сценарий 3](./media/data-factory-copy-activity-performance/scenario-3.png)

## <a name="reference"></a><span data-ttu-id="06cb5-470">Справочные материалы</span><span class="sxs-lookup"><span data-stu-id="06cb5-470">Reference</span></span>
<span data-ttu-id="06cb5-471">Ниже приведены справочные материалы по мониторингу и настройке производительности для некоторых поддерживаемых хранилищ данных.</span><span class="sxs-lookup"><span data-stu-id="06cb5-471">Here are performance monitoring and tuning references for some of the supported data stores:</span></span>

* <span data-ttu-id="06cb5-472">Служба хранилища Azure (включая хранилище BLOB-объектов и таблиц): [Целевые показатели масштабируемости и производительности службы хранилища Azure](../storage/common/storage-scalability-targets.md) и [Производительность хранилища Microsoft Azure и контрольный список масштабируемости](../storage/common/storage-performance-checklist.md).</span><span class="sxs-lookup"><span data-stu-id="06cb5-472">Azure Storage (including Blob storage and Table storage): [Azure Storage scalability targets](../storage/common/storage-scalability-targets.md) and [Azure Storage performance and scalability checklist](../storage/common/storage-performance-checklist.md)</span></span>
* <span data-ttu-id="06cb5-473">База данных SQL Azure: вы можете [наблюдать за производительностью](../sql-database/sql-database-single-database-monitor.md) и проверять процент использования единиц транзакций базы данных (DTU).</span><span class="sxs-lookup"><span data-stu-id="06cb5-473">Azure SQL Database: You can [monitor the performance](../sql-database/sql-database-single-database-monitor.md) and check the database transaction unit (DTU) percentage</span></span>
* <span data-ttu-id="06cb5-474">Хранилище данных SQL Azure: его использование измеряется в единицах использования хранилища данных (DWU). См. статью [Управление вычислительными ресурсами в хранилище данных SQL Azure (обзор)](../sql-data-warehouse/sql-data-warehouse-manage-compute-overview.md).</span><span class="sxs-lookup"><span data-stu-id="06cb5-474">Azure SQL Data Warehouse: Its capability is measured in data warehouse units (DWUs); see [Manage compute power in Azure SQL Data Warehouse (Overview)](../sql-data-warehouse/sql-data-warehouse-manage-compute-overview.md)</span></span>
* <span data-ttu-id="06cb5-475">Azure Cosmos DB: [Прекращение использования уровней производительности S1, S2 и S3 в DocumentDB](../documentdb/documentdb-performance-levels.md).</span><span class="sxs-lookup"><span data-stu-id="06cb5-475">Azure Cosmos DB: [Performance levels in Azure Cosmos DB](../documentdb/documentdb-performance-levels.md)</span></span>
* <span data-ttu-id="06cb5-476">Локальный SQL Server: [Мониторинг и настройка производительности](https://msdn.microsoft.com/library/ms189081.aspx)</span><span class="sxs-lookup"><span data-stu-id="06cb5-476">On-premises SQL Server: [Monitor and tune for performance](https://msdn.microsoft.com/library/ms189081.aspx)</span></span>
* <span data-ttu-id="06cb5-477">Локальный файловый сервер: [Performance tuning for file servers](https://msdn.microsoft.com/library/dn567661.aspx)</span><span class="sxs-lookup"><span data-stu-id="06cb5-477">On-premises file server: [Performance tuning for file servers](https://msdn.microsoft.com/library/dn567661.aspx)</span></span>
