---
title: "Конвейеры aaaCreate и расписанию, цепочка действия в фабрике данных | Документы Microsoft"
description: "Узнайте toocreate конвейера данных в toomove фабрики данных Azure и преобразования данных. Создайте данными сведений о готовности toouse tooproduce рабочего процесса."
keywords: "конвейер данных, управляемый данными рабочий процесс"
services: data-factory
documentationcenter: 
author: sharonlo101
manager: jhubbard
editor: monicar
ms.assetid: 13b137c7-1033-406f-aea7-b66f25b313c0
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 08/12/2017
ms.author: shlo
ms.openlocfilehash: 4a0fc20f98ce6453c16955e97fddb891926c173a
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 10/06/2017
---
# <a name="pipelines-and-activities-in-azure-data-factory"></a>Конвейеры и действия в фабрике данных Azure
Эта статья поможет вам понять, конвейеры и действия в фабрике данных Azure и использовать конца в конец tooconstruct управляемые данными рабочие процессы для перемещения данных и сценарии обработки данных.  

> [!NOTE]
> В этой статье предполагается, что Вы завершили [tooAzure введение фабрики данных](data-factory-introduction.md). Если у вас нет практического опыта создания фабрик данных, рекомендуем для лучшего понимания статьи изучить [руководства по преобразованию ](data-factory-build-your-first-pipeline.md) и (или) [по перемещению данных](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).  

## <a name="overview"></a>Обзор
Фабрика данных может иметь один или несколько конвейеров. Конвейеры — это логические группы действий, которые вместе отвечают за выполнение задачи. Hello действий в конвейере определить tooperform действия на данные. Например может использовать копирование данных toocopy действия из локального SQL Server tooan хранилища больших двоичных объектов. Затем с помощью действия Hive, соединяющий hello BLOB-объекта хранилища tooproduce выходных данных скрипта Hive для Azure HDInsight кластера tooprocess или преобразования данных. И, наконец используется второй копии действия toocopy hello вывода данных tooan Azure SQL хранилище данных поверх какие бизнес-аналитики (BI) строятся решений для составления отчетов. 

У каждого действия может быть несколько входных [наборов данных](data-factory-create-datasets.md) или же ни одного, и каждое действие может производить один или несколько выходных [наборов данных](data-factory-create-datasets.md). Hello следующей схеме показано hello связь между конвейера, действия и набор данных в фабрике данных. 

![Связь между конвейером, действием и набором данных](media/data-factory-create-pipelines/relationship-pipeline-activity-dataset.png)

Конвейер позволяет toomanage действия как набор вместо каждого из них по отдельности. Например можно развернуть, планирования, приостановить и возобновить конвейера, вместо решающих действий в конвейере hello независимо друг от друга.

Фабрика данных поддерживает два типа действий: действия перемещения данных и действия преобразования данных. У каждого действия может быть несколько входных [наборов данных](data-factory-create-datasets.md) или же ни одного, и каждое действие может производить один или несколько выходных наборов данных.

Входной набор данных представляет hello входных данных для действия в конвейере hello и выходной набор данных представляет hello выходные данные для действия "hello". Наборы данных представляют данные в разных хранилищах, например в таблицах, файлах, папках и документах. Созданные наборы данных можно использовать для действий в конвейере. Например, можно указать входной или выходной набор данных для действия HDInsightHive или действия копирования. Дополнительные сведения о наборах данных см. в статье [Наборы данных в фабрике данных Azure](data-factory-create-datasets.md).

### <a name="data-movement-activities"></a>Действия перемещения данных
Действие копирования в фабрике данных копирует данные из хранилища данных источника данных хранилища tooa приемника. Фабрика данных поддерживает hello, следуя хранилищ данных. Данные из любого источника, могут быть записаны tooany приемника. Нажмите кнопку toolearn хранилище данных как toocopy tooand данные из этого хранилища.

[!INCLUDE [data-factory-supported-data-stores](../../includes/data-factory-supported-data-stores.md)]

> [!NOTE]
> Данные хранятся с * может быть локальным или в Azure IaaS и требуют tooinstall [шлюз управления данными](data-factory-data-management-gateway.md) на машине IaaS на локальном или Azure.

Дополнительные сведения см. в статье [Перемещение данных с помощью действия копирования](data-factory-data-movement-activities.md).

### <a name="data-transformation-activities"></a>Действия преобразования данных
[!INCLUDE [data-factory-transformation-activities](../../includes/data-factory-transformation-activities.md)]

Дополнительные сведения см. в статье [Преобразование данных в фабрике данных Azure](data-factory-data-transformation-activities.md).

### <a name="custom-net-activities"></a>Пользовательские действия .NET 
Если требуются данные toomove в/из данных в хранилище, hello действие копирования не поддерживает, или преобразовывать данные с помощью собственной логики, создайте **настраиваемых действий .NET**. Сведения о создании и использовании настраиваемого действия см. в статье [Использование настраиваемых действий в конвейере фабрики данных Azure](data-factory-use-custom-activities.md).

## <a name="schedule-pipelines"></a>Планирование конвейеров
Конвейер работает только в период активности, то есть между временем **начала** и **окончания**. Не выполняется раньше времени начала hello или после времени окончания hello. Если конвейер hello приостановлена, она не была выполнена независимо от времени его начала и окончания. Для toorun конвейера он должен быть не приостановлен. В разделе [планирования и выполнения](data-factory-scheduling-and-execution.md) toounderstand, как работает планированием и выполнением в фабрике данных Azure.

## <a name="pipeline-json"></a>Конвейер JSON
Рассмотрим подробнее определение конвейера в формате JSON. Универсальная структура Hello для конвейера выглядит следующим образом:

```json
{
    "name": "PipelineName",
    "properties": 
    {
        "description" : "pipeline description",
        "activities":
        [

        ],
        "start": "<start date-time>",
        "end": "<end date-time>",
        "isPaused": true/false,
        "pipelineMode": "scheduled/onetime",
        "expirationTime": "15.00:00:00",
        "datasets": 
        [
        ]
    }
}
```

| Тег | Описание | Обязательно |
| --- | --- | --- |
| name |Имя конвейера hello. Укажите имя, которое представляет действие hello, hello конвейера выполняет. <br/><ul><li>Максимальное количество знаков: 260.</li><li>Должно начинаться с буквы, цифры или символа подчеркивания (_).</li><li>Следующие знаки не допускаются: ".", "+", "?", "/", "<", ">", "*", "%", "&", ":", "\\".</li></ul> |Да |
| Описание | Укажите текст hello, описывающий, какие hello конвейер используется для. |Да |
| Действия | Hello **действия** раздел может иметь одно или несколько действий, определенных внутри него. Hello следующем разделе для получения сведений об элементе JSON hello действий. | Да |  
| start | Дата и время начала для конвейера hello. Задается в [формате ISO](http://en.wikipedia.org/wiki/ISO_8601). Например, `2016-10-14T16:32:41Z`. <br/><br/>Это возможно toospecify местное время, например время. Пример: `2016-02-27T06:00:00-05:00`". Это 6:00 по восточному стандартному времени.<br/><br/>Hello начального и конечного свойства вместе задают активный период для конвейера hello. Срезы выходных данных создаются только в этот активный период. |Нет<br/><br/>Если указать значение для свойства окончания hello, необходимо указать значение для свойства начала hello.<br/><br/>Hello начальное и конечное время могут быть пустой toocreate конвейера. Необходимо указать оба значения tooset на активный период для конвейера toorun hello. Если не указать время начала и окончания при создании конвейера, можно установить их позже с помощью командлета Set AzureRmDataFactoryPipelineActivePeriod hello. |
| end | Дата и время окончания для конвейера hello. Не является обязательным и задается в формате ISO. Например: `2016-10-14T17:32:41Z` <br/><br/>Это возможно toospecify местное время, например время. Пример: `2016-02-27T06:00:00-05:00`. Это 6:00 по восточному стандартному времени.<br/><br/>toorun hello конвейера неопределенно долгое время, укажите 9999-09-09 как hello значение для свойства окончания hello. <br/><br/> Конвейер работает только в период активности, то есть между временем начала и окончания. Не выполняется раньше времени начала hello или после времени окончания hello. Если конвейер hello приостановлена, она не была выполнена независимо от времени его начала и окончания. Для toorun конвейера он должен быть не приостановлен. В разделе [планирования и выполнения](data-factory-scheduling-and-execution.md) toounderstand, как работает планированием и выполнением в фабрике данных Azure. |Нет <br/><br/>Если указать значение для свойства начала hello, необходимо указать значение для свойства окончания hello.<br/><br/>См. примечания для hello **запустить** свойство. |
| isPaused | Если набор tootrue, конвейер hello не выполняется. Его состояние в hello приостановлена. Значение по умолчанию — false. Можно использовать это свойство tooenable или отключение конвейера. |Нет |
| pipelineMode | метод Hello планирования выполняется для hello конвейера. Допустимые значения: scheduled (по умолчанию), onetime.<br/><br/>«Запланировано» указывает, что конвейера hello запускается в заданный интервал времени в соответствии с tooits активного периода (время начала и окончания). «Onetime» указывает, что этот конвейер hello запускается только один раз. В настоящее время изменить или обновить однократные конвейеры после их создания нельзя. Подробные сведения об однократном запуске см. в разделе [Однократный конвейер](#onetime-pipeline). |Нет |
| expirationTime; | Продолжительность времени после создания какие hello [одноразовый конвейера](#onetime-pipeline) является допустимым и должен оставаться подготовкой. Если он не поддерживает все активные сбой, или ожидающие выполнения, конвейера hello автоматически удалены после достижения hello время истечения срока действия. значение по умолчанию Hello:`"expirationTime": "3.00:00:00"`|Нет |
| datasets |Список toobe наборы данных, используемые действия, определенные в конвейере hello. Это свойство может быть используется toodefine наборы данных, которые являются определенной toothis конвейера и не задан в фабрике данных hello. Наборы данных, определенные в этом конвейере, могут использоваться только этим конвейером и не предназначены для совместного доступа. Дополнительные сведения см. в разделе [Контекст наборов данных](data-factory-create-datasets.md#scoped-datasets). |Нет |

## <a name="activity-json"></a>Действие JSON
Hello **действия** раздел может иметь одно или несколько действий, определенных внутри него. Каждое действие имеет hello следующая структура верхнего уровня.

```json
{
    "name": "ActivityName",
    "description": "description", 
    "type": "<ActivityType>",
    "inputs":  "[]",
    "outputs":  "[]",
    "linkedServiceName": "MyLinkedService",
    "typeProperties":
    {

    },
    "policy":
    {
    },
    "scheduler":
    {
    }
}
```

В действии hello определения JSON в следующей таблице описаны свойства:

| Тег | Описание | Обязательно |
| --- | --- | --- |
| name | Имя действия hello. Укажите имя, которое представляет действие hello, выполняющий действие hello. <br/><ul><li>Максимальное количество знаков: 260.</li><li>Должно начинаться с буквы, цифры или символа подчеркивания (_).</li><li>Следующие знаки не допускаются: ".", "+", "?", "/", "<", ">", "*", "%", "&", ":", "\\".</li></ul> |Да |
| Описание | Текст, описывающий новые hello действия или используется для |Да |
| type | Тип действия hello. . В разделе hello [действия перемещения данных](#data-movement-activities) и [действия преобразования данных](#data-transformation-activities) разделы для различных типов действий. |Да |
| inputs |Входные таблицы, используемые действием hello<br/><br/>`// one input table`<br/>`"inputs":  [ { "name": "inputtable1"  } ],`<br/><br/>`// two input tables` <br/>`"inputs":  [ { "name": "inputtable1"  }, { "name": "inputtable2"  } ],` |Да |
| outputs |Выходные таблицы, используемые с действия "hello".<br/><br/>`// one output table`<br/>`"outputs":  [ { "name": "outputtable1" } ],`<br/><br/>`//two output tables`<br/>`"outputs":  [ { "name": "outputtable1" }, { "name": "outputtable2" }  ],` |Да |
| linkedServiceName (имя связанной службы) |Имя hello связанной службы, используемый действием hello. <br/><br/>Действие может потребоваться указать hello связаны службы, которая связывает toohello необходимые вычислительную среду. |Да — для действия HDInsight и действия пакетной оценки показателей машинного обучения Azure;  <br/><br/>Нет — для всех остальных |
| typeProperties |Свойства в hello **typeProperties** раздел зависят от типа действия hello. свойства типа toosee для действия, щелкните действие toohello ссылки в предыдущем разделе hello. | Нет |
| policy |Политики, влияющие на поведение во время выполнения hello действия "hello". Если для этого свойства не задано значение, используются стандартные политики. |Нет |
| scheduler | Свойство «планировщик» является используется toodefine требуемого планирования для действия "hello". Его подсвойства так же, как в hello hello hello [доступность свойство в наборе данных](data-factory-create-datasets.md#dataset-availability). |Нет |


### <a name="policies"></a>Политики
Политики влияют на поведение hello во время выполнения действия, особенно при обработке среза таблицы hello. Привет, в следующей таблице подробно описаны hello.

| Свойство | Допустимые значения | Значение по умолчанию | Описание |
| --- | --- | --- | --- |
| concurrency |Целое число  <br/><br/>Максимальное значение — 10 |1 |Число одновременных выполнений действия hello.<br/><br/>Он определяет hello число параллельных выполнений действия может произойти на различных срезах. Например если действие должно toogo через большого набора данных, наличие большего значения параллелизма ускоряет обработку данных hello. |
| executionPriorityOrder |NewestFirst<br/><br/>OldestFirst |OldestFirst |Определяет порядок hello срезы данных, которые обрабатываются.<br/><br/>Предположим, есть два ожидающих обработки среза (от 16:00 и от 17:00). При установке toobe hello executionpriorityorder значения NewestFirst сначала обрабатывается срез hello в 17: 00. Аналогичным образом при установке toobe hello executionpriorityorder значения OldestFIrst затем обрабатываются срез hello в 16: 00. |
| retry |Целое число <br/><br/>Максимальное значение — 10 |0 |Число повторных попыток перед hello обработки данных для hello среза помечается как ошибка. Выполнение действия для среза данных будет предпринята повторная попытка копирования toohello указанное число повторных попыток. Повторная попытка Hello выполняется как можно быстрее после сбоя hello. |
| timeout |TimeSpan |00:00:00 |Время ожидания для действия "hello". Пример: 00:10:00 (время ожидания — 10 минут).<br/><br/>Если значение не указано или равно 0, используется бесконечное время ожидания hello.<br/><br/>Если hello время обработки данных среза превышает значение времени ожидания hello, отмены и hello система пытается tooretry hello обработки. Hello число повторов зависит от свойства retry hello. При возникновении времени ожидания hello перейдет в состояние tooTimedOut. |
| delay |TimeSpan |00:00:00 |Укажите задержку hello перед обработкой данных начинается срез hello.<br/><br/>Hello выполнение действия для среза данных запускается после hello задержки прошлом hello ожидаемое время выполнения.<br/><br/>Пример: 00:10:00 (означает задержку в 10 минут). |
| longRetry |Целое число <br/><br/>Максимальное значение — 10 |1 |Hello количество длинных повторных попыток: hello выполнение среза завершается сбоем.<br/><br/>Интервал между этими попытками задается свойством longRetryInterval. Поэтому если вам требуется toospecify время между попытками повтора, следует используйте longRetry. Если указаны свойства Retry и longRetry, каждая попытка longRetry включает повторных попыток и hello максимальное число попыток повтора * longRetry.<br/><br/>Например, если у нас есть следующие параметры в политике действия hello hello:<br/>Retry: 3<br/>longRetry: 2<br/>longRetryInterval: 01:00:00<br/><br/>Предположим, что существует только один срез tooexecute (состояние ожидания) и hello действие происходит сбой выполнения каждый раз. Первые три попытки будут выполнены подряд. После каждой попытки hello состояние среза будет Retry. После первых 3 попытки через hello состояние среза станет LongRetry.<br/><br/>Через час (значение свойства longRetryInterval) будут выполнены еще три попытки подряд. После этого состояние среза hello бы сбой, и дальнейшие попытки предприниматься. Поэтому всего было предпринято 6 попыток.<br/><br/>Если любое выполнение завершится успешно, hello состояние среза будет готова, и дальнейшие попытки не предпринимаются.<br/><br/>longRetry может использоваться в ситуациях, когда данные, зависящие от поступает на неопределенное время или hello общей среды подключением отображается под какие обработки данных. В таких случаях один за другим образом повторных попыток может не позволить и таким образом через определенные интервалы времени приводит к hello требуемого выходных данных.<br/><br/>Предупреждение. Не задавайте высокие значения для свойств longRetry и longRetryInterval. Как правило, более высокие значения приводят к появлению других системных проблем. |
| longRetryInterval |TimeSpan |00:00:00 |Hello задержка между попытками longretry |

## <a name="sample-copy-pipeline"></a>Пример конвейера копирования
В следующий пример конвейера hello, есть одно действие типа **копирования** в hello **действия** раздела. В этом образце hello [действие копирования](data-factory-data-movement-activities.md) копирует данные из базы данных Azure SQL tooan хранилища больших двоичных объектов Azure. 

```json
{
  "name": "CopyPipeline",
  "properties": {
    "description": "Copy data from a blob tooAzure SQL table",
    "activities": [
      {
        "name": "CopyFromBlobToSQL",
        "type": "Copy",
        "inputs": [
          {
            "name": "InputDataset"
          }
        ],
        "outputs": [
          {
            "name": "OutputDataset"
          }
        ],
        "typeProperties": {
          "source": {
            "type": "BlobSource"
          },
          "sink": {
            "type": "SqlSink",
            "writeBatchSize": 10000,
            "writeBatchTimeout": "60:00:00"
          }
        },
        "Policy": {
          "concurrency": 1,
          "executionPriorityOrder": "NewestFirst",
          "retry": 0,
          "timeout": "01:00:00"
        }
      }
    ],
    "start": "2016-07-12T00:00:00Z",
    "end": "2016-07-13T00:00:00Z"
  }
} 
```

Обратите внимание hello после точки.

* В разделе "действия" hello, имеется только одно действие, **тип** задано слишком**копирования**.
* Входных данных для действия hello установлено слишком**InputDataset** и вывода для hello действия установлено слишком**OutputDataset**. Сведения об определении наборов данных в JSON см. в статье [Наборы данных](data-factory-create-datasets.md). 
* В hello **typeProperties** разделе **BlobSource** указан в качестве типа источника hello и **SqlSink** указан как тип приемника hello. В hello [действия перемещения данных](#data-movement-activities) щелкните hello хранилища данных требуется toouse как источник или приемник toolearn Дополнительные сведения о перемещении данных из хранилища данных. 

Полное Пошаговое руководство по созданию этого конвейера, в разделе [учебника: копирование данных из хранилища больших двоичных объектов tooSQL базы данных](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md). 

## <a name="sample-transformation-pipeline"></a>Пример конвейера преобразования
В следующий пример конвейера hello, есть одно действие типа **HDInsightHive** в hello **действия** раздела. В этом образце hello [действие Hive в HDInsight](data-factory-hive-activity.md) преобразует данные из хранилища больших двоичных объектов Azure, выполнив файл скрипта Hive в кластере Azure HDInsight Hadoop. 

```json
{
    "name": "TransformPipeline",
    "properties": {
        "description": "My first Azure Data Factory pipeline",
        "activities": [
            {
                "type": "HDInsightHive",
                "typeProperties": {
                    "scriptPath": "adfgetstarted/script/partitionweblogs.hql",
                    "scriptLinkedService": "AzureStorageLinkedService",
                    "defines": {
                        "inputtable": "wasb://adfgetstarted@<storageaccountname>.blob.core.windows.net/inputdata",
                        "partitionedtable": "wasb://adfgetstarted@<storageaccountname>.blob.core.windows.net/partitioneddata"
                    }
                },
                "inputs": [
                    {
                        "name": "AzureBlobInput"
                    }
                ],
                "outputs": [
                    {
                        "name": "AzureBlobOutput"
                    }
                ],
                "policy": {
                    "concurrency": 1,
                    "retry": 3
                },
                "scheduler": {
                    "frequency": "Month",
                    "interval": 1
                },
                "name": "RunSampleHiveActivity",
                "linkedServiceName": "HDInsightOnDemandLinkedService"
            }
        ],
        "start": "2016-04-01T00:00:00Z",
        "end": "2016-04-02T00:00:00Z",
        "isPaused": false
    }
}
```

Обратите внимание hello после точки. 

* В разделе "действия" hello, имеется только одно действие, **тип** задано слишком**HDInsightHive**.
* файл скрипта Hive Hello, **partitionweblogs.hql**, хранятся в учетной записи хранилища Azure hello (определяемое scriptLinkedService hello, вызывается **AzureStorageLinkedService**) и в  **сценарий** папки в контейнере hello **adfgetstarted**.
* Hello `defines` раздел представляет параметры среды выполнения используется toospecify hello, переданных toohello скрипт hive в качестве значения конфигурации Hive (например `${hiveconf:inputtable}`, `${hiveconf:partitionedtable}`).

Hello **typeProperties** раздела отличается для каждого действия преобразования. toolearn о тип свойства, поддерживаемые для действия "преобразование", щелкните действие преобразования hello в hello [действия преобразования данных](#data-transformation-activities) таблицы. 

Полное Пошаговое руководство по созданию этого конвейера, в разделе [учебника: построение первые данные конвейера tooprocess использование кластера Hadoop](data-factory-build-your-first-pipeline.md). 

## <a name="multiple-activities-in-a-pipeline"></a>Несколько действий в конвейере
предыдущие два примера конвейеры Hello имеют только одно действие в них. Конвейер может содержать сразу несколько действий.  

При наличии нескольких действий в конвейере и выходные данные действия не являются входными данными другого действия, если готовых срезы входные данные для действия hello hello действия могут выполняться параллельно. 

Можно соединить в цепочку двух действий hello выходной набор данных из одного действия как hello входного набора данных hello, задав другие действия. Hello второе действие выполняется, только в том случае, когда hello сначала один завершается успешно.

![Цепочки действий в hello же конвейера](./media/data-factory-create-pipelines/chaining-one-pipeline.png)

В этом образце hello конвейера содержит два действия: Activity1 и Activity2. Hello Activity1 принимает Dataset1 в качестве входных данных и выводит результаты Dataset2. Hello действие использует Dataset2 в качестве входных данных и выводит результаты Dataset3. С момента выход hello Activity1 (Dataset2) будут входными данными hello Activity2, hello Activity2 запускается только после успешного завершения действия hello и выдает hello Dataset2 среза. Если hello Activity1 завершается сбоем по какой-либо причине и не создает hello Dataset2 срез, hello 2 действия не выполняется для этого среза (например: 9 AM too10 AM). 

Вы можете объединять в цепочку действия, находящиеся в разных конвейерах.

![Построение цепочки действий в двух конвейерах](./media/data-factory-create-pipelines/chaining-two-pipelines.png)

В этом примере конвейер Pipeline1 имеет только одно действие, принимающее входной набор данных Dataset1 и выводящее Dataset2. Hello Pipeline2 также имеет только одно действие, которая принимает в качестве входных данных и Dataset3 в качестве выходных данных Dataset2. 

Чтобы узнать больше, ознакомьтесь с [планированием и выполнением](data-factory-scheduling-and-execution.md#multiple-activities-in-a-pipeline). 

## <a name="create-and-monitor-pipelines"></a>Создание и мониторинг конвейеров
Конвейеры можно создать с помощью одного из указанных ниже средств или пакетов SDK. 

- Мастер копирования 
- Портал Azure
- Visual Studio
- Azure PowerShell
- Шаблон диспетчера ресурсов Azure
- Интерфейс REST API
- .NET API

См. следующие учебники пошаговые инструкции по созданию конвейеров с помощью одного из этих средств или пакеты SDK hello.
 
- [Учебник. Создание первого конвейера для преобразования данных с помощью кластера Hadoop](data-factory-build-your-first-pipeline.md)
- [Руководство. Копирование данных из хранилища BLOB-объектов Azure в базу данных SQL с помощью фабрики данных](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md)

После создания и развертывания конвейера, можно управлять и отслеживать конвейеров с помощью hello Azure портала колонках или монитор и управления приложения. См. следующие разделы для получения пошаговых инструкций hello. 

- [Мониторинг конвейеров фабрики данных Azure и управление ими с помощью портала Azure и PowerShell](data-factory-monitor-manage-pipelines.md)
- [Мониторинг конвейеров фабрики данных Azure и управление ими с помощью приложения для мониторинга и управления](data-factory-monitor-manage-app.md)


## <a name="onetime-pipeline"></a>Однократный конвейер
Можно создать и запланировать toorun конвейера периодически (например: ежечасно или ежедневно) время, укажите в определении конвейера hello в hello начала и окончания. Дополнительные сведения см. в разделе [Планирование действий](#scheduling-and-execution). Вы также можете создать конвейер, выполняемый однократно. toodo Итак, установите hello **pipelineMode** свойство в hello конвейера определение слишком**onetime** как показано в следующий пример JSON hello. значение по умолчанию Hello для этого свойства — **запланированных**.

```json
{
    "name": "CopyPipeline",
    "properties": {
        "activities": [
            {
                "type": "Copy",
                "typeProperties": {
                    "source": {
                        "type": "BlobSource",
                        "recursive": false
                    },
                    "sink": {
                        "type": "BlobSink",
                        "writeBatchSize": 0,
                        "writeBatchTimeout": "00:00:00"
                    }
                },
                "inputs": [
                    {
                        "name": "InputDataset"
                    }
                ],
                "outputs": [
                    {
                        "name": "OutputDataset"
                    }
                ]
                "name": "CopyActivity-0"
            }
        ]
        "pipelineMode": "OneTime"
    }
}
```

Обратите внимание hello следующие:

* **Запуск** и **окончания** времени для конвейера hello не указаны.
* **Доступность** ввода и вывода указан наборы данных (**частоты** и **интервал**), даже если фабрика данных не использует значения hello.  
* В представлении диаграммы однократные конвейеры не отображаются. В этом весь замысел.
* Однократные конвейеры не обновляются. Клонирование одноразовый конвейера, переименуйте его, обновить свойства и развернуть ее toocreate еще один.


## <a name="next-steps"></a>Дальнейшие действия
- Дополнительные сведения о наборах данных см. в статье [Создание наборов данных](data-factory-create-datasets.md). 
- Дополнительные сведения о планировании и выполнении конвейеров см. в статье [Планирование и выполнение в фабрике данных Azure](data-factory-scheduling-and-execution.md). 
  

