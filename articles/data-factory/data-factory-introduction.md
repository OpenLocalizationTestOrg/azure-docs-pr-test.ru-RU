---
title: "Общие сведения о фабрике данных — службе интеграции данных | Документация Майкрософт"
description: "Узнайте о фабрике данных Azure, облачной службе интеграции данных, которая организует и автоматизирует перемещение и преобразование данных."
keywords: "интеграция данных, интеграция данных в облаке, что такое фабрика данных Azure"
services: data-factory
documentationcenter: 
author: sharonlo101
manager: jhubbard
editor: monicar
ms.assetid: cec68cb5-ca0d-473b-8ae8-35de949a009e
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: get-started-article
ms.date: 08/14/2017
ms.author: shlo
ms.openlocfilehash: bc72c4d58b98f6521dbb7420a5d05a121b0ddbda
ms.sourcegitcommit: 50e23e8d3b1148ae2d36dad3167936b4e52c8a23
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 08/18/2017
---
# <a name="introduction-to-azure-data-factory"></a><span data-ttu-id="8c367-104">Введение в фабрику данных Azure</span><span class="sxs-lookup"><span data-stu-id="8c367-104">Introduction to Azure Data Factory</span></span> 
## <a name="what-is-azure-data-factory"></a><span data-ttu-id="8c367-105">Что такое фабрика данных Azure?</span><span class="sxs-lookup"><span data-stu-id="8c367-105">What is Azure Data Factory?</span></span>
<span data-ttu-id="8c367-106">Как имеющиеся большие данные используются в бизнес-среде?</span><span class="sxs-lookup"><span data-stu-id="8c367-106">In the world of big data, how is existing data leveraged in business?</span></span> <span data-ttu-id="8c367-107">Возможно ли расширить облачные данные за счет ссылочных данных из локальных источников данных или других разрозненных источников данных?</span><span class="sxs-lookup"><span data-stu-id="8c367-107">Is it possible to enrich data generated in the cloud by using reference data from on-premises data sources or other disparate data sources?</span></span> <span data-ttu-id="8c367-108">Например, компания-разработчик игр собирает разные журналы, создаваемые играми в облаке.</span><span class="sxs-lookup"><span data-stu-id="8c367-108">For example, a gaming company collects many logs produced by games in the cloud.</span></span> <span data-ttu-id="8c367-109">Компания хочет проанализировать эти журналы, чтобы получить сведения о предпочтениях клиентов, демографических данных, особенностях использования и т. д. Эти сведения помогут понять, как можно увеличить продажи и перекрестные продажи, разработать новые интересные функции, стимулирующие развитие бизнеса, а также предоставить клиентам более удобные возможности для работы.</span><span class="sxs-lookup"><span data-stu-id="8c367-109">It wants to analyze these logs to gain insights in to customer preferences, demographics, usage behavior etc. to identify up-sell and cross-sell opportunities, develop new compelling features to drive business growth, and provide a better experience to customers.</span></span> 

<span data-ttu-id="8c367-110">Для анализа этих журналов компании необходимо использовать справочные сведения о клиенте, игре и маркетинговой кампании, хранящиеся в локальном хранилище данных.</span><span class="sxs-lookup"><span data-stu-id="8c367-110">To analyze these logs, the company needs to use the reference data such as customer information, game information, marketing campaign information that is in an on-premises data store.</span></span> <span data-ttu-id="8c367-111">Таким образом компания хочет получить данные журнала из облачного хранилища данных, а справочные сведения — из локального хранилища данных.</span><span class="sxs-lookup"><span data-stu-id="8c367-111">Therefore, the company wants to ingest log data from the cloud data store and reference data from the on-premises data store.</span></span> <span data-ttu-id="8c367-112">Затем данные обрабатываются с помощью Hadoop в облаке (Azure HDInsight), а результаты публикуются в облачное хранилище данных (например, хранилище данных SQL Azure) или локальное хранилище данных (например, SQL Server).</span><span class="sxs-lookup"><span data-stu-id="8c367-112">Then, process the data by using Hadoop in the cloud (Azure HDInsight) and publish the result data into a cloud data warehouse such as Azure SQL Data Warehouse or an on-premises data store such as SQL Server.</span></span> <span data-ttu-id="8c367-113">И такой рабочий процесс должен выполняться еженедельно.</span><span class="sxs-lookup"><span data-stu-id="8c367-113">It wants this workflow to run weekly once.</span></span> 

<span data-ttu-id="8c367-114">Для этого нужна платформа, которая позволит компании создать рабочий процесс для приема данных из локального и облачного хранилищ данных, преобразовать или обработать эти данные с помощью существующих служб вычислений (например, Hadoop) и опубликовать результаты в локальное или облачное хранилище данных для использования приложениями бизнес-аналитики.</span><span class="sxs-lookup"><span data-stu-id="8c367-114">What is needed is a platform that allows the company to create a workflow that can ingest data from both on-premises and cloud data stores, and transform or process data by using existing compute services such as Hadoop, and publish the results to an on-premises or cloud data store for BI applications to consume.</span></span> 

![Обзор фабрики данных](media/data-factory-introduction/what-is-azure-data-factory.png) 

<span data-ttu-id="8c367-116">Фабрика данных Azure — это платформа для таких сценариев.</span><span class="sxs-lookup"><span data-stu-id="8c367-116">Azure Data Factory is the platform for this kind of scenarios.</span></span> <span data-ttu-id="8c367-117">Это **облачная служба интеграции данных, которая позволяет создавать управляемые данными рабочие процессы в облаке для оркестрации и автоматизации перемещения и преобразования данных**.</span><span class="sxs-lookup"><span data-stu-id="8c367-117">It is a **cloud-based data integration service that allows you to create data-driven workflows in the cloud for orchestrating and automating data movement and data transformation**.</span></span> <span data-ttu-id="8c367-118">С помощью фабрики данных Azure можно создавать и включать в расписание управляемые данными рабочие процессы (конвейеры), которые могут принимать данные из разнородных хранилищ данных, обрабатывать и преобразовывать эти данные с помощью служб вычислений (например, Azure HDInsight Hadoop, Spark, Azure Data Lake Analytics и машинного обучения Azure), а также публиковать выходные данные в хранилища данных (например, хранилище данных SQL Azure) для использования приложениями бизнес-аналитики.</span><span class="sxs-lookup"><span data-stu-id="8c367-118">Using Azure Data Factory, you can create and schedule data-driven workflows (called pipelines) that can ingest data from disparate data stores, process/transform the data by using compute services such as Azure HDInsight Hadoop, Spark, Azure Data Lake Analytics, and Azure Machine Learning, and publish output data to data stores such as Azure SQL Data Warehouse for business intelligence (BI) applications to consume.</span></span>  

<span data-ttu-id="8c367-119">В отличие от традиционных платформ для последовательного извлечения, преобразования и загрузки данных эта платформа предусматривает два этапа обработки: извлечение и загрузка, за которыми следуют преобразование и загрузка.</span><span class="sxs-lookup"><span data-stu-id="8c367-119">It's more of an Extract-and-Load (EL) and then Transform-and-Load (TL) platform rather than a traditional Extract-Transform-and-Load (ETL) platform.</span></span> <span data-ttu-id="8c367-120">Выполняемые преобразования служат для преобразования и обработки данных с помощью служб вычислений, а не для преобразований, предусматривающих добавление производных столбцов, подсчет числа строк, сортировку данных и т. д.</span><span class="sxs-lookup"><span data-stu-id="8c367-120">The transformations that are performed are to transform/process data by using compute services rather than to perform transformations like the ones for adding derived columns, counting number of rows, sorting data, etc.</span></span> 

<span data-ttu-id="8c367-121">Сейчас в фабрике данных Azure данные, полученные и созданные рабочими процессами, представляют **временные срезы**, то есть они могут обрабатываться ежечасно, ежедневно, еженедельно и т. д.</span><span class="sxs-lookup"><span data-stu-id="8c367-121">Currently, in Azure Data Factory, the data that is consumed and produced by workflows is **time-sliced data** (hourly, daily, weekly, etc.).</span></span> <span data-ttu-id="8c367-122">Например, конвейер может считывать входные данные, обрабатывать данные и генерировать выходные данные один раз в день.</span><span class="sxs-lookup"><span data-stu-id="8c367-122">For example, a pipeline may read input data, process data, and produce output data once a day.</span></span> <span data-ttu-id="8c367-123">Рабочий процесс также можно запускать однократно.</span><span class="sxs-lookup"><span data-stu-id="8c367-123">You can also run a workflow just one time.</span></span>  
  

## <a name="how-does-it-work"></a><span data-ttu-id="8c367-124">Как это работает?</span><span class="sxs-lookup"><span data-stu-id="8c367-124">How does it work?</span></span> 
<span data-ttu-id="8c367-125">Конвейеры (управляемые данными рабочие процессы) в фабрике Azure данных обычно выполняют следующие действия.</span><span class="sxs-lookup"><span data-stu-id="8c367-125">The pipelines (data-driven workflows) in Azure Data Factory typically perform the following three steps:</span></span>

![Три этапа обработки данных в фабрике данных Azure](media/data-factory-introduction/three-information-production-stages.png)

### <a name="connect-and-collect"></a><span data-ttu-id="8c367-127">Подключение и сбор данных</span><span class="sxs-lookup"><span data-stu-id="8c367-127">Connect and collect</span></span>
<span data-ttu-id="8c367-128">Предприятия работают с данными разных типов, хранимыми в разных источниках.</span><span class="sxs-lookup"><span data-stu-id="8c367-128">Enterprises have data of various types located in disparate sources.</span></span> <span data-ttu-id="8c367-129">Первым этапом в создании системы производства информации является подключение ко всем необходимым источникам данных и службам обработки, таким как службы SaaS, файловые ресурсы с общим доступом, FTP и веб-службы, и перемещение данных в централизованное расположение для последующей обработки.</span><span class="sxs-lookup"><span data-stu-id="8c367-129">The first step in building an information production system is to connect to all the required sources of data and processing, such as SaaS services, file shares, FTP, web services, and move the data as-needed to a centralized location for subsequent processing.</span></span>

<span data-ttu-id="8c367-130">Не имея фабрики данных предприятия вынуждены создавать компоненты для перемещения пользовательских данных или писать пользовательские службы для интеграции этих источников данных и обработки.</span><span class="sxs-lookup"><span data-stu-id="8c367-130">Without Data Factory, enterprises must build custom data movement components or write custom services to integrate these data sources and processing.</span></span> <span data-ttu-id="8c367-131">Такие системы дорого стоят, их сложно интегрировать и обслуживать. Кроме того, они часто не включают функции мониторинга и оповещений корпоративного уровня, а также элементы управления, которые может предложить полностью управляемая служба.</span><span class="sxs-lookup"><span data-stu-id="8c367-131">It is expensive and hard to integrate and maintain such systems, and it often lacks the enterprise grade monitoring and alerting, and the controls that a fully managed service can offer.</span></span>

<span data-ttu-id="8c367-132">С помощью фабрики данных вы можете использовать действие копирования в конвейере данных, чтобы переместить данные из локальных и облачных исходных хранилищ данных в централизованное хранилище данных в облаке для последующего анализа.</span><span class="sxs-lookup"><span data-stu-id="8c367-132">With Data Factory, you can use the Copy Activity in a data pipeline to move data from both on-premises and cloud source data stores to a centralization data store in the cloud for further analysis.</span></span> <span data-ttu-id="8c367-133">Например, вы можете собрать данные в Azure Data Lake Store и позже преобразовать эти данные с помощью службы вычислений Azure Data Lake Analytics.</span><span class="sxs-lookup"><span data-stu-id="8c367-133">For example, you can collect data in an Azure Data Lake Store and transform the data later by using an Azure Data Lake Analytics compute service.</span></span> <span data-ttu-id="8c367-134">Или же вы можете собрать данные в хранилище BLOB-объектов Azure и позже преобразовать их с помощью кластера Hadoop под управлением службы Azure HDInsight.</span><span class="sxs-lookup"><span data-stu-id="8c367-134">Or, collect data in an Azure Blob Storage and transform data later by using an Azure HDInsight Hadoop cluster.</span></span>

### <a name="transform-and-enrich"></a><span data-ttu-id="8c367-135">Преобразование и дополнение данных</span><span class="sxs-lookup"><span data-stu-id="8c367-135">Transform and enrich</span></span>
<span data-ttu-id="8c367-136">Данные, собранные в централизованном облачном хранилище данных, необходимо обработать или преобразовать с помощью служб вычислений, например HDInsight Hadoop, Spark, Data Lake Analytics и машинного обучения.</span><span class="sxs-lookup"><span data-stu-id="8c367-136">Once data is present in a centralized data store in the cloud, you want the collected data to be processed or transformed by using compute services such as HDInsight Hadoop, Spark, Data Lake Analytics, and Machine Learning.</span></span> <span data-ttu-id="8c367-137">Также необходимо надежно преобразовывать данные по определенному расписанию (поддерживаемому и управляемому) для насыщения рабочих сред доверенными данными.</span><span class="sxs-lookup"><span data-stu-id="8c367-137">You want to reliably produce transformed data on a maintainable and controlled schedule to feed production environments with trusted data.</span></span> 

### <a name="publish"></a><span data-ttu-id="8c367-138">Опубликовать</span><span class="sxs-lookup"><span data-stu-id="8c367-138">Publish</span></span> 
<span data-ttu-id="8c367-139">Преобразованные данные можно передавать из облака в локальные источники (например, SQL Server) или хранить в облачных источниках для бизнес-аналитики, а также использования средствами анализа и другими приложениями.</span><span class="sxs-lookup"><span data-stu-id="8c367-139">Deliver transformed data from the cloud to on-premises sources like SQL Server, or keep it in your cloud storage sources for consumption by business intelligence (BI) and analytics tools and other applications.</span></span>

## <a name="key-components"></a><span data-ttu-id="8c367-140">Ключевые компоненты</span><span class="sxs-lookup"><span data-stu-id="8c367-140">Key components</span></span>
<span data-ttu-id="8c367-141">В подписке Azure может быть один или несколько экземпляров фабрики данных Azure.</span><span class="sxs-lookup"><span data-stu-id="8c367-141">An Azure subscription may have one or more Azure Data Factory instances (or data factories).</span></span> <span data-ttu-id="8c367-142">Фабрика данных Azure включает четыре ключевых компонента. Они образуют платформу, на которой можно создавать управляемые данными рабочие процессы, предусматривающие перемещение и преобразование данных.</span><span class="sxs-lookup"><span data-stu-id="8c367-142">Azure Data Factory is composed of four key components that work together to provide the platform on which you can compose data-driven workflows with steps to move and transform data.</span></span> 

### <a name="pipeline"></a><span data-ttu-id="8c367-143">Конвейер</span><span class="sxs-lookup"><span data-stu-id="8c367-143">Pipeline</span></span>
<span data-ttu-id="8c367-144">В фабрике данных можно использовать один или несколько конвейеров.</span><span class="sxs-lookup"><span data-stu-id="8c367-144">A data factory may have one or more pipelines.</span></span> <span data-ttu-id="8c367-145">Конвейер представляет собой группу действий.</span><span class="sxs-lookup"><span data-stu-id="8c367-145">A pipeline is a group of activities.</span></span> <span data-ttu-id="8c367-146">Действия в конвейере совместно выполняют задачу.</span><span class="sxs-lookup"><span data-stu-id="8c367-146">Together, the activities in a pipeline perform a task.</span></span> <span data-ttu-id="8c367-147">Например, конвейер может включать группу действий, которые принимают данные из большого двоичного объекта Azure и выполняют запрос Hive в кластере HDInsight для секционирования данных.</span><span class="sxs-lookup"><span data-stu-id="8c367-147">For example, a pipeline could contain a group of activities that ingests data from an Azure blob, and then run a Hive query on an HDInsight cluster to partition the data.</span></span> <span data-ttu-id="8c367-148">Преимуществом является то, что конвейер позволяет управлять группами действий, а не каждым отдельным действием.</span><span class="sxs-lookup"><span data-stu-id="8c367-148">The benefit of this is that the pipeline allows you to manage the activities as a set instead of each one individually.</span></span> <span data-ttu-id="8c367-149">Например, вы можете развернуть конвейер и запланировать его работу, а не выполнять действия отдельно.</span><span class="sxs-lookup"><span data-stu-id="8c367-149">For example, you can deploy and schedule the pipeline, instead of the activities independently.</span></span> 

### <a name="activity"></a><span data-ttu-id="8c367-150">Действие</span><span class="sxs-lookup"><span data-stu-id="8c367-150">Activity</span></span>
<span data-ttu-id="8c367-151">Конвейер может включать одно или несколько действий.</span><span class="sxs-lookup"><span data-stu-id="8c367-151">A pipeline may have one or more activities.</span></span> <span data-ttu-id="8c367-152">Действия определяют то, что нужно выполнить с вашими данными.</span><span class="sxs-lookup"><span data-stu-id="8c367-152">Activities define the actions to perform on your data.</span></span> <span data-ttu-id="8c367-153">Например, действие копирования может использоваться для копирования данных из одного хранилища данных в другое.</span><span class="sxs-lookup"><span data-stu-id="8c367-153">For example, you may use a Copy activity to copy data from one data store to another data store.</span></span> <span data-ttu-id="8c367-154">Точно так же можно использовать действие Hive, которое выполняет запрос Hive к кластеру Azure HDInsight для преобразования или анализа данных.</span><span class="sxs-lookup"><span data-stu-id="8c367-154">Similarly, you may use a Hive activity, which runs a Hive query on an Azure HDInsight cluster to transform or analyze your data.</span></span> <span data-ttu-id="8c367-155">Фабрика данных поддерживает два типа действий: действия перемещения данных и действия преобразования данных.</span><span class="sxs-lookup"><span data-stu-id="8c367-155">Data Factory supports two types of activities: data movement activities and data transformation activities.</span></span>

### <a name="data-movement-activities"></a><span data-ttu-id="8c367-156">Действия перемещения данных</span><span class="sxs-lookup"><span data-stu-id="8c367-156">Data movement activities</span></span>
<span data-ttu-id="8c367-157">Действие копирования в фабрике данных копирует данные из хранилища-источника в хранилище-приемник.</span><span class="sxs-lookup"><span data-stu-id="8c367-157">Copy Activity in Data Factory copies data from a source data store to a sink data store.</span></span> <span data-ttu-id="8c367-158">Фабрика данных поддерживает приведенные ниже хранилища данных.</span><span class="sxs-lookup"><span data-stu-id="8c367-158">Data Factory supports the following data stores.</span></span> <span data-ttu-id="8c367-159">Данные из любого источника можно записывать в любой приемник.</span><span class="sxs-lookup"><span data-stu-id="8c367-159">Data from any source can be written to any sink.</span></span> <span data-ttu-id="8c367-160">Щелкните название хранилища, чтобы узнать, как скопировать данные из него или в него.</span><span class="sxs-lookup"><span data-stu-id="8c367-160">Click a data store to learn how to copy data to and from that store.</span></span>

[!INCLUDE [data-factory-supported-data-stores](../../includes/data-factory-supported-data-stores.md)]

<span data-ttu-id="8c367-161">Дополнительные сведения см. в статье [Перемещение данных с помощью действия копирования](data-factory-data-movement-activities.md).</span><span class="sxs-lookup"><span data-stu-id="8c367-161">For more information, see [Data Movement Activities](data-factory-data-movement-activities.md) article.</span></span>

### <a name="data-transformation-activities"></a><span data-ttu-id="8c367-162">Действия преобразования данных</span><span class="sxs-lookup"><span data-stu-id="8c367-162">Data transformation activities</span></span>
[!INCLUDE [data-factory-transformation-activities](../../includes/data-factory-transformation-activities.md)]

<span data-ttu-id="8c367-163">Дополнительные сведения см. в статье [Преобразование данных в фабрике данных Azure](data-factory-data-transformation-activities.md).</span><span class="sxs-lookup"><span data-stu-id="8c367-163">For more information, see [Data Transformation Activities](data-factory-data-transformation-activities.md) article.</span></span>

### <a name="custom-net-activities"></a><span data-ttu-id="8c367-164">Пользовательские действия .NET</span><span class="sxs-lookup"><span data-stu-id="8c367-164">Custom .NET activities</span></span>
<span data-ttu-id="8c367-165">Если необходимо переместить данные в хранилище данных, которое не поддерживается действием копирования, или из такого хранилища, либо преобразовать данные с использованием собственной логики, вы можете создать **настраиваемое действие .NET**.</span><span class="sxs-lookup"><span data-stu-id="8c367-165">If you need to move data to/from a data store that Copy Activity doesn't support, or transform data using your own logic, create a **custom .NET activity**.</span></span> <span data-ttu-id="8c367-166">Сведения о создании и использовании настраиваемого действия см. в статье [Использование настраиваемых действий в конвейере фабрики данных Azure](data-factory-use-custom-activities.md).</span><span class="sxs-lookup"><span data-stu-id="8c367-166">For details on creating and using a custom activity, see [Use custom activities in an Azure Data Factory pipeline](data-factory-use-custom-activities.md).</span></span>

### <a name="datasets"></a><span data-ttu-id="8c367-167">Наборы данных</span><span class="sxs-lookup"><span data-stu-id="8c367-167">Datasets</span></span>
<span data-ttu-id="8c367-168">Каждое действие принимает некоторое число наборов данных на входе и создает один или несколько наборов данных на выходе.</span><span class="sxs-lookup"><span data-stu-id="8c367-168">An activity takes zero or more datasets as inputs and one or more datasets as outputs.</span></span> <span data-ttu-id="8c367-169">Наборы данных представляют структуры данных в хранилищах. Эти структуры указывают данные, необходимые для использования в действиях, разделяя их на входные и выходные.</span><span class="sxs-lookup"><span data-stu-id="8c367-169">Datasets represent data structures within the data stores, which simply point or reference the data you want to use in your activities as inputs or outputs.</span></span> <span data-ttu-id="8c367-170">Например, набор данных больших двоичных объектов Azure указывает контейнер больших двоичных объектов и папку в хранилище BLOB-объектов, из которой конвейер должен считывать данные.</span><span class="sxs-lookup"><span data-stu-id="8c367-170">For example, an Azure Blob dataset specifies the blob container and folder in the Azure Blob Storage from which the pipeline should read the data.</span></span> <span data-ttu-id="8c367-171">Или же набор таблиц SQL Azure указывает таблицу, в которую с помощью действия записываются выходные данные.</span><span class="sxs-lookup"><span data-stu-id="8c367-171">Or, an Azure SQL Table dataset specifies the table to which the output data is written by the activity.</span></span> 

### <a name="linked-services"></a><span data-ttu-id="8c367-172">Связанные службы</span><span class="sxs-lookup"><span data-stu-id="8c367-172">Linked services</span></span>
<span data-ttu-id="8c367-173">Связанные службы напоминают строки подключения, определяющие сведения о подключении, необходимые для подключения фабрики данных к внешним ресурсам.</span><span class="sxs-lookup"><span data-stu-id="8c367-173">Linked services are much like connection strings, which define the connection information needed for Data Factory to connect to external resources.</span></span> <span data-ttu-id="8c367-174">Таким образом, набор данных представляет структуру данных, а связанная служба определяет подключение к источнику данных.</span><span class="sxs-lookup"><span data-stu-id="8c367-174">Think of it this way - a linked service defines the connection to the data source and a dataset represents the structure of the data.</span></span> <span data-ttu-id="8c367-175">Например, связанная служба хранилища Azure определяет строку подключения для подключения к учетной записи хранения Azure.</span><span class="sxs-lookup"><span data-stu-id="8c367-175">For example, an Azure Storage linked service specifies connection string to connect to the Azure Storage account.</span></span> <span data-ttu-id="8c367-176">А набор данных больших двоичных объектов Azure определяет контейнер больших двоичных объектов и папку, которая содержит данные.</span><span class="sxs-lookup"><span data-stu-id="8c367-176">And, an Azure Blob dataset specifies the blob container and the folder that contains the data.</span></span>   

<span data-ttu-id="8c367-177">Связанные службы используются в фабрике данных для двух целей:</span><span class="sxs-lookup"><span data-stu-id="8c367-177">Linked services are used for two purposes in Data Factory:</span></span>

* <span data-ttu-id="8c367-178">Для представления **хранилища данных**, включая, помимо прочего, локальный сервер SQL Server, базу данных Oracle, файловый ресурс и учетную запись хранилища BLOB-объектов Azure.</span><span class="sxs-lookup"><span data-stu-id="8c367-178">To represent a **data store** including, but not limited to, an on-premises SQL Server, Oracle database, file share, or an Azure Blob Storage account.</span></span> <span data-ttu-id="8c367-179">Список поддерживаемых хранилищ данных см. в статье [Перемещение данных с помощью действия копирования](#data-movement-activities).</span><span class="sxs-lookup"><span data-stu-id="8c367-179">See the [Data movement activities](#data-movement-activities) section for a list of supported data stores.</span></span>
* <span data-ttu-id="8c367-180">Для представления **вычислительного ресурса**, в котором можно выполнить действие.</span><span class="sxs-lookup"><span data-stu-id="8c367-180">To represent a **compute resource** that can host the execution of an activity.</span></span> <span data-ttu-id="8c367-181">Например, действие HDInsightHive выполняется в кластере Hadoop в HDInsight.</span><span class="sxs-lookup"><span data-stu-id="8c367-181">For example, the HDInsightHive activity runs on an HDInsight Hadoop cluster.</span></span> <span data-ttu-id="8c367-182">Список поддерживаемых вычислительных сред см. в статье [Преобразование данных в фабрике данных Azure](#data-transformation-activities).</span><span class="sxs-lookup"><span data-stu-id="8c367-182">See [Data transformation activities](#data-transformation-activities) section for a list of supported compute environments.</span></span>

### <a name="relationship-between-data-factory-entities"></a><span data-ttu-id="8c367-183">Связь между сущностями фабрики данных</span><span class="sxs-lookup"><span data-stu-id="8c367-183">Relationship between Data Factory entities</span></span>
<span data-ttu-id="8c367-184">![Схема. Фабрика данных, облачная служба интеграции данных: основные понятия](./media/data-factory-introduction/data-integration-service-key-concepts.png)
**Рисунок 2.**</span><span class="sxs-lookup"><span data-stu-id="8c367-184">![Diagram: Data Factory, a cloud data integration service - Key Concepts](./media/data-factory-introduction/data-integration-service-key-concepts.png)
**Figure 2.**</span></span> <span data-ttu-id="8c367-185">Связи между набором данных, действием, конвейером и связанной службой</span><span class="sxs-lookup"><span data-stu-id="8c367-185">Relationships between Dataset, Activity, Pipeline, and Linked service</span></span>

## <a name="supported-regions"></a><span data-ttu-id="8c367-186">Поддерживаемые регионы</span><span class="sxs-lookup"><span data-stu-id="8c367-186">Supported regions</span></span>
<span data-ttu-id="8c367-187">Сейчас фабрики данных можно создавать в таких регионах: **западная часть США**, **восточная часть США** и **Северная Европа**.</span><span class="sxs-lookup"><span data-stu-id="8c367-187">Currently, you can create data factories in the **West US**, **East US**, and **North Europe** regions.</span></span> <span data-ttu-id="8c367-188">Однако для перемещения данных между хранилищами данных или для обработки данных с помощью служб вычислений фабрики данных могут обращаться к хранилищам данных и службам вычислений в других регионах Azure.</span><span class="sxs-lookup"><span data-stu-id="8c367-188">However, a data factory can access data stores and compute services in other Azure regions to move data between data stores or process data using compute services.</span></span>

<span data-ttu-id="8c367-189">В самой фабрике данных Azure данные не хранятся.</span><span class="sxs-lookup"><span data-stu-id="8c367-189">Azure Data Factory itself does not store any data.</span></span> <span data-ttu-id="8c367-190">Эта служба позволяет создавать управляемые данными рабочие процессы для обработки данных с помощью [служб вычислений](#data-transformation-activities) в других регионах или локальной среде и оркестрации перемещения данных между [поддерживаемыми хранилищами](#data-movement-activities).</span><span class="sxs-lookup"><span data-stu-id="8c367-190">It lets you create data-driven workflows to orchestrate movement of data between [supported data stores](#data-movement-activities) and processing of data using [compute services](#data-transformation-activities) in other regions or in an on-premises environment.</span></span> <span data-ttu-id="8c367-191">Кроме того, с помощью фабрики данных можно [отслеживать рабочие процессы и управлять ими](data-factory-monitor-manage-pipelines.md) , используя программные методы и пользовательский интерфейс.</span><span class="sxs-lookup"><span data-stu-id="8c367-191">It also allows you to [monitor and manage workflows](data-factory-monitor-manage-pipelines.md) using both programmatic and UI mechanisms.</span></span>

<span data-ttu-id="8c367-192">Хотя фабрика данных доступна только в **западной части США**, **восточной части США** и **Северной Европе**, служба, которая обеспечивает перемещение данных в фабрике данных, доступна [глобально](data-factory-data-movement-activities.md#global) в нескольких регионах.</span><span class="sxs-lookup"><span data-stu-id="8c367-192">Even though Data Factory is available in only **West US**, **East US**, and **North Europe** regions, the service powering the data movement in Data Factory is available [globally](data-factory-data-movement-activities.md#global) in several regions.</span></span> <span data-ttu-id="8c367-193">Если хранилище данных находится за брандмауэром, данные перемещает [шлюз управления данными](data-factory-move-data-between-onprem-and-cloud.md), установленный в локальной среде.</span><span class="sxs-lookup"><span data-stu-id="8c367-193">If a data store is behind a firewall, then a [Data Management Gateway](data-factory-move-data-between-onprem-and-cloud.md) installed in your on-premises environment moves the data instead.</span></span>

<span data-ttu-id="8c367-194">Предположим, ваши вычислительные среды, например кластер Azure HDInsight и служба машинного обучения Azure, расположены в Западной Европе.</span><span class="sxs-lookup"><span data-stu-id="8c367-194">For an example, let us assume that your compute environments such as Azure HDInsight cluster and Azure Machine Learning are running out of West Europe region.</span></span> <span data-ttu-id="8c367-195">Вы можете создать экземпляр фабрики данных Azure в Северной Европе и с его помощью планировать задания в вычислительных средах в Западной Европе.</span><span class="sxs-lookup"><span data-stu-id="8c367-195">You can create and use an Azure Data Factory instance in North Europe and use it to schedule jobs on your compute environments in West Europe.</span></span> <span data-ttu-id="8c367-196">Фабрике данных требуется лишь несколько миллисекунд, чтобы запустить задание в вычислительной среде, но время выполнения задания в вашей вычислительной среде остается неизменным.</span><span class="sxs-lookup"><span data-stu-id="8c367-196">It takes a few milliseconds for Data Factory to trigger the job on your compute environment but the time for running the job on your computing environment does not change.</span></span>

## <a name="get-started-with-creating-a-pipeline"></a><span data-ttu-id="8c367-197">Начало работы — создание конвейера</span><span class="sxs-lookup"><span data-stu-id="8c367-197">Get started with creating a pipeline</span></span>
<span data-ttu-id="8c367-198">Для создания конвейеров данных в фабрике данных Azure можно использовать API-интерфейсы или одно из следующих средств:</span><span class="sxs-lookup"><span data-stu-id="8c367-198">You can use one of these tools or APIs to create data pipelines in Azure Data Factory:</span></span> 

- <span data-ttu-id="8c367-199">Портал Azure</span><span class="sxs-lookup"><span data-stu-id="8c367-199">Azure portal</span></span>
- <span data-ttu-id="8c367-200">Visual Studio</span><span class="sxs-lookup"><span data-stu-id="8c367-200">Visual Studio</span></span>
- <span data-ttu-id="8c367-201">PowerShell</span><span class="sxs-lookup"><span data-stu-id="8c367-201">PowerShell</span></span>
- <span data-ttu-id="8c367-202">.NET API</span><span class="sxs-lookup"><span data-stu-id="8c367-202">.NET API</span></span>
- <span data-ttu-id="8c367-203">Интерфейс REST API</span><span class="sxs-lookup"><span data-stu-id="8c367-203">REST API</span></span>
- <span data-ttu-id="8c367-204">Шаблон Azure Resource Manager</span><span class="sxs-lookup"><span data-stu-id="8c367-204">Azure Resource Manager template.</span></span> 

<span data-ttu-id="8c367-205">Чтобы научиться создавать фабрики данных с конвейерами данных, выполните пошаговые инструкции из следующих руководств:</span><span class="sxs-lookup"><span data-stu-id="8c367-205">To learn how to build data factories with data pipelines, follow step-by-step instructions in the following tutorials:</span></span>

| <span data-ttu-id="8c367-206">Учебник</span><span class="sxs-lookup"><span data-stu-id="8c367-206">Tutorial</span></span> | <span data-ttu-id="8c367-207">Описание</span><span class="sxs-lookup"><span data-stu-id="8c367-207">Description</span></span> |
| --- | --- |
| [<span data-ttu-id="8c367-208">Копирование данных из хранилища BLOB-объектов Azure в базу данных SQL с помощью фабрики данных</span><span class="sxs-lookup"><span data-stu-id="8c367-208">Move data between two cloud data stores</span></span>](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md) |<span data-ttu-id="8c367-209">В этом руководстве вы создадите фабрику данных с конвейером, который **перемещает данные** из хранилища BLOB-объектов в базу данных SQL.</span><span class="sxs-lookup"><span data-stu-id="8c367-209">In this tutorial, you create a data factory with a pipeline that **moves data** from Blob storage to SQL database.</span></span> |
| [<span data-ttu-id="8c367-210">Руководство. Создание первого конвейера для обработки данных с помощью кластера Hadoop</span><span class="sxs-lookup"><span data-stu-id="8c367-210">Transform data using Hadoop cluster</span></span>](data-factory-build-your-first-pipeline.md) |<span data-ttu-id="8c367-211">С помощью этого руководства вы создадите свою первую фабрику данных Azure с конвейером данных, который **обрабатывает данные** путем запуска сценария Hive в кластере Azure HDInsight (Hadoop).</span><span class="sxs-lookup"><span data-stu-id="8c367-211">In this tutorial, you build your first Azure data factory with a data pipeline that **processes data** by running Hive script on an Azure HDInsight (Hadoop) cluster.</span></span> |
| [<span data-ttu-id="8c367-212">Перемещение данных между локальными источниками и облаком с помощью шлюза управления данными</span><span class="sxs-lookup"><span data-stu-id="8c367-212">Move data between an on-premises data store and a cloud data store using Data Management Gateway</span></span>](data-factory-move-data-between-onprem-and-cloud.md) |<span data-ttu-id="8c367-213">В этом руководстве вы создадите фабрику данных с конвейером, который **перемещает данные** из **локальной** базы данных SQL Server в большой двоичный объект Azure.</span><span class="sxs-lookup"><span data-stu-id="8c367-213">In this tutorial, you build a data factory with a pipeline that **moves data** from an **on-premises** SQL Server database to an Azure blob.</span></span> <span data-ttu-id="8c367-214">В рамках этого пошагового руководства вы установите и настроите шлюз управления данными на своем компьютере.</span><span class="sxs-lookup"><span data-stu-id="8c367-214">As part of the walkthrough, you install and configure the Data Management Gateway on your machine.</span></span> |
