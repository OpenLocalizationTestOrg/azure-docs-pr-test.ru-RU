---
title: "Общие сведения о фабрике данных — службе интеграции данных | Документация Майкрософт"
description: "Узнайте о фабрике данных Azure, облачной службе интеграции данных, которая организует и автоматизирует перемещение и преобразование данных."
keywords: "интеграция данных, интеграция данных в облаке, что такое фабрика данных Azure"
services: data-factory
documentationcenter: 
author: sharonlo101
manager: jhubbard
editor: monicar
ms.assetid: cec68cb5-ca0d-473b-8ae8-35de949a009e
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: get-started-article
ms.date: 08/14/2017
ms.author: shlo
ms.openlocfilehash: bc72c4d58b98f6521dbb7420a5d05a121b0ddbda
ms.sourcegitcommit: 50e23e8d3b1148ae2d36dad3167936b4e52c8a23
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 08/18/2017
---
# <a name="introduction-to-azure-data-factory"></a>Введение в фабрику данных Azure 
## <a name="what-is-azure-data-factory"></a>Что такое фабрика данных Azure?
Как имеющиеся большие данные используются в бизнес-среде? Возможно ли расширить облачные данные за счет ссылочных данных из локальных источников данных или других разрозненных источников данных? Например, компания-разработчик игр собирает разные журналы, создаваемые играми в облаке. Компания хочет проанализировать эти журналы, чтобы получить сведения о предпочтениях клиентов, демографических данных, особенностях использования и т. д. Эти сведения помогут понять, как можно увеличить продажи и перекрестные продажи, разработать новые интересные функции, стимулирующие развитие бизнеса, а также предоставить клиентам более удобные возможности для работы. 

Для анализа этих журналов компании необходимо использовать справочные сведения о клиенте, игре и маркетинговой кампании, хранящиеся в локальном хранилище данных. Таким образом компания хочет получить данные журнала из облачного хранилища данных, а справочные сведения — из локального хранилища данных. Затем данные обрабатываются с помощью Hadoop в облаке (Azure HDInsight), а результаты публикуются в облачное хранилище данных (например, хранилище данных SQL Azure) или локальное хранилище данных (например, SQL Server). И такой рабочий процесс должен выполняться еженедельно. 

Для этого нужна платформа, которая позволит компании создать рабочий процесс для приема данных из локального и облачного хранилищ данных, преобразовать или обработать эти данные с помощью существующих служб вычислений (например, Hadoop) и опубликовать результаты в локальное или облачное хранилище данных для использования приложениями бизнес-аналитики. 

![Обзор фабрики данных](media/data-factory-introduction/what-is-azure-data-factory.png) 

Фабрика данных Azure — это платформа для таких сценариев. Это **облачная служба интеграции данных, которая позволяет создавать управляемые данными рабочие процессы в облаке для оркестрации и автоматизации перемещения и преобразования данных**. С помощью фабрики данных Azure можно создавать и включать в расписание управляемые данными рабочие процессы (конвейеры), которые могут принимать данные из разнородных хранилищ данных, обрабатывать и преобразовывать эти данные с помощью служб вычислений (например, Azure HDInsight Hadoop, Spark, Azure Data Lake Analytics и машинного обучения Azure), а также публиковать выходные данные в хранилища данных (например, хранилище данных SQL Azure) для использования приложениями бизнес-аналитики.  

В отличие от традиционных платформ для последовательного извлечения, преобразования и загрузки данных эта платформа предусматривает два этапа обработки: извлечение и загрузка, за которыми следуют преобразование и загрузка. Выполняемые преобразования служат для преобразования и обработки данных с помощью служб вычислений, а не для преобразований, предусматривающих добавление производных столбцов, подсчет числа строк, сортировку данных и т. д. 

Сейчас в фабрике данных Azure данные, полученные и созданные рабочими процессами, представляют **временные срезы**, то есть они могут обрабатываться ежечасно, ежедневно, еженедельно и т. д. Например, конвейер может считывать входные данные, обрабатывать данные и генерировать выходные данные один раз в день. Рабочий процесс также можно запускать однократно.  
  

## <a name="how-does-it-work"></a>Как это работает? 
Конвейеры (управляемые данными рабочие процессы) в фабрике Azure данных обычно выполняют следующие действия.

![Три этапа обработки данных в фабрике данных Azure](media/data-factory-introduction/three-information-production-stages.png)

### <a name="connect-and-collect"></a>Подключение и сбор данных
Предприятия работают с данными разных типов, хранимыми в разных источниках. Первым этапом в создании системы производства информации является подключение ко всем необходимым источникам данных и службам обработки, таким как службы SaaS, файловые ресурсы с общим доступом, FTP и веб-службы, и перемещение данных в централизованное расположение для последующей обработки.

Не имея фабрики данных предприятия вынуждены создавать компоненты для перемещения пользовательских данных или писать пользовательские службы для интеграции этих источников данных и обработки. Такие системы дорого стоят, их сложно интегрировать и обслуживать. Кроме того, они часто не включают функции мониторинга и оповещений корпоративного уровня, а также элементы управления, которые может предложить полностью управляемая служба.

С помощью фабрики данных вы можете использовать действие копирования в конвейере данных, чтобы переместить данные из локальных и облачных исходных хранилищ данных в централизованное хранилище данных в облаке для последующего анализа. Например, вы можете собрать данные в Azure Data Lake Store и позже преобразовать эти данные с помощью службы вычислений Azure Data Lake Analytics. Или же вы можете собрать данные в хранилище BLOB-объектов Azure и позже преобразовать их с помощью кластера Hadoop под управлением службы Azure HDInsight.

### <a name="transform-and-enrich"></a>Преобразование и дополнение данных
Данные, собранные в централизованном облачном хранилище данных, необходимо обработать или преобразовать с помощью служб вычислений, например HDInsight Hadoop, Spark, Data Lake Analytics и машинного обучения. Также необходимо надежно преобразовывать данные по определенному расписанию (поддерживаемому и управляемому) для насыщения рабочих сред доверенными данными. 

### <a name="publish"></a>Опубликовать 
Преобразованные данные можно передавать из облака в локальные источники (например, SQL Server) или хранить в облачных источниках для бизнес-аналитики, а также использования средствами анализа и другими приложениями.

## <a name="key-components"></a>Ключевые компоненты
В подписке Azure может быть один или несколько экземпляров фабрики данных Azure. Фабрика данных Azure включает четыре ключевых компонента. Они образуют платформу, на которой можно создавать управляемые данными рабочие процессы, предусматривающие перемещение и преобразование данных. 

### <a name="pipeline"></a>Конвейер
В фабрике данных можно использовать один или несколько конвейеров. Конвейер представляет собой группу действий. Действия в конвейере совместно выполняют задачу. Например, конвейер может включать группу действий, которые принимают данные из большого двоичного объекта Azure и выполняют запрос Hive в кластере HDInsight для секционирования данных. Преимуществом является то, что конвейер позволяет управлять группами действий, а не каждым отдельным действием. Например, вы можете развернуть конвейер и запланировать его работу, а не выполнять действия отдельно. 

### <a name="activity"></a>Действие
Конвейер может включать одно или несколько действий. Действия определяют то, что нужно выполнить с вашими данными. Например, действие копирования может использоваться для копирования данных из одного хранилища данных в другое. Точно так же можно использовать действие Hive, которое выполняет запрос Hive к кластеру Azure HDInsight для преобразования или анализа данных. Фабрика данных поддерживает два типа действий: действия перемещения данных и действия преобразования данных.

### <a name="data-movement-activities"></a>Действия перемещения данных
Действие копирования в фабрике данных копирует данные из хранилища-источника в хранилище-приемник. Фабрика данных поддерживает приведенные ниже хранилища данных. Данные из любого источника можно записывать в любой приемник. Щелкните название хранилища, чтобы узнать, как скопировать данные из него или в него.

[!INCLUDE [data-factory-supported-data-stores](../../includes/data-factory-supported-data-stores.md)]

Дополнительные сведения см. в статье [Перемещение данных с помощью действия копирования](data-factory-data-movement-activities.md).

### <a name="data-transformation-activities"></a>Действия преобразования данных
[!INCLUDE [data-factory-transformation-activities](../../includes/data-factory-transformation-activities.md)]

Дополнительные сведения см. в статье [Преобразование данных в фабрике данных Azure](data-factory-data-transformation-activities.md).

### <a name="custom-net-activities"></a>Пользовательские действия .NET
Если необходимо переместить данные в хранилище данных, которое не поддерживается действием копирования, или из такого хранилища, либо преобразовать данные с использованием собственной логики, вы можете создать **настраиваемое действие .NET**. Сведения о создании и использовании настраиваемого действия см. в статье [Использование настраиваемых действий в конвейере фабрики данных Azure](data-factory-use-custom-activities.md).

### <a name="datasets"></a>Наборы данных
Каждое действие принимает некоторое число наборов данных на входе и создает один или несколько наборов данных на выходе. Наборы данных представляют структуры данных в хранилищах. Эти структуры указывают данные, необходимые для использования в действиях, разделяя их на входные и выходные. Например, набор данных больших двоичных объектов Azure указывает контейнер больших двоичных объектов и папку в хранилище BLOB-объектов, из которой конвейер должен считывать данные. Или же набор таблиц SQL Azure указывает таблицу, в которую с помощью действия записываются выходные данные. 

### <a name="linked-services"></a>Связанные службы
Связанные службы напоминают строки подключения, определяющие сведения о подключении, необходимые для подключения фабрики данных к внешним ресурсам. Таким образом, набор данных представляет структуру данных, а связанная служба определяет подключение к источнику данных. Например, связанная служба хранилища Azure определяет строку подключения для подключения к учетной записи хранения Azure. А набор данных больших двоичных объектов Azure определяет контейнер больших двоичных объектов и папку, которая содержит данные.   

Связанные службы используются в фабрике данных для двух целей:

* Для представления **хранилища данных**, включая, помимо прочего, локальный сервер SQL Server, базу данных Oracle, файловый ресурс и учетную запись хранилища BLOB-объектов Azure. Список поддерживаемых хранилищ данных см. в статье [Перемещение данных с помощью действия копирования](#data-movement-activities).
* Для представления **вычислительного ресурса**, в котором можно выполнить действие. Например, действие HDInsightHive выполняется в кластере Hadoop в HDInsight. Список поддерживаемых вычислительных сред см. в статье [Преобразование данных в фабрике данных Azure](#data-transformation-activities).

### <a name="relationship-between-data-factory-entities"></a>Связь между сущностями фабрики данных
![Схема. Фабрика данных, облачная служба интеграции данных: основные понятия](./media/data-factory-introduction/data-integration-service-key-concepts.png)
**Рисунок 2.** Связи между набором данных, действием, конвейером и связанной службой

## <a name="supported-regions"></a>Поддерживаемые регионы
Сейчас фабрики данных можно создавать в таких регионах: **западная часть США**, **восточная часть США** и **Северная Европа**. Однако для перемещения данных между хранилищами данных или для обработки данных с помощью служб вычислений фабрики данных могут обращаться к хранилищам данных и службам вычислений в других регионах Azure.

В самой фабрике данных Azure данные не хранятся. Эта служба позволяет создавать управляемые данными рабочие процессы для обработки данных с помощью [служб вычислений](#data-transformation-activities) в других регионах или локальной среде и оркестрации перемещения данных между [поддерживаемыми хранилищами](#data-movement-activities). Кроме того, с помощью фабрики данных можно [отслеживать рабочие процессы и управлять ими](data-factory-monitor-manage-pipelines.md) , используя программные методы и пользовательский интерфейс.

Хотя фабрика данных доступна только в **западной части США**, **восточной части США** и **Северной Европе**, служба, которая обеспечивает перемещение данных в фабрике данных, доступна [глобально](data-factory-data-movement-activities.md#global) в нескольких регионах. Если хранилище данных находится за брандмауэром, данные перемещает [шлюз управления данными](data-factory-move-data-between-onprem-and-cloud.md), установленный в локальной среде.

Предположим, ваши вычислительные среды, например кластер Azure HDInsight и служба машинного обучения Azure, расположены в Западной Европе. Вы можете создать экземпляр фабрики данных Azure в Северной Европе и с его помощью планировать задания в вычислительных средах в Западной Европе. Фабрике данных требуется лишь несколько миллисекунд, чтобы запустить задание в вычислительной среде, но время выполнения задания в вашей вычислительной среде остается неизменным.

## <a name="get-started-with-creating-a-pipeline"></a>Начало работы — создание конвейера
Для создания конвейеров данных в фабрике данных Azure можно использовать API-интерфейсы или одно из следующих средств: 

- Портал Azure
- Visual Studio
- PowerShell
- .NET API
- Интерфейс REST API
- Шаблон Azure Resource Manager 

Чтобы научиться создавать фабрики данных с конвейерами данных, выполните пошаговые инструкции из следующих руководств:

| Учебник | Описание |
| --- | --- |
| [Копирование данных из хранилища BLOB-объектов Azure в базу данных SQL с помощью фабрики данных](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md) |В этом руководстве вы создадите фабрику данных с конвейером, который **перемещает данные** из хранилища BLOB-объектов в базу данных SQL. |
| [Руководство. Создание первого конвейера для обработки данных с помощью кластера Hadoop](data-factory-build-your-first-pipeline.md) |С помощью этого руководства вы создадите свою первую фабрику данных Azure с конвейером данных, который **обрабатывает данные** путем запуска сценария Hive в кластере Azure HDInsight (Hadoop). |
| [Перемещение данных между локальными источниками и облаком с помощью шлюза управления данными](data-factory-move-data-between-onprem-and-cloud.md) |В этом руководстве вы создадите фабрику данных с конвейером, который **перемещает данные** из **локальной** базы данных SQL Server в большой двоичный объект Azure. В рамках этого пошагового руководства вы установите и настроите шлюз управления данными на своем компьютере. |
