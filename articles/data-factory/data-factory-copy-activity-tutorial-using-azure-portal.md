---
title: "Руководство по созданию конвейера фабрики данных Azure для копирования данных (портал Azure) | Документация Майкрософт"
description: "В этом руководстве вы будете использовать портал Azure, чтобы создать конвейер с действием копирования фабрики данных Azure для копирования данных из хранилища BLOB-объектов Azure в базу данных SQL Azure."
services: data-factory
documentationcenter: 
author: spelluru
manager: jhubbard
editor: monicar
ms.assetid: d9317652-0170-4fd3-b9b2-37711272162b
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: get-started-article
ms.date: 07/10/2017
ms.author: spelluru
ms.openlocfilehash: 8072a863fab0b304ccbbba639aa56b403e8f37c7
ms.sourcegitcommit: 02e69c4a9d17645633357fe3d46677c2ff22c85a
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 08/03/2017
---
# <a name="tutorial-use-azure-portal-to-create-a-data-factory-pipeline-to-copy-data"></a><span data-ttu-id="1d2f2-103">Руководство по создания конвейера фабрики данных для копирования данных с помощью портала Azure</span><span class="sxs-lookup"><span data-stu-id="1d2f2-103">Tutorial: Use Azure portal to create a Data Factory pipeline to copy data</span></span> 
> [!div class="op_single_selector"]
> * [<span data-ttu-id="1d2f2-104">Обзор и предварительные требования</span><span class="sxs-lookup"><span data-stu-id="1d2f2-104">Overview and prerequisites</span></span>](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md)
> * [<span data-ttu-id="1d2f2-105">Мастер копирования</span><span class="sxs-lookup"><span data-stu-id="1d2f2-105">Copy Wizard</span></span>](data-factory-copy-data-wizard-tutorial.md)
> * [<span data-ttu-id="1d2f2-106">Портал Azure</span><span class="sxs-lookup"><span data-stu-id="1d2f2-106">Azure portal</span></span>](data-factory-copy-activity-tutorial-using-azure-portal.md)
> * [<span data-ttu-id="1d2f2-107">Visual Studio</span><span class="sxs-lookup"><span data-stu-id="1d2f2-107">Visual Studio</span></span>](data-factory-copy-activity-tutorial-using-visual-studio.md)
> * [<span data-ttu-id="1d2f2-108">PowerShell</span><span class="sxs-lookup"><span data-stu-id="1d2f2-108">PowerShell</span></span>](data-factory-copy-activity-tutorial-using-powershell.md)
> * [<span data-ttu-id="1d2f2-109">Шаблон Azure Resource Manager</span><span class="sxs-lookup"><span data-stu-id="1d2f2-109">Azure Resource Manager template</span></span>](data-factory-copy-activity-tutorial-using-azure-resource-manager-template.md)
> * [<span data-ttu-id="1d2f2-110">ИНТЕРФЕЙС REST API</span><span class="sxs-lookup"><span data-stu-id="1d2f2-110">REST API</span></span>](data-factory-copy-activity-tutorial-using-rest-api.md)
> * [<span data-ttu-id="1d2f2-111">API .NET</span><span class="sxs-lookup"><span data-stu-id="1d2f2-111">.NET API</span></span>](data-factory-copy-activity-tutorial-using-dotnet-api.md)
> 
> 

<span data-ttu-id="1d2f2-112">В этом руководстве показано, как создать фабрику данных c конвейером, который копирует данные из хранилища BLOB-объектов Azure в базу данных SQL Azure, с помощью [портала Azure](https://portal.azure.com).</span><span class="sxs-lookup"><span data-stu-id="1d2f2-112">In this article, you learn how to use [Azure portal](https://portal.azure.com) to create a data factory with a pipeline that copies data from an Azure blob storage to an Azure SQL database.</span></span> <span data-ttu-id="1d2f2-113">Если вы еще не работали с фабрикой данных Azure, перед выполнением действий, описанных в этом руководстве, ознакомьтесь со статьей [Введение в фабрику данных Azure](data-factory-introduction.md).</span><span class="sxs-lookup"><span data-stu-id="1d2f2-113">If you are new to Azure Data Factory, read through the [Introduction to Azure Data Factory](data-factory-introduction.md) article before doing this tutorial.</span></span>   

<span data-ttu-id="1d2f2-114">В этом руководстве описывается создание конвейера с одним действием — действием копирования.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-114">In this tutorial, you create a pipeline with one activity in it: Copy Activity.</span></span> <span data-ttu-id="1d2f2-115">Действие копирования копирует данные из поддерживаемого хранилища данных в поддерживаемое хранилище данных-приемник.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-115">The copy activity copies data from a supported data store to a supported sink data store.</span></span> <span data-ttu-id="1d2f2-116">Список хранилищ данных, которые поддерживаются в качестве источников и приемников, см. в разделе [Поддерживаемые хранилища данных и форматы](data-factory-data-movement-activities.md#supported-data-stores-and-formats).</span><span class="sxs-lookup"><span data-stu-id="1d2f2-116">For a list of data stores supported as sources and sinks, see [supported data stores](data-factory-data-movement-activities.md#supported-data-stores-and-formats).</span></span> <span data-ttu-id="1d2f2-117">Это действие выполняется с помощью глобально доступной службы, обеспечивающей безопасное, надежное и масштабируемое копирование данных между разными хранилищами.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-117">The activity is powered by a globally available service that can copy data between various data stores in a secure, reliable, and scalable way.</span></span> <span data-ttu-id="1d2f2-118">Дополнительные сведения о действии копирования см. в статье [Перемещение данных с помощью действия копирования](data-factory-data-movement-activities.md).</span><span class="sxs-lookup"><span data-stu-id="1d2f2-118">For more information about the Copy Activity, see [Data Movement Activities](data-factory-data-movement-activities.md).</span></span>

<span data-ttu-id="1d2f2-119">Конвейер может содержать сразу несколько действий.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-119">A pipeline can have more than one activity.</span></span> <span data-ttu-id="1d2f2-120">Два действия можно объединить в цепочку (выполнить одно действие вслед за другим), настроив выходной набор данных одного действия как входной набор данных другого действия.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-120">And, you can chain two activities (run one activity after another) by setting the output dataset of one activity as the input dataset of the other activity.</span></span> <span data-ttu-id="1d2f2-121">Дополнительные сведения см. в разделе [Несколько действий в конвейере](data-factory-scheduling-and-execution.md#multiple-activities-in-a-pipeline).</span><span class="sxs-lookup"><span data-stu-id="1d2f2-121">For more information, see [multiple activities in a pipeline](data-factory-scheduling-and-execution.md#multiple-activities-in-a-pipeline).</span></span> 

> [!NOTE] 
> <span data-ttu-id="1d2f2-122">В этом руководстве конвейер данных копирует данные из исходного хранилища данных в целевое.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-122">The data pipeline in this tutorial copies data from a source data store to a destination data store.</span></span> <span data-ttu-id="1d2f2-123">Инструкции по преобразованию данных с помощью фабрики данных Azure см. в [руководстве по созданию конвейера для преобразования данных с помощью кластера Hadoop](data-factory-build-your-first-pipeline.md).</span><span class="sxs-lookup"><span data-stu-id="1d2f2-123">For a tutorial on how to transform data using Azure Data Factory, see [Tutorial: Build a pipeline to transform data using Hadoop cluster](data-factory-build-your-first-pipeline.md).</span></span>

## <a name="prerequisites"></a><span data-ttu-id="1d2f2-124">Предварительные требования</span><span class="sxs-lookup"><span data-stu-id="1d2f2-124">Prerequisites</span></span>
<span data-ttu-id="1d2f2-125">Прежде чем начать работу, выполните предварительные требования, перечисленные в [этом руководстве](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).</span><span class="sxs-lookup"><span data-stu-id="1d2f2-125">Complete prerequisites listed in the [tutorial prerequisites](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md) article before performing this tutorial.</span></span>

## <a name="steps"></a><span data-ttu-id="1d2f2-126">Действия</span><span class="sxs-lookup"><span data-stu-id="1d2f2-126">Steps</span></span>
<span data-ttu-id="1d2f2-127">Ниже приведены шаги, которые вы выполните в процессе работы с этим руководством.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-127">Here are the steps you perform as part of this tutorial:</span></span>

1. <span data-ttu-id="1d2f2-128">Создайте **фабрику данных** Azure.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-128">Create an Azure **data factory**.</span></span> <span data-ttu-id="1d2f2-129">На этом этапе вы создадите фабрику данных Azure с именем ADFTutorialDataFactory.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-129">In this step, you create a data factory named ADFTutorialDataFactory.</span></span> 
2. <span data-ttu-id="1d2f2-130">Создайте в этой фабрике данных **связанные службы**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-130">Create **linked services** in the data factory.</span></span> <span data-ttu-id="1d2f2-131">На этом этапе вы создадите две связанные службы — службу хранилища Azure и базу данных SQL Azure.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-131">In this step, you create two linked services of types: Azure Storage and Azure SQL Database.</span></span> 
    
    <span data-ttu-id="1d2f2-132">Связанная служба хранилища Azure связывает учетную запись хранения Azure с фабрикой данных.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-132">The AzureStorageLinkedService links your Azure storage account to the data factory.</span></span> <span data-ttu-id="1d2f2-133">Вы создали контейнер и отправили данные в эту учетную запись хранения в ходе выполнения предварительных [требований](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).</span><span class="sxs-lookup"><span data-stu-id="1d2f2-133">You created a container and uploaded data to this storage account as part of [prerequisites](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).</span></span>   

    <span data-ttu-id="1d2f2-134">Связанная служба SQL Azure связывает базу данных SQL Azure с фабрикой данных.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-134">AzureSqlLinkedService links your Azure SQL database to the data factory.</span></span> <span data-ttu-id="1d2f2-135">В этой базе данных хранятся данные, скопированные из хранилища BLOB-объектов.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-135">The data that is copied from the blob storage is stored in this database.</span></span> <span data-ttu-id="1d2f2-136">Вы создали таблицу SQL в этой базе данных в ходе выполнения [предварительных требований](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).</span><span class="sxs-lookup"><span data-stu-id="1d2f2-136">You created a SQL table in this database as part of [prerequisites](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).</span></span>   
3. <span data-ttu-id="1d2f2-137">Создайте в фабрике данных входные и выходные **наборы данных**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-137">Create input and output **datasets** in the data factory.</span></span>  
    
    <span data-ttu-id="1d2f2-138">Связанная служба хранилища Azure указывает строку подключения, которую фабрика данных использует во время выполнения, чтобы подключиться к учетной записи хранения Azure.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-138">The Azure storage linked service specifies the connection string that Data Factory service uses at run time to connect to your Azure storage account.</span></span> <span data-ttu-id="1d2f2-139">А входной набор данных больших двоичных объектов определяет контейнер и папку с входными данными.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-139">And, the input blob dataset specifies the container and the folder that contains the input data.</span></span>  

    <span data-ttu-id="1d2f2-140">Аналогичным образом связанная служба базы данных SQL Azure указывает строку подключения, которую служба фабрики данных использует во время выполнения, чтобы подключиться к базе данных SQL Azure.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-140">Similarly, the Azure SQL Database linked service specifies the connection string that Data Factory service uses at run time to connect to your Azure SQL database.</span></span> <span data-ttu-id="1d2f2-141">А выходной набор данных таблицы SQL определяет таблицу в базе данных, в которую копируются данные из хранилища BLOB-объектов.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-141">And, the output SQL table dataset specifies the table in the database to which the data from the blob storage is copied.</span></span>
4. <span data-ttu-id="1d2f2-142">Создайте **конвейер** в фабрике данных.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-142">Create a **pipeline** in the data factory.</span></span> <span data-ttu-id="1d2f2-143">На этом этапе вы создадите конвейер с действием копирования.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-143">In this step, you create a pipeline with a copy activity.</span></span>   
    
    <span data-ttu-id="1d2f2-144">Действие копирования копирует данные из большого двоичного объекта из хранилища BLOB-объектов Azure в таблицу в базе данных SQL Azure.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-144">The copy activity copies data from a blob in the Azure blob storage to a table in the Azure SQL database.</span></span> <span data-ttu-id="1d2f2-145">Его можно использовать, чтобы копировать данные из любого поддерживаемого источника в любое расположение.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-145">You can use a copy activity in a pipeline to copy data from any supported source to any supported destination.</span></span> <span data-ttu-id="1d2f2-146">Список поддерживаемых хранилищ данных см. в [этом разделе](data-factory-data-movement-activities.md#supported-data-stores-and-formats).</span><span class="sxs-lookup"><span data-stu-id="1d2f2-146">For a list of supported data stores, see [data movement activities](data-factory-data-movement-activities.md#supported-data-stores-and-formats) article.</span></span> 
5. <span data-ttu-id="1d2f2-147">Выполните мониторинг конвейера.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-147">Monitor the pipeline.</span></span> <span data-ttu-id="1d2f2-148">На этом этапе вы **отследите** срезы входных и выходных наборов данных с помощью портала Azure.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-148">In this step, you **monitor** the slices of input and output datasets by using Azure portal.</span></span> 

## <a name="create-data-factory"></a><span data-ttu-id="1d2f2-149">Создание фабрики данных</span><span class="sxs-lookup"><span data-stu-id="1d2f2-149">Create data factory</span></span>
> [!IMPORTANT]
> <span data-ttu-id="1d2f2-150">Выполните [предварительные требования, необходимые для работы с этим руководством](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md), если вы еще этого не сделали.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-150">Complete [prerequisites for the tutorial](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md) if you haven't already done so.</span></span>   

<span data-ttu-id="1d2f2-151">Фабрика данных может иметь один или несколько конвейеров.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-151">A data factory can have one or more pipelines.</span></span> <span data-ttu-id="1d2f2-152">Конвейер может содержать одно или несколько действий.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-152">A pipeline can have one or more activities in it.</span></span> <span data-ttu-id="1d2f2-153">Это может быть, например, действие копирования данных из исходного хранилища в целевое или действие HDInsight Hive для выполнения скрипта Hive, преобразующего входные данные в выходные данные продукта.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-153">For example, a Copy Activity to copy data from a source to a destination data store and a HDInsight Hive activity to run a Hive script to transform input data to product output data.</span></span> <span data-ttu-id="1d2f2-154">Начнем с создания фабрики данных.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-154">Let's start with creating the data factory in this step.</span></span>

1. <span data-ttu-id="1d2f2-155">Войдите на [портал Azure](https://portal.azure.com/), нажмите кнопку **Создать** в меню слева, откройте раздел **Данные+аналитика** и щелкните **Фабрика данных**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-155">After logging in to the [Azure portal](https://portal.azure.com/), click **New** on the left menu, click **Data + Analytics**, and click **Data Factory**.</span></span> 
   
   ![Создать -> Фабрика данных](./media/data-factory-copy-activity-tutorial-using-azure-portal/NewDataFactoryMenu.png)    
2. <span data-ttu-id="1d2f2-157">В колонке **Создать фабрику данных** выполните следующие действия.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-157">In the **New data factory** blade:</span></span>
   
   1. <span data-ttu-id="1d2f2-158">Введите **ADFTutorialDataFactory** в поле **Имя**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-158">Enter **ADFTutorialDataFactory** for the **name**.</span></span> 
      
         ![Создать колонку "Фабрика данных"](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-new-data-factory.png)
      
       <span data-ttu-id="1d2f2-160">Имя фабрики данных Azure должно быть **глобально уникальным**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-160">The name of the Azure data factory must be **globally unique**.</span></span> <span data-ttu-id="1d2f2-161">При возникновении указанной ниже ошибки измените имя фабрики данных (например, на ваше_имя_ADFTutorialDataFactory) и попробуйте создать фабрику данных снова.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-161">If you receive the following error, change the name of the data factory (for example, yournameADFTutorialDataFactory) and try creating again.</span></span> <span data-ttu-id="1d2f2-162">Ознакомьтесь со статьей [Фабрика данных Azure — правила именования](data-factory-naming-rules.md) , чтобы узнать о правилах именования артефактов фабрики данных.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-162">See [Data Factory - Naming Rules](data-factory-naming-rules.md) topic for naming rules for Data Factory artifacts.</span></span>
      
           Data factory name “ADFTutorialDataFactory” is not available  
      
       ![Имя фабрики данных недоступно](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-data-factory-not-available.png)
   2. <span data-ttu-id="1d2f2-164">Выберите **подписку** Azure, в рамках которой вы хотите создать фабрику данных.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-164">Select your Azure **subscription** in which you want to create the data factory.</span></span> 
   3. <span data-ttu-id="1d2f2-165">Для **группы ресурсов** выполните одно из следующих действий.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-165">For the **Resource Group**, do one of the following steps:</span></span>
      
      - <span data-ttu-id="1d2f2-166">Выберите **Использовать существующую**и укажите существующую группу ресурсов в раскрывающемся списке.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-166">Select **Use existing**, and select an existing resource group from the drop-down list.</span></span> 
      - <span data-ttu-id="1d2f2-167">Выберите **Создать новую**и укажите имя группы ресурсов.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-167">Select **Create new**, and enter the name of a resource group.</span></span>   
         
          <span data-ttu-id="1d2f2-168">Некоторые действия, описанные в этом руководстве, предполагают, что для группы ресурсов используется имя **ADFTutorialResourceGroup**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-168">Some of the steps in this tutorial assume that you use the name: **ADFTutorialResourceGroup** for the resource group.</span></span> <span data-ttu-id="1d2f2-169">Сведения о группах ресурсов см. в статье, где описывается [использование групп ресурсов для управления ресурсами Azure](../azure-resource-manager/resource-group-overview.md).</span><span class="sxs-lookup"><span data-stu-id="1d2f2-169">To learn about resource groups, see [Using resource groups to manage your Azure resources](../azure-resource-manager/resource-group-overview.md).</span></span>  
   4. <span data-ttu-id="1d2f2-170">Укажите **расположение** фабрики данных.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-170">Select the **location** for the data factory.</span></span> <span data-ttu-id="1d2f2-171">В раскрывающемся списке отображаются только те регионы, которые поддерживаются службой фабрики данных.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-171">Only regions supported by the Data Factory service are shown in the drop-down list.</span></span>
   5. <span data-ttu-id="1d2f2-172">Кроме того, установите флажок **Закрепить на панели мониторинга**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-172">Select **Pin to dashboard**.</span></span>     
   6. <span data-ttu-id="1d2f2-173">Щелкните **Создать**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-173">Click **Create**.</span></span>
      
      > [!IMPORTANT]
      > <span data-ttu-id="1d2f2-174">Создавать экземпляры фабрики данных может пользователь с ролью [Участник фабрики данных](../active-directory/role-based-access-built-in-roles.md#data-factory-contributor) на уровне подписки или группы ресурсов.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-174">To create Data Factory instances, you must be a member of the [Data Factory Contributor](../active-directory/role-based-access-built-in-roles.md#data-factory-contributor) role at the subscription/resource group level.</span></span>
      > 
      > <span data-ttu-id="1d2f2-175">В будущем имя фабрики данных может быть зарегистрировано в качестве DNS-имени и, следовательно, стать отображаемым.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-175">The name of the data factory may be registered as a DNS name in the future and hence become publically visible.</span></span>                
      > 
      > 
3. <span data-ttu-id="1d2f2-176">На панели мониторинга вы увидите приведенный ниже элемент с состоянием **Deploying data factory** (Развертывание фабрики данных).</span><span class="sxs-lookup"><span data-stu-id="1d2f2-176">On the dashboard, you see the following tile with status: **Deploying data factory**.</span></span> 

    ![Элемент Deploying data factory (Развертывание фабрики данных)](media/data-factory-copy-activity-tutorial-using-azure-portal/deploying-data-factory.png)
4. <span data-ttu-id="1d2f2-178">Когда экземпляр будет создан, вы увидите колонку **Фабрика данных** , как показано на рисунке ниже.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-178">After the creation is complete, you see the **Data Factory** blade as shown in the image.</span></span>
   
   ![Домашняя страница фабрики данных](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-data-factory-home-page.png)

## <a name="create-linked-services"></a><span data-ttu-id="1d2f2-180">Создание связанных служб</span><span class="sxs-lookup"><span data-stu-id="1d2f2-180">Create linked services</span></span>
<span data-ttu-id="1d2f2-181">Связанная служба в фабрике данных связывает хранилища данных и службы вычислений с фабрикой данных.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-181">You create linked services in a data factory to link your data stores and compute services to the data factory.</span></span> <span data-ttu-id="1d2f2-182">В этом руководстве не используются службы вычислений, например Azure HDInsight или Azure Data Lake Analytics.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-182">In this tutorial, you don't use any compute service such as Azure HDInsight or Azure Data Lake Analytics.</span></span> <span data-ttu-id="1d2f2-183">Вы используете два хранилища данных — служба хранилища Azure (источник) и база данных SQL Azure (конечное хранилище).</span><span class="sxs-lookup"><span data-stu-id="1d2f2-183">You use two data stores of type Azure Storage (source) and Azure SQL Database (destination).</span></span> 

<span data-ttu-id="1d2f2-184">Поэтому нужно создать две связанные службы: служба хранилища Azure с именем AzureStorageLinkedService и база данных SQL Azure с именем AzureSqlLinkedService.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-184">Therefore, you create two linked services named AzureStorageLinkedService and AzureSqlLinkedService of types: AzureStorage and AzureSqlDatabase.</span></span>  

<span data-ttu-id="1d2f2-185">Связанная служба хранилища Azure связывает учетную запись хранения Azure с фабрикой данных.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-185">The AzureStorageLinkedService links your Azure storage account to the data factory.</span></span> <span data-ttu-id="1d2f2-186">В этой учетной записи хранения вы создали контейнер и отправили в нее данные в ходе выполнения предварительных [требований](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).</span><span class="sxs-lookup"><span data-stu-id="1d2f2-186">This storage account is the one in which you created a container and uploaded the data as part of [prerequisites](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).</span></span>   

<span data-ttu-id="1d2f2-187">Связанная служба SQL Azure связывает базу данных SQL Azure с фабрикой данных.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-187">AzureSqlLinkedService links your Azure SQL database to the data factory.</span></span> <span data-ttu-id="1d2f2-188">В этой базе данных хранятся данные, скопированные из хранилища BLOB-объектов.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-188">The data that is copied from the blob storage is stored in this database.</span></span> <span data-ttu-id="1d2f2-189">Вы создали пустую таблицу в этой базе данных в ходе выполнения [предварительных требований](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).</span><span class="sxs-lookup"><span data-stu-id="1d2f2-189">You created the emp table in this database as part of [prerequisites](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).</span></span>  

### <a name="create-azure-storage-linked-service"></a><span data-ttu-id="1d2f2-190">Создание связанной службы хранения Azure</span><span class="sxs-lookup"><span data-stu-id="1d2f2-190">Create Azure Storage linked service</span></span>
<span data-ttu-id="1d2f2-191">На этом шаге вы свяжете учетную запись хранения Azure с фабрикой данных.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-191">In this step, you link your Azure storage account to your data factory.</span></span> <span data-ttu-id="1d2f2-192">В этом разделе вы укажете имя и ключ вашей учетной записи хранения Azure.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-192">You specify the name and key of your Azure storage account in this section.</span></span>  

1. <span data-ttu-id="1d2f2-193">В колонке **Фабрика данных** щелкните элемент **Создать и развернуть**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-193">In the **Data Factory** blade, click **Author and deploy** tile.</span></span>
   
   ![Плитка "Создание и развертывание"](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-author-deploy-tile.png) 
2. <span data-ttu-id="1d2f2-195">Вы увидите **редактор фабрики данных**, как показано на следующем рисунке:</span><span class="sxs-lookup"><span data-stu-id="1d2f2-195">You see the **Data Factory Editor** as shown in the following image:</span></span> 

    ![Редактор фабрики данных](./media/data-factory-copy-activity-tutorial-using-azure-portal/data-factory-editor.png)
3. <span data-ttu-id="1d2f2-197">В редакторе нажмите кнопку **Новое хранилище данных** на панели инструментов и выберите в раскрывающемся меню пункт **Служба хранилища Azure**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-197">In the editor, click **New data store** button on the toolbar and select **Azure storage** from the drop-down menu.</span></span> <span data-ttu-id="1d2f2-198">На панели справа должен появиться шаблон JSON для создания связанной службы хранилища Azure.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-198">You should see the JSON template for creating an Azure storage linked service in the right pane.</span></span> 
   
    ![Кнопка "Создать хранилище данных" в редакторе](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-editor-newdatastore-button.png)    
3. <span data-ttu-id="1d2f2-200">Замените `<accountname>` и `<accountkey>` значениями имени и ключа учетной записи хранения Azure.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-200">Replace `<accountname>` and `<accountkey>` with the account name and account key values for your Azure storage account.</span></span> 
   
    ![Хранилище больших двоичных объектов JSON в редакторе](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-editor-blob-storage-json.png)    
4. <span data-ttu-id="1d2f2-202">На панели инструментов щелкните **Развернуть** .</span><span class="sxs-lookup"><span data-stu-id="1d2f2-202">Click **Deploy** on the toolbar.</span></span> <span data-ttu-id="1d2f2-203">Теперь в иерархическом представлении должен отобразиться развернутый экземпляр **AzureStorageLinkedService** .</span><span class="sxs-lookup"><span data-stu-id="1d2f2-203">You should see the deployed **AzureStorageLinkedService** in the tree view now.</span></span> 
   
    ![Развертывание хранилища больших двоичных объектов в редакторе](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-editor-blob-storage-deploy.png)

    <span data-ttu-id="1d2f2-205">Дополнительные сведения о свойствах JSON см. в статье о [соединителе хранилища BLOB-объектов Azure](data-factory-azure-blob-connector.md#linked-service-properties).</span><span class="sxs-lookup"><span data-stu-id="1d2f2-205">For more information about JSON properties in the linked service definition, see [Azure Blob Storage connector](data-factory-azure-blob-connector.md#linked-service-properties) article.</span></span>

### <a name="create-a-linked-service-for-the-azure-sql-database"></a><span data-ttu-id="1d2f2-206">Создание связанной службы для базы данных SQL Azure.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-206">Create a linked service for the Azure SQL Database</span></span>
<span data-ttu-id="1d2f2-207">На этом шаге вы свяжете базу данных SQL Azure с фабрикой данных.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-207">In this step, you link your Azure SQL database to your data factory.</span></span> <span data-ttu-id="1d2f2-208">В этом разделе вы укажете имя сервера SQL Azure, имя базы данных, имя пользователя и пароль.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-208">You specify the Azure SQL server name, database name, user name, and user password in this section.</span></span> 

1. <span data-ttu-id="1d2f2-209">В **редакторе фабрики данных** на панели инструментов щелкните **Новое хранилище данных** и выберите в раскрывающемся меню пункт **База данных SQL Azure**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-209">In the **Data Factory Editor**, click **New data store** button on the toolbar and select **Azure SQL Database** from the drop-down menu.</span></span> <span data-ttu-id="1d2f2-210">В правой панели должен появиться шаблон JSON для создания связанной службы SQL Azure.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-210">You should see the JSON template for creating the Azure SQL linked service in the right pane.</span></span>
2. <span data-ttu-id="1d2f2-211">Замените `<servername>`, `<databasename>`, `<username>@<servername>` и `<password>` именем своего сервера SQL Azure, именем учетной записи пользователя и паролем.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-211">Replace `<servername>`, `<databasename>`, `<username>@<servername>`, and `<password>` with names of your Azure SQL server, database, user account, and password.</span></span> 
3. <span data-ttu-id="1d2f2-212">На панели инструментов щелкните **Развернуть**, чтобы создать и развернуть экземпляр **AzureSqlLinkedService**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-212">Click **Deploy** on the toolbar to create and deploy the **AzureSqlLinkedService**.</span></span>
4. <span data-ttu-id="1d2f2-213">Экземпляр **AzureSqlLinkedService** должен отображаться в иерархическом представлении в разделе **Связанные службы**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-213">Confirm that you see **AzureSqlLinkedService** in the tree view under **Linked services**.</span></span>  

    <span data-ttu-id="1d2f2-214">Дополнительные сведения об этих свойствах JSON см. в статье о [соединителе базы данных SQL Azure](data-factory-azure-sql-connector.md#linked-service-properties).</span><span class="sxs-lookup"><span data-stu-id="1d2f2-214">For more information about these JSON properties, see [Azure SQL Database connector](data-factory-azure-sql-connector.md#linked-service-properties).</span></span>

## <a name="create-datasets"></a><span data-ttu-id="1d2f2-215">Создание наборов данных</span><span class="sxs-lookup"><span data-stu-id="1d2f2-215">Create datasets</span></span>
<span data-ttu-id="1d2f2-216">На предыдущем шаге вы создали связанные службы, связывающие учетную запись хранения Azure и базу данных SQL Azure с фабрикой данных.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-216">In the previous step, you created linked services to link your Azure Storage account and Azure SQL database to your data factory.</span></span> <span data-ttu-id="1d2f2-217">На этом этапе вы определите два набора данных (InputDataset и OutputDataset), представляющие входные и выходные данные в хранилищах данных, на которые ссылаются службы AzureStorageLinkedService и AzureSqlLinkedService соответственно.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-217">In this step, you define two datasets named InputDataset and OutputDataset that represent input and output data that is stored in the data stores referred by AzureStorageLinkedService and AzureSqlLinkedService respectively.</span></span>

<span data-ttu-id="1d2f2-218">Связанная служба хранилища Azure указывает строку подключения, которую фабрика данных использует во время выполнения, чтобы подключиться к учетной записи хранения Azure.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-218">The Azure storage linked service specifies the connection string that Data Factory service uses at run time to connect to your Azure storage account.</span></span> <span data-ttu-id="1d2f2-219">А входной набор данных больших двоичных объектов (InputDataset) определяет контейнер и папку с входными данными.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-219">And, the input blob dataset (InputDataset) specifies the container and the folder that contains the input data.</span></span>  

<span data-ttu-id="1d2f2-220">Аналогичным образом связанная служба базы данных SQL Azure указывает строку подключения, которую служба фабрики данных использует во время выполнения, чтобы подключиться к базе данных SQL Azure.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-220">Similarly, the Azure SQL Database linked service specifies the connection string that Data Factory service uses at run time to connect to your Azure SQL database.</span></span> <span data-ttu-id="1d2f2-221">А выходной набор данных таблицы SQL (OututDataset) определяет таблицу в базе данных, в которую копируются данные из хранилища BLOB-объектов.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-221">And, the output SQL table dataset (OututDataset) specifies the table in the database to which the data from the blob storage is copied.</span></span> 

### <a name="create-input-dataset"></a><span data-ttu-id="1d2f2-222">Создание входного набора данных</span><span class="sxs-lookup"><span data-stu-id="1d2f2-222">Create input dataset</span></span>
<span data-ttu-id="1d2f2-223">На этом этапе вы создадите набор данных с именем InputDataset. Он указывает на файл большого двоичного объекта (emp.txt) в корневой папке контейнера больших двоичных объектов в службе хранилища Azure, которая представлена связанной службой AzureStorageLinkedService.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-223">In this step, you create a dataset named InputDataset that points to a blob file (emp.txt) in the root folder of a blob container (adftutorial) in the Azure Storage represented by the AzureStorageLinkedService linked service.</span></span> <span data-ttu-id="1d2f2-224">Если не указать значение fileName (или пропустить его), данные из всех больших двоичных объектов в папке входных данных копируются в целевое расположение.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-224">If you don't specify a value for the fileName (or skip it), data from all blobs in the input folder are copied to the destination.</span></span> <span data-ttu-id="1d2f2-225">В этом руководстве вы укажете значение параметра fileName.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-225">In this tutorial, you specify a value for the fileName.</span></span> 

1. <span data-ttu-id="1d2f2-226">В **редакторе** фабрики данных щелкните **... Дополнительно**, **Новый набор данных**, а затем в раскрывающемся меню выберите пункт **Хранилище BLOB-объектов**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-226">In the **Editor** for the Data Factory, click **... More**, click **New dataset**, and click **Azure Blob storage** from the drop-down menu.</span></span> 
   
    ![Меню "Новый набор данных"](./media/data-factory-copy-activity-tutorial-using-azure-portal/new-dataset-menu.png)
2. <span data-ttu-id="1d2f2-228">Замените JSON на правой панели следующим фрагментом JSON:</span><span class="sxs-lookup"><span data-stu-id="1d2f2-228">Replace JSON in the right pane with the following JSON snippet:</span></span> 
   
    ```json
    {
      "name": "InputDataset",
      "properties": {
        "structure": [
          {
            "name": "FirstName",
            "type": "String"
          },
          {
            "name": "LastName",
            "type": "String"
          }
        ],
        "type": "AzureBlob",
        "linkedServiceName": "AzureStorageLinkedService",
        "typeProperties": {
          "folderPath": "adftutorial/",
          "fileName": "emp.txt",
          "format": {
            "type": "TextFormat",
            "columnDelimiter": ","
          }
        },
        "external": true,
        "availability": {
          "frequency": "Hour",
          "interval": 1
        }
      }
    }
    ```   

    <span data-ttu-id="1d2f2-229">В следующей таблице приведены описания свойств JSON, используемых в этом фрагменте кода.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-229">The following table provides descriptions for the JSON properties used in the snippet:</span></span>

    | <span data-ttu-id="1d2f2-230">Свойство</span><span class="sxs-lookup"><span data-stu-id="1d2f2-230">Property</span></span> | <span data-ttu-id="1d2f2-231">Описание</span><span class="sxs-lookup"><span data-stu-id="1d2f2-231">Description</span></span> |
    |:--- |:--- |
    | <span data-ttu-id="1d2f2-232">type</span><span class="sxs-lookup"><span data-stu-id="1d2f2-232">type</span></span> | <span data-ttu-id="1d2f2-233">Для свойства типа задано значение **AzureBlob**, так как данные хранятся в хранилище BLOB-объектов Azure.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-233">The type property is set to **AzureBlob** because data resides in an Azure blob storage.</span></span> |
    | <span data-ttu-id="1d2f2-234">linkedServiceName (имя связанной службы)</span><span class="sxs-lookup"><span data-stu-id="1d2f2-234">linkedServiceName</span></span> | <span data-ttu-id="1d2f2-235">Ссылается на созданную ранее службу **AzureStorageLinkedService**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-235">Refers to the **AzureStorageLinkedService** that you created earlier.</span></span> |
    | <span data-ttu-id="1d2f2-236">folderPath</span><span class="sxs-lookup"><span data-stu-id="1d2f2-236">folderPath</span></span> | <span data-ttu-id="1d2f2-237">Определяет **контейнер** больших двоичных объектов и **папку**, которая содержит входные большие двоичные объекты.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-237">Specifies the blob **container** and the **folder** that contains input blobs.</span></span> <span data-ttu-id="1d2f2-238">В этом руководстве adftutorial — это контейнер больших двоичных объектов, а созданная папка является корневой.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-238">In this tutorial, adftutorial is the blob container and folder is the root folder.</span></span> | 
    | <span data-ttu-id="1d2f2-239">fileName</span><span class="sxs-lookup"><span data-stu-id="1d2f2-239">fileName</span></span> | <span data-ttu-id="1d2f2-240">Это необязательное свойство.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-240">This property is optional.</span></span> <span data-ttu-id="1d2f2-241">Если это свойство не указано, выбираются все файлы из папки folderPath.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-241">If you omit this property, all files from the folderPath are picked.</span></span> <span data-ttu-id="1d2f2-242">В этом руководстве для свойства fileName указывается значение **emp.txt**, чтобы обрабатывался только этот файл.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-242">In this tutorial, **emp.txt** is specified for the fileName, so only that file is picked up for processing.</span></span> |
    | <span data-ttu-id="1d2f2-243">format -> type</span><span class="sxs-lookup"><span data-stu-id="1d2f2-243">format -> type</span></span> |<span data-ttu-id="1d2f2-244">Входной файл имеет текстовый формат, поэтому укажите значение **TextFormat**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-244">The input file is in the text format, so we use **TextFormat**.</span></span> |
    | <span data-ttu-id="1d2f2-245">columnDelimiter</span><span class="sxs-lookup"><span data-stu-id="1d2f2-245">columnDelimiter</span></span> | <span data-ttu-id="1d2f2-246">Столбцы во входном файле разделяются **запятыми (`,`)**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-246">The columns in the input file are delimited by **comma character (`,`)**.</span></span> |
    | <span data-ttu-id="1d2f2-247">frequency и interval</span><span class="sxs-lookup"><span data-stu-id="1d2f2-247">frequency/interval</span></span> | <span data-ttu-id="1d2f2-248">Для свойства frequency задано значение **Hour**, а для свойства interval — значение **1**. Это означает, что срезы входных данных будут создаваться **каждый час**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-248">The frequency is set to **Hour** and interval is  set to **1**, which means that the input slices are available **hourly**.</span></span> <span data-ttu-id="1d2f2-249">Иными словами, служба фабрики данных будет искать входные данные в корневой папке указанного контейнера BLOB-объектов (**adftutorial**) каждый час.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-249">In other words, the Data Factory service looks for input data every hour in the root folder of blob container (**adftutorial**) you specified.</span></span> <span data-ttu-id="1d2f2-250">Поиск данных осуществляется в пределах времени начала и времени окончания для конвейера, но не перед этим периодом или после него.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-250">It looks for the data within the pipeline start and end times, not before or after these times.</span></span>  |
    | <span data-ttu-id="1d2f2-251">external</span><span class="sxs-lookup"><span data-stu-id="1d2f2-251">external</span></span> | <span data-ttu-id="1d2f2-252">Это свойство имеет значение **true**, если этот конвейер не создает данные.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-252">This property is set to **true** if the data is not generated by this pipeline.</span></span> <span data-ttu-id="1d2f2-253">В этом руководстве входные данные находятся в файле emp.txt, который не создается этим конвейером, поэтому мы присвоим этому свойству значение true.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-253">The input data in this tutorial is in the emp.txt file, which is not generated by this pipeline, so we set this property to true.</span></span> |

    <span data-ttu-id="1d2f2-254">Дополнительные сведения об этих свойствах JSON см. в [этом разделе](data-factory-azure-blob-connector.md#dataset-properties).</span><span class="sxs-lookup"><span data-stu-id="1d2f2-254">For more information about these JSON properties, see [Azure Blob connector article](data-factory-azure-blob-connector.md#dataset-properties).</span></span>      
3. <span data-ttu-id="1d2f2-255">На панели инструментов щелкните **Развернуть**, чтобы создать и развернуть набор данных **InputDataset**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-255">Click **Deploy** on the toolbar to create and deploy the **InputDataset** dataset.</span></span> <span data-ttu-id="1d2f2-256">Набор данных **InputDataset** должен отображаться в иерархическом представлении.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-256">Confirm that you see the **InputDataset** in the tree view.</span></span>

### <a name="create-output-dataset"></a><span data-ttu-id="1d2f2-257">Создание выходного набора данных</span><span class="sxs-lookup"><span data-stu-id="1d2f2-257">Create output dataset</span></span>
<span data-ttu-id="1d2f2-258">База данных SQL Azure указывает строку подключения, которую служба фабрики данных использует во время выполнения, чтобы подключиться к базе данных SQL Azure.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-258">The Azure SQL Database linked service specifies the connection string that Data Factory service uses at run time to connect to your Azure SQL database.</span></span> <span data-ttu-id="1d2f2-259">Выходной набор данных таблицы SQL (OututDataset), который вы создаете на этом шаге, определяет таблицу в базе данных, в которую копируются данные из хранилища BLOB-объектов.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-259">The output SQL table dataset (OututDataset) you create in this step specifies the table in the database to which the data from the blob storage is copied.</span></span>

1. <span data-ttu-id="1d2f2-260">В **редакторе** фабрики данных щелкните **... Дополнительно**, **Новый набор данных**, а затем в раскрывающемся меню выберите пункт **Azure SQL**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-260">In the **Editor** for the Data Factory, click **... More**, click **New dataset**, and click **Azure SQL** from the drop-down menu.</span></span> 
2. <span data-ttu-id="1d2f2-261">Замените JSON на правой панели следующим фрагментом JSON:</span><span class="sxs-lookup"><span data-stu-id="1d2f2-261">Replace JSON in the right pane with the following JSON snippet:</span></span>

    ```json   
    {
      "name": "OutputDataset",
      "properties": {
        "structure": [
          {
            "name": "FirstName",
            "type": "String"
          },
          {
            "name": "LastName",
            "type": "String"
          }
        ],
        "type": "AzureSqlTable",
        "linkedServiceName": "AzureSqlLinkedService",
        "typeProperties": {
          "tableName": "emp"
        },
        "availability": {
          "frequency": "Hour",
          "interval": 1
        }
      }
    }
    ```     

    <span data-ttu-id="1d2f2-262">В следующей таблице приведены описания свойств JSON, используемых в этом фрагменте кода.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-262">The following table provides descriptions for the JSON properties used in the snippet:</span></span>

    | <span data-ttu-id="1d2f2-263">Свойство</span><span class="sxs-lookup"><span data-stu-id="1d2f2-263">Property</span></span> | <span data-ttu-id="1d2f2-264">Описание</span><span class="sxs-lookup"><span data-stu-id="1d2f2-264">Description</span></span> |
    |:--- |:--- |
    | <span data-ttu-id="1d2f2-265">type</span><span class="sxs-lookup"><span data-stu-id="1d2f2-265">type</span></span> | <span data-ttu-id="1d2f2-266">Свойство type имеет значение **AzureSqlTable**, так как данные копируются в таблицу в базе данных SQL Azure.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-266">The type property is set to **AzureSqlTable** because data is copied to a table in an Azure SQL database.</span></span> |
    | <span data-ttu-id="1d2f2-267">linkedServiceName (имя связанной службы)</span><span class="sxs-lookup"><span data-stu-id="1d2f2-267">linkedServiceName</span></span> | <span data-ttu-id="1d2f2-268">Ссылается на созданную ранее службу **AzureSqlLinkedService**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-268">Refers to the **AzureSqlLinkedService** that you created earlier.</span></span> |
    | <span data-ttu-id="1d2f2-269">tableName</span><span class="sxs-lookup"><span data-stu-id="1d2f2-269">tableName</span></span> | <span data-ttu-id="1d2f2-270">Указывает **таблицу**, в которую копируются данные.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-270">Specified the **table** to which the data is copied.</span></span> | 
    | <span data-ttu-id="1d2f2-271">frequency и interval</span><span class="sxs-lookup"><span data-stu-id="1d2f2-271">frequency/interval</span></span> | <span data-ttu-id="1d2f2-272">Для свойства frequency задано значение **Hour**, а для interval — **1**. Это означает, что срезы выходных данных создаются **каждый час** в пределах времени начала и времени окончания для конвейера, но не перед этим периодом или после него.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-272">The frequency is set to **Hour** and interval is **1**, which means that the output slices are produced **hourly** between the pipeline start and end times, not before or after these times.</span></span>  |

    <span data-ttu-id="1d2f2-273">В таблице emp в базе данных есть три столбца: **ID**, **FirstName** и **LastName**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-273">There are three columns – **ID**, **FirstName**, and **LastName** – in the emp table in the database.</span></span> <span data-ttu-id="1d2f2-274">ID — это столбец для идентификаторов, поэтому здесь вам нужно указать только значения **FirstName** и **LastName**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-274">ID is an identity column, so you need to specify only **FirstName** and **LastName** here.</span></span>

    <span data-ttu-id="1d2f2-275">Дополнительные сведения об этих свойствах JSON см. в [этом разделе](data-factory-azure-sql-connector.md#dataset-properties).</span><span class="sxs-lookup"><span data-stu-id="1d2f2-275">For more information about these JSON properties, see [Azure SQL connector article](data-factory-azure-sql-connector.md#dataset-properties).</span></span>
3. <span data-ttu-id="1d2f2-276">На панели инструментов щелкните **Развернуть**, чтобы создать и развернуть набор данных **OutputDatase**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-276">Click **Deploy** on the toolbar to create and deploy the **OutputDataset** dataset.</span></span> <span data-ttu-id="1d2f2-277">Набор данных **OutputDataset** должен отображаться в иерархическом представлении в разделе **Наборы данных**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-277">Confirm that you see the **OutputDataset** in the tree view under **Datasets**.</span></span> 

## <a name="create-pipeline"></a><span data-ttu-id="1d2f2-278">Создание конвейера</span><span class="sxs-lookup"><span data-stu-id="1d2f2-278">Create pipeline</span></span>
<span data-ttu-id="1d2f2-279">На этом этапе вы создадите конвейер с **действием копирования**, которое использует **InputDataset** в качестве входных данных и **OutputDataset** в качестве выходных.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-279">In this step, you create a pipeline with a **copy activity** that uses **InputDataset** as an input and **OutputDataset** as an output.</span></span>

<span data-ttu-id="1d2f2-280">Сейчас на основе этого набора настраивается расписание.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-280">Currently, output dataset is what drives the schedule.</span></span> <span data-ttu-id="1d2f2-281">В этом руководстве выходной набор данных создает срез раз в час.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-281">In this tutorial, output dataset is configured to produce a slice once an hour.</span></span> <span data-ttu-id="1d2f2-282">Для конвейера настроено время начала и время окончания с разницей в сутки.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-282">The pipeline has a start time and end time that are one day apart, which is 24 hours.</span></span> <span data-ttu-id="1d2f2-283">Таким образом, конвейер создает 24 среза для выходного набора данных.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-283">Therefore, 24 slices of output dataset are produced by the pipeline.</span></span> 

1. <span data-ttu-id="1d2f2-284">В **редакторе** фабрики данных щелкните **... Дополнительно** и **Новый конвейер**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-284">In the **Editor** for the Data Factory, click **... More**, and click **New pipeline**.</span></span> <span data-ttu-id="1d2f2-285">Кроме того, можно щелкнуть правой кнопкой мыши **Конвейеры** в древовидном представлении и выбрать **Создать конвейер**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-285">Alternatively, you can right-click **Pipelines** in the tree view and click **New pipeline**.</span></span>
2. <span data-ttu-id="1d2f2-286">Замените JSON на правой панели следующим фрагментом JSON:</span><span class="sxs-lookup"><span data-stu-id="1d2f2-286">Replace JSON in the right pane with the following JSON snippet:</span></span> 

    ```json   
    {
      "name": "ADFTutorialPipeline",
      "properties": {
        "description": "Copy data from a blob to Azure SQL table",
        "activities": [
          {
            "name": "CopyFromBlobToSQL",
            "type": "Copy",
            "inputs": [
              {
                "name": "InputDataset"
              }
            ],
            "outputs": [
              {
                "name": "OutputDataset"
              }
            ],
            "typeProperties": {
              "source": {
                "type": "BlobSource"
              },
              "sink": {
                "type": "SqlSink",
                "writeBatchSize": 10000,
                "writeBatchTimeout": "60:00:00"
              }
            },
            "Policy": {
              "concurrency": 1,
              "executionPriorityOrder": "NewestFirst",
              "retry": 0,
              "timeout": "01:00:00"
            }
          }
        ],
        "start": "2017-05-11T00:00:00Z",
        "end": "2017-05-12T00:00:00Z"
      }
    } 
    ```   
    
    <span data-ttu-id="1d2f2-287">Обратите внимание на следующие моменты.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-287">Note the following points:</span></span>
   
    - <span data-ttu-id="1d2f2-288">В разделе действий доступно только одно действие, параметр **type** которого имеет значение **Copy**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-288">In the activities section, there is only one activity whose **type** is set to **Copy**.</span></span> <span data-ttu-id="1d2f2-289">Дополнительные сведения о действии копирования см. в статье [Перемещение данных с помощью действия копирования](data-factory-data-movement-activities.md).</span><span class="sxs-lookup"><span data-stu-id="1d2f2-289">For more information about the copy activity, see [data movement activities](data-factory-data-movement-activities.md).</span></span> <span data-ttu-id="1d2f2-290">В решениях фабрики данных можно также использовать [действия преобразования данных](data-factory-data-transformation-activities.md).</span><span class="sxs-lookup"><span data-stu-id="1d2f2-290">In Data Factory solutions, you can also use [data transformation activities](data-factory-data-transformation-activities.md).</span></span>
    - <span data-ttu-id="1d2f2-291">Для этого действия параметру input присвоено значение **InputDataset**, а параметру output — значение **OutputDataset**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-291">Input for the activity is set to **InputDataset** and output for the activity is set to **OutputDataset**.</span></span> 
    - <span data-ttu-id="1d2f2-292">В разделе **typeProperties** в качестве типа источника указано **BlobSource**, а в качестве типа приемника — **SqlSink**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-292">In the **typeProperties** section, **BlobSource** is specified as the source type and **SqlSink** is specified as the sink type.</span></span> <span data-ttu-id="1d2f2-293">Список хранилищ данных, поддерживаемых действием копирования в качестве источников и приемников, см. в разделе [Поддерживаемые хранилища данных и форматы](data-factory-data-movement-activities.md#supported-data-stores-and-formats).</span><span class="sxs-lookup"><span data-stu-id="1d2f2-293">For a complete list of data stores supported by the copy activity as sources and sinks, see [supported data stores](data-factory-data-movement-activities.md#supported-data-stores-and-formats).</span></span> <span data-ttu-id="1d2f2-294">Чтобы узнать, как использовать конкретное хранилище данных в качестве источника или приемника, щелкните ссылку в таблице.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-294">To learn how to use a specific supported data store as a source/sink, click the link in the table.</span></span>
    - <span data-ttu-id="1d2f2-295">Даты начала и окончания должны быть в [формате ISO](http://en.wikipedia.org/wiki/ISO_8601).</span><span class="sxs-lookup"><span data-stu-id="1d2f2-295">Both start and end datetimes must be in [ISO format](http://en.wikipedia.org/wiki/ISO_8601).</span></span> <span data-ttu-id="1d2f2-296">Например, 2016-10-14T16:32:41Z.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-296">For example: 2016-10-14T16:32:41Z.</span></span> <span data-ttu-id="1d2f2-297">Время **окончания** указывать не обязательно, однако в этом примере мы будем его использовать.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-297">The **end** time is optional, but we use it in this tutorial.</span></span> <span data-ttu-id="1d2f2-298">Если не указать значение свойства **end**, оно вычисляется по формуле "**время начала + 48 часов**".</span><span class="sxs-lookup"><span data-stu-id="1d2f2-298">If you do not specify value for the **end** property, it is calculated as "**start + 48 hours**".</span></span> <span data-ttu-id="1d2f2-299">Чтобы запустить конвейер в течение неопределенного срока, укажите значение **9999-09-09** в качестве значения свойства **end**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-299">To run the pipeline indefinitely, specify **9999-09-09** as the value for the **end** property.</span></span>
     
    <span data-ttu-id="1d2f2-300">В примере выше получено 24 среза данных, так как они создаются каждый час.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-300">In the preceding example, there are 24 data slices as each data slice is produced hourly.</span></span>

    <span data-ttu-id="1d2f2-301">Описание свойств JSON в определении конвейера см. в статье [Конвейеры и действия в фабрике данных Azure](data-factory-create-pipelines.md).</span><span class="sxs-lookup"><span data-stu-id="1d2f2-301">For descriptions of JSON properties in a pipeline definition, see [create pipelines](data-factory-create-pipelines.md) article.</span></span> <span data-ttu-id="1d2f2-302">Описание свойств JSON в определении действия копирования см. в статье [Перемещение данных с помощью действия копирования](data-factory-data-movement-activities.md).</span><span class="sxs-lookup"><span data-stu-id="1d2f2-302">For descriptions of JSON properties in a copy activity definition, see [data movement activities](data-factory-data-movement-activities.md).</span></span> <span data-ttu-id="1d2f2-303">Описание свойств JSON, поддерживаемых BlobSource, см. в статье о [соединителе больших двоичных объектов Azure](data-factory-azure-blob-connector.md).</span><span class="sxs-lookup"><span data-stu-id="1d2f2-303">For descriptions of JSON properties supported by BlobSource, see [Azure Blob connector article](data-factory-azure-blob-connector.md).</span></span> <span data-ttu-id="1d2f2-304">Описание свойств JSON, поддерживаемых SqlSink, см. в статье о [соединителе базы данных SQL Azure](data-factory-azure-sql-connector.md).</span><span class="sxs-lookup"><span data-stu-id="1d2f2-304">For descriptions of JSON properties supported by SqlSink, see [Azure SQL Database connector article](data-factory-azure-sql-connector.md).</span></span>
3. <span data-ttu-id="1d2f2-305">Щелкните **Развернуть** на панели инструментов, чтобы создать и развернуть конвейер **ADFTutorialPipeline**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-305">Click **Deploy** on the toolbar to create and deploy the **ADFTutorialPipeline**.</span></span> <span data-ttu-id="1d2f2-306">Убедитесь, что конвейер отображается в иерархической структуре.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-306">Confirm that you see the pipeline in the tree view.</span></span> 
4. <span data-ttu-id="1d2f2-307">Теперь закройте колонку **Редактор**, щелкнув **X**. Щелкните **X** снова, чтобы отобразить домашнюю страницу **фабрики данных** для экземпляра **ADFTutorialDataFactory**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-307">Now, close the **Editor** blade by clicking **X**. Click **X** again to see the **Data Factory** home page for the **ADFTutorialDataFactory**.</span></span>

<span data-ttu-id="1d2f2-308">**Поздравляем!**</span><span class="sxs-lookup"><span data-stu-id="1d2f2-308">**Congratulations!**</span></span> <span data-ttu-id="1d2f2-309">Фабрика данных Azure с конвейером, который копирует данные из хранилища BLOB-объектов Azure в базу данных SQL Azure, успешно создана.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-309">You have successfully created an Azure data factory with a pipeline to copy data from an Azure blob storage to an Azure SQL database.</span></span> 


## <a name="monitor-pipeline"></a><span data-ttu-id="1d2f2-310">Отслеживание конвейера</span><span class="sxs-lookup"><span data-stu-id="1d2f2-310">Monitor pipeline</span></span>
<span data-ttu-id="1d2f2-311">На этом шаге используется портал Azure для мониторинга фабрики данных Azure.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-311">In this step, you use the Azure portal to monitor what’s going on in an Azure data factory.</span></span>    

### <a name="monitor-pipeline-using-monitor--manage-app"></a><span data-ttu-id="1d2f2-312">Мониторинг конвейера с использованием приложения по мониторингу и управлению</span><span class="sxs-lookup"><span data-stu-id="1d2f2-312">Monitor pipeline using Monitor & Manage App</span></span>
<span data-ttu-id="1d2f2-313">Ниже приведены действия по мониторингу конвейеров в фабрике данных с помощью приложения "Мониторинг и управление".</span><span class="sxs-lookup"><span data-stu-id="1d2f2-313">The following steps show you how to monitor pipelines in your data factory by using the Monitor & Manage application:</span></span> 

1. <span data-ttu-id="1d2f2-314">Щелкните плитку **Monitor & Manage** (Мониторинг и управление) на домашней странице фабрики данных.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-314">Click **Monitor & Manage** tile on the home page for your data factory.</span></span>
   
    ![Плитка Monitor & Manage (Мониторинг и управление)](./media/data-factory-copy-activity-tutorial-using-azure-portal/monitor-manage-tile.png) 
2. <span data-ttu-id="1d2f2-316">**Приложение "Мониторинг и управление"** должно появиться на отдельной вкладке.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-316">You should see **Monitor & Manage application** in a separate tab.</span></span> 

    > [!NOTE]
    > <span data-ttu-id="1d2f2-317">Если веб-браузер завис на действии "Авторизация...", сделайте следующее: снимите флажок **Block third-party cookies and site data** (Блокировать сторонние файлы cookie и данные сайта) или создайте исключение для адреса **login.microsoftonline.com**, а затем попробуйте открыть приложение еще раз.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-317">If you see that the web browser is stuck at "Authorizing...", do one of the following: clear the **Block third-party cookies and site data** check box (or) create an exception for **login.microsoftonline.com**, and then try to open the app again.</span></span>

    ![Приложение по мониторингу и управлению](./media/data-factory-copy-activity-tutorial-using-azure-portal/monitor-and-manage-app.png)
3. <span data-ttu-id="1d2f2-319">Измените значения параметров **Время начала** и **Время окончания**, чтобы они включали соответствующие значения (2017-05-11 и 2017-05-12) для конвейера, и щелкните **Применить**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-319">Change the **Start time** and **End time** to include start (2017-05-11) and end times (2017-05-12) of your pipeline, and click **Apply**.</span></span>       
3. <span data-ttu-id="1d2f2-320">В списке в центре страницы отображаются **окна действий**, связанные с каждым часом в промежутке между временем начала и окончания конвейера.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-320">You see the **activity windows** associated with each hour between pipeline start and end times in the list in the middle pane.</span></span> 
4. <span data-ttu-id="1d2f2-321">Чтобы просмотреть сведения об окне действия, выберите его в списке **Activity Windows** (Окна действий).</span><span class="sxs-lookup"><span data-stu-id="1d2f2-321">To see details about an activity window, select the activity window in the **Activity Windows** list.</span></span> 
    <span data-ttu-id="1d2f2-322">![Сведения об окне действия](./media/data-factory-copy-activity-tutorial-using-azure-portal/activity-window-details.png)</span><span class="sxs-lookup"><span data-stu-id="1d2f2-322">![Activity window details](./media/data-factory-copy-activity-tutorial-using-azure-portal/activity-window-details.png)</span></span>

    <span data-ttu-id="1d2f2-323">В обозревателе окон действий справа вы увидите, что все срезы вплоть до текущего времени в формате UTC (20:12) обработаны (отображаются зеленым цветом).</span><span class="sxs-lookup"><span data-stu-id="1d2f2-323">In Activity Window Explorer on the right, you see that the slices up to the current UTC time (8:12 PM) are all processed (in green color).</span></span> <span data-ttu-id="1d2f2-324">Срезы, полученные в промежутке с 20:00 до 21:00, с 21:00 до 22:00, с 22:00 до 23:00, с 23:00 до 00:00, еще не обработаны.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-324">The 8-9 PM, 9 - 10 PM, 10 - 11 PM, 11 PM - 12 AM slices are not processed yet.</span></span>

    <span data-ttu-id="1d2f2-325">В разделе **Попытки** в области справа содержатся сведения о выполнении действия для среза данных.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-325">The **Attempts** section in the right pane provides information about the activity run for the data slice.</span></span> <span data-ttu-id="1d2f2-326">Если при выполнении произошла ошибка, в этом разделе отображаются сведения о ней.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-326">If there was an error, it provides details about the error.</span></span> <span data-ttu-id="1d2f2-327">Например, если входная папка или контейнер еще не созданы и произошел сбой обработки среза, вы увидите соответствующее сообщение об ошибке.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-327">For example, if the input folder or container does not exist and the slice processing fails, you see an error message stating that the container or folder does not exist.</span></span>

    ![Попытки выполнения действия](./media/data-factory-copy-activity-tutorial-using-azure-portal/activity-run-attempts.png) 
4. <span data-ttu-id="1d2f2-329">Запустите **SQL Server Management Studio**, подключитесь к базе данных SQL Azure и убедитесь, что строки вставляются в таблицу **emp** в базе данных.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-329">Launch **SQL Server Management Studio**, connect to the Azure SQL Database, and verify that the rows are inserted in to the **emp** table in the database.</span></span>
    
    ![результаты SQL-запроса](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-sql-query-results.png)

<span data-ttu-id="1d2f2-331">Дополнительные сведения об использовании этого приложения см. в статье [Мониторинг конвейеров фабрики данных Azure и управление ими с помощью нового приложения по мониторингу и управлению](data-factory-monitor-manage-app.md).</span><span class="sxs-lookup"><span data-stu-id="1d2f2-331">For detailed information about using this application, see [Monitor and manage Azure Data Factory pipelines using Monitoring and Management App](data-factory-monitor-manage-app.md).</span></span>

### <a name="monitor-pipeline-using-diagram-view"></a><span data-ttu-id="1d2f2-332">Мониторинг конвейера с использованием представления схемы</span><span class="sxs-lookup"><span data-stu-id="1d2f2-332">Monitor pipeline using Diagram View</span></span>
<span data-ttu-id="1d2f2-333">Конвейеры данных также можно отслеживать, используя представление схемы.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-333">You can also monitor data pipelines by using the diagram view.</span></span>  

1. <span data-ttu-id="1d2f2-334">В колонке **Фабрика данных** щелкните **Схема**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-334">In the **Data Factory** blade, click **Diagram**.</span></span>
   
    ![Колонка "Фабрика данных" — плитка схемы](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-datafactoryblade-diagramtile.png)
2. <span data-ttu-id="1d2f2-336">Вы должны увидеть схему, аналогичную приведенной ниже:</span><span class="sxs-lookup"><span data-stu-id="1d2f2-336">You should see the diagram similar to the following image:</span></span> 
   
    ![Представление схемы](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-diagram-blade.png)  
5. <span data-ttu-id="1d2f2-338">В представлении схемы дважды щелкните входной набор данных **InputDataset**, чтобы просмотреть его срезы.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-338">In the diagram view, double-click **InputDataset** to see slices for the dataset.</span></span>  
   
    ![Наборы данных с выбранным элементом InputDataset](./media/data-factory-copy-activity-tutorial-using-azure-portal/DataSetsWithInputDatasetFromBlobSelected.png)   
5. <span data-ttu-id="1d2f2-340">Щелкните ссылку **Еще**, чтобы отобразить все срезы данных.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-340">Click **See more** link to see all the data slices.</span></span> <span data-ttu-id="1d2f2-341">Вы увидите срезы, созданные в течение 24 часов в промежутке между временем начала и окончания конвейера.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-341">You see 24 hourly slices between pipeline start and end times.</span></span> 
   
    ![Все срезы входных данных](./media/data-factory-copy-activity-tutorial-using-azure-portal/all-input-slices.png)  
   
    <span data-ttu-id="1d2f2-343">Обратите внимание, что срезы данных вплоть до текущего времени (в формате UTC) находятся в состоянии **Готово**, так как файл **emp.txt** все это время находится в контейнере больших двоичных объектов **adftutorial\input**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-343">Notice that all the data slices up to the current UTC time are **Ready** because the **emp.txt** file exists all the time in the blob container: **adftutorial\input**.</span></span> <span data-ttu-id="1d2f2-344">Срезы для будущих периодов пока что не находятся в состоянии "Готово".</span><span class="sxs-lookup"><span data-stu-id="1d2f2-344">The slices for the future times are not in ready state yet.</span></span> <span data-ttu-id="1d2f2-345">Убедитесь, что срезы не отображаются в разделе **Срезы, в которых недавно произошел сбой** в нижней части.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-345">Confirm that no slices show up in the **Recently failed slices** section at the bottom.</span></span>
6. <span data-ttu-id="1d2f2-346">Закрывайте колонки, пока не появится представление схемы, или прокрутите окно влево.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-346">Close the blades until you see the diagram view (or) scroll left to see the diagram view.</span></span> <span data-ttu-id="1d2f2-347">Затем дважды щелкните **OutputDataset**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-347">Then, double-click **OutputDataset**.</span></span> 
8. <span data-ttu-id="1d2f2-348">Щелкните ссылку **Еще** в колонке **Таблица** набора данных **OutputDataset**, чтобы увидеть все его срезы.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-348">Click **See more** link on the **Table** blade for **OutputDataset** to see all the slices.</span></span>

    ![Колонка срезов данных](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-dataslices-blade.png) 
9. <span data-ttu-id="1d2f2-350">Обратите внимание, что срезы данных вплоть до текущего времени (в формате UTC) перешли из состояния **Ожидает выполнения** в состояние **Выполняется** ==> **Готово**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-350">Notice that all the slices up to the current UTC time move from **pending execution** state => **In progress** ==> **Ready** state.</span></span> <span data-ttu-id="1d2f2-351">По умолчанию срезы, полученные в прошлом (до текущего времени), обрабатываются по порядку от последних до самых старых.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-351">The slices from the past (before current time) are processed from latest to oldest by default.</span></span> <span data-ttu-id="1d2f2-352">Например, если сейчас 20:12 (UTC), сначала обрабатывается срез, полученный в промежутке с 19:00 до 20:00, а затем срез, полученный в промежутке с 18:00 до 19:00.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-352">For example, if the current time is 8:12 PM UTC, the slice for 7 PM - 8 PM is processed ahead of the 6 PM - 7 PM slice.</span></span> <span data-ttu-id="1d2f2-353">По умолчанию срез, полученный в промежутке с 20:00 до 21:00, обрабатывается в конце временного интервала, то есть после 21:00.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-353">The 8 PM - 9 PM slice is processed at the end of the time interval by default, that is after 9 PM.</span></span>  
10. <span data-ttu-id="1d2f2-354">Щелкните любой срез данных в списке, чтобы отобразить колонку **Срез данных** .</span><span class="sxs-lookup"><span data-stu-id="1d2f2-354">Click any data slice from the list and you should see the **Data slice** blade.</span></span> <span data-ttu-id="1d2f2-355">Фрагмент данных, связанный с окном действия, называется срезом.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-355">A piece of data associated with an activity window is called a slice.</span></span> <span data-ttu-id="1d2f2-356">Срез может быть одним файлом или несколькими файлами.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-356">A slice can be one file or multiple files.</span></span>  
    
     ![Колонка среза данных](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-dataslice-blade.png)
    
     <span data-ttu-id="1d2f2-358">Если срез не находится в состоянии **Готов**, вы можете увидеть восходящие срезы, которые не находятся в состоянии готовности и блокируют выполнение текущего среза в списке **Неготовые восходящие срезы**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-358">If the slice is not in the **Ready** state, you can see the upstream slices that are not Ready and are blocking the current slice from executing in the **Upstream slices that are not ready** list.</span></span>
11. <span data-ttu-id="1d2f2-359">В колонке **СРЕЗ ДАННЫХ** в списке в нижней части окна отображаются все выполненные действия.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-359">In the **DATA SLICE** blade, you should see all activity runs in the list at the bottom.</span></span> <span data-ttu-id="1d2f2-360">Щелкните **выполняемое действие**, чтобы просмотреть колонку **Подробности о выполнении операции**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-360">Click an **activity run** to see the **Activity run details** blade.</span></span> 
    
    ![Сведения о выполнении действия](./media/data-factory-copy-activity-tutorial-using-azure-portal/ActivityRunDetails.png)

    <span data-ttu-id="1d2f2-362">В этой колонке приведены сведения о времени выполнения операции копирования, пропускной способности, объеме записанных и прочитанных данных, времени начала и окончания выполнения и т. д.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-362">In this blade, you see how long the copy operation took, what throughput is, how many bytes of data were read and written, run start time, run end time etc.</span></span>  
12. <span data-ttu-id="1d2f2-363">С помощью кнопки **X** закройте все колонки, чтобы вернуться к начальной колонке **ADFTutorialDataFactory**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-363">Click **X** to close all the blades until you get back to the home blade for the **ADFTutorialDataFactory**.</span></span>
13. <span data-ttu-id="1d2f2-364">Чтобы открыть колонки, используемые на предыдущих этапах, щелкните элемент **Наборы данных** или **Конвейеры**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-364">(optional) click the **Datasets** tile or **Pipelines** tile to get the blades you have seen the preceding steps.</span></span> 
14. <span data-ttu-id="1d2f2-365">Запустите **SQL Server Management Studio**, подключитесь к базе данных SQL Azure и убедитесь, что строки вставляются в таблицу **emp** в базе данных.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-365">Launch **SQL Server Management Studio**, connect to the Azure SQL Database, and verify that the rows are inserted in to the **emp** table in the database.</span></span>
    
    ![результаты SQL-запроса](./media/data-factory-copy-activity-tutorial-using-azure-portal/getstarted-sql-query-results.png)


## <a name="summary"></a><span data-ttu-id="1d2f2-367">Сводка</span><span class="sxs-lookup"><span data-stu-id="1d2f2-367">Summary</span></span>
<span data-ttu-id="1d2f2-368">В этом учебнике вы создали фабрику данных Azure для копирования данных из большого двоичного объекта Azure в базу данных SQL Azure.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-368">In this tutorial, you created an Azure data factory to copy data from an Azure blob to an Azure SQL database.</span></span> <span data-ttu-id="1d2f2-369">Вы использовали портал Azure для создания фабрики данных, связанных служб, наборов данных и конвейера.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-369">You used the Azure portal to create the data factory, linked services, datasets, and a pipeline.</span></span> <span data-ttu-id="1d2f2-370">Вот обобщенные действия, которые вы выполнили в этом руководстве:</span><span class="sxs-lookup"><span data-stu-id="1d2f2-370">Here are the high-level steps you performed in this tutorial:</span></span>  

1. <span data-ttu-id="1d2f2-371">Создание **фабрики данных Azure**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-371">Created an Azure **data factory**.</span></span>
2. <span data-ttu-id="1d2f2-372">Создание **связанных служб**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-372">Created **linked services**:</span></span>
   1. <span data-ttu-id="1d2f2-373">**Служба хранилища Azure** — связанная служба для связи с учетной записью хранения Azure, которая содержит входные данные.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-373">An **Azure Storage** linked service to link your Azure Storage account that holds input data.</span></span>     
   2. <span data-ttu-id="1d2f2-374">**SQL Azure** — связанная служба для связи с базой данных SQL Azure, которая содержит выходные данные.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-374">An **Azure SQL** linked service to link your Azure SQL database that holds the output data.</span></span> 
3. <span data-ttu-id="1d2f2-375">Создание **наборов данных** , которые описывают входные и выходные данные для конвейеров.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-375">Created **datasets** that describe input data and output data for pipelines.</span></span>
4. <span data-ttu-id="1d2f2-376">Создание **конвейера** с **BlobSource** в качестве источника и **SqlSink** в качестве приемника с помощью **действия копирования**.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-376">Created a **pipeline** with a **Copy Activity** with **BlobSource** as source and **SqlSink** as sink.</span></span>  

## <a name="next-steps"></a><span data-ttu-id="1d2f2-377">Дальнейшие действия</span><span class="sxs-lookup"><span data-stu-id="1d2f2-377">Next steps</span></span>
<span data-ttu-id="1d2f2-378">В этом руководстве в ходе операции копирования вы использовали хранилище BLOB-объектов Azure как исходное хранилище данных, а базу данных SQL Azure — как целевое хранилище данных.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-378">In this tutorial, you used Azure blob storage as a source data store and an Azure SQL database as a destination data store in a copy operation.</span></span> <span data-ttu-id="1d2f2-379">В следующей таблице приведен список хранилищ данных, которые поддерживаются в качестве источников и целевых расположений для действия копирования.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-379">The following table provides a list of data stores supported as sources and destinations by the copy activity:</span></span> 

[!INCLUDE [data-factory-supported-data-stores](../../includes/data-factory-supported-data-stores.md)]

<span data-ttu-id="1d2f2-380">Чтобы получить дополнительные сведения о том, как скопировать данные в хранилище данных или из него, щелкните ссылку для хранилища данных в таблице.</span><span class="sxs-lookup"><span data-stu-id="1d2f2-380">To learn about how to copy data to/from a data store, click the link for the data store in the table.</span></span>