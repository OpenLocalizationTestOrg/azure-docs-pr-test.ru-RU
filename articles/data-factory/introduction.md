---
title: "Знакомство с фабрикой данных Azure | Документация Майкрософт"
description: "Сведения о фабрике данных Azure. Это облачная служба интеграции данных, которая организует и автоматизирует перемещение и преобразование данных."
services: data-factory
documentationcenter: 
author: sharonlo101
manager: jhubbard
editor: spelluru
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: get-started-article
ms.date: 01/11/2018
ms.author: shlo
ms.openlocfilehash: ac1ecf8ef9f1e30eb5bdd2fe86433a4981d73d8d
ms.sourcegitcommit: 384d2ec82214e8af0fc4891f9f840fb7cf89ef59
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/16/2018
---
# <a name="introduction-to-azure-data-factory"></a>Введение в фабрику данных Azure 
> [!div class="op_single_selector" title1="Select the version of Data Factory service you are using:"]
> * [Версия 1 — общедоступная](v1/data-factory-introduction.md)
> * [Версия 2 — предварительная](introduction.md)

В мире больших данных в реляционных, нереляционных и других системах хранения часто хранятся необработанные и неорганизованные данные. Но необработанные данные сами по себе не содержат нужного контекста или значения, чтобы быть полезными для аналитиков, специалистов по анализу данных и руководителей компаний. 

Для больших данных нужна служба, которая поддерживает процессы организации и подготовки к использованию, чтобы просеять эти огромные хранилища необработанных данных и преобразовать их в полезные аналитические выводы. Фабрика данных Azure — это управляемая облачная служба, созданная для сложных гибридных процессов извлечения, преобразования и загрузки (или извлечения, загрузки и преобразования) и интеграции данных.

В качестве примера рассмотрим компанию, которая создает облачные игры и собирает петабайты информации в виде журналов этих игр. Компания хочет проанализировать эти журналы, чтобы получить сведения о предпочтениях клиентов, демографических параметрах и особенностях использования. Эти сведения помогут понять, как можно увеличить дополнительные и перекрестные продажи, разработать новые интересные функции, стимулировать развитие компании и улучшить качество обслуживания клиентов.

Чтобы проанализировать эти журналы, компании необходимо использовать справочные сведения, например информацию о клиентах, игре и маркетинговых действиях, которые хранятся в локальном хранилище данных. Компании нужно объединить эти данные из локального хранилища данных с дополнительными данными журналов, собранными в облачном хранилище данных. 

Чтобы получить аналитические данные, компания обработает объединенные данные с помощью кластера Spark в облаке (Azure HDInsight), а затем опубликует преобразованные данные в облачное хранилище данных, например в хранилище данных SQL Azure, из которого можно будет легко получать нужные отчеты. Этот рабочий процесс должен выполняться автоматически при помещении файлов в контейнер хранилища больших двоичных объектов и должен ежедневно отслеживаться. Кроме того, должно быть налажено ежедневное управление им.

Фабрика данных Azure является идеальной платформой для таких сценариев обработки данных. Это *облачная служба интеграции данных, которая позволяет создавать управляемые данными рабочие процессы в облаке для оркестрации и автоматизации перемещения и преобразования данных*. С помощью фабрики данных Azure можно создавать и включать в расписание управляемые данными рабочие процессы (конвейеры), которые могут принимать данные из разнородных хранилищ данных, обрабатывать и преобразовывать эти данные с помощью служб вычислений (например, Azure HDInsight Hadoop, Spark, Azure Data Lake Analytics и машинного обучения Azure), 

а также публиковать выходные данные в хранилища данных (например, хранилище данных SQL Azure) для использования приложениями бизнес-аналитики. Необработанные данные с помощью фабрики данных Azure можно организовать в полезные хранилища данных и озера данных для принятия лучших деловых решений.

![Высокоуровневое представление фабрики данных](media/introduction/big-picture.png)

> [!NOTE]
> Эта статья относится к версии 2 фабрики данных, которая в настоящее время доступна в предварительной версии. Если вы используете общедоступную версию 1 службы фабрики данных, см. [статью о знакомстве с версией 1 фабрики данных](v1/data-factory-introduction.md).

## <a name="how-does-it-work"></a>Как это работает?
Конвейеры (управляемые данными рабочие процессы) в фабрике Azure данных обычно выполняют следующие четыре действия.

![Четыре действия рабочего процесса на основе данных](media/introduction/four-steps-of-a-workflow.png)

### <a name="connect-and-collect"></a>Подключение и сбор данных

Предприятия собирают данные различных типов в разнородных локальных и облачных источниках данных. Структурированные, неструктурированные или частично структурированные данные поступают с разными интервалами и с разной скоростью. 

Первым этапом в создании системы производства информации является подключение ко всем необходимым источникам данных и службам обработки, таким как службы SaaS (программное обеспечение как услуга), базы данных, файловые ресурсы с общим доступом, FTP и веб-службы, и перемещение данных, нуждающихся в последующей обработке, в централизованное расположение.

Не имея фабрики данных предприятия вынуждены создавать компоненты для перемещения пользовательских данных или писать пользовательские службы для интеграции этих источников данных и обработки. Такие системы дорого стоят, их сложно интегрировать и обслуживать. Кроме того, они часто не включают функции мониторинга и оповещений корпоративного уровня, а также элементы управления, которые может предложить полностью управляемая служба.

В фабрике данных вы можете использовать [действие копирования](copy-activity-overview.md) в конвейере данных для перемещения данных из локальных и облачных исходных хранилищ данных в централизованное хранилище данных в облаке для последующего анализа. Например, вы можете собрать данные в Azure Data Lake Store и позже преобразовать эти данные с помощью службы вычислений Azure Data Lake Analytics. Или же вы можете собрать данные в хранилище BLOB-объектов Azure и позже преобразовать их с помощью кластера Hadoop под управлением службы Azure HDInsight.

### <a name="transform-and-enrich"></a>Преобразование и дополнение данных
Обработайте или преобразуйте данные, собранные в централизованном облачном хранилище данных, с помощью служб вычислений, например HDInsight Hadoop, Spark, Data Lake Analytics и машинного обучения. Также необходимо надежно преобразовывать данные по определенному расписанию (поддерживаемому и управляемому) для насыщения рабочих сред доверенными данными.

### <a name="publish"></a>Опубликовать
Когда необработанные данные преобразованы в готовую к использованию форму, вы можете передать данные в хранилище данных Azure, базу данных SQL Azure, Azure Cosmos DB или в любую аналитическую платформу, которую могут выбрать бизнес-пользователи для своих средств бизнес-аналитики.

### <a name="monitor"></a>Мониторинг
После создания и развертывания конвейера интеграции данных, который извлекает полезные данные из обработанных данных, вам понадобится отслеживать успешное выполнение и сбои запланированных операций и конвейеров. Фабрика данных Azure предоставляет встроенную поддержку мониторинга конвейеров через Azure Monitor, API-интерфейсы, PowerShell, Microsoft Operations Management Suite и панели работоспособности на портале Azure.

## <a name="top-level-concepts"></a>Основные понятия
В подписке Azure может быть один или несколько экземпляров фабрики данных Azure. Фабрика данных Azure состоит из четырех основных компонентов. Они образуют платформу, на которой можно создавать управляемые данными рабочие процессы, предусматривающие перемещение и преобразование данных.

### <a name="pipeline"></a>Конвейер
В фабрике данных можно использовать один или несколько конвейеров. Конвейер — это логическая группа действий, которые выполняют определенный блок задач. Действия в конвейере совместно выполняют задачу. Например, конвейер может включать группу действий, которые принимают данные из большого двоичного объекта Azure и выполняют запрос Hive в кластере HDInsight для секционирования данных. 

Преимущество конвейера в том, что он позволяет управлять группами действий, а не каждым отдельным действием. Действия в конвейере можно связывать друг с другом последовательно или выполнять параллельно и независимо друг от друга.

### <a name="activity"></a>Действие
Действия представляют отдельные этапы обработки в конвейере. Например, действие копирования может использоваться для копирования данных из одного хранилища данных в другое. Точно так же можно использовать действие Hive, которое выполняет запрос Hive к кластеру Azure HDInsight, для преобразования или анализа данных. Фабрика данных поддерживает три типа действий: действия перемещения данных, действия преобразования данных и действия управления.

### <a name="datasets"></a>Наборы данных
Наборы данных представляют структуры данных в хранилищах. Эти структуры указывают данные, необходимые для использования в действиях, разделяя их на входные и выходные. 

### <a name="linked-services"></a>Связанные службы
Связанные службы напоминают строки подключения, определяющие сведения о подключении, необходимые для подключения фабрики данных к внешним ресурсам. Таким образом, набор данных представляет структуру данных, а связанная служба определяет подключение к источнику данных. Например, связанная служба хранилища Azure определяет строку подключения для подключения к учетной записи хранения Azure. Кроме того, набор данных больших двоичных объектов Azure определяет контейнер больших двоичных объектов и папку, которая содержит данные.

Связанные службы используются в фабрике данных для двух целей:

- Для представления **хранилища данных**, включая, помимо прочего, локальную базу данных SQL Server, базу данных Oracle, общий файловый ресурс и учетную запись хранилища BLOB-объектов Azure. Список поддерживаемых хранилищ см. в статье [о действии копирования](copy-activity-overview.md).

- Для представления **вычислительного ресурса**, в котором можно выполнить действие. Например, действие HDInsightHive выполняется в кластере Hadoop в HDInsight. Список поддерживаемых действий преобразования и вычислительных сред см. в статье [о преобразовании данных](transform-data.md).

### <a name="triggers"></a>триггеры;
Триггеры обозначают единицу обработки, которая определяет время запуска для выполнения конвейера. Существует несколько типов триггеров для разных событий. В предварительной версии фабрики данных поддерживается триггер планировщика, выполняемый по времени. 

### <a name="pipeline-runs"></a>Запуски конвейера
Запуск конвейера — это экземпляр выполнения конвейера. Запуск конвейера обычно создается путем передачи аргументов для параметров, определенных в конвейерах. Аргументы можно передавать вручную или в определении триггера.

### <a name="parameters"></a>Параметры
Параметры представляют собой пары "ключ — значение" в конфигурации только для чтения.  Параметры определяются в конвейере, а аргументы для них передаются во время выполнения из контекста запуска, созданного триггером, или из конвейера, который выполняется вручную. Действия в конвейере используют значения параметров.

Набор данных — это строго типизированный параметр и сущность, доступная для ссылок и повторного использования. Действие может ссылаться на наборы данных и может использовать параметры, определенные в определении набора данных.

Связанная служба также является строго типизированным параметром, который содержит сведения о подключении к хранилищу данных или среде вычислений. Служба также доступна для ссылок и (или) повторного использования.

### <a name="control-flow"></a>Поток управления
Поток управления — это оркестрация действий в конвейере, которая включает цепочки действий в последовательности, ветвление, определение параметров на уровне конвейера и передачу аргументов во время вызова конвейера по запросу или из триггера. Кроме того, сюда входит передача пользовательского состояния и контейнеров зацикливания (то есть итераторы For-each).


Дополнительные сведения о понятиях фабрики данных см. в следующих статьях:

- [Datasets and linked services in Azure Data Factory](concepts-datasets-linked-services.md) (Наборы данных и связанные службы в фабрике данных Azure)
- [Конвейеры и действия](concepts-pipelines-activities.md)
- [Среда выполнения интеграции в фабрике данных Azure](concepts-integration-runtime.md)

## <a name="supported-regions"></a>Поддерживаемые регионы

Сейчас фабрики данных можно создавать в таких регионах: восточная часть США, восточная часть США 2, Западная Европа. Однако для перемещения данных между хранилищами данных или для обработки данных с помощью служб вычислений фабрики данных могут обращаться к хранилищам данных и службам вычислений в других регионах Azure.

В самой фабрике данных Azure данные не хранятся. Она предоставляет возможность создавать управляемые данными рабочие процессы для обработки данных с помощью служб вычислений в других регионах или локальной среде, а также для оркестрации перемещения данных между поддерживаемыми хранилищами данных. Кроме того, с помощью фабрики данных можно отслеживать рабочие процессы и управлять ими, используя программные методы и пользовательский интерфейс.

Хотя фабрика данных доступна только в восточной части США, восточной части США 2 и Западной Европе, служба фабрики данных для поддержки перемещения данных доступна глобально в нескольких регионах. Если хранилище данных находится за брандмауэром, данные перемещает локальная среда выполнения интеграции, установленная в локальной среде.

Предположим, ваши вычислительные среды, например кластер Azure HDInsight и служба машинного обучения Azure, расположены в Западной Европе. Вы можете создать экземпляр фабрики данных Azure в восточной части США и восточной части США 2 и с его помощью планировать задания в вычислительных средах в Западной Европе. Фабрике данных требуется лишь несколько миллисекунд, чтобы запустить задание в вычислительной среде, но время выполнения задания в вашей вычислительной среде остается неизменным.

## <a name="compare-with-version-2"></a>Сравнение с версией 2
Список различий между версиями 1 и 2 службы фабрики данных см. в разделе о [сравнении с версией 1](compare-versions.md). 

## <a name="next-steps"></a>Дополнительная информация
Создание конвейера фабрики данных с помощью одного из следующих средств и пакетов SDK: 

- [Пользовательский интерфейс фабрики данных на портале Azure](quickstart-create-data-factory-portal.md)
- [Средство копирования данных на портале Azure](quickstart-create-data-factory-copy-data-tool.md)
- [PowerShell](quickstart-create-data-factory-powershell.md)
- [.NET](quickstart-create-data-factory-dot-net.md)
- [Python](quickstart-create-data-factory-python.md)
- [REST](quickstart-create-data-factory-rest-api.md)
- [Шаблон Azure Resource Manager](quickstart-create-data-factory-resource-manager-template.md)
 
