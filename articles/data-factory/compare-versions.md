---
title: "Сравнение фабрики данных Azure версий 1 и 2 | Документация Майкрософт"
description: "В этой статье сравниваются возможности фабрики данных Azure версий 1 и 2."
services: data-factory
documentationcenter: 
author: kromerm
manager: jhubbard
editor: spelluru
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: get-started-article
ms.date: 01/24/2018
ms.author: makromer
ms.openlocfilehash: 83065e6cacd784a3914cfac3ff2552a712688366
ms.sourcegitcommit: 79683e67911c3ab14bcae668f7551e57f3095425
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/25/2018
---
# <a name="compare-azure-data-factory-v1-and-v2"></a>Сравнение фабрики данных Azure версий 1 и 2
В этой статье сравниваются версии 1 и 2 фабрики данных Azure. Дополнительные сведения о фабрике данных Azure версии 1 см. в статье [Введение в фабрику данных Azure](v1/data-factory-introduction.md). Дополнительные сведения о фабрике данных Azure версии 2 см. в [этой статье](introduction.md).

## <a name="feature-comparison"></a>Сравнение возможностей
В следующей таблице сравниваются возможности двух версий. 

| Функция | версия 1 | версия 2 | 
| ------- | --------- | --------- | 
| Наборы данных | Именованное представление данных. Определяет данные, которые будут использоваться в действиях как входные и выходные. Наборы данных представляют данные в разных хранилищах, например в таблицах, файлах, папках и документах. Например, набор данных больших двоичных объектов Azure указывает контейнер больших двоичных объектов и папку в хранилище BLOB-объектов Azure, из которой действие должно считывать данные.<br/><br/>Значение **доступности** определяет модель среза в окне обработки для набора данных (например, каждый час, ежедневно и т. д.). | Как и в версии 2. Но вам не нужно планировать **доступность** для наборов данных. Вы можете определить ресурс триггера, который будет планировать работу конвейеров, используя парадигму планировщика часов. См. дополнительные сведения о [триггерах](concepts-pipeline-execution-triggers.md#triggers) и [наборах данных](concepts-datasets-linked-services.md). | 
| Связанные службы | Связанные службы напоминают строки подключения, определяющие сведения о подключении, необходимые для подключения фабрики данных к внешним ресурсам. | Связанные службы аналогичны службам в фабрике данных версии 1, но с новым свойством **connectVia** для использования вычислительной среды выполнения интеграции фабрики данных версии 2. Дополнительные сведения см. в статье [Среда выполнения интеграции в фабрике данных Azure](concepts-integration-runtime.md) и разделе [Свойства связанной службы](connector-azure-blob-storage.md#linked-service-properties). |
| Конвейеры | Фабрика данных может иметь один или несколько конвейеров. Конвейеры — это логические группы действий, которые вместе отвечают за выполнение задачи. Для планирования и выполнения конвейеров можно использовать значения startTime, endTime и isPaused. | Конвейеры представляют собой группы действий, выполняемых с данными. Но теперь планирование действий в конвейере включено в функции новых ресурсов триггера. Конвейеры в фабрике данных версии 2 можно рассматривать как единицы рабочих процессов, выполнение которых планируется отдельно с помощью триггеров. <br/><br/>В фабрике данных версии 2 для конвейеров не предусмотрено выполнение операций в рамках временных окон. Такие базовые значения фабрики данных версии 1, как startTime, endTime и isPaused, больше не поддерживаются в фабрике данных версии 2. Дополнительные сведения см. в статьях [Выполнение конвейера и триггеры в фабрике данных Azure](concepts-pipeline-execution-triggers.md) и [Конвейеры и действия в фабрике данных Azure](concepts-pipelines-activities.md). |
| Действия | Действия в конвейере определяют операции с данными. Поддерживаются такие операции, как перемещение данных (действие копирования) и преобразование данных (например, Hive, Pig и MapReduce). | В фабрике данных версии V2 операции по-прежнему представляют определенные действия, выполняемые в конвейере. В версии 2 реализованы новые [действия потока управления](concepts-pipelines-activities.md#control-activities). Эти действия выполняются в потоке управления (циклическая обработка и ветвление). Действия перемещения и преобразования данных, которые поддерживались в версии 1, поддерживаются и в версии 2. Действия преобразования в версии 2 можно определить без использования наборов данных. |
| Перенос гибридных данных и диспетчеризация действий | [Шлюз управления данными](v1/data-factory-data-management-gateway.md), теперь именуемый средой выполнения интеграции, поддерживает перемещение данных между локальной и облачной средами.| Шлюз управления данными теперь называется локальной средой выполнения интеграции. Он обеспечивает те же возможности, что и в версии 1. <br/><br/> В версии 2 Integration Runtime служб Azure SSIS также поддерживает развертывание и выполнение пакетов SQL Server Integration Services (SSIS) в облаке. Дополнительные сведения см. в статье [Среда выполнения интеграции в фабрике данных Azure](concepts-integration-runtime.md).|
| Параметры | Нет данных | Параметры представлены парами "ключ — значение" параметров конфигурации с доступом только на чтение, которые определены в конвейерах. Вы можете передавать аргументы для параметров конвейера при запуске конвейера вручную. Если вы используете триггер планировщика, он также может передавать значения для параметров. Действия в конвейере используют значения параметров.  |
| Выражения | В фабрике данных версии 1 можно использовать функции и системные переменные в запросах выбора данных и свойствах действий или наборов данных. | В фабрике данных версии 2 можно использовать выражения в любом месте в строковом значении JSON. Дополнительные сведения см. в статье [Выражения и функции в фабрике данных Azure](control-flow-expression-language-functions.md).|
| Запуски конвейера | Нет данных | Экземпляр выполнения конвейера. Например, у вас есть конвейер, который выполняется в 8:00, 9:00 и 10:00. В этом случае выполняются три отдельных запуска конвейера. Для каждого запуска конвейера предусмотрен уникальный идентификатор. Идентификатор запуска конвейера представляет собой уникальный идентификатор GUID. Запуск конвейера обычно создается путем передачи аргументов в параметры, определенные в конвейерах. |
| Выполнение действия | Нет данных | Экземпляр выполнения действий в конвейере. | 
| Выполнения триггеров | Нет данных | Экземпляр выполнения триггера. Дополнительные сведения см. в описании [триггеров](concepts-pipeline-execution-triggers.md). |
| Планирование | Планирование зависит от времени начала и окончания работы конвейера, а также доступности набора данных. | Триггер или выполнение планировщика с помощью внешнего планировщика. Дополнительные сведения см. в статье [Выполнение конвейера и триггеры в фабрике данных Azure](concepts-pipeline-execution-triggers.md). |

В следующих разделах приведены дополнительные сведения о возможностях версии 2. 

## <a name="control-flow"></a>Поток управления  
Чтобы обеспечить поддержку разнообразных последовательностей и шаблонов интеграции в современных хранилищах данных, фабрика данных версии 2 предлагает новую гибкую модель конвейеров данных, которая теперь не привязана к данным временных рядов. Теперь доступны стандартные потоки, которые раньше не поддерживались. Они описаны в следующих разделах.   

### <a name="chaining-activities"></a>Цепочки действий
Чтобы связать два действия в версии 1, нужно было определять выходные данные одного действия в качестве входных данных другого. В версии 2 вы можете создать в конвейере последовательность действий в виде цепочки. Связать действие с вышестоящим можно с помощью свойства **dependsOn** в определении действия. Дополнительные сведения и пример см. в разделе [Несколько действий в конвейере](concepts-pipelines-activities.md#multiple-activities-in-a-pipeline) и статье [Ветвления и создание цепочки действий в конвейере фабрики данных](tutorial-control-flow.md). 

### <a name="branching-activities"></a>Ветвления
В версии 2 можно выполнять действия ветвления в конвейере. Действие [условия If](control-flow-if-condition-activity.md) выполняет те же функции, что и инструкция `if` в языках программирования. Оно определяет набор действий, если условие принимает значение `true`, и другой набор действий, если условие принимает значение `false`. Примеры действий ветвления см. в руководстве о [ветвлении и создании цепочки действий в конвейере фабрики данных](tutorial-control-flow.md).

### <a name="parameters"></a>Параметры 
Вы можете определять параметры на уровне конвейера и передавать аргументы при вызове конвейера по запросу или из триггера. Действия могут использовать аргументы, передаваемые в конвейер. Дополнительные сведения см. в статье [Выполнение конвейера и триггеры в фабрике данных Azure](concepts-pipeline-execution-triggers.md). 

### <a name="custom-state-passing"></a>Передача пользовательского состояния:
Выходные данные действия содержат состояние, которое можно использовать в следующем действии в конвейере. Например, в определении JSON действия получить доступ к выходным данным предыдущего действия можно с помощью следующего синтаксиса: `@activity('NameofPreviousActivity').output.value`. Эта функция позволяет создавать рабочие процессы, в рамках которых значения могут передаваться через действия.

### <a name="looping-containers"></a>Контейнеры зацикливания:
[Действие ForEach](control-flow-for-each-activity.md) определяет повторяющийся поток управления в конвейере. Это действие используется для выполнения итерации коллекции и запускает указанные в цикле действия. Реализация цикла этого действия аналогична структуре цикла Foreach на языках программирования. 

Действие [Until](control-flow-until-activity.md) выполняет те же функции, что и циклическая структура do-until в языках программирования. Оно запускает набор действий в цикле, пока условие, связанное с действием, не получит значение `true`. Можно указать значение времени ожидания для действия until в фабрике данных.  

### <a name="trigger-based-flows"></a>Потоки на основе триггеров:
Конвейеры можно вызывать по требованию или в определенное время. Дополнительные сведения о триггерах см. в статье [Выполнение конвейера и триггеры в фабрике данных Azure](concepts-pipeline-execution-triggers.md). 

### <a name="invoking-a-pipeline-from-another-pipeline"></a>Вызов конвейера из другого конвейера
[Действие выполнения конвейера](control-flow-execute-pipeline-activity.md) позволяет конвейеру фабрики данных вызвать другой конвейер.

### <a name="delta-flows"></a>Разностные потоки:
Возможность использования ключа в шаблонах извлечения, преобразования и загрузки представлена разностной загрузкой — загрузкой только тех данных, которые изменялись с момента последней итерации конвейера. Новые функции в версии 2, такие как [действие поиска](control-flow-lookup-activity.md), гибкое планирование и поток управления, поддерживают эту возможность естественным образом. Дополнительные сведения см. в статье [Пошаговая загрузка данных из базы данных SQL Azure в хранилище BLOB-объектов Azure](tutorial-incremental-copy-powershell.md).

### <a name="other-control-flow-activities"></a>Другие действия потока управления
Ниже представлены другие действия потока управления, которые поддерживаются фабрикой данных версии 2. 

Действие управления | ОПИСАНИЕ
---------------- | -----------
[Действие ForEach](control-flow-for-each-activity.md) | Определяет повторяющийся поток управления в конвейере. Это действие используется для выполнения итерации коллекции и запускает указанные в цикле действия. Реализация цикла этого действия аналогична структуре цикла Foreach на языках программирования.
[Веб-действие](control-flow-web-activity.md) | Используется для вызова из конвейера фабрики данных пользовательской конечной точки REST. Вы можете передать наборы данных и связанные службы, которые будет использовать это действие и к которым оно будет обращаться. 
[Действие поиска](control-flow-lookup-activity.md) | Считывает или ищет значение имени таблицы или записи из внешнего источника. На эти выходные данные можно затем ссылаться в последующих действиях. 
[Действие получения метаданных](control-flow-get-metadata-activity.md) | Извлекает метаданные всех данных в фабрике данных Azure. 
[Действие ожидания](control-flow-wait-activity.md) | Останавливает работу конвейера на указанный период времени.

## <a name="deploy-ssis-packages-to-azure"></a>Развертывание пакетов служб SSIS в Azure 
Вы можете использовать службы SSIS Azure, если хотите переместить рабочие нагрузки служб SSIS в облако, создать фабрику данных с помощью версии 2 и подготовить среду выполнения интеграции служб SSIS Azure.

Среда выполнения интеграции Azure SSIS — это полностью управляемый кластер виртуальных машин (узлов) Azure, выделенных для выполнения пакетов служб SSIS в облаке. Подготовив среду выполнения интеграции Azure SSIS, вы сможете использовать те же средства, с которыми вы работали при развертывании пакетов служб SSIS для служб SSIS в локальной среде. 

Например, вы можете использовать SQL Server Data Tools ​​или SQL Server Management Studio для развертывания пакетов служб SSIS в этой среде выполнения в Azure. Пошаговые инструкции см. в руководстве [Развертывание пакетов служб интеграции SQL Server (SSIS) в Azure](tutorial-deploy-ssis-packages-azure.md). 

## <a name="flexible-scheduling"></a>Гибкое планирование
В фабрике данных версии 2 вам не нужно определять расписание обеспечения доступности для наборов данных. Вы можете определить ресурс триггера, который будет планировать работу конвейеров, используя парадигму планировщика часов. Вы также можете передавать параметры в конвейеры из триггера для использования гибкой модели планирования и выполнения. 

В фабрике данных версии 2 для конвейеров не предусмотрено выполнение операций в рамках временных окон. Такие базовые значения фабрики данных версии 1, как startTime, endTime и isPaused, больше не поддерживаются в фабрике данных версии 2. Дополнительные сведения о том, как создать конвейер в фабрике данных версии 2 и запланировать его работу, см. в статье [Выполнение конвейера и триггеры в фабрике данных Azure](concepts-pipeline-execution-triggers.md).

## <a name="support-for-more-data-stores"></a>Поддержка нескольких хранилищ данных
Версия 2 поддерживает больше хранилищ данных для двунаправленного копирования, чем версия 1. Список поддерживаемых хранилищ данных см. по следующим ссылкам:

- [для версии 1](v1/data-factory-data-movement-activities.md#supported-data-stores-and-formats);
- [для версии 2](copy-activity-overview.md#supported-data-stores-and-formats).

## <a name="support-for-on-demand-spark-cluster"></a>Поддержка кластера Spark по запросу
Версия 2 поддерживает создание кластера Azure HDInsight Spark по запросу. Чтобы создать кластер Spark по запросу, укажите тип кластера как Spark в определении связанной службы HDInsight по запросу. Затем можно настроить действие Spark в конвейере для использования этой связанной службы. 

При выполнении действия служба фабрики данных автоматически создает кластер Spark. Дополнительные сведения см. в следующих статьях:

- [Преобразование данных с помощью действия Spark в фабрике данных Azure](transform-data-using-spark.md)
- [Вычислительные среды, поддерживаемые фабрикой данных Azure](compute-linked-services.md#azure-hdinsight-on-demand-linked-service)

## <a name="custom-activities"></a>Пользовательские действия
В версии 1 вы реализуете код действия DotNet (настраиваемый) с помощью создания проекта библиотеки классов .NET, а также используя класс, реализующий метод Execute в интерфейсе IDotNetActivity. Таким образом, необходимо написать настраиваемый код с помощью .NET Framework версии 4.5.2 и запустить его на узлах пула пакетной службы Azure под управлением Windows. 

В настраиваемых действиях версии 2 не нужно реализовывать интерфейс .NET. Все команды, скрипты и пользовательский код можно компилировать и выполнять в виде исполняемого файла. 

Дополнительные сведения см. в разделе [Различия между настраиваемым действием в фабрике данных Azure версии 2 и (настраиваемым) действием DotNet в фабрике данных Azure версии 1](transform-data-using-dotnet-custom-activity.md#difference-between-custom-activity-in-azure-data-factory-v2-and-custom-dotnet-activity-in-azure-data-factory-v1).

## <a name="sdks"></a>Пакеты SDK
 В версии 2 фабрики данных доступны разные пакеты SDK, которые можно использовать для создания, администрирования и мониторинга конвейеров.

- **Пакет SDK для .NET.** — обновлен для использования с версией 2.

- **Командлеты PowerShell** — обновлены для использования с версией 2. Командлеты версии 2 содержат в имени **DataFactoryV2**. Например, Get-AzureRmDataFactoryV2. 

- **Пакет SDK для Python** — с предыдущей версией не использовался.

- **REST API** — обновлен для использования с версией 2. 

Пакеты SDK, которые обновлены для использования с версией 2, не обладают обратной совместимостью с клиентами версии 1. 

## <a name="authoring-experience"></a>Среда разработки

| &nbsp; | V2 | V1 |
| ------ | -- | -- | 
| Портал Azure | [Да](quickstart-create-data-factory-portal.md) | [Да](data-factory-build-your-first-pipeline-using-editor.md) |
| Azure PowerShell | [Да](quickstart-create-data-factory-powershell.md) | [Да](data-factory-build-your-first-pipeline-using-powershell.md) |
| ПАКЕТ SDK .NET | [Да](quickstart-create-data-factory-dot-net.md) | [Да](data-factory-build-your-first-pipeline-using-vs.md) |
| ИНТЕРФЕЙС REST API | [Да](quickstart-create-data-factory-rest-api.md) | [Да](data-factory-build-your-first-pipeline-using-rest-api.md) |
| Пакет SDK для Python | [Да](quickstart-create-data-factory-python.md) | Нет  |
| Шаблон Resource Manager | [Да](quickstart-create-data-factory-resource-manager-template.md) | [Да](data-factory-build-your-first-pipeline-using-arm.md) | 


## <a name="monitoring-experience"></a>Средства мониторинга
В версии 2 вы можете отслеживать фабрики данных с помощью [Azure Monitor](monitor-using-azure-monitor.md). Новые командлеты PowerShell позволяют отслеживать [среды выполнения интеграции](monitor-integration-runtime.md). Обе версии поддерживают визуальный мониторинг с помощью приложения мониторинга, которое можно запустить на портале Azure.


## <a name="next-steps"></a>Дополнительная информация
Дополнительные сведения о создании фабрики данных см. в руководствах по [PowerShell](quickstart-create-data-factory-powershell.md), [.NET](quickstart-create-data-factory-dot-net.md), [Python](quickstart-create-data-factory-python.md) и [REST API](quickstart-create-data-factory-rest-api.md). 
