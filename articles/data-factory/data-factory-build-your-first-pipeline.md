---
title: "Руководство по фабрике данных: первый конвейер данных | Документация Майкрософт"
description: "В этом руководстве по фабрике данных Azure объясняется, как создать и запланировать фабрику данных, которая обрабатывает данные с помощью сценария Hive в кластере Hadoop."
services: data-factory
keywords: "руководство по фабрике данных Azure, кластер hadoop, hadoop hive"
documentationcenter: 
author: spelluru
manager: jhubbard
editor: 
ms.assetid: 81f36c76-6e78-4d93-a3f2-0317b413f1d0
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 07/10/2017
ms.author: spelluru
ms.openlocfilehash: 08e2988d455cca21726162d9fb128e91fd51f463
ms.sourcegitcommit: 18ad9bc049589c8e44ed277f8f43dcaa483f3339
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 08/29/2017
---
# <a name="tutorial-build-your-first-pipeline-to-transform-data-using-hadoop-cluster"></a><span data-ttu-id="3abf4-104">Учебник. Создание первого конвейера для преобразования данных с помощью кластера Hadoop</span><span class="sxs-lookup"><span data-stu-id="3abf4-104">Tutorial: Build your first pipeline to transform data using Hadoop cluster</span></span>
> [!div class="op_single_selector"]
> * [<span data-ttu-id="3abf4-105">Обзор и предварительные требования</span><span class="sxs-lookup"><span data-stu-id="3abf4-105">Overview and prerequisites</span></span>](data-factory-build-your-first-pipeline.md)
> * [<span data-ttu-id="3abf4-106">Портал Azure</span><span class="sxs-lookup"><span data-stu-id="3abf4-106">Azure portal</span></span>](data-factory-build-your-first-pipeline-using-editor.md)
> * [<span data-ttu-id="3abf4-107">Visual Studio</span><span class="sxs-lookup"><span data-stu-id="3abf4-107">Visual Studio</span></span>](data-factory-build-your-first-pipeline-using-vs.md)
> * [<span data-ttu-id="3abf4-108">PowerShell</span><span class="sxs-lookup"><span data-stu-id="3abf4-108">PowerShell</span></span>](data-factory-build-your-first-pipeline-using-powershell.md)
> * [<span data-ttu-id="3abf4-109">Шаблон Resource Manager</span><span class="sxs-lookup"><span data-stu-id="3abf4-109">Resource Manager template</span></span>](data-factory-build-your-first-pipeline-using-arm.md)
> * [<span data-ttu-id="3abf4-110">REST API</span><span class="sxs-lookup"><span data-stu-id="3abf4-110">REST API</span></span>](data-factory-build-your-first-pipeline-using-rest-api.md)

<span data-ttu-id="3abf4-111">Из этого учебника вы узнаете, как создать свою первую фабрику данных Azure, используя конвейер данных.</span><span class="sxs-lookup"><span data-stu-id="3abf4-111">In this tutorial, you build your first Azure data factory with a data pipeline.</span></span> <span data-ttu-id="3abf4-112">Конвейер преобразует входные данные, запуская сценарий Hive в кластере Azure HDInsight (Hadoop) для создания выходных данных.</span><span class="sxs-lookup"><span data-stu-id="3abf4-112">The pipeline transforms input data by running Hive script on an Azure HDInsight (Hadoop) cluster to produce output data.</span></span>  

<span data-ttu-id="3abf4-113">Эта статья содержит общие сведения и описание необходимых компонентов для работы с учебником.</span><span class="sxs-lookup"><span data-stu-id="3abf4-113">This article provides overview and prerequisites for the tutorial.</span></span> <span data-ttu-id="3abf4-114">Обеспечив наличие всех необходимых компонентов, можно пройти учебник, используя одно из следующих средств или пакетов SDK: портала Azure, Visual Studio, PowerShell, шаблон Resource Manager или интерфейс REST API.</span><span class="sxs-lookup"><span data-stu-id="3abf4-114">After you complete the prerequisites, you can do the tutorial using one of the following tools/SDKs: Azure portal, Visual Studio, PowerShell, Resource Manager template, REST API.</span></span> <span data-ttu-id="3abf4-115">Выберите один из вариантов в раскрывающемся списке в начале (или) ссылки в конце этой статьи, чтобы пройти учебник, используя один из этих вариантов.</span><span class="sxs-lookup"><span data-stu-id="3abf4-115">Select one of the options in the drop-down list at the beginning (or) links at the end of this article to do the tutorial using one of these options.</span></span>    

## <a name="tutorial-overview"></a><span data-ttu-id="3abf4-116">Обзор учебника</span><span class="sxs-lookup"><span data-stu-id="3abf4-116">Tutorial overview</span></span>
<span data-ttu-id="3abf4-117">Вот какие шаги выполняются в этом учебнике:</span><span class="sxs-lookup"><span data-stu-id="3abf4-117">In this tutorial, you perform the following steps:</span></span>

1. <span data-ttu-id="3abf4-118">Создание **фабрики данных**.</span><span class="sxs-lookup"><span data-stu-id="3abf4-118">Create a **data factory**.</span></span> <span data-ttu-id="3abf4-119">Фабрика данных может содержать один или несколько конвейеров данных для перемещения и преобразования данных.</span><span class="sxs-lookup"><span data-stu-id="3abf4-119">A data factory can contain one or more data pipelines that move and transform data.</span></span> 

    <span data-ttu-id="3abf4-120">В этом учебнике рассказывается о том, как создать один конвейер в фабрике данных.</span><span class="sxs-lookup"><span data-stu-id="3abf4-120">In this tutorial, you create one pipeline in the data factory.</span></span> 
2. <span data-ttu-id="3abf4-121">Создание **конвейера**.</span><span class="sxs-lookup"><span data-stu-id="3abf4-121">Create a **pipeline**.</span></span> <span data-ttu-id="3abf4-122">Конвейер может включать одно или несколько действий (например, действие копирования, действие Hive HDInsight).</span><span class="sxs-lookup"><span data-stu-id="3abf4-122">A pipeline can have one or more activities (Examples: Copy Activity, HDInsight Hive Activity).</span></span> <span data-ttu-id="3abf4-123">В этом примере используется действие HDInsight Hive, которое запускает скрипт Hive в кластере HDInsight Hadoop.</span><span class="sxs-lookup"><span data-stu-id="3abf4-123">This sample uses the HDInsight Hive activity that runs a Hive script on a HDInsight Hadoop cluster.</span></span> <span data-ttu-id="3abf4-124">Этот скрипт сначала создает таблицу, которая ссылается на необработанные данные веб-журнала в хранилище BLOB-объектов Azure, а затем разбивает необработанные данные по годам и месяцам.</span><span class="sxs-lookup"><span data-stu-id="3abf4-124">The script first creates a table that references the raw web log data stored in Azure blob storage and then partitions the raw data by year and month.</span></span>

    <span data-ttu-id="3abf4-125">Описанный в данном учебнике конвейер использует действие Hive для преобразования данных с помощью запроса Hive в кластере Hadoop под управлением службы Azure HDInsight.</span><span class="sxs-lookup"><span data-stu-id="3abf4-125">In this tutorial, the pipeline uses the Hive Activity to transform data by running a Hive query on an Azure HDInsight Hadoop cluster.</span></span> 
3. <span data-ttu-id="3abf4-126">Создание **связанных служб**.</span><span class="sxs-lookup"><span data-stu-id="3abf4-126">Create **linked services**.</span></span> <span data-ttu-id="3abf4-127">С помощью связанной службы можно связать хранилище данных или службу вычислений с фабрикой данных.</span><span class="sxs-lookup"><span data-stu-id="3abf4-127">You create a linked service to link a data store or a compute service to the data factory.</span></span> <span data-ttu-id="3abf4-128">Хранилище данных, например хранилище Azure, содержит входные и выходные данные действий в конвейере.</span><span class="sxs-lookup"><span data-stu-id="3abf4-128">A data store such as Azure Storage holds input/output data of activities in the pipeline.</span></span> <span data-ttu-id="3abf4-129">Служба вычислений, такая как кластер HDInsight Hadoop, обрабатывает и преобразует данные.</span><span class="sxs-lookup"><span data-stu-id="3abf4-129">A compute service such as HDInsight Hadoop cluster processes/transforms data.</span></span>

    <span data-ttu-id="3abf4-130">В этом учебнике рассказывается о том, как создать две связанные службы: **службу хранилища Azure** и **Azure HDInsight**.</span><span class="sxs-lookup"><span data-stu-id="3abf4-130">In this tutorial, you create two linked services: **Azure Storage** and **Azure HDInsight**.</span></span> <span data-ttu-id="3abf4-131">Связанная служба хранилища Azure используется, чтобы связать учетную запись хранения Azure, которая содержит входные и выходные данные, с фабрикой данных.</span><span class="sxs-lookup"><span data-stu-id="3abf4-131">The Azure Storage linked service links an Azure Storage Account that holds the input/output data to the data factory.</span></span> <span data-ttu-id="3abf4-132">Связанная служба Azure HDInsight используется, чтобы связать кластер Azure HDInsight, который применяется для преобразования данных, с фабрикой данных.</span><span class="sxs-lookup"><span data-stu-id="3abf4-132">Azure HDInsight linked service links an Azure HDInsight cluster that is used to transform data to the data factory.</span></span> 
3. <span data-ttu-id="3abf4-133">Создание входных и выходных **наборов данных**.</span><span class="sxs-lookup"><span data-stu-id="3abf4-133">Create input and output **datasets**.</span></span> <span data-ttu-id="3abf4-134">Входной набор данных представляет входные данные для действия в конвейере, а выходной набор данных — выходные данные для действия.</span><span class="sxs-lookup"><span data-stu-id="3abf4-134">An input dataset represents the input for an activity in the pipeline and an output dataset represents the output for the activity.</span></span>

    <span data-ttu-id="3abf4-135">В этом учебнике наборы входных и выходных данных задают расположение входных и выходных данных в хранилище BLOB-объектов Azure.</span><span class="sxs-lookup"><span data-stu-id="3abf4-135">In this tutorial, the input and output datasets specify locations of input and output data in the Azure Blob Storage.</span></span> <span data-ttu-id="3abf4-136">Связанная служба хранилища Azure указывает, какая учетная запись хранения Azure используется.</span><span class="sxs-lookup"><span data-stu-id="3abf4-136">The Azure Storage linked service specifies what Azure Storage Account is used.</span></span> <span data-ttu-id="3abf4-137">Входной набор данных определяет, где расположены входные файлы, а выходной набор данных — где будут размещаться выходные файлы.</span><span class="sxs-lookup"><span data-stu-id="3abf4-137">An input dataset specifies where the input files are located and an output dataset specifies where the output files are placed.</span></span> 


<span data-ttu-id="3abf4-138">Подробный обзор фабрики данных Azure см. в статье [Общие сведения о службе фабрики данных Azure, службе интеграции данных в облаке](data-factory-introduction.md).</span><span class="sxs-lookup"><span data-stu-id="3abf4-138">See [Introduction to Azure Data Factory](data-factory-introduction.md) article for a detailed overview of Azure Data Factory.</span></span>
  
<span data-ttu-id="3abf4-139">Ниже приведено **представление схемы** примера фабрики данных, создаваемого в этом руководстве.</span><span class="sxs-lookup"><span data-stu-id="3abf4-139">Here is the **diagram view** of the sample data factory you build in this tutorial.</span></span> <span data-ttu-id="3abf4-140">У **MyFirstPipeline** есть одно действие типа Hive, которое использует набор данных **AzureBlobInput** в качестве входных данных и выдает набор данных **AzureBlobOutput** в качестве выходных данных.</span><span class="sxs-lookup"><span data-stu-id="3abf4-140">**MyFirstPipeline** has one activity of type Hive that consumes **AzureBlobInput** dataset as an input and produces **AzureBlobOutput** dataset as an output.</span></span> 

![Схема в руководстве по фабрике данных](media/data-factory-build-your-first-pipeline/data-factory-tutorial-diagram-view.png)


<span data-ttu-id="3abf4-142">В этом руководстве папка **inputdata** контейнера больших двоичных объектов Azure **adfgetstarted** содержит один файл с именем input.log.</span><span class="sxs-lookup"><span data-stu-id="3abf4-142">In this tutorial, **inputdata** folder of the **adfgetstarted** Azure blob container contains one file named input.log.</span></span> <span data-ttu-id="3abf4-143">Этот файл журнала содержит записи за три месяца: январь, февраль и март 2016 г.</span><span class="sxs-lookup"><span data-stu-id="3abf4-143">This log file has entries from three months: January, February, and March of 2016.</span></span> <span data-ttu-id="3abf4-144">Вот пример строк за каждый месяц во входном файле.</span><span class="sxs-lookup"><span data-stu-id="3abf4-144">Here are the sample rows for each month in the input file.</span></span> 

```
2016-01-01,02:01:09,SAMPLEWEBSITE,GET,/blogposts/mvc4/step2.png,X-ARR-LOG-ID=2ec4b8ad-3cf0-4442-93ab-837317ece6a1,80,-,1.54.23.196,Mozilla/5.0+(Windows+NT+6.3;+WOW64)+AppleWebKit/537.36+(KHTML,+like+Gecko)+Chrome/31.0.1650.63+Safari/537.36,-,http://weblogs.asp.net/sample/archive/2007/12/09/asp-net-mvc-framework-part-4-handling-form-edit-and-post-scenarios.aspx,\N,200,0,0,53175,871 
2016-02-01,02:01:10,SAMPLEWEBSITE,GET,/blogposts/mvc4/step7.png,X-ARR-LOG-ID=d7472a26-431a-4a4d-99eb-c7b4fda2cf4c,80,-,1.54.23.196,Mozilla/5.0+(Windows+NT+6.3;+WOW64)+AppleWebKit/537.36+(KHTML,+like+Gecko)+Chrome/31.0.1650.63+Safari/537.36,-,http://weblogs.asp.net/sample/archive/2007/12/09/asp-net-mvc-framework-part-4-handling-form-edit-and-post-scenarios.aspx,\N,200,0,0,30184,871
2016-03-01,02:01:10,SAMPLEWEBSITE,GET,/blogposts/mvc4/step7.png,X-ARR-LOG-ID=d7472a26-431a-4a4d-99eb-c7b4fda2cf4c,80,-,1.54.23.196,Mozilla/5.0+(Windows+NT+6.3;+WOW64)+AppleWebKit/537.36+(KHTML,+like+Gecko)+Chrome/31.0.1650.63+Safari/537.36,-,http://weblogs.asp.net/sample/archive/2007/12/09/asp-net-mvc-framework-part-4-handling-form-edit-and-post-scenarios.aspx,\N,200,0,0,30184,871
```

<span data-ttu-id="3abf4-145">Когда файл обрабатывается в конвейере с помощью действия Hive HDInsight, действие запускает в кластере HDInsight сценарий Hive, который разбивает входные данные по годам и месяцам.</span><span class="sxs-lookup"><span data-stu-id="3abf4-145">When the file is processed by the pipeline with HDInsight Hive Activity, the activity runs a Hive script on the HDInsight cluster that partitions input data by year and month.</span></span> <span data-ttu-id="3abf4-146">Этот сценарий создает три выходные папки, содержащие файл с записями за каждый месяц.</span><span class="sxs-lookup"><span data-stu-id="3abf4-146">The script creates three output folders that contain a file with entries from each month.</span></span>  

```
adfgetstarted/partitioneddata/year=2016/month=1/000000_0
adfgetstarted/partitioneddata/year=2016/month=2/000000_0
adfgetstarted/partitioneddata/year=2016/month=3/000000_0
```

<span data-ttu-id="3abf4-147">В примерах строк выше первая из них (содержащая дату 2016-01-01) записывается в файл 000000_0 в папке month=1.</span><span class="sxs-lookup"><span data-stu-id="3abf4-147">From the sample lines shown above, the first one (with 2016-01-01) is written to the 000000_0 file in the month=1 folder.</span></span> <span data-ttu-id="3abf4-148">Аналогичным образом вторая строка записывается в файл в папке month=2, а третья — в файл в папке month=3.</span><span class="sxs-lookup"><span data-stu-id="3abf4-148">Similarly, the second one is written to the file in the month=2 folder and the third one is written to the file in the month=3 folder.</span></span>  

## <a name="prerequisites"></a><span data-ttu-id="3abf4-149">Предварительные требования</span><span class="sxs-lookup"><span data-stu-id="3abf4-149">Prerequisites</span></span>
<span data-ttu-id="3abf4-150">Для работы с этим учебником необходимо следующее:</span><span class="sxs-lookup"><span data-stu-id="3abf4-150">Before you begin this tutorial, you must have the following prerequisites:</span></span>

1. <span data-ttu-id="3abf4-151">**Подписка Azure**. Если ее нет, можно за пару минут создать бесплатную пробную учетную запись.</span><span class="sxs-lookup"><span data-stu-id="3abf4-151">**Azure subscription** - If you don't have an Azure subscription, you can create a free trial account in just a couple of minutes.</span></span> <span data-ttu-id="3abf4-152">Сведения о том, как получить такую учетную запись, см. на странице [бесплатного ознакомительного периода](https://azure.microsoft.com/pricing/free-trial/).</span><span class="sxs-lookup"><span data-stu-id="3abf4-152">See the [Free Trial](https://azure.microsoft.com/pricing/free-trial/) article on how you can obtain a free trial account.</span></span>
2. <span data-ttu-id="3abf4-153">**Служба хранилища Azure**. В данном руководстве предполагается, что для хранения данных используется стандартная универсальная учетная запись хранения Azure.</span><span class="sxs-lookup"><span data-stu-id="3abf4-153">**Azure Storage** – You use a general-purpose standard Azure storage account for storing the data in this tutorial.</span></span> <span data-ttu-id="3abf4-154">Если у вас ее нет, прочитайте раздел [Создание учетной записи хранения](../storage/common/storage-create-storage-account.md#create-a-storage-account).</span><span class="sxs-lookup"><span data-stu-id="3abf4-154">If you don't have a general-purpose standard Azure storage account, see the [Create a storage account](../storage/common/storage-create-storage-account.md#create-a-storage-account) article.</span></span> <span data-ttu-id="3abf4-155">После создания учетной записи хранения запишите **ее имя** и **ключ доступа**.</span><span class="sxs-lookup"><span data-stu-id="3abf4-155">After you have created the storage account, note down the **account name** and **access key**.</span></span> <span data-ttu-id="3abf4-156">См. разделы о [просмотре, копировании и повторном создании ключей доступа к хранилищу](../storage/common/storage-create-storage-account.md#view-and-copy-storage-access-keys).</span><span class="sxs-lookup"><span data-stu-id="3abf4-156">See [View, copy and regenerate storage access keys](../storage/common/storage-create-storage-account.md#view-and-copy-storage-access-keys).</span></span>
3. <span data-ttu-id="3abf4-157">Загрузите и просмотрите файл запроса Hive (**HQL**) по адресу: [https://adftutorialfiles.blob.core.windows.net/hivetutorial/partitionweblogs.hql](https://adftutorialfiles.blob.core.windows.net/hivetutorial/partitionweblogs.hql).</span><span class="sxs-lookup"><span data-stu-id="3abf4-157">Download and review the Hive query file (**HQL**) located at: [https://adftutorialfiles.blob.core.windows.net/hivetutorial/partitionweblogs.hql](https://adftutorialfiles.blob.core.windows.net/hivetutorial/partitionweblogs.hql).</span></span> <span data-ttu-id="3abf4-158">Этот запрос преобразовывает входные данные в выходные.</span><span class="sxs-lookup"><span data-stu-id="3abf4-158">This query transforms input data to produce output data.</span></span> 
4. <span data-ttu-id="3abf4-159">Загрузите и просмотрите файл примера входных данных (**input.log**) по адресу: [https://adftutorialfiles.blob.core.windows.net/hivetutorial/input.log](https://adftutorialfiles.blob.core.windows.net/hivetutorial/input.log).</span><span class="sxs-lookup"><span data-stu-id="3abf4-159">Download and review the sample input file (**input.log**) located at: [https://adftutorialfiles.blob.core.windows.net/hivetutorial/input.log](https://adftutorialfiles.blob.core.windows.net/hivetutorial/input.log)</span></span>
5. <span data-ttu-id="3abf4-160">Создайте контейнер больших двоичных объектов с именем **adfgetstarted** в хранилище BLOB-объектов Azure.</span><span class="sxs-lookup"><span data-stu-id="3abf4-160">Create a blob container named **adfgetstarted** in your Azure Blob Storage.</span></span> 
6. <span data-ttu-id="3abf4-161">Передайте файл **partitionweblogs.hql** в папку **script** в контейнере **adfgetstarted**.</span><span class="sxs-lookup"><span data-stu-id="3abf4-161">Upload **partitionweblogs.hql** file to the **script** folder in the **adfgetstarted** container.</span></span> <span data-ttu-id="3abf4-162">Воспользуйтесь таким средством, как [Обозреватель службы хранилища Microsoft Azure](http://storageexplorer.com/).</span><span class="sxs-lookup"><span data-stu-id="3abf4-162">Use tools such as [Microsoft Azure Storage Explorer](http://storageexplorer.com/).</span></span> 
7. <span data-ttu-id="3abf4-163">Передайте файл **input.log** в папку **inputdata** в контейнере **adfgetstarted**.</span><span class="sxs-lookup"><span data-stu-id="3abf4-163">Upload **input.log** file to the **inputdata** folder in the **adfgetstarted** container.</span></span> 

<span data-ttu-id="3abf4-164">Обеспечив наличие всех необходимых компонентов, выберите одно из следующих средств или пакетов SDK для прохождения этого учебника:</span><span class="sxs-lookup"><span data-stu-id="3abf4-164">After you complete the prerequisites, select one of the following tools/SDKs to do the tutorial:</span></span> 

- [<span data-ttu-id="3abf4-165">Портал Azure</span><span class="sxs-lookup"><span data-stu-id="3abf4-165">Azure portal</span></span>](data-factory-build-your-first-pipeline-using-editor.md)
- [<span data-ttu-id="3abf4-166">Visual Studio</span><span class="sxs-lookup"><span data-stu-id="3abf4-166">Visual Studio</span></span>](data-factory-build-your-first-pipeline-using-vs.md)
- [<span data-ttu-id="3abf4-167">PowerShell</span><span class="sxs-lookup"><span data-stu-id="3abf4-167">PowerShell</span></span>](data-factory-build-your-first-pipeline-using-powershell.md)
- [<span data-ttu-id="3abf4-168">Шаблон Resource Manager</span><span class="sxs-lookup"><span data-stu-id="3abf4-168">Resource Manager template</span></span>](data-factory-build-your-first-pipeline-using-arm.md)
- [<span data-ttu-id="3abf4-169">REST API</span><span class="sxs-lookup"><span data-stu-id="3abf4-169">REST API</span></span>](data-factory-build-your-first-pipeline-using-rest-api.md)

<span data-ttu-id="3abf4-170">Портал Azure и Visual Studio позволяют создавать фабрики данных с помощью графического пользовательского интерфейса.</span><span class="sxs-lookup"><span data-stu-id="3abf4-170">Azure portal and Visual Studio provide GUI way of building your data factories.</span></span> <span data-ttu-id="3abf4-171">PowerShell, шаблон Resource Manager и интерфейс REST API, в свою очередь, дают возможность сделать это с помощью средств создания сценариев и программирования.</span><span class="sxs-lookup"><span data-stu-id="3abf4-171">Whereas, PowerShell, Resource Manager Template, and REST API options provides scripting/programming way of building your data factories.</span></span>

> [!NOTE]
> <span data-ttu-id="3abf4-172">Описанный в этом руководстве конвейер данных преобразовывает входные данные в выходные.</span><span class="sxs-lookup"><span data-stu-id="3abf4-172">The data pipeline in this tutorial transforms input data to produce output data.</span></span> <span data-ttu-id="3abf4-173">Он не копирует данные из исходного хранилища данных в целевое.</span><span class="sxs-lookup"><span data-stu-id="3abf4-173">It does not copy data from a source data store to a destination data store.</span></span> <span data-ttu-id="3abf4-174">Инструкции по копированию данных из хранилища BLOB-объектов Azure в базу данных SQL с помощью фабрики данных Azure см. в [этой статье](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).</span><span class="sxs-lookup"><span data-stu-id="3abf4-174">For a tutorial on how to copy data using Azure Data Factory, see [Tutorial: Copy data from Blob Storage to SQL Database](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).</span></span>
> 
> <span data-ttu-id="3abf4-175">Можно объединить в цепочку два действия (выполнить одно действие вслед за другим), настроив выходной набор данных одного действия как входной набор данных другого действия.</span><span class="sxs-lookup"><span data-stu-id="3abf4-175">You can chain two activities (run one activity after another) by setting the output dataset of one activity as the input dataset of the other activity.</span></span> <span data-ttu-id="3abf4-176">Подробные сведения см. в статье [Планирование и исполнение с использованием фабрики данных](data-factory-scheduling-and-execution.md).</span><span class="sxs-lookup"><span data-stu-id="3abf4-176">See [Scheduling and execution in Data Factory](data-factory-scheduling-and-execution.md) for detailed information.</span></span> 





  
