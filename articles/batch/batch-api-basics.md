---
title: "Обзор функций пакетной службы Azure для разработчиков | Документация Майкрософт"
description: "Ознакомьтесь с функциями пакетной службы и ее API-интерфейсов с точки зрения разработки."
services: batch
documentationcenter: .net
author: tamram
manager: timlt
editor: 
ms.assetid: 416b95f8-2d7b-4111-8012-679b0f60d204
ms.service: batch
ms.devlang: multiple
ms.topic: get-started-article
ms.tgt_pltfrm: na
ms.workload: big-compute
ms.date: 06/28/2017
ms.author: tamram
ms.custom: H1Hack27Feb2017
ms.openlocfilehash: c2f2a878414e4efd626d674ef9a182ae52eeb1ff
ms.sourcegitcommit: 18ad9bc049589c8e44ed277f8f43dcaa483f3339
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 08/29/2017
---
# <a name="develop-large-scale-parallel-compute-solutions-with-batch"></a>Разработка решений для крупномасштабных параллельных вычислений с использованием пакетной службы

В этом обзоре рассматриваются основные функции и ресурсы пакетной службы Azure, которые могут использовать разработчики при создании решений для крупномасштабных параллельных вычислительных нагрузок.

Как при разработке распределенного вычислительного приложения или службы, которая отправляет прямые вызовы [REST API][batch_rest_api], так и при использовании одного из [пакетов SDK для пакетной службы](batch-apis-tools.md#azure-accounts-for-batch-development) вам понадобятся многие ресурсы и функции, описанные в этой статье.

> [!TIP]
> Дополнительные сведения о пакетной службе Azure см. в [этой статье](batch-technical-overview.md).
>
>

## <a name="batch-service-workflow"></a>Рабочий процесс пакетной службы
Далее приводится обобщенная схема рабочего процесса практически для всех приложений и служб, использующих пакетную службу для обработки параллельных рабочих нагрузок.

1. Отправьте **файлы данных**, которые необходимо обработать, в учетную запись [службы хранилища Azure][azure_storage]. В пакетную службу встроена поддержка доступа к хранилищу BLOB-объектов Azure, и эти файлы могут быть скачаны на [вычислительные узлы](#compute-node) в ходе выполнения задач.
2. Отправьте **файлы приложения**, которые будут выполнять задачи. Это могут быть двоичные файлы или сценарии и их зависимости. Они выполняются с помощью задач в заданиях. Эти файлы можно скачать из учетной записи службы хранения. Либо можно использовать [пакеты приложений](#application-packages) пакетной службы для развертывания приложений и управления ими.
3. Создайте [пул](#pool) вычислительных узлов. При создании пула указывается количество вычислительных узлов, их размер и операционная система. Каждая задача в задании выполняется на одном из узлов в пуле.
4. Создайте [задание](#job). Задание — это набор задач. Каждое задание назначается конкретному пулу, в котором будут выполняться задачи этого задания.
5. Добавьте [задачи](#task) в задание. Каждая задача выполняет приложение или сценарий, загруженные для обработки файлов данных, скачанных из учетной записи службы хранилища. Выходные данные каждой задачи после ее завершения могут быть отправлены в службу хранилища Azure.
6. Отслеживайте ход выполнения заданий и получайте выходные данные задач из службы хранилища Azure.

В следующих разделах рассматриваются эти и другие ресурсы пакетной службы, которые позволяют использовать распределенные вычисления.

> [!NOTE]
> Для использования пакетной службы вам потребуется [учетная запись пакетной службы](#account). Кроме того, большинство решений пакетной службы предполагают наличие [учетной записи хранения Azure][azure_storage] для хранения и извлечения файлов. Сейчас пакетная служба поддерживает только учетные записи хранения **общего назначения**, как описано на шаге 5 раздела [о создании учетной записи хранения](../storage/common/storage-create-storage-account.md#create-a-storage-account) в статье [Об учетных записях хранения Azure](../storage/common/storage-create-storage-account.md).
>
>

## <a name="batch-service-resources"></a>Ресурсы пакетной службы
Для всех решений, использующих пакетную службу, требуются такие ресурсы, как учетные записи, вычислительные узлы, пулы, задания и задачи. Другие ресурсы, например расписания заданий и пакеты приложений, являются полезными дополнительными функциями.

* [Учетная запись.](#account)
* [Вычислительный узел.](#compute-node)
* [Пул.](#pool)
* [Задание.](#job)

  * [Расписания заданий](#scheduled-jobs)
* [Задача.](#task)

  * [Задача запуска](#start-task)
  * [Задача диспетчера заданий](#job-manager-task)
  * [Задачи подготовки и завершения заданий.](#job-preparation-and-release-tasks)
  * [Задачи с несколькими экземплярами](#multi-instance-tasks)
  * [Зависимости задачи](#task-dependencies)
* [Пакеты приложений](#application-packages)

## <a name="account"></a>Учетная запись.
Учетная запись Пакетной службы — это уникально идентифицируемая сущность в Пакетной службе. Вся обработка данных привязана к учетной записи пакетной службы.

Вы можете создать учетную запись пакетной службы Azure с помощью [портала](batch-account-create-portal.md) или программными средствами, например с помощью [библиотеки. NET управления пакетной службой](batch-management-dotnet.md). При создании учетной записи можно связать учетную запись хранения Azure.

### <a name="pool-allocation-mode"></a>Режим распределения пула

При создании учетной записи пакетной службы можно указать способ распределения [пулов](#pool) вычислительных узлов. Вы можете выделить пулы вычислительных узлов в подписке, управляемой пакетной службой Azure, или же в собственной подписке. Свойство *Режим выделения пула* учетной записи определяет, где должны выделяться пулы. 

Чтобы решить, какой режим распределения пула следует использовать, определите, какой из них лучше всего соответствует вашему сценарию:

* **Пакетная служба.** Это режим распределения пула, используемый по умолчанию. В нем пулы автоматически выделяются в подписках, управляемых Azure. Учитывайте следующие основные моменты в отношении режима распределения пула "Пакетная служба":

    - Этот режим распределения пула поддерживает как пулы облачной службы, так и пулы виртуальных машин.
    - Этот режим поддерживает проверку подлинности с общим ключом и [проверку подлинности Azure Active Directory](batch-aad-auth.md) (Azure AD). 
    - В пулах, выделенных в режиме "Пакетная служба", вы можете использовать специальные или низкоприоритетные вычислительные узлы.
    - Не используйте этот режим, если вы планируете создавать пулы виртуальных машин Azure из пользовательских образов виртуальных машин или использовать виртуальную сеть. Вместо этого создайте учетную запись с режимом распределения пула "Пользовательская подписка".
    - Пулы виртуальных машин, подготовленные в учетной записи с режимом распределения пула "Пользовательская подписка", должны быть созданы из образов виртуальных машин в [Azure Marketplace][vm_marketplace].

* **Пользовательская подписка.** При использовании этого режима пулы пакетной службы выделяются в подписке Azure, в которой создана учетная запись. Учитывайте следующие основные моменты в отношении режима распределения пула "Пользовательская подписка":
     
    - Этот режим распределения пула поддерживает только пулы виртуальных машин. Она не поддерживает пулы облачных служб.
    - Чтобы создать пулы виртуальных машин из пользовательских образов виртуальных машин или использовать с этими пулами виртуальную сеть, следует использовать этот режим.  
    - Для пулов, выделенных в пользовательской подписке, необходимо использовать [проверку подлинности Azure Active Directory](batch-aad-auth.md). 
    - Если выбран этот режим распределения пула, необходимо настроить Azure Key Vault для учетной записи пакетной службы. 
    - Вы можете использовать только специальные вычислительные узлы в пулах в учетных записях, созданных в режиме распределения пула "Пользовательская подписка". Низкоприоритетные узлы не поддерживаются.
    - Пулы виртуальных машин, подготовленные в учетной записи с режимом распределения пула "Пользовательская подписка", могут быть созданы из пользовательских образов, предоставленных вами, или из образов виртуальных машин в [Azure Marketplace][vm_marketplace].

В следующей таблице сравниваются режимы распределения пула "Пакетная служба" и "Пользовательская подписка".

| **Режим распределения пула**                 | **Пакетная служба**                                                                                       | **Пользовательская подписка**                                                              |
|-------------------------------------------|---------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------|
| **Место распределения пула**               | Подписка, управляемая Azure                                                                           | Пользовательская подписка, в которой создана учетная запись пакетной службы                        |
| **Поддерживаемые конфигурации**             | <ul><li>Конфигурация облачной службы</li><li>Конфигурация виртуальной машины (Linux и Windows)</li></ul> | <ul><li>Конфигурация виртуальной машины (Linux и Windows)</li></ul>                |
| **Поддерживаемые образы виртуальных машин**                  | <ul><li>Образы из Azure Marketplace</li></ul>                                                              | <ul><li>Образы из Azure Marketplace</li><li>Пользовательские образы</li></ul>                   |
| **Поддерживаемые типы вычислительных узлов**         | <ul><li>Специальные узлы</li><li>Низкоприоритетные узлы</li></ul>                                            | <ul><li>Специальные узлы</li></ul>                                                  |
| **Поддерживаемый тип проверки подлинности**             | <ul><li>Общий ключ</li><li>Azure AD</li></ul>                                                           | <ul><li>Azure AD</li></ul>                                                         |
| **Требуется ли хранилище Azure Key Vault**             | Нет                                                                                                      | Да                                                                                |
| **Квота на ядра**                           | Определяется по квоте на ядра для пакетной службы                                                                          | Определяется по квоте на ядра для подписки                                              |
| **Поддержка виртуальной сети Azure** | Пулы, созданные с использованием конфигурации облачной службы                                                      | Пулы, созданные с использованием конфигурации виртуальной машины                               |
| **Поддерживаемая модель развертывания виртуальной сети**      | Виртуальные сети, созданные по классической модели развертывания                                                             | Виртуальные сети, созданные по классической модели развертывания или модели развертывания с помощью Azure Resource Manager |

## <a name="azure-storage-account"></a>Учетная запись хранения Azure

В большинстве решений пакетной службы для хранения файлов ресурсов и выходных файлов используется служба хранилища Azure.  

Сейчас пакетная служба поддерживает только учетные записи хранения общего назначения, как описано в шаге 5 раздела о [создании учетной записи хранения](../storage/common/storage-create-storage-account.md#create-a-storage-account) в статье [Об учетных записях хранения Azure](../storage/common/storage-create-storage-account.md). В задачах пакетной службы (включая стандартные задачи, задачи запуска, задачи подготовки и прекращения заданий) необходимо указывать файлы ресурсов, которые находятся в учетных записях хранения общего назначения.


## <a name="compute-node"></a>Вычислительный узел.
Вычислительный узел — это виртуальная машина Azure или облачной службы, назначенная для обработки определенной рабочей нагрузки вашего приложения. Размер узла определяет количество ядер ЦП, объем памяти и размер локальной файловой системы, которые выделяются узлу. Вы можете создавать пулы узлов Windows или Linux с помощью облачных служб Azure, образов виртуальных машин из [Azure Marketplace][vm_marketplace] или пользовательских образов, подготовленных вами. Дополнительные сведения см. в разделе [Пул](#pool) ниже.

На узлах может выполняться любой исполняемый файл или скрипт, поддерживаемый его операционной системой: скрипты \*EXE, \*CMD, \*BAT и PowerShell для Windows и двоичные файлы, скрипты оболочки и Python для Linux.

Для всех вычислительных узлов в пакетной службе характерно следующее:

* Стандартная [структура папок](#files-and-directories) и связанные [переменные среды](#environment-settings-for-tasks), на которые могут ссылаться задачи.
* **брандмауэра**, настроенные для управления доступом.
* [Удаленный доступ](#connecting-to-compute-nodes) к узлам Windows (по протоколу RDP) и Linux (по протоколу SSH).

## <a name="pool"></a>пул
Пул — это коллекция узлов, на которых выполняется приложение. Пул может быть создан как вами (вручную), так и пакетной службой (автоматически) при указании выполняемых работ. Вы можете создавать и изменять пулы в соответствии с потребностями ресурсов своего приложения. Пул может использоваться только той учетной записью пакетной службы, в которой он был создан. Учетная запись Пакетной службы может содержать более одного пула.

Пулы пакетной службы Azure основаны на базовой вычислительной платформе Azure. Они удобны для крупномасштабных операций выделения, установки приложений, распространения данных и мониторинга работоспособности. Кроме того, пулы позволяют выполнять [масштабирование](#scaling-compute-resources) — гибкое изменение числа вычислительных узлов в пуле.

Каждому узлу, который добавляется в пул, присваивается уникальное имя и IP-адрес. При удалении узла из пула будут потеряны любые изменения, внесенные в операционную систему или файлы. Имя и IP-адрес удаленного узла освобождаются для использования в других целях. Когда узел покидает пул, он перестает существовать.

При создании пула можно указать следующие атрибуты. Некоторые параметры различаются в зависимости от режима выделения пула в [учетной записи](#account) пакетной службы:

- операционная система и версия вычислительного узла;
- тип вычислительного узла и целевое количество узлов;
- размер вычислительных узлов;
- политика масштабирования;
- политика планирования задач;
- состояние взаимодействия между вычислительными узлами;
- задачи запуска для вычислительных узлов;
- Пакеты приложений
- Конфигурация сети

Каждый из этих параметров описан более подробно в следующих разделах.

> [!IMPORTANT]
> Для учетных записей пакетной службы с режимом распределения пула "Пакетная служба" установлена квота по умолчанию, которая ограничивает количество ядер в учетной записи пакетной службы. Число ядер соответствует количеству вычислительных узлов. Дополнительные сведения о квотах по умолчанию и инструкцию по [увеличению квоты](batch-quota-limit.md#increase-a-quota) см. в статье [Квоты и ограничения пакетной службы Azure](batch-quota-limit.md). Если пул не достигает целевого количества узлов, причиной может быть основная квота.
>
>В учетных записях пакетной службы, созданных в режиме распределения пула "Пользовательская подписка", квоты пакетной службы не соблюдаются. Вместо этого они совместно используют основную квоту для указанной подписки. Дополнительные сведения см. в разделе [Ограничения виртуальных машин](../azure-subscription-service-limits.md#virtual-machines-limits) в статье [Подписка Azure, границы, квоты и ограничения службы](../azure-subscription-service-limits.md).
>
>

### <a name="compute-node-operating-system-and-version"></a>Операционная система и версия вычислительного узла

При создании пула пакетной службы можно указать конфигурацию виртуальной машины Azure и тип операционной системы, которую вы хотите запустить на каждом вычислительном узле в пуле. В пакетной службе доступны два типа конфигураций:

- **Конфигурация виртуальной машины**, которая указывает, что пул состоит из виртуальных машин Azure. Эти виртуальные машины могут быть созданы из образов Windows или Linux. 

    Создавая пул, основанный на конфигурации виртуальных машин, необходимо указать не только размер узлов и источник образов, которые использовались для их создания, но и **ссылку на образ виртуальной машины** и **номер SKU агента узла** пакетной службы для установки на узлах. Дополнительные сведения об указании этих свойств пула см. в статье [Подготовка вычислительных узлов Linux в пулах пакетной службы Azure](batch-linux-nodes.md).

- **Конфигурация облачных служб**, которая указывает, что пул состоит из узлов облачных служб Azure. Облачные службы предоставляют *только* вычислительные узлы Windows.

    Доступные операционные системы пулов с конфигурацией облачных служб перечислены в статье [Таблица совместимости выпусков гостевых ОС Azure и пакетов SDK](../cloud-services/cloud-services-guestos-update-matrix.md). При создании пула, содержащего узлы облачных служб, необходимо указать размер узла и соответствующее *семейство ОС*. Облачные службы развертываются в Azure быстрее, чем виртуальные машины под управлением Windows. Если вам нужны пулы вычислительных узлов Windows, вы можете обнаружить, что облачные службы предоставляют преимущества производительности с точки зрения времени развертывания.

    * *Семейство ОС* также определяет, какие версии .NET устанавливаются вместе с операционной системой.
    * Вы можете выбрать для узлов *версию ОС*, так же как и для рабочих ролей в облачных службах (дополнительные сведения о рабочих ролях см. в разделе [Информация об облачных службах](../cloud-services/cloud-services-choose-me.md#tell-me-about-cloud-services) статьи [Стоит ли сделать выбор в пользу облачных служб или чего-то другого?](../cloud-services/cloud-services-choose-me.md)).
    * Как и для рабочих ролей, мы рекомендуем указывать значение `*` в качестве *версии ОС*. Тогда узлы будут обновляться автоматически, и вам не нужно будет выполнять дополнительные действия при выходе новых версий. Выбор конкретной версии ОС обычно нужен только для гарантии совместимости приложений. Это позволит протестировать обратную совместимость перед установкой обновлений. После успешной проверки вам понадобится обновить *версию ОС* для пула и установить новый образ ОС. Все выполняемые задачи будут при этом прерваны и повторно поставлены в очередь.

При создании пула вам необходимо выбрать соответствующий **nodeAgentSkuId** в зависимости от ОС базового образа вашего VHD. Вы можете получить сопоставление идентификаторов SKU доступных агентов узла с их ссылками на образы на ОС, вызвав операцию [List Supported Node Agent SKUs](https://docs.microsoft.com/rest/api/batchservice/list-supported-node-agent-skus) (Вывод списка поддерживаемых SKU агентов узла).

Дополнительные сведения о настройке режима выделения пула при создании учетной записи пакетной службы см. в разделе [Учетная запись](#account).

#### <a name="custom-images-for-virtual-machine-pools"></a>Пользовательские образы для пулов виртуальных машин

Чтобы использовать пользовательский образ для подготовки пулов виртуальных машин, создайте учетную запись пакетной службы в режиме распределения пула "Пользовательская подписка". В этом режиме пулы пакетной службы выделяются для подписки, в которой находится учетная запись. Дополнительные сведения о настройке режима выделения пула при создании учетной записи пакетной службы см. в разделе [Учетная запись](#account).

Чтобы использовать пользовательский образ, подготовьте его, сделав универсальным. Сведения о подготовке пользовательских образов под управлением Linux на основе виртуальных машин Azure см. в статье [Запись виртуальной машины Linux, работающей в Azure](../virtual-machines/linux/capture-image-nodejs.md). Сведения о подготовке пользовательских образов под управлением Windows на основе виртуальных машин Azure см. в статье [Создание пользовательского образа виртуальной машины Azure с помощью PowerShell](../virtual-machines/windows/tutorial-custom-images.md). 

> [!IMPORTANT]
> При подготовке пользовательского образа учитывайте следующие факторы:
> - Убедитесь, что в базовом образе операционной системы, который используется для подготовки пулов пакетной службы, нет предварительно установленных расширений Azure, например расширения "Настраиваемый скрипт". Если образ содержит предварительно установленное расширение, могут возникнуть проблемы при развертывании виртуальной машины в Azure.
> - Убедитесь, что для базового образа операционной системы, предоставленного вами, по умолчанию используется временный диск, так как на текущем этапе для агента узла пакетной службы требуется этот временный диск.
>
>

Чтобы создать пул конфигурации виртуальной машины с помощью пользовательского образа, потребуется одна или несколько стандартных учетных записей хранения Azure для хранения пользовательских образов VHD. Пользовательские образы хранятся в виде больших двоичных объектов. Чтобы сослаться на свои пользовательские образы при создании пула, укажите URI больших двоичных объектов VHD-файлов пользовательских образов для свойства [osDisk](https://docs.microsoft.com/rest/api/batchservice/add-a-pool-to-an-account#bk_osdisk) свойства [virtualMachineConfiguration](https://docs.microsoft.com/rest/api/batchservice/add-a-pool-to-an-account#bk_vmconf).

Убедитесь, что учетные записи хранения соответствуют следующим критериям:   

- Учетные записи хранения, содержащие большие двоичные объекты VHD-файлов пользовательских образов, должны находиться в той же подписке, что и учетная запись пакетной службы (подписка пользователя).
- Указанная учетная запись хранения должна быть в том же регионе, что и учетная запись пакетной службы.
- Сейчас поддерживаются только стандартные учетные записи хранения общего назначения. В дальнейшем будет поддерживаться хранилище Azure класса Premium.
- Вы можете указать одну учетную запись хранения с несколькими большими двоичными объектами пользовательских VHD-файлов или несколькими учетными записями хранения, каждая из которых имеет один большой двоичный объект. Мы советуем использовать несколько учетных записей хранения, чтобы получить лучшую производительность.
- Один уникальный большой двоичный объект VHD пользовательского образа может поддерживать до 40 экземпляров виртуальных машин Linux или до 20 экземпляров виртуальных машин Windows. Необходимо будет создать копии большого двоичного объекта VHD для создания пулов с большим количеством виртуальных машин. Например, пулу с 200 виртуальными машинами Windows необходимо указать 10 уникальных больших двоичных объектов VHD для свойства **osDisk**.

Чтобы создать пул из пользовательского образа, используя портал Azure:

1. Войдите в свою учетную запись пакетной службы на портале Azure.
2. В колонке **Параметры** выберите пункт меню **Пулы**.
3. В колонке **Пулы** выберите команду **Добавить**, после чего отобразится колонка **Добавить пул**.
4. В раскрывающемся списке **Тип образа** выберите **Пользовательский образ (Linux или Windows)**. На портале отобразится средство выбора **пользовательского образа**. Выберите один или несколько VHD из одного контейнера и нажмите кнопку **Выбрать**. 
    Поддержка нескольких VHD из разных учетных записей хранения и других контейнеров будет добавлена в будущем.
5. Выберите правильные значения **издателя, предложения, SKU** для пользовательских VHD, выберите желаемый режим **кэширования**, а затем заполните все остальные параметры для пула.
6. Чтобы проверить, основан ли пул на пользовательском образе, найдите свойство **Операционная система** в разделе сводки по ресурсу колонки **Пул**. Это свойство должно иметь значение **Пользовательский образ виртуальной машины**.
7. Все пользовательские VHD, связанные с пулом, отображаются в колонке **Свойства** пула.

### <a name="compute-node-type-and-target-number-of-nodes"></a>Тип вычислительного узла и целевое количество узлов

При создании пула можно указать нужные типы вычислительных узлов, а также целевое количество узлов. Ниже приведены два типа вычислительных узлов.

- **Выделенные вычислительные узлы.** Выделенные вычислительные узлы зарезервированы для рабочих нагрузок. Они более затратные, чем низкоприоритетные узлы, но они никогда не замещаются.

- **Низкоприоритетные вычислительные узлы.** Низкоприоритетные узлы используют избыточные ресурсы в Azure для выполнения рабочих нагрузок пакетной службы. Они экономичнее (дешевле в час) по сравнению с выделенными узлами и выполняют рабочие нагрузки, требующие большого объема вычислительной мощности. Дополнительные сведения см. в статье [Использование низкоприоритетных виртуальных машин в пакетной службе (предварительная версия)](batch-low-pri-vms.md).

    При недостаточном количестве избыточных ресурсов в Azure низкоприоритетные вычислительные узлы замещаются. Если при выполнении задач узел замещается, задачи помещаются в очередь и перезапускаются, как только он снова станет доступным. Низкоприоритетные узлы — это оптимальный вариант для рабочих нагрузок, где время завершения задания гибкое, а работа распределяется по нескольким узлам. Прежде чем использовать низкоприоритетные узлы для своего сценария, убедитесь, что любые потери работы из-за замещения будут минимальны и легко воссоздаваемы.

    Они доступны только для учетных записей пакетной службы со значением **Пакетная служба** для режима выделения пула.

Низкоприоритетные и выделенные вычислительные узлы могут находиться в одном и том же пуле. Каждый тип узла &mdash; с низким приоритетом и выделенный &mdash; содержит свой собственный целевой объект, для которого можно указать необходимое количество узлов. 
    
Оно называется *целевым*, так как в некоторых случаях пул не может достигнуть требуемого числа узлов. Например, это может произойти из-за достижения [квоты на ядра](batch-quota-limit.md) для учетной записи пакетной службы или если примененная к пулу формула автоматического масштабирования ограничивает максимальное количество узлов.

Дополнительные сведения о ценах на низкоприоритетные и выделенные вычислительные узлы см. на странице [цен на пакетную службу](https://azure.microsoft.com/pricing/details/batch/).

### <a name="size-of-the-compute-nodes"></a>Размер вычислительных узлов

**конфигурация облачных служб**, приведены в статье [Размеры для облачных служб](../cloud-services/cloud-services-sizes-specs.md). Пакетная служба поддерживает все размеры облачных служб, кроме `ExtraSmall`, `STANDARD_A1_V2` и `STANDARD_A2_V2`.

Размеры вычислительных узлов, доступные в **конфигурации виртуальной машины**, перечислены в статьях [Размеры виртуальных машин в Azure](../virtual-machines/linux/sizes.md) для Linux и [Размеры виртуальных машин в Azure](../virtual-machines/windows/sizes.md) для Windows. Пакетная служба поддерживает все размеры виртуальных машин Azure, кроме `STANDARD_A0`. Для хранилища класса Premium также не поддерживаются размеры таких серий: `STANDARD_GS`, `STANDARD_DS` и `STANDARD_DSV2`.

При выборе размера вычислительного узла учтите характеристики и требования приложений, которые будут на нем выполняться. Чтобы выбрать правильный размер узла, что позволит снизить затраты, также следует учитывать такие аспекты, как многопоточность приложений и требуемый объем памяти. Обычно при выборе размера узла предполагается, что единовременно на нем будет выполняться одна задача. Вы можете настроить [параллельное выполнение](batch-parallel-node-tasks.md) нескольких задач (а значит и нескольких экземпляров приложения) на вычислительном узле во время выполнения задания. В таком случае обычно выбирается более крупный узел с учетом роста потребностей, связанных с выполнением параллельных задач. Дополнительные сведения см. в описании атрибута [Политика планирования задач](#task-scheduling-policy).

Все узлы в пуле имеют одинаковый размер. Если вы планируете выполнять приложения с разными требованиями к системе и/или с разной нагрузкой, рекомендуется использовать отдельные пулы.

### <a name="scaling-policy"></a>Политика масштабирования

Для динамических рабочих нагрузок можно написать и применить к пулу [формулу автоматического масштабирования](#scaling-compute-resources). По этой формуле пакетная служба периодически вычисляет и изменяет количество узлов в пуле в зависимости от выбранных вами параметров пула, заданий и задач.

### <a name="task-scheduling-policy"></a>Политика планирования задач

Параметр конфигурации [Максимальное число заданий на узел](batch-parallel-node-tasks.md) определяет максимальное число задач, которые могут параллельно выполняться на каждом вычислительном узле пула.

В конфигурации по умолчанию указывается выполнение только одной задачи на узле в любое время. Но в некоторых ситуациях выполнение нескольких задач на одном узле будет более правильным выбором. Сведения о преимуществах выполнения нескольких задач на узле см. в разделе [Пример сценария](batch-parallel-node-tasks.md#example-scenario) статьи [Повышение эффективности вычислительных ресурсов в пакетной службе Azure благодаря параллельному выполнению задач на узлах](batch-parallel-node-tasks.md).

Вы также можете выбрать *тип заполнения*. Пакетная служба может равномерно распределять задачи между всеми узлами в пуле или назначать каждому узлу максимально возможное число задач, прежде чем переходить к загрузке следующего узла пула.

### <a name="communication-status-for-compute-nodes"></a>Состояние взаимодействия между вычислительными узлами

В большинстве случаев задачи работают независимо друг от друга и взаимодействие между ними не требуется. Но в некоторых приложениях задачи должны взаимодействовать (например, при использовании [задач с несколькими экземплярами](batch-mpi.md)).

Вы можете разрешить **обмен данными между узлами**, входящими в один пул, для взаимодействия во время выполнения. При включении обмена данными между узлами узлы в пулах с конфигурацией облачных служб могут взаимодействовать друг с другом через порты с номерами выше 1100. При этом пулы с конфигурацией виртуальной машины не ограничивают трафик через какой-либо порт.

Обратите внимание, что включение обмена данными между узлами также влияет на размещение узлов в кластерах и из-за ограничений развертывания может ограничить максимальное количество узлов в пуле. Если приложению не требуется обмен данными между узлами, пакетная служба может выделить для пула большое количество узлов из разных кластеров и центров обработки данных. Это позволяет увеличить производительность параллельной обработки.

### <a name="start-tasks-for-compute-nodes"></a>Задачи запуска для вычислительных узлов

*Задача запуска* (необязательный параметр) будет выполняться на каждом узле при его присоединении к пулу, а также при каждом перезапуске или пересоздании образа узла. Она особенно полезна для подготовки вычислительных узлов к выполнению таких операций, как установка приложений, которые запускаются задачами на вычислительных узлах.

### <a name="application-packages"></a>Пакеты приложений

Вы можете указать [пакеты приложений](#application-packages) для развертывания на вычислительных узлах в пуле. Пакеты приложений обеспечивают упрощенное развертывание и управление версиями для приложений, запускаемых с помощью задач. Пакеты приложений, которые указываются для пула, устанавливаются на каждый вычислительный узел, который присоединяется к пулу, а также каждый раз, когда узел перезагружается или для него пересоздается образ.

> [!NOTE]
> Пакеты приложений поддерживаются во всех пулах пакетной службы, созданных после 5 июля 2017 г. Если пул создан с помощью конфигурации облачной службы, пакеты приложений также поддерживаются в пулах пакетной службы, созданных между 10 марта 2016 г. и 5 июля 2017 г. Пулы пакетной службы, созданные до 10 марта 2016 г., не поддерживают пакеты приложений. Дополнительные сведения о развертывании приложений на узлах пакетной службы с помощью пакетов приложений см .в [этой статье](batch-application-packages.md).
>
>

### <a name="network-configuration"></a>Конфигурация сети

Можно указать подсеть [виртуальной сети Azure](../virtual-network/virtual-networks-overview.md), в которой необходимо создать вычислительные узлы для пула. Более подробную информацию см. в разделе [Конфигурация сети пула](#pool-network-configuration).


## <a name="job"></a>задание
Задание представляет собой набор задач. Оно управляет порядком выполнения вычислений каждой задачей на вычислительных узлах в пуле.

* Задание указывает **пул**, в котором будет выполняться работа. Вы можете создавать отдельный пул для каждого задания или использовать один пул для множества заданий. Кроме того, вы можете создавать пул для каждого задания, включенного в расписание, или единый пул для всех заданий в одном расписании.
* Вы можете указать **приоритет задания**, но это необязательный параметр. Если вы создаете задание с более высоким приоритетом, его задачи добавляются в очередь перед задачами менее приоритетных заданий. Задачи с более низким приоритетом, которые уже выполняются, прерываться не будут.
* Вы можете задать некоторые **ограничения** для заданий.

    Например, **максимальное время выполнения**. Таким образом, если задание выполняется дольше этого времени, оно будет завершено вместе со всеми задачами.

    Пакетная служба может обнаруживать и повторно выполнять незавершенные задачи. В качестве ограничения можно указать **максимальное число повторных попыток задачи**, а также следует ли пытаться повторно выполнить задачу (*всегда* или *никогда*). Повторное выполнение задачи означает, что она повторно помещается в очередь и будет снова запущена.
* Задачи к заданию может добавлять клиентское приложение. Кроме того, можно настроить [задачу диспетчера заданий](#job-manager-task). Задача диспетчера заданий содержит всю информацию для создания необходимых задач в рамках задания. Эту задачу выполняет один из вычислительных узлов пула. Задача диспетчера заданий обрабатывается пакетной службой особым образом: она помещается в очередь сразу при создании задания и перезапускается, если происходит сбой. Задача диспетчера заданий *необходима* для заданий, создаваемых согласно [расписанию заданий](#scheduled-jobs), так как это единственный способ определить задачи перед созданием экземпляра задания.
* По умолчанию задания остаются в активном состоянии после выполнения всех задач в задании. Это поведение можно изменить, чтобы задание автоматически завершалось после выполнения всех входящих в него задач. Для этого следует присвоить свойству **onAllTasksComplete** ([OnAllTasksComplete][net_onalltaskscomplete] в .NET пакетной службы) значение *terminatejob*.

    Обратите внимание, что пакетная служба считает задание *без* задач заданием, все задачи которого выполнены. Поэтому этот параметр чаще всего используется с [задачами диспетчера заданий](#job-manager-task). Если вы хотите использовать автоматическое завершение заданий без диспетчера заданий, необходимо сначала присвоить свойству **onAllTasksComplete** нового задания значение *noaction*. Значение *terminatejob* следует присвоить этому свойству только после добавления задач в задание.

### <a name="job-priority"></a>приоритет задания
При создании задания в пакетной службе ему можно назначить приоритет. Пакетная служба использует значения приоритетов заданий, чтобы определять порядок выполнения разных заданий в одной учетной записи (не путайте с [запланированным заданием](#scheduled-jobs)). Приоритет может иметь значение в диапазоне от -1000 до 1000, где -1000 означает наименьший приоритет, а 1000 — наивысший. Вы можете изменить приоритет задания с помощью вызова операции [обновления свойств задания][rest_update_job] в REST для пакетной службы или изменив свойство [CloudJob.Priority][net_cloudjob_priority] в .NET для пакетной службы.

В рамках одной учетной записи задания с высоким приоритетом имеют преимущество при планировании относительно заданий с низким приоритетом. Задания с более высоким приоритетом, относящиеся к одной учетной записи, не имеют преимущества при планировании относительно других заданий с более низким приоритетом, относящихся к другой учетной записи.

Задания распределяются по пулам независимо друг от друга. Если используется несколько пулов, задание с более высоким приоритетом не обязательно будет выполняться первым. Задание задерживается, если в связанном с ним пуле недостаточно свободных узлов. Если задания выполняются в одном пуле и имеют одинаковый приоритет, они имеют равные шансы на распределение.

### <a name="scheduled-jobs"></a>Запланированные задания
[Расписания заданий][rest_job_schedules] позволяют создавать в пакетной службе повторяющиеся задания. Расписание заданий определяет время запуска заданий и параметры для запуска этих заданий. Вы можете указать период действия задания, то есть с какого момента и в течение какого времени служба будет применять это расписание, а также частоту выполнения периодических заданий в этот период.

## <a name="task"></a>Задача
Задача представляет собой единицу вычисления, которая связана с заданием и выполняется на узле. Задачи назначаются узлу для выполнения или ставятся в очередь, пока не освободится какой-либо узел. Говоря простыми словами, задача запускает одну или несколько программ или сценариев на вычислительном узле, чтобы выполнить необходимую работу.

При создании задачи можно указать следующее:

* **Командная строка** задачи. Это командная строка, которая запускает приложение или сценарий на вычислительном узле.

    Следует отметить, что командная строка не выполняется на базе оболочки и поэтому не может автоматически использовать функции оболочки, например расширение [переменных среды](#environment-settings-for-tasks) (в том числе `PATH`). Чтобы воспользоваться этими функциями, необходимо вызвать оболочку в командной строке. Это можно сделать путем запуска `cmd.exe` на узлах Windows или `/bin/sh` на узлах Linux:

    `cmd /c MyTaskApplication.exe %MY_ENV_VAR%`

    `/bin/sh -c MyTaskApplication $MY_ENV_VAR`

    Если требуется, чтобы задачи выполняли приложение или скрипт без использования переменной `PATH` или переменных среды узла, на которые содержится ссылка, необходимо явным образом вызвать оболочку в командной строке задачи.
* **Файлы ресурсов**, которые содержат данные для обработки. Эти файлы автоматически копируются на узел из хранилища BLOB-объектов в учетной записи службы хранилища Azure общего назначения перед выполнением командной строки задачи. Дополнительные сведения см. в разделах [Задача запуска](#start-task) и [Файлы и каталоги](#files-and-directories).
* **Переменные среды**, необходимые для приложения. Дополнительные сведения см. в разделе [Параметры среды для задач](#environment-settings-for-tasks).
* **Ограничения**, в рамках которых должна выполняться задача. Например, может быть задано максимальное время на выполнение задачи, максимальное количество повторных попыток выполнить задачу, завершенную сбоем, и максимальное время хранения файлов в рабочем каталоге задачи.
* **Пакеты приложений** для развертывания на вычислительном узле, на котором запланировано выполнение задачи. [Пакеты приложений](#application-packages) обеспечивают упрощенное развертывание и управление версиями для приложений, запускаемых с помощью задач. Пакеты приложений уровня задач особенно полезны в средах с общим пулом, где различные задания выполняются в одном пуле, который не удаляется по завершении задания. Если задание содержит меньше задач, чем число узлов в пуле, пакеты приложений задач помогут минимизировать объем передаваемых данных, так как приложение развертывается только на узлах, на которых выполняются задачи.

Помимо задач, которые можно определить для вычислений на узле, пакетная служба выполняет следующие специальные задачи.

* [Задача запуска](#start-task)
* [Задача диспетчера заданий](#job-manager-task)
* [Задачи подготовки и завершения заданий.](#job-preparation-and-release-tasks)
* [Задачи с несколькими экземплярами](#multi-instance-tasks)
* [Зависимости задачи](#task-dependencies)

### <a name="start-task"></a>Задача запуска
Связав **задачу запуска** с пулом, можно подготовить среду выполнения на его узлах. Например, эта задача может выполнять установку приложений, которые будут использовать задачи, или запуск фоновых процессов. Задача запуска выполняется при каждом запуске узла, пока узел остается в пуле, в том числе при первом добавлении узла к пулу и при перезапуске или пересоздании образа узла.

Задача запуска особенно полезна тем, что она может содержать все сведения для настройки вычислительных узлов и установки приложений, которые нужны для выполнения задач. Таким образом, для увеличения числа узлов в пуле достаточно указать новое количество узлов. Задача запуска предоставляет пакетной службе сведения, необходимые для настройки новых узлов и подготовки их к выполнению задач.

Для этой задачи, как для любой задачи пакетной службы Azure, кроме исполняемой **командной строки**, можно указать список **файлов ресурсов**, которые хранятся в [службе хранилища Azure][azure_storage]. Пакетная служба сначала скопирует эти файлы на узел из службы хранилища Azure, а затем запустит командную строку. Список файлов для задачи запуска пула обычно содержит приложение задач или его зависимости.

В задаче запуска также могут содержаться справочные данные, которые будут использоваться всеми задачами, выполняемыми на вычислительном узле. Например, командная строка задачи запуска может выполнять операцию `robocopy`, чтобы скопировать файлы приложения (указанные в качестве файлов ресурсов и скачанные на узел) из [рабочего каталога](#files-and-directories) задачи запуска в [общую папку](#files-and-directories), а затем запустить MSI-файл или `setup.exe`.

Обычно желательно, чтобы пакетная служба дождалась завершения задачи запуска, прежде чем считать узел готовым к назначению задач, но это поведение можно изменить.

Если задача запуска на узле пула завершится сбоем, этот сбой отобразится в параметре состояния узла. При этом узлу не будут назначаться задачи. Задача запуска может завершиться сбоем, если не удастся скопировать файлы ресурсов из хранилища или если процесс, запущенный командной строкой задачи запуска, вернет ненулевой код завершения.

При добавлении или обновлении задачи запуска для существующего пула необходимо перезапустить его вычислительные узлы, чтобы применить к ним задачу запуска.

>[!NOTE]
> Общий размер задачи запуска не должен превышать 32 768 символов, включая файлы ресурсов и переменные среды. Чтобы убедиться, что ваша задача запуска соответствует этим требованиям, используйте один из двух следующих методов.
>
> 1. Можно применить пакеты для распределения приложений или данных в каждом узле пула пакетной службы. Дополнительные сведения о пакетах приложений см. в статье [Развертывание приложений на вычислительных узлах с помощью пакетов приложений пакетной службы](batch-application-packages.md).
> 2. Можно вручную создать ZIP-архив с файлами приложения. Отправьте ZIP-архив в службу хранилища Azure как большой двоичный объект. Укажите ZIP-архив в качестве файла ресурсов для задачи запуска. Перед использованием командной строки для задачи запуска распакуйте архив из командной строки. 
>
>    Для распаковки архива можно использовать средство архивации по своему усмотрению. Средство, которое использовалось для распаковки архива, необходимо указать как файл ресурсов для задачи запуска.
>
>

### <a name="job-manager-task"></a>Задача диспетчера заданий
**Задача диспетчера заданий** обычно используется для управления заданием и/или отслеживания его выполнения. Например, она создает и отправляет задачи для задания, определяет дополнительные задачи, которые нужно выполнить, и фиксирует завершение задания. Но задача диспетчера заданий не ограничивается такими действиями. Это полнофункциональная задача, которая может выполнять любые действия, требуемые в рамках задания. Например, задача диспетчера заданий может скачать файл, указанный в качестве параметра, проанализировать содержимое этого файла и в зависимости от содержимого отправить на выполнение дополнительные задачи.

Задача диспетчера заданий запускается перед выполнением всех других задач. Она предоставляет следующие возможности.

* Пакетная служба автоматически создает эту задачу при создании задания.
* Эта задача выполняется раньше любых других задач в задании.
* Узел, на котором выполняется задача, удаляется из пула последним при уменьшении размера пула.
* Такое завершение задачи может привести к завершению всех задач данного задания.
* При перезапуске задача диспетчера заданий получает наивысший приоритет. При этом, если нет свободных узлов, пакетная служба может освободить ресурсы для этой задачи, прервав выполнение одной из других задач, запущенных в пуле.
* Задача диспетчера заданий не имеет приоритета над задачами других заданий. Приоритеты между заданиями определяются только на уровне заданий.

### <a name="job-preparation-and-release-tasks"></a>Задачи подготовки и завершения заданий.
Для настройки среды выполнения задания в пакетной службе предусмотрена задача подготовки задания, а для очистки или обслуживания по окончании задания — задача завершения задания.

* **Задача подготовки задания**. Эта задача выполняется на всех вычислительных узлах, на которых запланировано выполнение задач, до выполнения какой-либо другой задачи задания. Например, вы можете применить задачу подготовки задания для копирования данных, которые используются всеми задачами, но только в рамках одного задания.
* **Задача завершения задания**. Когда задание завершается, эта задача выполняется на каждом узле в пуле, на котором была выполнена хотя бы одна задача. Задачу завершения задания можно использовать для удаления данных, скопированных задачей подготовки задания, или для сжатия и передачи диагностических данных журналов.

Задачи подготовки и завершения задания позволяют указать командную строку, которая будет выполняться при вызове задачи. Они предоставляют такие возможности, как загрузка файлов, выполнение с повышенными правами, пользовательские переменные среды, максимальная продолжительность выполнения, число повторных попыток и время хранения файла.

Дополнительные сведения о задачах подготовки и завершения заданий см. в статье [Выполнение задач подготовки и завершения заданий на вычислительных узлах пакетной службы Azure](batch-job-prep-release.md).

### <a name="multi-instance-task"></a>Задачи с несколькими экземплярами
[Задача с несколькими экземплярами](batch-mpi.md) — это задача, которая может выполняться на нескольких вычислительных узлах одновременно. С помощью задач с несколькими экземплярами можно включать высокопроизводительные вычислительные сценарии (такие как интерфейс передачи сообщений (MPI)), которым необходимо несколько совместно выделенных вычислительных узлов для обработки одной рабочей нагрузки.

Дополнительные сведения о выполнении заданий задач с несколькими экземплярами в пакетной службе с использованием библиотеки .NET для пакетной службы см. в статье [Использование задач с несколькими экземплярами для запуска приложений с интерфейсом передачи сообщений в пакетной службе Azure](batch-mpi.md).

### <a name="task-dependencies"></a>Зависимости задачи
[Зависимости задач](batch-task-dependencies.md), как можно понять из названия, позволяют настроить выполнение задачи в зависимости от предварительного завершения других задач. Эта функция обеспечивает поддержку в ситуациях, когда "подчиненная" задача использует выходные данные "вышестоящей" задачи или когда вышестоящая задача выполняет инициализацию, необходимую для подчиненных задач. Чтобы использовать эту функцию, необходимо сначала включить зависимости задач для задания пакетной службы. Затем для каждой задачи, зависящей от другой (или нескольких других), укажите задачи, от которых она зависит.

С помощью зависимостей задач можно настраивать различные сценарии, например:

* Задача *taskB* зависит от задачи *taskA* (выполнение задачи *taskB* не начнется, пока не завершится выполнение задачи *taskA*).
* Задача *taskC* зависит от задач *taskA* и *taskB*.
* Задача *taskD* зависит от ряда задач — от задачи *1* до задачи *10*.

Дополнительные сведения об этой возможности см. в статье [Зависимости задач в пакетной службе Azure](batch-task-dependencies.md) и в примере кода [TaskDependencies][github_sample_taskdeps] в репозитории [azure-batch-samples][github_samples] на сайте GitHub.

## <a name="environment-settings-for-tasks"></a>Параметры среды для задач
Каждая задача, выполняемая пакетной службой, имеет доступ к переменным среды, заданным на вычислительных узлах. Сюда входят переменные среды, определенные пакетной службой ([служебные][msdn_env_vars]), и пользовательские переменные среды, которые вы можете определить для задач. Приложения и скрипты, выполняемые с помощью задач, получают доступ к переменным среды во время выполнения.

Пользовательские переменные среды можно задать на уровне задачи или задания, задав свойство *параметров среды* для этих объектов. Для примера см. раздел об операции [добавления задачи к заданию][rest_add_task] (в REST API пакетной службы) или о свойствах [CloudTask.EnvironmentSettings][net_cloudtask_env] и [CloudJob.CommonEnvironmentSettings][net_job_env] в .NET для пакетной службы.

Чтобы получить значения служебных и пользовательских переменных среды задачи для клиентского приложения или службы, можно использовать операцию [получения сведений о задаче][rest_get_task_info] в REST для пакетной службы или свойство [CloudTask.EnvironmentSettings][net_cloudtask_env] в .NET для пакетной службы. Процессы, которые выполняются на вычислительном узле, могут обращаться к этим и другим переменным среды узла, например с помощью привычного синтаксиса `%VARIABLE_NAME%` в Windows или `$VARIABLE_NAME` в Linux.

Полный список всех служебных переменных среды см. в статье [Azure Batch compute node environment variables][msdn_env_vars] (Переменные среды вычислительного узла пакетной службы Azure).

## <a name="files-and-directories"></a>Файлы и каталоги
У каждой задачи есть *рабочий каталог*, в котором она может создавать дополнительные файлы и каталоги. Он может использоваться для хранения выполняемой программы, обрабатываемых данных и результатов обработки. Все файлы и каталоги задачи принадлежат пользователю задачи.

Пакетная служба предоставляет часть файловой системы на узле в качестве *корневого каталога*. Задачи могут обратиться к корневому каталогу с помощью ссылки на переменную среды `AZ_BATCH_NODE_ROOT_DIR`. Дополнительные сведения об использовании переменных среды см. в разделе [Параметры среды для задач](#environment-settings-for-tasks).

Корневой каталог имеет следующую структуру каталогов.

![Структура каталогов вычислительного узла][1]

* **shared**— в этом каталоге *все* задачи, выполняемые на узле, имеют права чтения и записи. Любая задача, выполняемая на узле, может создавать, читать, обновлять и удалять файлы в этом каталоге. Задачи могут получить доступ к этому каталогу с помощью ссылки на переменную среды `AZ_BATCH_NODE_SHARED_DIR` .
* **startup**— этот каталог используется задачей запуска в качестве рабочего каталога. Здесь хранятся все файлы, скачанные на узел с помощью задачи запуска. Задача запуска может создавать, читать, обновлять и удалять файлы в данном каталоге. Задачи могут получить доступ к этому каталогу с помощью ссылки на переменную среды `AZ_BATCH_NODE_STARTUP_DIR` .
* **Tasks**— такой каталог создается отдельно для каждой задачи, которая выполняется на узле. К нему можно получить доступ с помощью ссылки на переменную среды `AZ_BATCH_TASK_DIR` .

    В каждом каталоге задачи пакетная служба создает рабочий каталог (`wd`), который имеет уникальный путь, указанный в переменной среды `AZ_BATCH_TASK_WORKING_DIR`. Этот каталог предоставляет задаче доступ на чтение и запись. Задача может создавать, читать, обновлять и удалять файлы в данном каталоге. Время существования каталога определяется указанным для задачи ограничением *RetentionTime* .

    `stdout.txt` и `stderr.txt` — эти файлы сохраняются в папку задачи во время ее выполнения.

> [!IMPORTANT]
> При удалении узла из пула *все* файлы, хранящиеся на этом узле, удаляются.
>
>

## <a name="application-packages"></a>Пакеты приложений
[Пакеты приложений](batch-application-packages.md) упрощают управление приложениями и их развертывание на вычислительных узлах в пулах. Вы можете отправлять несколько версий приложений, выполняемых задачами, включая двоичные файлы и файлы поддержки (а также управлять этими версиями), а затем автоматически развертывать одно или несколько таких приложений на вычислительных узлах в пуле.

Пакеты приложений можно указывать на уровне пула и задачи. Если пакеты приложений определены на уровне пула, приложение развертывается на всех узлах в пуле. Если пакеты приложений определены на уровне задачи, приложение развертывается только на узлах, на которых запланировано выполнение хотя бы одной задачи задания, перед запуском командной строки задачи.

Пакетная служба обрабатывает сведения о работе со службой хранилища Azure, обеспечивая хранение пакетов приложений и их развертывание на вычислительных узлах. При этом упрощается код и сокращаются издержки, связанные с управлением.

Дополнительные сведения об использовании пакетов приложений см. в статье [Развертывание приложений на вычислительных узлах с помощью пакетов приложений пакетной службы](batch-application-packages.md).

> [!NOTE]
> При добавлении пакетов приложений пула в *существующий* пул необходимо перезагрузить его вычислительные узлы, чтобы обеспечить развертывание пакетов приложений на узлах.
>
>

## <a name="pool-and-compute-node-lifetime"></a>Время существования пула и вычислительного узла
При проектировании решения на базе пакетной службы Azure следует принять решение о том, когда и как будут создаваться пулы и как долго будут доступны вычислительные узлы в этих пулах.

Одной из крайностей является создание отдельного пула для каждого отправляемого задания и его удаление сразу по завершении выполнения задач. Такой вариант позволит максимально эффективно использовать ресурсы, так как узлы выделяются в необходимом количестве и завершают работу, как только переходят в состояние простоя. Но при этом задание должно ожидать выделения узлов. Важно отметить, что планирование задач для выполнения происходит по мере доступности и выделения каждого отдельного узла сразу после выполнения на нем задачи запуска. Иными словами, пакетная служба *не* дожидается, пока все узлы в пуле станут доступными, чтобы назначить задачи узлам. Это позволяет обеспечить максимально эффективное использование ресурсов.

Другим крайним вариантом является заблаговременное создание пула и подготовка его узлов до запуска заданий. Этот вариант применим для тех ситуаций, когда немедленный запуск задания имеет наивысший приоритет. В этом случае задачи будут запускаться немедленно, но при этом узлы могут некоторое время простаивать в ожидании назначения задач.

Смешанный подход обычно используется для обработки постоянной нагрузки, интенсивность которой изменяется. В этом случае создается пул для нескольких заданий, количество узлов в котором изменяется в зависимости от текущей нагрузки (см. раздел [Масштабирование вычислительных ресурсов](#scaling-compute-resources) ниже). Масштабирование можно выполнять по мере изменения интенсивности нагрузки или с упреждением, если нагрузка является прогнозируемой.

## <a name="virtual-network-vnet-and-firewall-configuration"></a>Конфигурация виртуальной сети и брандмауэра 

При подготовке пула вычислительных узлов в пакетной службе Azure можно связать его с подсетью [виртуальной сети Azure](../virtual-network/virtual-networks-overview.md). Дополнительные сведения о создании виртуальной сети с подсетями см. в статье [Создание виртуальной сети с несколькими подсетями](../virtual-network/virtual-networks-create-vnet-arm-pportal.md). 

 * Виртуальная сеть, связанная с пулом, должна:

   * Находиться в том же **регионе Azure**, что и учетная запись пакетной службы Azure.
   * Относиться к той же **подписке**, что и учетная запись пакетной службы Azure.

* Тип поддерживаемой виртуальной сети зависит от способа распределения пулов в учетной записи пакетной службы.

    - Если для учетной записи пакетной службы выбран режим распределения пула "Пакетная служба", то виртуальную сеть можно назначить только пулам, созданным с **конфигурацией облачной службы**. Кроме того, указанная виртуальная сеть должна быть создана по классической модели развертывания. Виртуальные сети, созданные по модели развертывания с помощью Azure Resource Manager, не поддерживаются.
 
    - Если для учетной записи пакетной службы выбран режим распределения пула "Пользовательская подписка", то виртуальную сеть можно назначить только пулам, созданным с **конфигурацией виртуальной сети**. Пулы, созданные с **конфигурацией облачной службы**, не поддерживаются. Связанная виртуальная сеть может быть создана как по классической модели развертывания, так и по модели развертывания с помощью Azure Resource Manager.

    Таблицу со сведениями о поддерживаемых виртуальных сетях в зависимости от режима распределения пула см. в разделе [Режим распределения пула](#pool-allocation-mode).

* Если для учетной записи пакетной службы выбран режим распределения пула "Пакетная служба", субъекту-службе пакетной службы необходимо предоставить разрешения для доступа к виртуальной сети. Субъекту-службе пакетной службы должна быть назначена роль [участника классической виртуальной машины](https://azure.microsoft.com/documentation/articles/role-based-access-built-in-roles/#classic-virtual-machine-contributor) для виртуальной сети в системе управления доступом на основе ролей (RBAC). Если такая роль RBAC не назначена, пакетная служба возвращает ошибку 400 (неправильный запрос). Чтобы добавить роль на портале Azure, сделайте следующее.

    1. Выберите **виртуальную сеть** и последовательно щелкните **Управление доступом (IAM)** > **Роли** > **Участник виртуальных машин** > **Добавить**.
    2. В колонке **Добавление разрешений** выберите роль **Участник виртуальных машин**.
    3. В колонке **Добавление разрешений** выполните поиск API пакетной службы. Продолжайте поиск по каждой из этих строк поочередно, пока не найдете API:
        1. **MicrosoftAzureBatch**;
        2. **Microsoft Azure Batch**. Более новые клиенты Azure AD могут использовать это имя.
        3. **ddbf3205-c6bd-46ae-8127-60eb93363864** — это идентификатор API пакетной службы. 
    3. Выберите субъект-службу для API пакетной службы. 
    4. Щелкните **Сохранить**.

        ![Назначение субъекту-службе пакетной службы роли участника виртуальных машин](./media/batch-api-basics/iam-add-role.png)


* В указанной подсети должно быть достаточно свободных **IP-адресов**, чтобы разместить общее число целевых узлов, которое представляет собой сумму свойств `targetDedicatedNodes` и `targetLowPriorityNodes` пула. Если в подсети недостаточно свободных IP-адресов, пакетная служба частично выделяет вычислительные узлы пула и возвращает ошибку изменения размера.

* Чтобы на вычислительных узлах можно было назначать задачи, указанная подсеть должна разрешать подключения из пакетной службы. Если **группа безопасности сети (NSG)**, связанная с этой виртуальной сетью, запрещает взаимодействие с вычислительными узлами, пакетная служба установит для вычислительных узлов состояние **Непригоден**.

* Если в указанной виртуальной сети есть связанные **группы безопасности сети (NSG)** и (или) **брандмауэр**, необходимо включить несколько зарезервированных системных портов для входящего трафика:

- Для пулов, созданных с помощью конфигурации виртуальной машины, включите порты 29876 и 29877, а также порт 22 для Linux и порт 3389 для Windows. 
- Для пулов, созданных с помощью конфигурации облачной службы, включите порты 10100, 20100 и 30100. 
- Включите исходящие подключения к службе хранилища Azure через порт 443. Также убедитесь, что конечная точка службы хранилища Azure может разрешаться на всех пользовательских DNS-серверах, используемых в виртуальной сети. В частности, URL-адрес в формате `<account>.table.core.windows.net` должен быть разрешаемым.

    В таблице ниже описаны входящие порты, которые необходимо включить для пулов, созданных с помощью конфигурации виртуальной машины.

    |    Конечные порты    |    Исходный IP-адрес      |    Добавляет ли пакетная служба группы NSG?    |    Требуется для использования виртуальной машины?    |    Действие пользователя   |
    |---------------------------|---------------------------|----------------------------|-------------------------------------|-----------------------|
    |    <ul><li>Для пулов, созданных с помощью конфигурации виртуальной машины: 29876, 29877</li><li>Для пулов, созданных с помощью конфигурации облачной службы: 10100, 20100, 30100</li></ul>         |    Только IP-адреса для ролей пакетной службы |    Да. Пакетная служба добавляет группы NSG на уровне сетевых интерфейсов (NIC), подключенных к виртуальным машинам. Группы NSG пропускают трафик только с IP-адресов для ролей пакетной службы. Даже если открыть эти порты для всего Интернета, трафик будет блокироваться в сетевом интерфейсе. |    Да  |  Указывать NSG не требуется, так как пакетная служба пропускает только трафик с IP-адресов пакетной службы. <br /><br /> Если вы все же укажете NSG, убедитесь, что эти порты открыты для входящего трафика. <br /><br /> При указании * в качестве исходного IP-адреса в группе NSG пакетная служба по-прежнему добавляет группы NSG на уровне сетевого интерфейса, подключенного к виртуальным машинам. |
    |    3389, 22               |    Компьютеры пользователя, используемые для отладки и удаленного доступа к виртуальной машине.    |    Нет                                    |    Нет                     |    Добавьте группы NSG, чтобы разрешить удаленный доступ (по протоколу RDP или SSH) к виртуальной машине.   |                 

    В таблице ниже описан исходящий порт, который необходимо включить, чтобы разрешить доступ к службе хранилища Azure.

    |    Исходящие порты    |    Место назначения    |    Добавляет ли пакетная служба группы NSG?    |    Требуется для использования виртуальной машины?    |    Действие пользователя    |
    |------------------------|-------------------|----------------------------|-------------------------------------|------------------------|
    |    443    |    Хранилище Azure    |    Нет    |    Да    |    При добавлении групп NSG убедитесь, что этот порт открыт для исходящего трафика.    |


## <a name="scaling-compute-resources"></a>Масштабирование вычислительных ресурсов
[Автоматическое масштабирование](batch-automatic-scaling.md)позволяет использовать пакетную службу для динамической настройки количества вычислительных узлов в пуле в соответствии с текущей рабочей нагрузкой и использованием ресурсов в рамках вашего сценария вычислений. Это позволит снизить общую стоимость работы приложения за счет использования только необходимых ресурсов и освобождения остальных.

Чтобы включить автоматическое масштабирование, необходимо написать [соответствующую формулу](batch-automatic-scaling.md#automatic-scaling-formulas) и связать ее с пулом. Пакетная служба использует эту формулу для определения целевого количества узлов в пуле для следующего интервала масштабирования (интервал, который можно настроить). Вы можете указать параметры автоматического масштабирования для пула при его создании или включить масштабирование позже. Вы также можете обновить параметры масштабирования в пуле с включенным масштабированием.

Рассмотрим для примера задание, которое требует отправки большого количества задач для выполнения. Вы можете назначить для пула формулу масштабирования, которая изменяет количество узлов пула в зависимости от текущего числа задач в очереди и скорости выполнения этих задач, входящих в задание. Пакетная служба периодически вычисляет формулу и изменяет размер пула в зависимости от рабочей нагрузки и других параметров формулы. По мере необходимости служба добавляет узлы, если в очереди стоит большое количество задач, и удаляет узлы при отсутствии задач в очереди или выполняемых задач.

Формула масштабирования может использовать следующие метрики.

* **Метрики времени** — основываются на статистических данных, которые собираются каждые 5 минут за указанное число часов.
* **Метрики ресурсов** — зависят от показателей загрузки ЦП, использования пропускной способности и памяти, а также количества узлов.
* **Метрики задач** зависят от состояния задачи: *Активная* (в очереди), *Выполняется* или *Завершена*.

Если при автоматическом масштабировании уменьшается количество вычислительных узлов в пуле, необходимо учитывать способ обработки текущих выполняемых задач. Чтобы решить эту проблему, пакетная служба предоставляет *параметр отмены выделения узла*, который можно добавить в формулу. Например, можно указать, чтобы выполняемые задачи сразу останавливались, останавливались, а затем помещались в очередь на выполнение на другом узле или завершались до удаления узла из пула.

Подробные сведения об автоматическом масштабировании приложения см. в статье [Автоматическое масштабирование вычислительных узлов в пуле пакетной службы Azure](batch-automatic-scaling.md).

> [!TIP]
> Для максимально эффективного использования ресурсов укажите значение "ноль" для целевого количества узлов на момент завершения задания, но позвольте текущим задачам завершиться нормально.
>
>

## <a name="security-with-certificates"></a>Безопасность с использованием сертификатов
Обычно сертификаты нужны для шифрования и расшифровки конфиденциальных сведений, используемых задачами, например ключей [учетной записи службы хранилища Azure][azure_storage]. Такие сертификаты можно установить на узлах. Зашифрованные данные передаются задачам через параметры командной строки или через ресурсы задачи, а установленные сертификаты позволяют расшифровать их.

Для добавления сертификата к учетной записи пакетной службы используйте операцию [добавления сертификата][rest_add_cert] в REST API пакетной службы или метод [CertificateOperations.CreateCertificate][net_create_cert] в .NET для пакетной службы. Затем можно будет связать сертификат с новым или существующим пулом. Если к пулу привязан сертификат, пакетная служба устанавливает этот сертификат на каждом узле пула. Пакетная служба устанавливает нужные сертификаты при запуске узла до начала выполнения каких-либо задач (в том числе задач запуска и задач диспетчера заданий).

При добавлении сертификатов в *существующий* пул необходимо перезагрузить его вычислительные узлы, чтобы применить к ним сертификаты.

## <a name="error-handling"></a>Обработка ошибок
Возможно, вы захотите обрабатывать ошибки задач и приложений в своем решении пакетной службы.

### <a name="task-failure-handling"></a>Обработка сбоев задач
Сбои задач делятся на следующие категории.

* **Ошибки предварительной обработки**

    Если не удается запустить задачу, для нее устанавливается ошибка предварительной обработки.  

    Ошибки предварительной обработки могут возникать, если файлы ресурсов задачи перемещены, учетная запись хранения недоступна или не удалось выполнить копирование файлов на узел из-за другой проблемы.

* **Ошибки передачи файлов**

    Если по какой-либо причине происходит сбой передачи файлов, указанных для задачи, для нее устанавливается ошибка передачи файлов.

    Ошибки передачи файлов могут возникать, если подписанный URL-адрес, указанный для доступа к службе хранилища Azure, недействителен или не предоставляет разрешения на запись, учетная запись хранения недоступна либо произошла другая ошибка, которая не позволяет скопировать файлы с узла.    

* **Ошибки приложений**

    Процесс, указанный в командной строке задачи, также может завершиться ошибкой. Если процесс, который выполняет задача, возвращает ненулевой код завершения, считается, что такой процесс завершился ошибкой (см. подраздел *Код завершения задач* в следующем разделе).

    Вы можете настроить пакетную службу так, чтобы в случае ошибки приложения она автоматически повторяла задачу, а также указать максимальное количество таких попыток.

* **Ошибки ограничения**

    Вы можете установить ограничение на максимальное время выполнения задания или задачи с помощью параметра *maxWallClockTime*. Это полезно для завершения задач, переставших отвечать на запросы.

    Если превышено максимальное время выполнения, задача отмечается как *завершенная*, но с кодом выхода `0xC000013A`. При этом поле *schedulingError* будет иметь значение `{ category:"ServerError", code="TaskEnded"}`.

### <a name="debugging-application-failures"></a>Отладка ошибок приложений
* `stderr` и `stdout`

    Во время выполнения приложение может создавать диагностические данные, которые помогут устранить неполадки. Как упоминалось выше в разделе [Файлы и каталоги](#files-and-directories), пакетная служба записывает стандартные потоки вывода и ошибок в файлы `stdout.txt` и `stderr.txt`, расположенные в каталоге задач на вычислительном узле. Чтобы получить эти файлы, можно использовать портал Azure или один из пакетов SDK пакетной службы. Например, вы можете получить эти и другие файлы для устранения неполадок, используя методы [ComputeNode.GetNodeFile][net_getfile_node] и [CloudTask.GetNodeFile][net_getfile_task] библиотеки .NET для пакетной службы.

* **Код завершения задач**

    Как упоминалось выше, пакетная служба помечает задачу как завершившуюся сбоем, если процесс, выполняемый задачей, возвращает ненулевой код завершения. Когда задача выполняет процесс, пакетная служба заполняет свойство кода завершения задачи *кодом возврата процесса*. Следует отметить, что код завершения задачи определяется **не** пакетной службой. Код завершения задачи определяется самим процессом или операционной системой, в которой он выполняется.

### <a name="accounting-for-task-failures-or-interruptions"></a>Работа со сбоями и прерываниями задач
Задачи могут иногда завершаться ошибками или прерываться. Например, может завершиться ошибкой приложение задачи или узел, на котором выполняется задача, может быть перезапущен. Кроме того, узел может быть удален из пула при изменении размера, если установленная политика отмены выделения предусматривает немедленное удаление узла без ожидания завершения задачи. Во всех случаях пакетная служба может автоматически поставить задачу в очередь на повторное выполнение на другом узле.

Задача может также зависнуть или выполняться слишком долго из-за кратковременного сбоя. Для задачи можно установить максимальный интервал выполнения. В случае его превышения пакетная служба прерывает выполнение приложения задачи.

### <a name="connecting-to-compute-nodes"></a>Подключение к вычислительным узлам
Дополнительные возможности для отладки и устранения неполадок можно получить, выполнив вход на вычислительный узел удаленно. Вы можете использовать портал Azure, чтобы скачать RDP-файл для узлов Windows и получить сведения о подключении SSH для узлов Linux. Это также можно сделать с помощью API пакетной службы (например, в экземплярах [Batch .NET][net_rdpfile] или [Batch Python](batch-linux-nodes.md#connect-to-linux-nodes-using-ssh)).

> [!IMPORTANT]
> Чтобы подключиться к узлу по протоколу RDP или SSH, на узле нужно создать пользователя. Для этого можно использовать портал Azure, [добавить учетную запись пользователя на узел][rest_create_user] с помощью REST API пакетной службы, вызвать метод [ComputeNode.CreateComputeNodeUser][net_create_user] в .NET API пакетной службы или метод [add_user][py_add_user] в модуле Python пакетной службы.
>
>

### <a name="troubleshooting-problematic-compute-nodes"></a>Устранение неполадок проблемных вычислительных узлов
В ситуациях, когда при выполнении некоторых задач происходит сбой, пакетное клиентское приложение или служба может проверить метаданные неудачных задач для определения узла, который плохо работает. Каждому узлу в пуле присваивается уникальный идентификатор, а сведения об узле, на котором выполняется задача, включены в метаданные задачи. Определив проблемный узел, вы можете предпринять некоторые действия:

* **Перезапустить узел** ([REST][rest_reboot] | [.NET][net_reboot])

    В некоторых случаях перезапуск узла может устранить некоторые скрытые проблемы, например задержки и сбои при выполнении процессов. Обратите внимание, что если пул использует начальную задачу или задание использует задачу подготовки задания, они будут выполнены при перезапуске узла.
* **Пересоздать образ узла** ([REST][rest_reimage] | [.NET][net_reimage])

    Это обеспечит переустановку операционной системы на узле. Как и в случае перезагрузки узла, задачи запуска и задачи подготовки заданий будут повторно выполнены после повторного создания образа узла.
* **Удалить узел из пула** ([REST][rest_remove] | [.NET][net_remove])

    Иногда бывает необходимо полностью удалить узел из пула.
* **Отключить планирование задач на узле** ([REST][rest_offline] | [.NET][net_offline])

    Это эффективно переключит узел в "автономный режим", чтобы ему не назначались дальнейшие задачи, но сохранялась возможность продолжать выполнять текущие задачи, оставаясь в пуле. Благодаря этому вы сможете продолжить поиск причины сбоев без потери данных невыполненной задачи и без сбоев при выполнении дополнительных задач на узле. Например, можно отключить планирование задач на узле, а затем выполнить [удаленный вход](#connecting-to-compute-nodes) на узел для анализа журналов событий или устранения других неполадок. Проанализировав проблемы, вы сможете снова подключить узел к сети, включив планирование задач ([REST][rest_online] | [.NET][net_online]) или выполнив одно из перечисленных выше действий.

> [!IMPORTANT]
> С помощью каждого действия, перечисленного в этом разделе, (перезагрузки, пересоздания образа, удаления, отключения планирования задач) вы можете указать вариант обработки текущих задач на узле при выполнении действия. Например, при отключении планирования задач на узле с помощью клиентской библиотеки .NET для пакетной службы вы можете указать значение перечисления [DisableComputeNodeSchedulingOption][net_offline_option], чтобы определить, что нужно сделать до выполнения действия (**TaskCompletion**): **прекратить** выполнение текущих задач, **повторно поставить их в очередь** для планирования выполнения на других узлах или разрешить завершение текущих задач.
>
>

## <a name="next-steps"></a>Дальнейшие действия
* См. дополнительные сведения об [API-интерфейсах и средствах пакетной службы](batch-apis-tools.md) для сборки решений пакетной службы.
* Ознакомьтесь с пошаговой инструкцией по созданию примера приложения пакетной службы в статье [Начало работы с библиотекой пакетной службы Azure для .NET](batch-dotnet-get-started.md). Существует также [версия Python](batch-python-tutorial.md) этого руководства. В ней рассматривается выполнение рабочих нагрузок на вычислительных узлах Linux.
* Скачайте и соберите пример проекта [обозревателя пакетной службы][github_batchexplorer], который вы сможете использовать при разработке собственных решений пакетной службы. С помощью обозревателя пакетной службы вы можете выполнять множество операций, в частности:

  * отслеживать и изменять работу пулов, заданий и задач в своей учетной записи пакетной службы;
  * загружать с узлов файлы `stdout.txt`, `stderr.txt` или любые другие;
  * создавать на узлах пользователей и загружать RDP-файлы для удаленного входа.
* Узнайте, как [создавать пулы вычислительных узлов Linux](batch-linux-nodes.md).
* Посетите [форум по пакетной службе Azure][batch_forum] на сайте MSDN. Здесь могут задавать вопросы как начинающие, так и опытные пользователи пакетной службы.

[1]: ./media/batch-api-basics/node-folder-structure.png

[azure_storage]: https://azure.microsoft.com/services/storage/
[batch_forum]: https://social.msdn.microsoft.com/Forums/en-US/home?forum=azurebatch
[cloud_service_sizes]: ../cloud-services/cloud-services-sizes-specs.md
[msmpi]: https://msdn.microsoft.com/library/bb524831.aspx
[github_samples]: https://github.com/Azure/azure-batch-samples
[github_sample_taskdeps]:  https://github.com/Azure/azure-batch-samples/tree/master/CSharp/ArticleProjects/TaskDependencies
[github_batchexplorer]: https://github.com/Azure/azure-batch-samples/tree/master/CSharp/BatchExplorer
[batch_net_api]: https://msdn.microsoft.com/library/azure/mt348682.aspx
[msdn_env_vars]: https://msdn.microsoft.com/library/azure/mt743623.aspx
[net_cloudjob_jobmanagertask]: https://msdn.microsoft.com/library/azure/microsoft.azure.batch.cloudjob.jobmanagertask.aspx
[net_cloudjob_priority]: https://msdn.microsoft.com/library/azure/microsoft.azure.batch.cloudjob.priority.aspx
[net_cloudpool_starttask]: https://msdn.microsoft.com/library/azure/microsoft.azure.batch.cloudpool.starttask.aspx
[net_cloudtask_env]: https://msdn.microsoft.com/library/azure/microsoft.azure.batch.cloudtask.environmentsettings.aspx
[net_create_cert]: https://msdn.microsoft.com/library/azure/microsoft.azure.batch.certificateoperations.createcertificate.aspx
[net_create_user]: https://msdn.microsoft.com/library/azure/microsoft.azure.batch.computenode.createcomputenodeuser.aspx
[net_getfile_node]: https://msdn.microsoft.com/library/azure/microsoft.azure.batch.computenode.getnodefile.aspx
[net_getfile_task]: https://msdn.microsoft.com/library/azure/microsoft.azure.batch.cloudtask.getnodefile.aspx
[net_job_env]: https://msdn.microsoft.com/library/azure/microsoft.azure.batch.cloudjob.commonenvironmentsettings.aspx
[net_multiinstancesettings]: https://msdn.microsoft.com/library/azure/microsoft.azure.batch.multiinstancesettings.aspx
[net_onalltaskscomplete]: https://msdn.microsoft.com/library/azure/microsoft.azure.batch.cloudjob.onalltaskscomplete.aspx
[net_rdp]: https://msdn.microsoft.com/library/azure/microsoft.azure.batch.computenode.getrdpfile.aspx
[net_reboot]: https://msdn.microsoft.com/library/azure/mt631495.aspx
[net_reimage]: https://msdn.microsoft.com/library/azure/mt631496.aspx
[net_remove]: https://msdn.microsoft.com/library/azure/microsoft.azure.batch.pooloperations.removefrompoolasync.aspx
[net_offline]: https://msdn.microsoft.com/library/azure/microsoft.azure.batch.computenode.disableschedulingasync.aspx
[net_online]: https://msdn.microsoft.com/library/azure/microsoft.azure.batch.computenode.enableschedulingasync.aspx
[net_offline_option]: https://msdn.microsoft.com/library/azure/microsoft.azure.batch.common.disablecomputenodeschedulingoption.aspx
[net_rdpfile]: https://msdn.microsoft.com/library/azure/Mt272127.aspx
[vnet]: https://msdn.microsoft.com/library/azure/dn820174.aspx#bk_netconf

[py_add_user]: http://azure-sdk-for-python.readthedocs.io/en/latest/ref/azure.batch.operations.html#azure.batch.operations.ComputeNodeOperations.add_user

[batch_rest_api]: https://msdn.microsoft.com/library/azure/Dn820158.aspx
[rest_add_job]: https://msdn.microsoft.com/library/azure/mt282178.aspx
[rest_add_pool]: https://msdn.microsoft.com/library/azure/dn820174.aspx
[rest_add_cert]: https://msdn.microsoft.com/library/azure/dn820169.aspx
[rest_add_task]: https://msdn.microsoft.com/library/azure/dn820105.aspx
[rest_create_user]: https://msdn.microsoft.com/library/azure/dn820137.aspx
[rest_get_task_info]: https://msdn.microsoft.com/library/azure/dn820133.aspx
[rest_job_schedules]: https://msdn.microsoft.com/library/azure/mt282179.aspx
[rest_multiinstance]: https://msdn.microsoft.com/library/azure/mt637905.aspx
[rest_multiinstancesettings]: https://msdn.microsoft.com/library/azure/dn820105.aspx#multiInstanceSettings
[rest_update_job]: https://msdn.microsoft.com/library/azure/dn820162.aspx
[rest_rdp]: https://msdn.microsoft.com/library/azure/dn820120.aspx
[rest_reboot]: https://msdn.microsoft.com/library/azure/dn820171.aspx
[rest_reimage]: https://msdn.microsoft.com/library/azure/dn820157.aspx
[rest_remove]: https://msdn.microsoft.com/library/azure/dn820194.aspx
[rest_offline]: https://msdn.microsoft.com/library/azure/mt637904.aspx
[rest_online]: https://msdn.microsoft.com/library/azure/mt637907.aspx

[vm_marketplace]: https://azure.microsoft.com/marketplace/virtual-machines/
