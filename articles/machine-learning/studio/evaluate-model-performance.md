---
title: "Оценка эффективности модели в машинном обучении | Документация Майкрософт"
description: "Описание способов оценки эффективности модели в Машинном обучении Microsoft Azure."
services: machine-learning
documentationcenter: 
author: garyericson
manager: jhubbard
editor: cgronlun
ms.assetid: 5dc5348a-4488-4536-99eb-ff105be9b160
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 03/20/2017
ms.author: bradsev;garye
ms.openlocfilehash: 48ce4584f7270d78b1d09b848bfdd305d03012b9
ms.sourcegitcommit: 6699c77dcbd5f8a1a2f21fba3d0a0005ac9ed6b7
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 10/11/2017
---
# <a name="how-to-evaluate-model-performance-in-azure-machine-learning"></a>Оценка эффективности модели в Машинном обучении Microsoft Azure
В этой статье показано, как оценить эффективность модели в студии машинного обучения Azure. Вы также найдете здесь краткое описание метрик, доступных для выполнения этой задачи. Доступны три стандартных сценария управляемого обучения: 

* регрессия;
* двоичная классификация; 
* классификация по нескольким классам.

[!INCLUDE [machine-learning-free-trial](../../../includes/machine-learning-free-trial.md)]

Оценка эффективности модели является одним из основных этапов процесса обработки и анализа данных. Она показывает, насколько успешно обученная модель обрабатывает (прогнозирует) набор данных. 

Оценка модели в Машинном обучении Azure базируется на двух основных модулях машинного обучения: [Evaluate Model][evaluate-model] (Анализ модели) и [Cross-Validate Model][cross-validate-model] (Перекрестная проверка модели). Эти модули позволяют видеть эффективность модели в пересчете на различные показатели, обычно используемые в машинном обучении и статистике.

## <a name="evaluation-vs-cross-validation"></a>Сравнение оценки и перекрестной проверки
Оценка и перекрестная проверка — это стандартные способы для измерения эффективности модели. Оба модуля генерируют показатели оценки, которые вы можете проверить или сравнить с показателями других моделей.

[Evaluate Model][evaluate-model] (Анализ модели) в качестве входных данных принимает подсчитанный набор данных (или два таких набора, если нужно сравнить эффективность двух различных моделей). Это означает, что, прежде чем вы сможете оценить результаты, вам понадобится обучить свою модель с помощью модуля [Обучение модели][train-model] и сделать прогнозы насчет набора данных с помощью модуля [Score Model][score-model] (Оценка модели). Оценка основывается на подсчитанных метках или вероятностях и на истинных метках. Все эти значения предоставляет модуль [Score Model][score-model] (Оценка модели).

Кроме того, вы можете использовать перекрестную проверку, чтобы автоматически выполнить ряд операций «обучить-подсчитать-оценить» (10 сборок) для различных подмножеств входных данных. Входные данные делятся на 10 частей: одна резервируется для тестирования, а остальные 9 — для обучения. Этот процесс повторяется 10 раз, затем из показателей оценки выводится средняя величина. Эта процедура позволяет определить, насколько хорошо модель будет обобщаться на новых наборах данных. Модуль [Cross-Validate Model][cross-validate-model] (Перекрестная проверка модели) берет необученную модель и несколько группированных наборов данных, а затем в дополнение к усредненным результатам выводит результаты оценки каждой из 10 сборок.

В следующих разделах мы создадим простые модели регрессии и классификации и оценим их эффективность, используя модули [Evaluate Model][evaluate-model] (Анализ модели) и [Cross-Validate Model][cross-validate-model] (Перекрестная проверка модели).

## <a name="evaluating-a-regression-model"></a>Оценка модели регрессии
Предположим, мы хотим предсказать цену автомобиля, используя такие параметры, как размеры, мощность, характеристики двигателя и т. д. Это типичная задача регрессии, где целевой переменной *price* (Цена) присвоено непрерывное числовое значение. Мы можем подобрать простую модель линейной регрессии, которая сможет прогнозировать цену автомобиля, учитывая значения параметров этого автомобиля. Эту модель регрессии можно использовать для подсчета того же набора данных, который использовался для обучения. После того как мы получим прогнозируемые цены на все автомобили, мы сможем оценить эффективность модели. Для этого мы сравним, насколько прогнозы отличаются от фактических цен в среднем. Чтобы проиллюстрировать этот сценарий, мы воспользуемся *набором необработанных данных о ценах на автомобили*, доступным в разделе **сохраненных наборов данных** студии машинного обучения Microsoft Azure.

### <a name="creating-the-experiment"></a>Создание эксперимента
Добавьте следующие модули в рабочую область Студии машинного обучения Microsoft Azure:

* данные о ценах на автомобили (необработанные);
* [Линейная регрессия;][linear-regression]
* [Обучение модели;][train-model]
* [Score Model][score-model] (Оценка модели);
* [Evaluate Model][evaluate-model] (Анализ модели);

Соедините порты, как показано на рисунке 1 ниже, и установите для столбца "Метка" модуля [Обучение модели][train-model] значение *цена*.

![Оценка модели регрессии](./media/evaluate-model-performance/1.png)

Рисунок 1. Оценка модели регрессии.

### <a name="inspecting-the-evaluation-results"></a>Проверка результатов оценки
После проведения эксперимента щелкните порт вывода модуля [Evaluate Model][evaluate-model] (Анализ модели) и выберите *Визуализировать*, чтобы отобразить результаты оценки. Для моделей регрессии доступны такие метрики оценки: *Mean Absolute Error* (Средняя абсолютная погрешность), *Root Mean Absolute Error* (Среднеквадратическая абсолютная погрешность), *Relative Absolute Error* (Относительная абсолютная погрешность), *Relative Squared Error* (Относительная среднеквадратическая погрешность) и *Coefficient of Determination* (Коэффициент детерминации).

Термин «ошибка» здесь означает разницу между прогнозируемым значением и истинным значением. Абсолютное значение или квадрат этой разницы обычно вычисляется, чтобы зафиксировать абсолютную величину ошибки во всех экземплярах, так как разница между прогнозируемым и истинным значением иногда может быть отрицательным числом. Показатели ошибки измеряют прогнозируемую эффективность модели регрессии с точки зрения среднего отклонения ее прогнозов от истинных значений. Чем ниже значения ошибок, тем более точно модель прогнозирует. Общий показатель ошибок 0 означает, что модель идеально подбирает данные.

Для определения способности модели подбирать данные также часто используется коэффициент детерминации, который также известен как R-квадрат. Его можно интерпретировать как пропорцию отклонений, которые объясняются моделью. В этом случае чем выше пропорция, тем лучше. Значение 1 означает идеальное совпадение.

![Показатели оценки линейной регрессии](./media/evaluate-model-performance/2.png)

Рис. 2. Показатели оценки линейной регрессии.

### <a name="using-cross-validation"></a>Использование перекрестной проверки
Как уже упоминалось ранее, вы можете повторно выполнять обучение, подсчет и оценку автоматически с помощью модуля [Cross-Validate Model][cross-validate-model] (Перекрестная проверка модели). Для этого вам потребуются набор данных, необученная модель и модуль [Cross-Validate Model][cross-validate-model] (Перекрестная проверка модели) (см. рисунок ниже). Не забудьте установить значение *цена* для столбца "Метка" в свойствах модуля [Cross-Validate Model][cross-validate-model] (Перекрестная проверка модели).

![Перекрестная проверка модели регрессии](./media/evaluate-model-performance/3.png)

Рис. 3. Перекрестная проверка модели регрессии.

После проведения эксперимента вы можете проверить результаты оценки. Для этого щелкните правый порт вывода модуля [Cross-Validate Model][cross-validate-model] (Перекрестная проверка модели). Вы увидите подробное представление показателей для каждой итерации (сборки) и усредненные результаты каждого из показателей (рис. 4).

![Результаты перекрестной проверки модели регрессии](./media/evaluate-model-performance/4.png)

Рис. 4 Результаты перекрестной проверки модели регрессии.

## <a name="evaluating-a-binary-classification-model"></a>Оценка модели двоичной классификации
При использовании двоичной классификации целевая переменная имеет только два возможных результата (например, {0, 1} или {ложь, истина}, {отрицательный, положительный}). Предположим, вы получили набор данных взрослых специалистов с некоторыми демографическими переменными и переменными их занятости. Вас просят предсказать уровень их доходов. Результат нужно выразить в виде бинарной переменной со значениями {“<=50 000”, “>50 000”}. Иными словами, отрицательный класс представляет специалистов, которые зарабатывают меньше 50 000 $ в год, а положительный класс представляет всех остальных специалистов. Как и в сценарии с регрессией, мы должны обучить модель, посчитать некоторые данные и оценивать результаты. Основным различием этого сценария будет показателей, которые вычисляет и выводит Машинное обучение Azure. Чтобы проиллюстрировать сценарий прогнозирования уровня доходов мы воспользуемся [набором данных о взрослых](http://archive.ics.uci.edu/ml/datasets/Adult), чтобы создать эксперимент машинного обучения Azure и оценить эффективность двухклассовой регрессионной логистической модели (популярный двоичный классификатор).

### <a name="creating-the-experiment"></a>Создание эксперимента
Добавьте следующие модули в рабочую область Студии машинного обучения Microsoft Azure:

* набор данных Adult Census Income Binary Classification;
* [двухклассная регрессионная логистическая модель;][two-class-logistic-regression]
* [Обучение модели;][train-model]
* [Score Model][score-model] (Оценка модели);
* [Evaluate Model][evaluate-model] (Анализ модели);

Соедините порты, как показано на рисунке 5 ниже, и установите для столбца "Метка" модуля [Обучение модели][train-model] значение *доход*.

![Оценка модели двоичной классификации](./media/evaluate-model-performance/5.png)

Рис. 5. Оценка модели двоичной классификации.

### <a name="inspecting-the-evaluation-results"></a>Проверка результатов оценки
После проведения эксперимента щелкните порт вывода модуля [Evaluate Model][evaluate-model] (Анализ модели) и выберите *Визуализировать*, чтобы увидеть результаты оценки (рис. 7). Для моделей двоичной классификации доступны такие метрики оценки: *Accuracy* (Правильность), *Precision* (Точность), *Recall* (Полнота), *F1 Score* (Оценка F1) и *AUC*. Кроме того, модуль выводит матрицы неточностей, которые отображают число истинно положительных, ложноотрицательных, ложноположительных и истинно отрицательных результатов, а также кривые *ROC*, *Precision/Recall* (Точность и полнота) и *Lift* (Точность прогноза).

Правильность выражается пропорцией правильно классифицированных экземпляров. Это, как правило, первый показатель, который вы видите во время оценки классификатора. Но если тестовые данные не сбалансированы (большинство экземпляров относятся к одному из классов) или вас больше интересует эффективность на одном из классов, правильность не будет отражать фактическую эффективность классификатора. Предположим, вы тестируете в сценарии классификации уровня дохода, данные, в которых 99 % экземпляров представляют людей, которые зарабатывают меньше или ровно 50 000 $ в год. Можно достичь уровня точности 0,99 путем прогнозирования класса «<=50K» для всех экземпляров. Кажется, что классификатор в целом хорошо справляется с заданием, но в действительности он не смог правильно классифицировать ни одно из лиц с высоким уровнем дохода (1 %).

Поэтому будет целесообразно вычислить дополнительные показатели, которые фиксируют более конкретные аспекты оценки. Прежде чем углубляться в подробности таких показателей, важно понять матрицу неточностей оценки двоичной классификации. Класс меток в обучающем множестве может принимать только 2 возможных значения, которые обычно называются положительным или отрицательным. Положительные и отрицательные экземпляры, которые классификатор прогнозирует правильно, называются истинно положительными (ИП) и истинно отрицательными (ИО) результатами соответственно. Точно так же неправильно классифицированные экземпляры называются ложно положительными (ЛП) и ложно отрицательными результатами (ЛО). Матрица неточностей — это таблица, которая показывает количество случаев, которые подпадают под каждую из этих четырех категорий. Машинное обучение Azure автоматически определяет, какой из двух классов в наборе данных является положительным классом. Если метки класса являются логическими операторами или целыми числами, то экземпляры с метками «истина» или «1» присваиваются положительному классу. Если метки являются строками, как в случае с набором данных о доходах, метки сортируются в алфавитном порядке. Первый уровень присваивается отрицательному классу, а второй уровень — положительному классу.

![Матрица неточностей двоичной классификации](./media/evaluate-model-performance/6a.png)

Рис. 6. Матрица неточностей двоичной классификации.

Возвращаясь к проблеме классификации доходов, нужно задать несколько оценочных вопросов, которые помогут определить эффективность используемого классификатора. Вполне естественный вопрос: «Сколько лиц, которые по прогнозам модели зарабатывают > 50 000 (ИП + ЛП), классифицированы правильно (ИП)?» На этот вопрос можно ответить, взглянув на показатель **точности** модели, который представляет долю правильно классифицированных положительных результатов: ИП / (ИП + ЛП). Другой распространенный вопрос: «Из всех высокооплачиваемых специалистов с доходом > 50 000 $ (ИП + ЛП) скольких классификатор классифицировал правильно (ИП)?» Это значение представлено показателем **полноты** или процента истинно положительных результатов классификатора: ИП / (ИП + ЛП). Вы могли заметить, что существует очевидный компромисс между точностью и полнотой. Например, обрабатывая относительно сбалансированный набор данных, классификатор, который прогнозирует в основном положительные экземпляры, будет иметь высокий уровень полноты, но довольно низкий уровень точности, так как многие отрицательные экземпляры будут неправильно классифицированы из-за большого количества ложно позитивных результатов. Чтобы увидеть график изменения этих двух показателей, щелкните кривую «ТОЧНОСТЬ/ПОЛНОТА» на странице вывода результатов оценки (верхняя левая часть рисунка 7).

![Результаты оценки двоичной классификации](./media/evaluate-model-performance/7.png)

Рис. 7. Результаты оценки двоичной классификации.

Не менее часто используется показатель **оценки F1**, который учитывает и точность, и полноту. Это среднее гармоническое этих 2 показателей, которое вычисляется так: F1 = 2 (точность x полнота) / (точность + полнота). Показатель F1 — это удобный способ обобщения оценки в одно число. Но все-таки рекомендуется смотреть на точность и полноту вместе, чтобы лучше понять поведение классификатора.

Кроме того, вы можете сравнить доли истинно положительных результатов и ложноположительных результатов, представленных кривой **рабочей характеристики приемника (ROC)** и соответствующим значением **площади под ROC-кривой (AUC)**. Чем ближе эта кривая к верхнему левому углу, тем выше эффективность классификатора. То есть речь идет о максимальном проценте истинно положительных результатов и минимальном проценте ложно положительных результатов. Кривые, близкие к диагонали графика, получаются из классификаторов, которые, как правило, делают прогнозы, близкие к случайному угадыванию.

### <a name="using-cross-validation"></a>Использование перекрестной проверки
Как и в примере регрессии, мы можем выполнить перекрестную проверку, чтобы многократно обучить, посчитать и оценить разные подмножества данных автоматически. Подобным образом мы можем использовать модуль [Cross-Validate Model][cross-validate-model] (Перекрестная проверка модели), необученную регрессионную логистическую модель и набор данных. В свойствах модуля *Cross-Validate Model* (Перекрестная проверка модели) в столбце "Метка" должно быть установлено значение [доход][cross-validate-model]. Если по завершении эксперимента щелкнуть правый порт вывода в модуле [Cross-Validate Model][cross-validate-model] (Модель перекрестной проверки), отобразятся значения метрик двоичной классификации для каждой свертки, а также среднее значение и стандартное отклонение каждого из них. 

![Перекрестная проверка модели двоичной классификации](./media/evaluate-model-performance/8.png)

Рис. 8. Перекрестная проверка модели двоичной классификации.

![Результаты перекрестной проверки модели двоичной классификации](./media/evaluate-model-performance/9.png)

Рис. 9. Результаты перекрестной проверки модели двоичной классификации.

## <a name="evaluating-a-multiclass-classification-model"></a>Оценка модели классификации по нескольким классам
В этом эксперименте мы воспользуемся популярным набором данных [Iris](http://archive.ics.uci.edu/ml/datasets/Iris "Iris"), который содержит экземпляры трех разных типов (классов) растения ирис. Для каждого экземпляра существует 4 значения признаков: длина и ширина чашелистика и длина и ширина лепестка. В предыдущих экспериментах мы обучали и тестировали модели, используя те же наборы данных. Здесь мы будем использовать модуль [разделения данных][split], чтобы создать два подмножества данных: одно для обучения и второе для оценки и анализа. Набор данных Iris находится в открытом доступе в [репозитории машинного обучения UCI](http://archive.ics.uci.edu/ml/index.html). Его можно скачать с помощью модуля [импорта данных][import-data].

### <a name="creating-the-experiment"></a>Создание эксперимента
Добавьте следующие модули в рабочую область Студии машинного обучения Microsoft Azure:

* [Импорт данных][import-data]
* [Multiclass Decision Forest][multiclass-decision-forest] (Лес решений с несколькими классами);
* [Split Data][split] (Разделение данных);
* [Обучение модели;][train-model]
* [Score Model][score-model] (Оценка модели);
* [Evaluate Model][evaluate-model] (Анализ модели);

Соедините порты, как показано на рисунке 10.

Установите значение 5 для индекса столбца "Метка" в модуле [Обучение модели][train-model]. У этого набора данных нет строки заголовка, но мы знаем, что этикетки находятся в пятом столбце.

Щелкните модуль [импорта данных][import-data] и присвойте свойству *Источник данных* значение *Web URL via HTTP* (URL-адрес веб-узла через HTTP), а свойству *URL* (URL-адрес) — http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data.

Укажите дробное число экземпляров, которые будут использоваться для обучения модуля [разделения данных][split] (например, 0,7).

![Оценка классификатора с несколькими классами](./media/evaluate-model-performance/10.png)

Рис. Оценка классификатора с несколькими классами

### <a name="inspecting-the-evaluation-results"></a>Проверка результатов оценки
Запустите эксперимент и щелкните порт вывода в модуле [Evaluate Model][evaluate-model] (Анализ модели). В этом случае результаты оценки представлены в виде матрицы неточностей. Матрица показывает фактические экземпляры по сравнению с прогнозируемыми для всех 3 классов.

![Результаты оценки классификации по нескольким классам](./media/evaluate-model-performance/11.png)

Рис. 11. Результаты оценки классификации по нескольким классам.

### <a name="using-cross-validation"></a>Использование перекрестной проверки
Как уже упоминалось ранее, вы можете повторно выполнять обучение, подсчет и оценку автоматически с помощью модуля [Cross-Validate Model][cross-validate-model] (Перекрестная проверка модели). Вам потребуется набор данных, необученная модель и модуль [Cross-Validate Model][cross-validate-model] (Перекрестная проверка модели) (см. рисунок ниже). Снова нужно установить значение для столбца "Метка" в модуле [Cross-Validate Model][cross-validate-model] (Перекрестная проверка модели) (в данном случае индекс столбца — 5). Если по завершении эксперимента щелкнуть правый порт вывода в модуле [Cross-Validate Model][cross-validate-model] (Перекрестная проверка модели), вы увидите значения показателей для каждой свертки, а также среднее значение и стандартное отклонение. Отображаемые здесь показатели похожи на показатели, о которых шла речь в разделе, посвященном двоичной классификации. Но обратите внимание, что в классификации по нескольким классам истинно положительные/отрицательные результаты и ложно положительные/отрицательные результаты вычисляются путем подсчета на основе каждого класса, так как не существует общего положительного или отрицательного класса. Например, при расчете точности или полноты класса «Ирис щетинистый» предполагается, что это положительный класс, а все остальные являются отрицательными.

![Перекрестная проверка модели классификации по нескольким классам](./media/evaluate-model-performance/12.png)

Рис. 12. Перекрестная проверка модели классификации по нескольким классам.

![Результаты перекрестной проверки модели классификации по нескольким классам](./media/evaluate-model-performance/13.png)

Рис. 13. Результаты перекрестной проверки модели классификации по нескольким классам.

<!-- Module References -->
[cross-validate-model]: https://msdn.microsoft.com/library/azure/75fb875d-6b86-4d46-8bcc-74261ade5826/
[evaluate-model]: https://msdn.microsoft.com/library/azure/927d65ac-3b50-4694-9903-20f6c1672089/
[linear-regression]: https://msdn.microsoft.com/library/azure/31960a6f-789b-4cf7-88d6-2e1152c0bd1a/
[multiclass-decision-forest]: https://msdn.microsoft.com/library/azure/5e70108d-2e44-45d9-86e8-94f37c68fe86/
[import-data]: https://msdn.microsoft.com/library/azure/4e1b0fe6-aded-4b3f-a36f-39b8862b9004/
[score-model]: https://msdn.microsoft.com/library/azure/401b4f92-e724-4d5a-be81-d5b0ff9bdb33/
[split]: https://msdn.microsoft.com/library/azure/70530644-c97a-4ab6-85f7-88bf30a8be5f/
[train-model]: https://msdn.microsoft.com/library/azure/5cc7053e-aa30-450d-96c0-dae4be720977/
[two-class-logistic-regression]: https://msdn.microsoft.com/library/azure/b0fd7660-eeed-43c5-9487-20d9cc79ed5d/

