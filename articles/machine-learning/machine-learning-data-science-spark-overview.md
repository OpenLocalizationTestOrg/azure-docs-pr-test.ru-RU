---
title: "aaaOverview процесса обработки и анализа данных с помощью Spark на Azure HDInsight | Документы Microsoft"
description: "набор средств Spark MLlib Hello переводит существенное машинного обучения моделирования возможности распределенного toohello HDInsight среды."
services: machine-learning
documentationcenter: 
author: bradsev
manager: jhubbard
editor: cgronlun
ms.assetid: a4e1de99-a554-4240-9647-2c6d669593c8
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 03/15/2017
ms.author: deguhath;bradsev;gokuma
ms.openlocfilehash: 515705684a46917c2741bf063d439b1cda016abb
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 10/06/2017
---
# <a name="overview-of-data-science-using-spark-on-azure-hdinsight"></a><span data-ttu-id="dcf1e-103">Общие сведения об обработке и анализе данных с помощью платформы Spark в Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="dcf1e-103">Overview of data science using Spark on Azure HDInsight</span></span>
[!INCLUDE [machine-learning-spark-modeling](../../includes/machine-learning-spark-modeling.md)]

<span data-ttu-id="dcf1e-104">Этот набор разделов показано, как задачи toouse HDInsight Spark toocomplete общие обработки и анализа данных, такие как приема данных, конструируются, моделирования и вычисления моделей.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-104">This suite of topics shows how toouse HDInsight Spark toocomplete common data science tasks such as data ingestion, feature engineering, modeling, and model evaluation.</span></span> <span data-ttu-id="dcf1e-105">Hello данные, используемые приводится образец hello 2013 NYC такси маршрута и тариф авиакомпании набора данных.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-105">hello data used is a sample of hello 2013 NYC taxi trip and fare dataset.</span></span> <span data-ttu-id="dcf1e-106">Hello моделей, построенных включают логистической и линейной регрессии, случайные леса и градиента повышенных деревьев.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-106">hello models built include logistic and linear regression, random forests, and gradient boosted trees.</span></span> <span data-ttu-id="dcf1e-107">Hello также показано, как toostore эти модели в Azure BLOB-объектов хранилища (WASB) и как tooscore и оценить их прогнозирования производительности.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-107">hello topics also show how toostore these models in Azure blob storage (WASB) and how tooscore and evaluate their predictive performance.</span></span> <span data-ttu-id="dcf1e-108">В более расширенных разделах рассматриваются способы обучения моделей с помощью перекрестной проверки и перебора гиперпараметров.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-108">More advanced topics cover how models can be trained using cross-validation and hyper-parameter sweeping.</span></span> <span data-ttu-id="dcf1e-109">В этом обзорном разделе также ссылается hello разделы, описывающие, каким образом tooset копирование hello кластера Spark, необходимые шаги hello toocomplete hello пошаговых руководств, приведенных.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-109">This overview topic also references hello topics that describe how tooset up hello Spark cluster that you need toocomplete hello steps in hello walkthroughs provided.</span></span> 

## <a name="spark-and-mllib"></a><span data-ttu-id="dcf1e-110">Spark и MLlib</span><span class="sxs-lookup"><span data-stu-id="dcf1e-110">Spark and MLlib</span></span>
<span data-ttu-id="dcf1e-111">[Spark](http://spark.apache.org/) платформу параллельной обработки с открытым исходным кодом, поддерживающий в памяти обрабатывает tooboost hello производительность приложений для анализа больших данных.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-111">[Spark](http://spark.apache.org/) is an open-source parallel processing framework that supports in-memory processing tooboost hello performance of big-data analytic applications.</span></span> <span data-ttu-id="dcf1e-112">Подсистема обработки Spark Hello, созданную для скорости, простоте использования и сложные analytics.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-112">hello Spark processing engine is built for speed, ease of use, and sophisticated analytics.</span></span> <span data-ttu-id="dcf1e-113">Возможности распределенных вычислений в памяти Spark лучше всего подходит для hello итеративный алгоритмы, используемые в вычислениях машины обучения и диаграммы.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-113">Spark's in-memory distributed computation capabilities make it a good choice for hello iterative algorithms used in machine learning and graph computations.</span></span> <span data-ttu-id="dcf1e-114">[MLlib](http://spark.apache.org/mllib/) Spark в масштабируемой машины обучения библиотека, которая переводит hello алгоритмической моделирования возможности toothis распределенной среде.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-114">[MLlib](http://spark.apache.org/mllib/) is Spark's scalable machine learning library that brings hello algorithmic modeling capabilities toothis distributed environment.</span></span> 

## <a name="hdinsight-spark"></a><span data-ttu-id="dcf1e-115">HDInsight Spark</span><span class="sxs-lookup"><span data-stu-id="dcf1e-115">HDInsight Spark</span></span>
<span data-ttu-id="dcf1e-116">[HDInsight Spark](../hdinsight/hdinsight-apache-spark-overview.md) hello Azure размещается предложения из Spark с открытым исходным кодом.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-116">[HDInsight Spark](../hdinsight/hdinsight-apache-spark-overview.md) is hello Azure hosted offering of open-source Spark.</span></span> <span data-ttu-id="dcf1e-117">Она также включает поддержку **записные книжки Jupyter PySpark** на кластере Spark hello, можно запустить Spark SQL интерактивной обработки запросов для преобразования, фильтрации и наглядное представление данных, хранящихся в больших двоичных объектов Azure (WASB).</span><span class="sxs-lookup"><span data-stu-id="dcf1e-117">It also includes support for **Jupyter PySpark notebooks** on hello Spark cluster that can run Spark SQL interactive queries for transforming, filtering, and visualizing data stored in Azure Blobs (WASB).</span></span> <span data-ttu-id="dcf1e-118">PySpark — hello API Python для Spark.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-118">PySpark is hello Python API for Spark.</span></span> <span data-ttu-id="dcf1e-119">фрагменты кода Hello, которые обеспечивают hello и Показать hello соответствующие графики toovisualize hello данные здесь выполняются в записные книжки Jupyter установлен в кластерах Spark hello.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-119">hello code snippets that provide hello solutions and show hello relevant plots toovisualize hello data here run in Jupyter notebooks installed on hello Spark clusters.</span></span> <span data-ttu-id="dcf1e-120">шаги моделирования Hello в этих разделах содержат код, который показывает, как tootrain, вычисления, сохранения и использования каждого типа модели.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-120">hello modeling steps in these topics contain code that shows how tootrain, evaluate, save, and consume each type of model.</span></span> 

## <a name="setup-spark-clusters-and-jupyter-notebooks"></a><span data-ttu-id="dcf1e-121">Настройка кластеров Spark и записных книжек Jupyter</span><span class="sxs-lookup"><span data-stu-id="dcf1e-121">Setup: Spark clusters and Jupyter notebooks</span></span>
<span data-ttu-id="dcf1e-122">Действия по настройке и код, указанные в этом пошаговом руководстве, применимы к использованию для HDInsight Spark 1.6.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-122">Setup steps and code are provided in this walkthrough for using an HDInsight Spark 1.6.</span></span> <span data-ttu-id="dcf1e-123">Но записные книжки Jupyter можно использовать для кластеров HDInsight Spark 1.6 и Spark 2.0.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-123">But Jupyter notebooks are provided for both HDInsight Spark 1.6 and Spark 2.0 clusters.</span></span> <span data-ttu-id="dcf1e-124">Описание toothem hello записных книжек и ссылки, представлено в hello [Readme.md](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Readme.md) для репозитория GitHub hello, содержащий их.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-124">A description of hello notebooks and links toothem are provided in hello [Readme.md](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Readme.md) for hello GitHub repository containing them.</span></span> <span data-ttu-id="dcf1e-125">Кроме того код hello здесь и в записных книжках hello связаны является универсальным и должен работать на любой кластер Spark.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-125">Moreover, hello code here and in hello linked notebooks is generic and should work on any Spark cluster.</span></span> <span data-ttu-id="dcf1e-126">Если вы не используете HDInsight Spark, настройку и управление ими действия hello кластера может быть немного отличается от показанной здесь.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-126">If you are not using HDInsight Spark, hello cluster setup and management steps may be slightly different from what is shown here.</span></span> <span data-ttu-id="dcf1e-127">Для удобства ниже приведены hello ссылки записные книжки Jupyter toohello для 1.6 Spark (выполняются в ядро pySpark hello hello server книжке Jupyter toobe) и 2.0 Spark (toobe запуска ядра pySpark3 hello объекта hello книжке Jupyter сервера).</span><span class="sxs-lookup"><span data-stu-id="dcf1e-127">For convenience, here are hello links toohello Jupyter notebooks for Spark 1.6 (toobe run in hello pySpark kernel of hello Jupyter Notebook server) and  Spark 2.0 (toobe run in hello pySpark3 kernel of hello Jupyter Notebook server):</span></span>

### <a name="spark-16-notebooks"></a><span data-ttu-id="dcf1e-128">Записные книжки для Spark 1.6</span><span class="sxs-lookup"><span data-stu-id="dcf1e-128">Spark 1.6 notebooks</span></span>
<span data-ttu-id="dcf1e-129">Эти портативные компьютеры являются toobe запуска ядра pySpark hello из блокнота jupyter.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-129">These notebooks are toobe run in hello pySpark kernel of Jupyter notebook server.</span></span>

- <span data-ttu-id="dcf1e-130">[pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb): содержит сведения о том, как просмотр данных tooperform, моделирование и оценка с несколько разных алгоритмов.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-130">[pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb): Provides information on how tooperform data exploration, modeling, and scoring with several different algorithms.</span></span>
- <span data-ttu-id="dcf1e-131">[pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb). Содержит разделы в записной книжке №1 и варианты моделей с использованием настройки гиперпараметров и перекрестной проверки.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-131">[pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): Includes topics in notebook #1, and model development using hyperparameter tuning and cross-validation.</span></span>
- <span data-ttu-id="dcf1e-132">[pySpark-machine-learning-data-science-spark-model-consumption.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb): показано, как toooperationalize сохраненную модель с помощью Python в HDInsight кластеров.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-132">[pySpark-machine-learning-data-science-spark-model-consumption.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb): Shows how toooperationalize a saved model using Python on HDInsight clusters.</span></span>

### <a name="spark-20-notebooks"></a><span data-ttu-id="dcf1e-133">Записные книжки для Spark 2.0</span><span class="sxs-lookup"><span data-stu-id="dcf1e-133">Spark 2.0 notebooks</span></span>
<span data-ttu-id="dcf1e-134">Эти портативные компьютеры являются toobe запуска ядра pySpark3 hello из блокнота jupyter.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-134">These notebooks are toobe run in hello pySpark3 kernel of Jupyter notebook server.</span></span>

- <span data-ttu-id="dcf1e-135">[Spark2.0-pySpark3-Machine-Learning-Data-Science-Spark-Advanced-Data-exploration-Modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): этот файл содержит сведения о как tooperform Просмотр данных, моделирования и оценки в Spark 2.0 кластеры, использующие hello trip такси NYC и набор данных тариф авиакомпании, описано [здесь](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span><span class="sxs-lookup"><span data-stu-id="dcf1e-135">[Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): This file provides information on how tooperform data exploration, modeling, and scoring in Spark 2.0 clusters using hello NYC Taxi trip and fare data-set described [here](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span></span> <span data-ttu-id="dcf1e-136">Записной книжки может быть хорошей отправной точкой для быстрого исследования кода hello, предоставленные для Spark 2.0.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-136">This notebook may be a good starting point for quickly exploring hello code we have provided for Spark 2.0.</span></span> <span data-ttu-id="dcf1e-137">Для подробных записной книжки анализирует hello такси NYC данных, см. Далее записной книжки hello в этом списке.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-137">For a more detailed notebook analyzes hello NYC Taxi data, see hello next notebook in this list.</span></span> <span data-ttu-id="dcf1e-138">См. примечания hello ниже, сравнивающие эти портативные компьютеры.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-138">See hello notes following this list that compare these notebooks.</span></span> 
- <span data-ttu-id="dcf1e-139">[Spark2.0 pySpark3_NYC_Taxi_Tip_Regression.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_NYC_Taxi_Tip_Regression.ipynb): этот файл показывает, как tooperform данные wrangling (Spark SQL и кадр данных операции), просмотр, моделирование и оценка с помощью hello trip такси NYC и тариф авиакомпании набор данных описывается [ Здесь](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span><span class="sxs-lookup"><span data-stu-id="dcf1e-139">[Spark2.0-pySpark3_NYC_Taxi_Tip_Regression.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_NYC_Taxi_Tip_Regression.ipynb): This file shows how tooperform data wrangling (Spark SQL and dataframe operations), exploration, modeling and scoring using hello NYC Taxi trip and fare data-set described [here](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span></span>
- <span data-ttu-id="dcf1e-140">[Spark2.0 pySpark3_Airline_Departure_Delay_Classification.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_Airline_Departure_Delay_Classification.ipynb): этот файл показывает, как tooperform данные wrangling (Spark SQL и кадр данных операции), просмотр, моделирование и оценка с помощью hello хорошо известных авиакомпании на время отправления набор данных на основе 2011 г. и 2012.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-140">[Spark2.0-pySpark3_Airline_Departure_Delay_Classification.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_Airline_Departure_Delay_Classification.ipynb): This file shows how tooperform data wrangling (Spark SQL and dataframe operations), exploration, modeling and scoring using hello well-known Airline On-time departure dataset from 2011 and 2012.</span></span> <span data-ttu-id="dcf1e-141">Мы интегрировать dataset авиакомпании hello hello аэропорта погоды данных (например, windspeed, температуры, высота над уровнем моря т. д.) предыдущих toomodeling, эти функции погоды могут быть включены в модель hello.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-141">We integrated hello airline dataset with hello airport weather data (e.g. windspeed, temperature, altitude etc.) prior toomodeling, so these weather features can be included in hello model.</span></span>

<!-- -->

> [!NOTE]
> <span data-ttu-id="dcf1e-142">набор данных авиакомпании Hello был добавлен toohello Spark 2.0 записных книжек toobetter иллюстрируют использование hello алгоритмы классификации.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-142">hello airline dataset was added toohello Spark 2.0 notebooks toobetter illustrate hello use of classification algorithms.</span></span> <span data-ttu-id="dcf1e-143">См. следующие ссылки на сведения о набора данных на время отправления авиакомпании и набора данных погоды hello.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-143">See hello following links for information about airline on-time departure dataset and weather dataset:</span></span>

>- <span data-ttu-id="dcf1e-144">Данные о расписании вылетов авиакомпании: [http://www.transtats.bts.gov/ONTIME/](http://www.transtats.bts.gov/ONTIME/)</span><span class="sxs-lookup"><span data-stu-id="dcf1e-144">Airline on-time departure data: [http://www.transtats.bts.gov/ONTIME/](http://www.transtats.bts.gov/ONTIME/)</span></span>

>- <span data-ttu-id="dcf1e-145">Данные о погоде в аэропортах: [https://www.ncdc.noaa.gov/](https://www.ncdc.noaa.gov/)</span><span class="sxs-lookup"><span data-stu-id="dcf1e-145">Airport weather data: [https://www.ncdc.noaa.gov/](https://www.ncdc.noaa.gov/)</span></span> 
> 
> 

<!-- -->

<!-- -->

> [!NOTE]
<span data-ttu-id="dcf1e-146">записных книжек Spark 2.0 Hello на такси NYC hello и наборы авиакомпании рейса задержка данных может занять 10 минут или более toorun (в зависимости от размера hello кластер HDI).</span><span class="sxs-lookup"><span data-stu-id="dcf1e-146">hello Spark 2.0 notebooks on hello NYC taxi and airline flight delay data-sets can take 10 mins or more toorun (depending on hello size of your HDI cluster).</span></span> <span data-ttu-id="dcf1e-147">Hello первой записной книжки в hello над списком показаны различные аспекты hello исследования данных, визуализации и машинного Обучения моделей обучения в записной книжке, занимает меньше времени toorun уменьшается NYC набора данных, в которой hello такси и тариф авиакомпании файлы были предварительно присоединены к домену: [ Spark2.0-pySpark3-Machine-Learning-Data-Science-Spark-Advanced-Data-exploration-Modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb) записной книжки принимает более короткое время toofinish (2-3 минуты) и может быть это хорошая отправная точка для быстро анализ кода hello у нас есть обеспечивает Spark 2.0.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-147">hello first notebook in hello above list shows many aspects of hello data exploration, visualization and ML model training in a notebook that takes less time toorun with down-sampled NYC data set, in which hello taxi and fare files have been pre-joined: [Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb) This notebook takes a much shorter time toofinish (2-3 mins) and may be a good starting point for quickly exploring hello code we have provided for Spark 2.0.</span></span> 

<!-- -->

<span data-ttu-id="dcf1e-148">Рекомендации по ввода в эксплуатацию hello Spark 2.0 модели и модели потребления для оценки разделе hello [документа Spark 1.6 на потребление](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb) пример структурирование hello шаги.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-148">For guidance on hello operationalization of a Spark 2.0 model and model consumption for scoring, see hello [Spark 1.6 document on consumption](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb) for an example outlining hello steps required.</span></span> <span data-ttu-id="dcf1e-149">toouse это 2.0 Spark, замените файл кода hello Python с [этот файл](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/Python/Spark2.0_ConsumeRFCV_NYCReg.py).</span><span class="sxs-lookup"><span data-stu-id="dcf1e-149">toouse this on Spark 2.0, replace hello Python code file with [this file](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/Python/Spark2.0_ConsumeRFCV_NYCReg.py).</span></span>

### <a name="prerequisites"></a><span data-ttu-id="dcf1e-150">Предварительные требования</span><span class="sxs-lookup"><span data-stu-id="dcf1e-150">Prerequisites</span></span>
<span data-ttu-id="dcf1e-151">Hello следующих процедур, связанных tooSpark 1.6.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-151">hello following procedures are related tooSpark 1.6.</span></span> <span data-ttu-id="dcf1e-152">Для версии Spark 2.0 hello записных книжек hello используйте описанные и связанных toopreviously.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-152">For  hello Spark 2.0 version, use hello notebooks described and linked toopreviously.</span></span> 

<span data-ttu-id="dcf1e-153">1. У вас должна быть подписка Azure.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-153">1.You must have an Azure subscription.</span></span> <span data-ttu-id="dcf1e-154">Если у вас ее нет, см. статью [о получении бесплатной пробной версии Azure](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span><span class="sxs-lookup"><span data-stu-id="dcf1e-154">If you do not already have one, see [Get Azure free trial](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span></span>

<span data-ttu-id="dcf1e-155">2. необходимо toocomplete кластера Spark 1.6 в данном пошаговом руководстве.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-155">2.You need a Spark 1.6 cluster toocomplete this walkthrough.</span></span> <span data-ttu-id="dcf1e-156">hello следуйте инструкциям в разделе toocreate, [приступить к работе: создание Apache Spark на Azure HDInsight](../hdinsight/hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="dcf1e-156">toocreate one, see hello instructions provided in [Get started: create Apache Spark on Azure HDInsight](../hdinsight/hdinsight-apache-spark-jupyter-spark-sql.md).</span></span> <span data-ttu-id="dcf1e-157">тип кластера Hello и версии указан из hello **Выбор типа кластера** меню.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-157">hello cluster type and version is specified from hello **Select Cluster Type** menu.</span></span> 

![Настройка кластера](./media/machine-learning-data-science-spark-overview/spark-cluster-on-portal.png)

<!-- -->

> [!NOTE]
> <span data-ttu-id="dcf1e-159">Раздел, показывающий выполнение задач по toouse toocomplete Scala, а не Python для процесса обработки и анализа данных с начала до конца, в разделе hello [обработки и анализа данных с помощью Scala с Spark на Azure](machine-learning-data-science-process-scala-walkthrough.md).</span><span class="sxs-lookup"><span data-stu-id="dcf1e-159">For a topic that shows how toouse Scala rather than Python toocomplete tasks for an end-to-end data science process, see hello [Data Science using Scala with Spark on Azure](machine-learning-data-science-process-scala-walkthrough.md).</span></span>
> 
> 

<!-- -->

> [!INCLUDE [delete-cluster-warning](../../includes/hdinsight-delete-cluster-warning.md)]
> 
> 

## <a name="hello-nyc-2013-taxi-data"></a><span data-ttu-id="dcf1e-160">Hello такси 2013 NYC данных</span><span class="sxs-lookup"><span data-stu-id="dcf1e-160">hello NYC 2013 Taxi data</span></span>
<span data-ttu-id="dcf1e-161">Hello Trip такси NYC данных составляет около 20 ГБ файлы сжатых значений с разделителями запятыми (CSV) (~ 48 ГБ несжатого), включающего в себя более миллиона 173 отдельных приема-передачи и hello цен платная для каждого маршрута.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-161">hello NYC Taxi Trip data is about 20 GB of compressed comma-separated values (CSV) files (~48 GB uncompressed), comprising more than 173 million individual trips and hello fares paid for each trip.</span></span> <span data-ttu-id="dcf1e-162">Каждой записи маршрута включены отгрузки hello и истощение и времени, анонимные hack (драйвер) номер соглашения и номер medallion (уникальный идентификатор элемента такси).</span><span class="sxs-lookup"><span data-stu-id="dcf1e-162">Each trip record includes hello pick up and drop-off location and time, anonymized hack (driver's) license number and medallion (taxi’s unique id) number.</span></span> <span data-ttu-id="dcf1e-163">данные Hello охватывает все приема-передачи в 2013 году, hello и предоставляется в следующих двух наборов данных для каждого месяца hello:</span><span class="sxs-lookup"><span data-stu-id="dcf1e-163">hello data covers all trips in hello year 2013 and is provided in hello following two datasets for each month:</span></span>

1. <span data-ttu-id="dcf1e-164">Hello «trip_data» CSV-файлы содержат обработки таких сведений, как количество пассажиров, взять и указывает dropoff, быть длительность и длина пути.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-164">hello 'trip_data' CSV files contain trip details, such as number of passengers, pick up and dropoff points, trip duration, and trip length.</span></span> <span data-ttu-id="dcf1e-165">Вот несколько примеров записей:</span><span class="sxs-lookup"><span data-stu-id="dcf1e-165">Here are a few sample records:</span></span>
   
        medallion,hack_license,vendor_id,rate_code,store_and_fwd_flag,pickup_datetime,dropoff_datetime,passenger_count,trip_time_in_secs,trip_distance,pickup_longitude,pickup_latitude,dropoff_longitude,dropoff_latitude
        89D227B655E5C82AECF13C3F540D4CF4,BA96DE419E711691B9445D6A6307C170,CMT,1,N,2013-01-01 15:11:48,2013-01-01 15:18:10,4,382,1.00,-73.978165,40.757977,-73.989838,40.751171
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,1,N,2013-01-06 00:18:35,2013-01-06 00:22:54,1,259,1.50,-74.006683,40.731781,-73.994499,40.75066
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,1,N,2013-01-05 18:49:41,2013-01-05 18:54:23,1,282,1.10,-74.004707,40.73777,-74.009834,40.726002
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,1,N,2013-01-07 23:54:15,2013-01-07 23:58:20,2,244,.70,-73.974602,40.759945,-73.984734,40.759388
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,1,N,2013-01-07 23:25:03,2013-01-07 23:34:24,1,560,2.10,-73.97625,40.748528,-74.002586,40.747868
2. <span data-ttu-id="dcf1e-166">CSV-файлы «trip_fare» Hello содержат подробные сведения о тариф авиакомпании hello платная для каждого маршрута, например тип платежа, сумма тариф авиакомпании, излишнюю нагрузку налоги, советы и тарифы и hello общей оплаты.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-166">hello 'trip_fare' CSV files contain details of hello fare paid for each trip, such as payment type, fare amount, surcharge and taxes, tips and tolls, and hello total amount paid.</span></span> <span data-ttu-id="dcf1e-167">Вот несколько примеров записей:</span><span class="sxs-lookup"><span data-stu-id="dcf1e-167">Here are a few sample records:</span></span>
   
        medallion, hack_license, vendor_id, pickup_datetime, payment_type, fare_amount, surcharge, mta_tax, tip_amount, tolls_amount, total_amount
        89D227B655E5C82AECF13C3F540D4CF4,BA96DE419E711691B9445D6A6307C170,CMT,2013-01-01 15:11:48,CSH,6.5,0,0.5,0,0,7
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,2013-01-06 00:18:35,CSH,6,0.5,0.5,0,0,7
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,2013-01-05 18:49:41,CSH,5.5,1,0.5,0,0,7
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,2013-01-07 23:54:15,CSH,5,0.5,0.5,0,0,6
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,2013-01-07 23:25:03,CSH,9.5,0.5,0.5,0,0,10.5

<span data-ttu-id="dcf1e-168">Образец 0,1% эти файлы и присоединены к домену hello trip перешли\_данных и обработки\_успешного CVS файлы в toouse один набор данных как hello входного набора данных в этом пошаговом руководстве.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-168">We have taken a 0.1% sample of these files and joined hello trip\_data and trip\_fare CVS files into a single dataset toouse as hello input dataset for this walkthrough.</span></span> <span data-ttu-id="dcf1e-169">Hello trip уникальных ключей toojoin\_данных и обработки\_тариф авиакомпании состоит из полей hello: medallion hack\_лицензии и раскладки\_даты и времени.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-169">hello unique key toojoin trip\_data and trip\_fare is composed of hello fields: medallion, hack\_licence and pickup\_datetime.</span></span> <span data-ttu-id="dcf1e-170">Каждая запись hello набор данных содержит следующие атрибуты, представляющий маршрут такси NYC hello:</span><span class="sxs-lookup"><span data-stu-id="dcf1e-170">Each record of hello dataset contains hello following attributes representing a NYC Taxi trip:</span></span>

| <span data-ttu-id="dcf1e-171">Поле</span><span class="sxs-lookup"><span data-stu-id="dcf1e-171">Field</span></span> | <span data-ttu-id="dcf1e-172">Краткое описание</span><span class="sxs-lookup"><span data-stu-id="dcf1e-172">Brief Description</span></span> |
| --- | --- |
| <span data-ttu-id="dcf1e-173">medallion</span><span class="sxs-lookup"><span data-stu-id="dcf1e-173">medallion</span></span> |<span data-ttu-id="dcf1e-174">Обезличенный медальон такси (уникальный идентификатор такси)</span><span class="sxs-lookup"><span data-stu-id="dcf1e-174">Anonymized taxi medallion (unique taxi id)</span></span> |
| <span data-ttu-id="dcf1e-175">hack_license</span><span class="sxs-lookup"><span data-stu-id="dcf1e-175">hack_license</span></span> |<span data-ttu-id="dcf1e-176">Обезличенный номер лицензии такси</span><span class="sxs-lookup"><span data-stu-id="dcf1e-176">Anonymized Hackney Carriage License number</span></span> |
| <span data-ttu-id="dcf1e-177">vendor_id</span><span class="sxs-lookup"><span data-stu-id="dcf1e-177">vendor_id</span></span> |<span data-ttu-id="dcf1e-178">Идентификатор поставщика услуг такси</span><span class="sxs-lookup"><span data-stu-id="dcf1e-178">Taxi vendor id</span></span> |
| <span data-ttu-id="dcf1e-179">rate_code</span><span class="sxs-lookup"><span data-stu-id="dcf1e-179">rate_code</span></span> |<span data-ttu-id="dcf1e-180">Тариф на такси в Нью-Йорке</span><span class="sxs-lookup"><span data-stu-id="dcf1e-180">NYC taxi rate of fare</span></span> |
| <span data-ttu-id="dcf1e-181">store_and_fwd_flag</span><span class="sxs-lookup"><span data-stu-id="dcf1e-181">store_and_fwd_flag</span></span> |<span data-ttu-id="dcf1e-182">Отметка записи и дальнейшей передачи</span><span class="sxs-lookup"><span data-stu-id="dcf1e-182">Store and forward flag</span></span> |
| <span data-ttu-id="dcf1e-183">pickup_datetime</span><span class="sxs-lookup"><span data-stu-id="dcf1e-183">pickup_datetime</span></span> |<span data-ttu-id="dcf1e-184">Дата и время посадки пассажира</span><span class="sxs-lookup"><span data-stu-id="dcf1e-184">Pick up date & time</span></span> |
| <span data-ttu-id="dcf1e-185">dropoff_datetime</span><span class="sxs-lookup"><span data-stu-id="dcf1e-185">dropoff_datetime</span></span> |<span data-ttu-id="dcf1e-186">Дата и время высадки пассажира</span><span class="sxs-lookup"><span data-stu-id="dcf1e-186">Dropoff date & time</span></span> |
| <span data-ttu-id="dcf1e-187">pickup_hour</span><span class="sxs-lookup"><span data-stu-id="dcf1e-187">pickup_hour</span></span> |<span data-ttu-id="dcf1e-188">Час посадки пассажира</span><span class="sxs-lookup"><span data-stu-id="dcf1e-188">Pick up hour</span></span> |
| <span data-ttu-id="dcf1e-189">pickup_week</span><span class="sxs-lookup"><span data-stu-id="dcf1e-189">pickup_week</span></span> |<span data-ttu-id="dcf1e-190">Взять неделя года hello</span><span class="sxs-lookup"><span data-stu-id="dcf1e-190">Pick up week of hello year</span></span> |
| <span data-ttu-id="dcf1e-191">weekday</span><span class="sxs-lookup"><span data-stu-id="dcf1e-191">weekday</span></span> |<span data-ttu-id="dcf1e-192">День недели (диапазон 1–7)</span><span class="sxs-lookup"><span data-stu-id="dcf1e-192">Weekday (range 1-7)</span></span> |
| <span data-ttu-id="dcf1e-193">passenger_count</span><span class="sxs-lookup"><span data-stu-id="dcf1e-193">passenger_count</span></span> |<span data-ttu-id="dcf1e-194">Количество пассажиров во время поездки на такси</span><span class="sxs-lookup"><span data-stu-id="dcf1e-194">Number of passengers in a taxi trip</span></span> |
| <span data-ttu-id="dcf1e-195">trip_time_in_secs</span><span class="sxs-lookup"><span data-stu-id="dcf1e-195">trip_time_in_secs</span></span> |<span data-ttu-id="dcf1e-196">Длительность поездки в секундах</span><span class="sxs-lookup"><span data-stu-id="dcf1e-196">Trip time in seconds</span></span> |
| <span data-ttu-id="dcf1e-197">trip_distance</span><span class="sxs-lookup"><span data-stu-id="dcf1e-197">trip_distance</span></span> |<span data-ttu-id="dcf1e-198">Расстояние поездки в милях</span><span class="sxs-lookup"><span data-stu-id="dcf1e-198">Trip distance traveled in miles</span></span> |
| <span data-ttu-id="dcf1e-199">pickup_longitude</span><span class="sxs-lookup"><span data-stu-id="dcf1e-199">pickup_longitude</span></span> |<span data-ttu-id="dcf1e-200">Долгота места посадки пассажира</span><span class="sxs-lookup"><span data-stu-id="dcf1e-200">Pick up longitude</span></span> |
| <span data-ttu-id="dcf1e-201">pickup_latitude</span><span class="sxs-lookup"><span data-stu-id="dcf1e-201">pickup_latitude</span></span> |<span data-ttu-id="dcf1e-202">Широта места посадки пассажира</span><span class="sxs-lookup"><span data-stu-id="dcf1e-202">Pick up latitude</span></span> |
| <span data-ttu-id="dcf1e-203">dropoff_longitude</span><span class="sxs-lookup"><span data-stu-id="dcf1e-203">dropoff_longitude</span></span> |<span data-ttu-id="dcf1e-204">Долгота высадки пассажира</span><span class="sxs-lookup"><span data-stu-id="dcf1e-204">Dropoff longitude</span></span> |
| <span data-ttu-id="dcf1e-205">dropoff_latitude</span><span class="sxs-lookup"><span data-stu-id="dcf1e-205">dropoff_latitude</span></span> |<span data-ttu-id="dcf1e-206">Широта высадки пассажира</span><span class="sxs-lookup"><span data-stu-id="dcf1e-206">Dropoff latitude</span></span> |
| <span data-ttu-id="dcf1e-207">direct_distance</span><span class="sxs-lookup"><span data-stu-id="dcf1e-207">direct_distance</span></span> |<span data-ttu-id="dcf1e-208">Расстояние по прямой между местами посадки и высадки</span><span class="sxs-lookup"><span data-stu-id="dcf1e-208">Direct distance between pick up and dropoff locations</span></span> |
| <span data-ttu-id="dcf1e-209">payment_type</span><span class="sxs-lookup"><span data-stu-id="dcf1e-209">payment_type</span></span> |<span data-ttu-id="dcf1e-210">Тип оплаты (наличные, кредитная карта и т. д.)</span><span class="sxs-lookup"><span data-stu-id="dcf1e-210">Payment type (cas, credit-card etc.)</span></span> |
| <span data-ttu-id="dcf1e-211">fare_amount</span><span class="sxs-lookup"><span data-stu-id="dcf1e-211">fare_amount</span></span> |<span data-ttu-id="dcf1e-212">Сумма к оплате</span><span class="sxs-lookup"><span data-stu-id="dcf1e-212">Fare amount in</span></span> |
| <span data-ttu-id="dcf1e-213">surcharge</span><span class="sxs-lookup"><span data-stu-id="dcf1e-213">surcharge</span></span> |<span data-ttu-id="dcf1e-214">Доплата</span><span class="sxs-lookup"><span data-stu-id="dcf1e-214">Surcharge</span></span> |
| <span data-ttu-id="dcf1e-215">mta_tax</span><span class="sxs-lookup"><span data-stu-id="dcf1e-215">mta_tax</span></span> |<span data-ttu-id="dcf1e-216">Налог MTA</span><span class="sxs-lookup"><span data-stu-id="dcf1e-216">Mta tax</span></span> |
| <span data-ttu-id="dcf1e-217">tip_amount</span><span class="sxs-lookup"><span data-stu-id="dcf1e-217">tip_amount</span></span> |<span data-ttu-id="dcf1e-218">Сумма чаевых</span><span class="sxs-lookup"><span data-stu-id="dcf1e-218">Tip amount</span></span> |
| <span data-ttu-id="dcf1e-219">tolls_amount</span><span class="sxs-lookup"><span data-stu-id="dcf1e-219">tolls_amount</span></span> |<span data-ttu-id="dcf1e-220">Дорожные пошлины</span><span class="sxs-lookup"><span data-stu-id="dcf1e-220">Tolls amount</span></span> |
| <span data-ttu-id="dcf1e-221">total_amount</span><span class="sxs-lookup"><span data-stu-id="dcf1e-221">total_amount</span></span> |<span data-ttu-id="dcf1e-222">Общая сумма</span><span class="sxs-lookup"><span data-stu-id="dcf1e-222">Total amount</span></span> |
| <span data-ttu-id="dcf1e-223">tipped</span><span class="sxs-lookup"><span data-stu-id="dcf1e-223">tipped</span></span> |<span data-ttu-id="dcf1e-224">Чаевые (0 — нет, 1 — да)</span><span class="sxs-lookup"><span data-stu-id="dcf1e-224">Tipped (0/1 for no or yes)</span></span> |
| <span data-ttu-id="dcf1e-225">tip_class</span><span class="sxs-lookup"><span data-stu-id="dcf1e-225">tip_class</span></span> |<span data-ttu-id="dcf1e-226">Класс чаевых (0: 0 долларов, 1: 0–5 долларов, 2: 6–10 долларов, 3: 11–20 долларов, 4: >20 долларов)</span><span class="sxs-lookup"><span data-stu-id="dcf1e-226">Tip class (0: $0, 1: $0-5, 2: $6-10, 3: $11-20, 4: > $20)</span></span> |

## <a name="execute-code-from-a-jupyter-notebook-on-hello-spark-cluster"></a><span data-ttu-id="dcf1e-227">Выполнять код из записной книжке Jupyter на кластере Spark hello</span><span class="sxs-lookup"><span data-stu-id="dcf1e-227">Execute code from a Jupyter notebook on hello Spark cluster</span></span>
<span data-ttu-id="dcf1e-228">Вы можете запустить hello книжке Jupyter из hello портал Azure.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-228">You can launch hello Jupyter Notebook from hello Azure portal.</span></span> <span data-ttu-id="dcf1e-229">Найдите свой кластер Spark на информационной панели и щелкните его tooenter страницы управления для кластера.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-229">Find your Spark cluster on your dashboard and click it tooenter management page for your cluster.</span></span> <span data-ttu-id="dcf1e-230">Щелкните записной книжки tooopen hello, связанные с кластера Spark hello, **панели мониторинга кластера** -> **книжке Jupyter** .</span><span class="sxs-lookup"><span data-stu-id="dcf1e-230">tooopen hello notebook associated with hello Spark cluster, click **Cluster Dashboards** -> **Jupyter Notebook** .</span></span>

![Панели мониторинга кластера](./media/machine-learning-data-science-spark-overview/spark-jupyter-on-portal.png)

<span data-ttu-id="dcf1e-232">Можно также просмотреть слишком***https://CLUSTERNAME.azurehdinsight.net/jupyter*** tooaccess hello записные книжки Jupyter.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-232">You can also browse too***https://CLUSTERNAME.azurehdinsight.net/jupyter*** tooaccess hello Jupyter Notebooks.</span></span> <span data-ttu-id="dcf1e-233">Замените этот URL-адресе ИМЯ_КЛАСТЕРА hello hello имя свой кластер.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-233">Replace hello CLUSTERNAME part of this URL with hello name of your own cluster.</span></span> <span data-ttu-id="dcf1e-234">Вам необходим пароль hello для записных книжек hello tooaccess учетной записи администратора.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-234">You need hello password for your admin account tooaccess hello notebooks.</span></span>

![Просмотр записных книжек Jupyter](./media/machine-learning-data-science-spark-overview/spark-jupyter-notebook.png)

<span data-ttu-id="dcf1e-236">Выберите PySpark toosee каталога, который содержит несколько примеров предварительно упакованные ноутбуки, использующие hello PySpark API.hello портативные компьютеры, содержащие hello образцы кода для этого набора Spark раздела можно найти по адресу [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark)</span><span class="sxs-lookup"><span data-stu-id="dcf1e-236">Select PySpark toosee a directory that contains a few examples of pre-packaged notebooks that use hello PySpark API.hello notebooks that contain hello code samples for this suite of Spark topic are available at [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark)</span></span>

<span data-ttu-id="dcf1e-237">Вы можете отправить записных книжек hello непосредственно из [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark) блокнота jupyter toohello на кластере Spark.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-237">You can upload hello notebooks directly from [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark) toohello Jupyter notebook server on your Spark cluster.</span></span> <span data-ttu-id="dcf1e-238">На домашней странице hello вашей Jupyter, нажмите кнопку hello **отправить** кнопку в правой части экрана приветствия hello.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-238">On hello home page of your Jupyter, click hello **Upload** button on hello right part of hello screen.</span></span> <span data-ttu-id="dcf1e-239">Откроется окно проводника.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-239">It opens a file explorer.</span></span> <span data-ttu-id="dcf1e-240">Здесь можно вставить hello GitHub (необработанное содержимое) URL-адрес hello записной книжки и нажмите кнопку **откройте**.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-240">Here you can paste hello GitHub (raw content) URL of hello Notebook and click **Open**.</span></span> 

<span data-ttu-id="dcf1e-241">Вы увидите hello имя файла в список файлов Jupyter с **отправить** еще раз.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-241">You see hello file name on your Jupyter file list with an **Upload** button again.</span></span> <span data-ttu-id="dcf1e-242">Нажмите кнопку **Отправить** .</span><span class="sxs-lookup"><span data-stu-id="dcf1e-242">Click this **Upload** button.</span></span> <span data-ttu-id="dcf1e-243">Теперь импорта записной книжки hello.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-243">Now you have imported hello notebook.</span></span> <span data-ttu-id="dcf1e-244">Повторите эти шаги tooupload hello других записных книжек из этого пошагового руководства.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-244">Repeat these steps tooupload hello other notebooks from this walkthrough.</span></span>

> [!TIP]
> <span data-ttu-id="dcf1e-245">Щелкнуть правой кнопкой мыши hello ссылок в браузере и выберите **Копировать ссылку** tooget hello github необработанный URL-адрес содержимого.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-245">You can right-click hello links on your browser and select **Copy Link** tooget hello github raw content URL.</span></span> <span data-ttu-id="dcf1e-246">Этот URL-адрес можно вставить в hello отправить Jupyter explorer диалоговое окно файла.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-246">You can paste this URL into hello Jupyter Upload file explorer dialog box.</span></span>
> 
> 

<span data-ttu-id="dcf1e-247">Теперь вы можете:</span><span class="sxs-lookup"><span data-stu-id="dcf1e-247">Now you can:</span></span>

* <span data-ttu-id="dcf1e-248">Просмотреть кода hello, щелкнув записной книжки hello.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-248">See hello code by clicking hello notebook.</span></span>
* <span data-ttu-id="dcf1e-249">выполнить отдельную ячейку, нажав клавиши **SHIFT+ВВОД**;</span><span class="sxs-lookup"><span data-stu-id="dcf1e-249">Execute each cell by pressing **SHIFT-ENTER**.</span></span>
* <span data-ttu-id="dcf1e-250">Запустите всей записной книжки hello, щелкнув **ячейки** -> **запуска**.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-250">Run hello entire notebook by clicking on **Cell** -> **Run**.</span></span>
* <span data-ttu-id="dcf1e-251">Используйте автоматическое визуализацию hello запросов.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-251">Use hello automatic visualization of queries.</span></span>

> [!TIP]
> <span data-ttu-id="dcf1e-252">Hello PySpark ядра автоматически визуализирует hello вывод запросов SQL (HiveQL).</span><span class="sxs-lookup"><span data-stu-id="dcf1e-252">hello PySpark kernel automatically visualizes hello output of SQL (HiveQL) queries.</span></span> <span data-ttu-id="dcf1e-253">Hello tooselect вариант среди различных типов визуализации (таблицы, круговая, строки, области или панели), получают с помощью hello **тип** кнопок меню в записной книжке hello:</span><span class="sxs-lookup"><span data-stu-id="dcf1e-253">You are given hello option tooselect among several different types of visualizations (Table, Pie, Line, Area, or Bar) by using hello **Type** menu buttons in hello notebook:</span></span>
> 
> 

![Кривая ROC логистической регрессии для универсального подхода](./media/machine-learning-data-science-spark-overview/pyspark-jupyter-autovisualization.png)

## <a name="whats-next"></a><span data-ttu-id="dcf1e-255">Что дальше?</span><span class="sxs-lookup"><span data-stu-id="dcf1e-255">What's next?</span></span>
<span data-ttu-id="dcf1e-256">Теперь, настраиваются с кластером HDInsight Spark и переданы записные книжки Jupyter hello, все готово toowork через hello разделы, соответствующие toohello три PySpark блокнота.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-256">Now that you are set up with an HDInsight Spark cluster and have uploaded hello Jupyter notebooks, you are ready toowork through hello topics that correspond toohello three PySpark notebooks.</span></span> <span data-ttu-id="dcf1e-257">Они показывают как tooexplore данных и как затем toocreate и использования моделей.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-257">They show how tooexplore your data and then how toocreate and consume models.</span></span> <span data-ttu-id="dcf1e-258">Расширенный просмотр данных и моделирование записной книжки показано как Hello tooinclude свертки перекрестной проверки, hyper параметр и вычисления моделей.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-258">hello advanced data exploration and modeling notebook shows how tooinclude cross-validation, hyper-parameter sweeping, and model evaluation.</span></span> 

<span data-ttu-id="dcf1e-259">**Просмотр данных и моделирование с помощью Spark:** изучение набора данных hello и создать, оценки и оценивать hello моделей машинного обучения, прохождение hello [создания двоичных классификационных и регрессионных моделей данных с hello Spark Набор средств MLlib](machine-learning-data-science-spark-data-exploration-modeling.md) раздела.</span><span class="sxs-lookup"><span data-stu-id="dcf1e-259">**Data Exploration and modeling with Spark:** Explore hello dataset and create, score, and evaluate hello machine learning models by working through hello [Create binary classification and regression models for data with hello Spark MLlib toolkit](machine-learning-data-science-spark-data-exploration-modeling.md) topic.</span></span>

<span data-ttu-id="dcf1e-260">**Модели потребления:** toolearn tooscore hello классификационных и регрессионных моделей создан в этом разделе в статье [оценка и оценки моделей построен Spark машинного обучения](machine-learning-data-science-spark-model-consumption.md).</span><span class="sxs-lookup"><span data-stu-id="dcf1e-260">**Model consumption:** toolearn how tooscore hello classification and regression models created in this topic, see [Score and evaluate Spark-built machine learning models](machine-learning-data-science-spark-model-consumption.md).</span></span>

<span data-ttu-id="dcf1e-261">**Перекрестная проверка и перебор гиперпараметров**. Сведения об обучении моделей с помощью перекрестной проверки и перебора гиперпараметров см. в статье [Расширенное исследование и моделирование данных с помощью Spark](machine-learning-data-science-spark-advanced-data-exploration-modeling.md).</span><span class="sxs-lookup"><span data-stu-id="dcf1e-261">**Cross-validation and hyperparameter sweeping**: See [Advanced data exploration and modeling with Spark](machine-learning-data-science-spark-advanced-data-exploration-modeling.md) on how models can be trained using cross-validation and hyper-parameter sweeping</span></span>

