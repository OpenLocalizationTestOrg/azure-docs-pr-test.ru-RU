---
title: "Очистка и подготовка данных для Машинного обучения Azure | Документация Майкрософт"
description: "Предварительная обработка и очистка данных для подготовки к машинному обучению."
services: machine-learning
documentationcenter: 
author: bradsev
manager: jhubbard
editor: cgronlun
ms.assetid: bdf659ec-4881-4324-8b9c-747cbfa0c3cd
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 01/29/2017
ms.author: bradsev
ms.openlocfilehash: cfaccad0a7d81950d80486dcb0d9e6520deab9b3
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 07/11/2017
---
# <a name="tasks-to-prepare-data-for-enhanced-machine-learning"></a>Задачи по подготовке данных для расширенного машинного обучения
Предварительная обработка и очистка данных — это важные этапы, обеспечивающие эффективное использование набора данных для машинного обучения. Необработанные данные зачастую искажены и ненадежны, и в них могут быть пропущены значения. Использование таких данных при моделировании может приводить к неверным результатам. Эти задачи являются частью процесса обработки и анализа данных группы и обычно подразумевают первоначальное изучение набора данных, используемого для определения и планирования необходимой предварительной обработки. Более подробные инструкции по процессу TDSP см. в процедуре, описанной в статье [Процесс обработки и анализа данных группы](https://azure.microsoft.com/documentation/learning-paths/cortana-analytics-process/).

Задачи предварительной обработки и очистки данных, например задача изучения данных, могут быть выполнены в самых разнообразных средах, таких как SQL, Hive или Студия машинного обучения Azure, и с помощью различных средств и языков, таких как R или Python, в зависимости от того, где хранятся данные и как они отформатированы. Так как по своей природе процесс TDSP является итеративным, эти задачи могут выполняться на различных этапах рабочего процесса.

В этой статье рассматриваются разные концепции и принципы обработки данных, которые могут применяться как перед использованием данных в машинном обучении Azure, так и после него.

Пример просмотра и предварительной обработки данных в Студии машинного обучения Azure см. в [этом видеоролике](https://azure.microsoft.com/documentation/videos/preprocessing-data-in-azure-ml-studio/).

## <a name="why-pre-process-and-clean-data"></a>Зачем нужна предварительная обработка и очистка данных?
Реальные данные собираются для последующей обработки из разных источников и процессов. Они могут содержать ошибки и повреждения, негативно влияющие на качество набора данных. Вот какими могут быть типичные проблемы с качеством данных:

* **Неполнота**: данные не содержат атрибутов, или в них пропущены значения.
* **Шум**: данные содержат ошибочные записи или выбросы.
* **Несогласованность**: данные содержат конфликтующие между собой записи или расхождения.

Качественные данные — это необходимое условие для создания качественных моделей прогнозирования. Чтобы избежать появления ситуации «мусор на входе, мусор на выходе» и повысить качество данных и, как следствие, эффективность модели, необходимо провести мониторинг работоспособности данных, как можно раньше обнаружить проблемы и решить, какие действия по предварительной обработке и очистке данных необходимы.

## <a name="what-are-some-typical-data-health-screens-that-are-employed"></a>Какие есть стандартные методы мониторинга работоспособности данных
Вот что нужно оценить, чтобы проверить качество данных:

* Количество **записей**.
* количество **атрибутов** (или **компонентов**);
* **Типы данных** атрибута (номинальные, порядковые или непрерывные).
* Количество **пропущенных значений**.
* **Правильность формата** данных.
  * Если данные имеют формат TSV или CSV, проверьте правильность разделения столбцов и строк соответствующими разделителями.
  * Если данные имеют формат HTML или XML, убедитесь, что формат данных соответствует надлежащим стандартам.
  * Для извлечения структурированной информации из частично структурированных или неструктурированных данных также может потребоваться синтаксический анализ.
* **Несогласованные записи данных**. Проверьте допустимость диапазона значений. Например, если данные содержат средний балл ученика, проверьте, находится ли этот средний балл в обозначенном диапазоне (например, 0~4).

При обнаружении проблем с данными необходимо выполнить **обработку** , которая зачастую включает очистку пропущенных значений, нормализацию данных, дискретизацию, обработку текста для удаления и/или замены внедренных символов, которые могут влиять на выравнивание данных, смешанные типы данных в общих полях и пр.

**В машинном обучении Azure используются табличные данные правильного формата**.  Если данные уже представлены в табличной форме, то вы можете провести их предварительную обработку с помощью Машинного обучения Azure прямо в Студии машинного обучения.  Если данные находятся не в табличной форме, а, например, в формате XML, для их преобразования в табличную форму может потребоваться синтаксический анализ.  

## <a name="what-are-some-of-the-major-tasks-in-data-pre-processing"></a>Каковы главные задачи предварительной обработки данных
* **Очистка данных** — восполнение пропущенных значений, обнаружение и удаление искаженных данных и выбросов.
* **Преобразование данных** — нормализация данных для снижения измерений и искажений.
* **Уплотнение данных** — создание выборки данных или атрибутов для упрощения обработки данных.
* **Дискретизация данных** — преобразование непрерывных атрибутов в категориальные, чтобы проще было использовать некоторые методы машинного обучения.
* **Очистка текста**: удаление внедренных символов, которые могут нарушать выравнивание данных, например внедренных символов табуляции в файле с разделителем-табуляцией, внедренных новых линий, которые могут разбивать записи, и пр.

В следующем разделе описаны некоторые шаги предварительной обработки данных.

## <a name="how-to-deal-with-missing-values"></a>Как обрабатывать пропущенные значения
При работе с пропущенными значениями лучше сначала определить причину их появления в данных, что поможет решить проблему. Вот какие бывает методы обработки пропущенных значений:

* **Удаление**: удаление записей с пропущенными значениями.
* **Фиктивная подстановка** — замена пропущенных значений фиктивными, например подстановка значения *unknown* (неизвестно) вместо категориальных или значения 0 вместо чисел.
* **Подстановка среднего значения**: пропущенные числовые данные можно заменить средним значением.
* **Подстановка часто используемого элемента**: пропущенные категориальные значения можно заменить наиболее часто используемым элементом.
* **Подстановка по регрессии**: использование регрессионного метода для замены пропущенных значений регрессионными.  

## <a name="how-to-normalize-data"></a>Как нормализовать данные
Нормализация данных позволяет масштабировать числовые значения в указанном диапазоне. Ниже представлены распространенные методы нормализации данных.

* **Нормализация по методу минимакса**: линейное преобразование данных в диапазоне, например, от 0 до 1, где минимальное и максимальное масштабируемые значения соответствуют 0 и 1 соответственно.
* **Нормализация по Z-показателю**: масштабирование данных на основе среднего значения и стандартного отклонения: деление разницы между данными и средним значением на стандартное отклонение.
* **Десятичное масштабирование**: масштабирование данных путем удаления десятичного разделителя значения атрибута.  

## <a name="how-to-discretize-data"></a>Как дискретизировать данные
Данные можно дискретизировать, преобразовав непрерывные значения в номинальные атрибуты или интервалы. Это можно сделать несколькими способами.

* **Группирование равной ширины**: разделение диапазона всех возможных значений атрибута в группы (N) одинакового размера с последующим присвоением значений, относящихся к ячейке с соответствующим номером.
* **Группирование равной высоты**: разделение всех возможных значений атрибута в группы (N), содержащие одинаковое количество экземпляров, с последующим присвоением значений, относящихся к ячейке с соответствующим номером.  

## <a name="how-to-reduce-data"></a>Как сократить объем данных
Существуют различные методы, с помощью которых вы можете уменьшить размер данных для упрощения обработки данных. В зависимости от размера данных и домена вы можете применить такие методы:

* **Выборка записей**: создание выборки записей данных и выбор репрезентативного подмножества из общего набора данных.
* **Выборка атрибутов**: выбор в данных набора важнейших атрибутов.  
* **Агрегирование**: разделение данных на группы и хранение числовых значений для каждой группы. Например, для уменьшения размера данных вы можете агрегировать числа, обозначающие ежедневный доход сети ресторанов за последние 20 лет, так, чтобы указывался ежемесячный доход.  

## <a name="how-to-clean-text-data"></a>Как очистить данные
**Текстовые поля в табличных данных** могут содержать символы, сбивающие выравнивание столбцов или границы записей (или и то и другое вместе). Например, табуляции, внедренные в файл с разделителем-табуляцией, могут сбить выравнивание столбцов, а внедренные символы новой строки могут разорвать линии записей. Неправильная кодировка текста приводит при его чтении или записи к потере информации, появлению нечитаемых символов, например нуль-символов, и может также помешать разбору текста. Чтобы очистить текстовые поля, исправить выравнивание и извлечь структурированные текстовые данные из неструктурированных или полу-структурированных, могут потребоваться тщательные разбор и редактирование текста.

**Функция просмотра данных** позволяет ознакомиться с данными заблаговременно. Это поможет вам выявить те или иные проблемы с данными и применить соответствующие методы для решения этих проблем.  Важно понимать, что породило проблемы, как они могли появиться. Это поможет решить, к каким действиям по обработке данных нужно прибегнуть для устранения проблем. Подробности, которые, работая с данными, вы стремитесь получить, вы можете использовать для того, чтобы назначить обработке данных приоритет.

## <a name="references"></a>Ссылки
> *Интеллектуальный анализ данных: концепции и методы.* Издание третье, Morgan Kaufmann Publishers, 2011. Цзявей Хань (Jiawei Han), Мишлин Кэмбер (Micheline Kamber) и Цзянь Пей (Jian Pei)
> 
> 

