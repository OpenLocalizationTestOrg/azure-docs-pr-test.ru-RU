---
title: "Выбор алгоритмов машинного обучения | Документация Майкрософт"
description: "Как выбрать алгоритмы машинного обучения Azure для контролируемого и неконтролируемого обучения в экспериментах кластеризации, классификации или регрессии."
services: machine-learning
documentationcenter: 
author: garyericson
manager: jhubbard
editor: cgronlun
tags: 
ms.assetid: a3b23d7f-f083-49c4-b6b1-3911cd69f1b4
ms.service: machine-learning
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: data-services
ms.date: 04/25/2017
ms.author: garye
ms.openlocfilehash: e7e912f1b9bb57c1e23d10c49216f7d7b4fe4690
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 07/11/2017
---
# <a name="how-to-choose-algorithms-for-microsoft-azure-machine-learning"></a><span data-ttu-id="91d25-103">Выбор алгоритмов машинного обучения Microsoft Azure</span><span class="sxs-lookup"><span data-stu-id="91d25-103">How to choose algorithms for Microsoft Azure Machine Learning</span></span>
<span data-ttu-id="91d25-104">Ответ на вопрос "Какие алгоритмы машинного обучения использовать?"</span><span class="sxs-lookup"><span data-stu-id="91d25-104">The answer to the question "What machine learning algorithm should I use?"</span></span> <span data-ttu-id="91d25-105">всегда звучит так: "Это зависит от ряда обстоятельств".</span><span class="sxs-lookup"><span data-stu-id="91d25-105">is always "It depends."</span></span> <span data-ttu-id="91d25-106">Это зависит от размера, качества и природы данных.</span><span class="sxs-lookup"><span data-stu-id="91d25-106">It depends on the size, quality, and nature of the data.</span></span> <span data-ttu-id="91d25-107">Это зависит от того, что нужно сделать с ответом.</span><span class="sxs-lookup"><span data-stu-id="91d25-107">It depends on what you want to do with the answer.</span></span> <span data-ttu-id="91d25-108">Это зависит от того, как математический алгоритм был преобразован в инструкции для вашего компьютера.</span><span class="sxs-lookup"><span data-stu-id="91d25-108">It depends on how the math of the algorithm was translated into instructions for the computer you are using.</span></span> <span data-ttu-id="91d25-109">И это зависит от того, сколько времени у вас есть.</span><span class="sxs-lookup"><span data-stu-id="91d25-109">And it depends on how much time you have.</span></span> <span data-ttu-id="91d25-110">Даже самые опытные специалисты по данным не смогут определить наилучший алгоритм, не попробовав его.</span><span class="sxs-lookup"><span data-stu-id="91d25-110">Even the most experienced data scientists can't tell which algorithm will perform best before trying them.</span></span>

## <a name="the-machine-learning-algorithm-cheat-sheet"></a><span data-ttu-id="91d25-111">Памятка по алгоритмам машинного обучения</span><span class="sxs-lookup"><span data-stu-id="91d25-111">The Machine Learning Algorithm Cheat Sheet</span></span>
<span data-ttu-id="91d25-112">**Памятка по алгоритмам машинного обучения для Студии машинного обучения Microsoft Azure** поможет выбрать правильный алгоритм из библиотеки алгоритмов машинного обучения Microsoft Azure для решений прогнозной аналитики.</span><span class="sxs-lookup"><span data-stu-id="91d25-112">The **Microsoft Azure Machine Learning Algorithm Cheat Sheet** helps you choose the right machine learning algorithm for your predictive analytics solutions from the Microsoft Azure Machine Learning library of algorithms.</span></span>
<span data-ttu-id="91d25-113">В этой статье описано, как пользоваться памяткой.</span><span class="sxs-lookup"><span data-stu-id="91d25-113">This article walks you through how to use it.</span></span>

> [!NOTE]
> <span data-ttu-id="91d25-114">Чтобы загрузить памятку и последовать указаниям в этой статье, перейдите к разделу [Памятка по алгоритмам машинного обучения для Студии машинного обучения Microsoft Azure](machine-learning-algorithm-cheat-sheet.md).</span><span class="sxs-lookup"><span data-stu-id="91d25-114">To download the cheat sheet and follow along with this article, go to [Machine learning algorithm cheat sheet for Microsoft Azure Machine Learning Studio](machine-learning-algorithm-cheat-sheet.md).</span></span>
> 
> 

<span data-ttu-id="91d25-115">Это памятка рассчитана на очень узкую аудиторию: начинающих специалистов по данным, которые пытаются выбрать алгоритм для начала работы со Студией машинного обучения Microsoft Azure.</span><span class="sxs-lookup"><span data-stu-id="91d25-115">This cheat sheet has a very specific audience in mind: a beginning data scientist with undergraduate-level machine learning, trying to choose an algorithm to start with in Azure Machine Learning Studio.</span></span> <span data-ttu-id="91d25-116">Это означает, что в памятке используются некоторые обобщения и упрощения, но она направит вас в верном направлении.</span><span class="sxs-lookup"><span data-stu-id="91d25-116">That means that it makes some generalizations and oversimplifications, but it points you in a safe direction.</span></span> <span data-ttu-id="91d25-117">Это также означает, что существует множество алгоритмов, которые не описаны в памятке.</span><span class="sxs-lookup"><span data-stu-id="91d25-117">It also means that there are lots of algorithms not listed here.</span></span> <span data-ttu-id="91d25-118">По мере развития машинного обучения Azure и пополнения списка доступных методов мы будем добавлять их в памятку.</span><span class="sxs-lookup"><span data-stu-id="91d25-118">As Azure Machine Learning grows to encompass a more complete set of available methods, we'll add them.</span></span>

<span data-ttu-id="91d25-119">Эти рекомендации представляют собой объединенные отзывы и советы от большого количества специалистов по обработке и анализу данных, а также экспертов по машинному обучению.</span><span class="sxs-lookup"><span data-stu-id="91d25-119">These recommendations are compiled feedback and tips from many data scientists and machine learning experts.</span></span> <span data-ttu-id="91d25-120">Мы достигли соглашения не во всем, но попытались прийти к единому мнению по сложным вопросам.</span><span class="sxs-lookup"><span data-stu-id="91d25-120">We didn't agree on everything, but I've tried to harmonize our opinions into a rough consensus.</span></span> <span data-ttu-id="91d25-121">Большинство инструкций, в которых возникли разногласия, начинаются со слов "Это зависит от..."</span><span class="sxs-lookup"><span data-stu-id="91d25-121">Most of the statements of disagreement begin with "It depends…"</span></span>

### <a name="how-to-use-the-cheat-sheet"></a><span data-ttu-id="91d25-122">Как пользоваться памяткой</span><span class="sxs-lookup"><span data-stu-id="91d25-122">How to use the cheat sheet</span></span>
<span data-ttu-id="91d25-123">Обозначения пути и алгоритма на схеме следует читать как "для *&lt;обозначения пути&gt;* используйте *&lt;алгоритм&gt;*".</span><span class="sxs-lookup"><span data-stu-id="91d25-123">Read the path and algorithm labels on the chart as "For *&lt;path label&gt;*, use *&lt;algorithm&gt;*."</span></span> <span data-ttu-id="91d25-124">Например, "для *скорости* используйте *двухклассную логистическую регрессию*".</span><span class="sxs-lookup"><span data-stu-id="91d25-124">For example, "For *speed*, use *two class logistic regression*."</span></span> <span data-ttu-id="91d25-125">Иногда может использоваться более одной ветви алгоритма.</span><span class="sxs-lookup"><span data-stu-id="91d25-125">Sometimes more than one branch applies.</span></span>
<span data-ttu-id="91d25-126">Иногда ни одна из ветвей алгоритма не подходит идеально.</span><span class="sxs-lookup"><span data-stu-id="91d25-126">Sometimes none of them are a perfect fit.</span></span> <span data-ttu-id="91d25-127">Эти рекомендации приближенные, поэтому не нужно беспокоиться о том, что они не являются точными.</span><span class="sxs-lookup"><span data-stu-id="91d25-127">They're intended to be rule-of-thumb recommendations, so don't worry about it being exact.</span></span>
<span data-ttu-id="91d25-128">Некоторые специалисты по данным, с которыми я общался, говорили, что единственный надежный способ определить наилучший алгоритм — попробовать их все.</span><span class="sxs-lookup"><span data-stu-id="91d25-128">Several data scientists I talked with said that the only sure way to find the very best algorithm is to try all of them.</span></span>

<span data-ttu-id="91d25-129">Ниже приведен пример эксперимента из [коллекции Cortana Intelligence](http://gallery.cortanaintelligence.com/), в котором используется несколько алгоритмов для одних и тех же данных, а затем сравниваются результаты: [Сравнение многоклассовых классификаторов: распознавание букв](http://gallery.cortanaintelligence.com/Details/a635502fc98b402a890efe21cec65b92).</span><span class="sxs-lookup"><span data-stu-id="91d25-129">Here's an example from the [Cortana Intelligence Gallery](http://gallery.cortanaintelligence.com/) of an experiment that tries several algorithms against the same data and compares the results: [Compare Multi-class Classifiers: Letter recognition](http://gallery.cortanaintelligence.com/Details/a635502fc98b402a890efe21cec65b92).</span></span>

> [!TIP]
> <span data-ttu-id="91d25-130">Чтобы скачать и распечатать схему, на которой представлены общие возможности Студии машинного обучения, см. [обзорную схему возможностей Студии машинного обучения Azure](machine-learning-studio-overview-diagram.md).</span><span class="sxs-lookup"><span data-stu-id="91d25-130">To download and print a diagram that gives an overview of the capabilities of Machine Learning Studio, see [Overview diagram of Azure Machine Learning Studio capabilities](machine-learning-studio-overview-diagram.md).</span></span>
> 
> 

## <a name="flavors-of-machine-learning"></a><span data-ttu-id="91d25-131">Разновидности машинного обучения</span><span class="sxs-lookup"><span data-stu-id="91d25-131">Flavors of machine learning</span></span>
### <a name="supervised"></a><span data-ttu-id="91d25-132">Контролируемое</span><span class="sxs-lookup"><span data-stu-id="91d25-132">Supervised</span></span>
<span data-ttu-id="91d25-133">Контролируемые алгоритмы обучения выполняют прогнозирование на основе набора примеров.</span><span class="sxs-lookup"><span data-stu-id="91d25-133">Supervised learning algorithms make predictions based on a set of examples.</span></span> <span data-ttu-id="91d25-134">Например, стоимость акций в прошлом позволяет предположить стоимость акций в будущем.</span><span class="sxs-lookup"><span data-stu-id="91d25-134">For instance, historical stock prices can be used to hazard guesses at future prices.</span></span> <span data-ttu-id="91d25-135">Каждый пример, используемый для обучения, помечается интересующим нас значением — в данном случае это стоимость акций.</span><span class="sxs-lookup"><span data-stu-id="91d25-135">Each example used for training is labeled with the value of interest—in this case the stock price.</span></span> <span data-ttu-id="91d25-136">Контролируемый алгоритм обучения выполняет поиск шаблонов в этих значениях.</span><span class="sxs-lookup"><span data-stu-id="91d25-136">A supervised learning algorithm looks for patterns in those value labels.</span></span> <span data-ttu-id="91d25-137">Он может использовать любые соответствующие сведения — день недели, время года, финансовые данные компании, тип отрасли, наличие важных геополитических событий — и каждый алгоритм ищет шаблоны различных типов.</span><span class="sxs-lookup"><span data-stu-id="91d25-137">It can use any information that might be relevant—the day of the week, the season, the company's financial data, the type of industry, the presence of disruptive geopolitical events—and each algorithm looks for different types of patterns.</span></span> <span data-ttu-id="91d25-138">После того как алгоритм обнаружил наилучший шаблон, он может на основе этого шаблона предсказать неразмеченные проверочные данные — завтрашние цены.</span><span class="sxs-lookup"><span data-stu-id="91d25-138">After the algorithm has found the best pattern it can, it uses that pattern to make predictions for unlabeled testing data—tomorrow's prices.</span></span>

<span data-ttu-id="91d25-139">Контролируемое обучение — это популярный и полезный тип машинного обучения.</span><span class="sxs-lookup"><span data-stu-id="91d25-139">Supervised learning is a popular and useful type of machine learning.</span></span> <span data-ttu-id="91d25-140">За одним исключением все модули машинного обучения Azure являются контролируемыми алгоритмами обучения.</span><span class="sxs-lookup"><span data-stu-id="91d25-140">With one exception, all the modules in Azure Machine Learning are supervised learning algorithms.</span></span> <span data-ttu-id="91d25-141">В машинном обучении Azure существует несколько типов контролируемых алгоритмов обучения: классификация, регрессия и обнаружение аномалий.</span><span class="sxs-lookup"><span data-stu-id="91d25-141">There are several specific types of supervised learning that are represented within Azure Machine Learning: classification, regression, and anomaly detection.</span></span>

* <span data-ttu-id="91d25-142">**Классификация**.</span><span class="sxs-lookup"><span data-stu-id="91d25-142">**Classification**.</span></span> <span data-ttu-id="91d25-143">Если данные используются для прогнозирования категории, контролируемое обучение также называется классификацией.</span><span class="sxs-lookup"><span data-stu-id="91d25-143">When the data are being used to predict a category, supervised learning is also called classification.</span></span> <span data-ttu-id="91d25-144">Это происходит, когда рисунок определяется как изображение "кошки" или "собаки".</span><span class="sxs-lookup"><span data-stu-id="91d25-144">This is the case when assigning an image as a picture of either a 'cat' or a 'dog'.</span></span> <span data-ttu-id="91d25-145">При наличии только двух вариантов такая классификация называется **двухклассной** или **биномиальной**.</span><span class="sxs-lookup"><span data-stu-id="91d25-145">When there are only two choices, it's called **two-class** or **binomial classification**.</span></span> <span data-ttu-id="91d25-146">При наличии нескольких категорий, как при прогнозировании победителя турнира NCAA March Madness, классификация называется **многоклассовой**.</span><span class="sxs-lookup"><span data-stu-id="91d25-146">When there are more categories, as when predicting the winner of the NCAA March Madness tournament, this problem is known as **multi-class classification**.</span></span>
* <span data-ttu-id="91d25-147">**Регрессия**.</span><span class="sxs-lookup"><span data-stu-id="91d25-147">**Regression**.</span></span> <span data-ttu-id="91d25-148">При прогнозировании значения, например стоимости акций, контролируемое обучение называется регрессией.</span><span class="sxs-lookup"><span data-stu-id="91d25-148">When a value is being predicted, as with stock prices, supervised learning is called regression.</span></span>
* <span data-ttu-id="91d25-149">**Обнаружение аномалий**.</span><span class="sxs-lookup"><span data-stu-id="91d25-149">**Anomaly detection**.</span></span> <span data-ttu-id="91d25-150">Иногда задача состоит в идентификации точек данных, которые просто являются необычными.</span><span class="sxs-lookup"><span data-stu-id="91d25-150">Sometimes the goal is to identify data points that are simply unusual.</span></span> <span data-ttu-id="91d25-151">Например, при выявлении мошенничества с кредитной картой подозрительными являются любые необычные операции оплаты.</span><span class="sxs-lookup"><span data-stu-id="91d25-151">In fraud detection, for example, any highly unusual credit card spending patterns are suspect.</span></span> <span data-ttu-id="91d25-152">Количество возможных вариантов так велико, а количество известных примеров так мало, что научиться определять мошеннические действия очень трудно.</span><span class="sxs-lookup"><span data-stu-id="91d25-152">The possible variations are so numerous and the training examples so few, that it's not feasible to learn what fraudulent activity looks like.</span></span> <span data-ttu-id="91d25-153">Подход, который используется при обнаружении аномалий, состоит в том, чтобы просто изучить, как выглядят нормальные действия (с помощью журнала нормальных транзакций), и определять все действия, которые существенно отличаются от нормальных.</span><span class="sxs-lookup"><span data-stu-id="91d25-153">The approach that anomaly detection takes is to simply learn what normal activity looks like (using a history non-fraudulent transactions) and identify anything that is significantly different.</span></span>

### <a name="unsupervised"></a><span data-ttu-id="91d25-154">Неконтролируемое</span><span class="sxs-lookup"><span data-stu-id="91d25-154">Unsupervised</span></span>
<span data-ttu-id="91d25-155">При неконтролируемом обучении точкам данных не присваиваются метки.</span><span class="sxs-lookup"><span data-stu-id="91d25-155">In unsupervised learning, data points have no labels associated with them.</span></span> <span data-ttu-id="91d25-156">Вместо этого цель алгоритма неконтролируемого обучения — определенное упорядочивание данных или описание их структуры.</span><span class="sxs-lookup"><span data-stu-id="91d25-156">Instead, the goal of an unsupervised learning algorithm is to organize the data in some way or to describe its structure.</span></span> <span data-ttu-id="91d25-157">Это может означать группировку данных в кластеры или поиск различных способов анализа сложных данных для их упрощения или улучшения их организации.</span><span class="sxs-lookup"><span data-stu-id="91d25-157">This can mean grouping it into clusters or finding different ways of looking at complex data so that it appears simpler or more organized.</span></span>

### <a name="reinforcement-learning"></a><span data-ttu-id="91d25-158">Обучение с подкреплением</span><span class="sxs-lookup"><span data-stu-id="91d25-158">Reinforcement learning</span></span>
<span data-ttu-id="91d25-159">В обучении с подкреплением алгоритм выбирает действие в ответ на каждую точку данных.</span><span class="sxs-lookup"><span data-stu-id="91d25-159">In reinforcement learning, the algorithm gets to choose an action in response to each data point.</span></span> <span data-ttu-id="91d25-160">Алгоритм обучения также вскоре получает сигнал, оповещающий об успехе, который дает понять, насколько удачно было принято решение.</span><span class="sxs-lookup"><span data-stu-id="91d25-160">The learning algorithm also receives a reward signal a short time later, indicating how good the decision was.</span></span>
<span data-ttu-id="91d25-161">На основе этого алгоритм изменяет свою стратегию для достижения лучшего результата.</span><span class="sxs-lookup"><span data-stu-id="91d25-161">Based on this, the algorithm modifies its strategy in order to achieve the highest reward.</span></span> <span data-ttu-id="91d25-162">На данный момент в машинном обучении Azure модули алгоритмов обучения с подкреплением отсутствуют.</span><span class="sxs-lookup"><span data-stu-id="91d25-162">Currently there are no reinforcement learning algorithm modules in Azure Machine Learning.</span></span> <span data-ttu-id="91d25-163">Обучение с подкреплением широко распространено в робототехнике, где набор показаний датчиков в один момент времени представляет собой точку данных и алгоритму необходимо выбрать следующее действие робота.</span><span class="sxs-lookup"><span data-stu-id="91d25-163">Reinforcement learning is common in robotics, where the set of sensor readings at one point in time is a data point, and the algorithm must choose the robot's next action.</span></span> <span data-ttu-id="91d25-164">Кроме того, оно естественным образом подходит для приложений из Интернета вещей.</span><span class="sxs-lookup"><span data-stu-id="91d25-164">It is also a natural fit for Internet of Things applications.</span></span>

## <a name="considerations-when-choosing-an-algorithm"></a><span data-ttu-id="91d25-165">Рекомендации по выбору алгоритма</span><span class="sxs-lookup"><span data-stu-id="91d25-165">Considerations when choosing an algorithm</span></span>
### <a name="accuracy"></a><span data-ttu-id="91d25-166">Точность</span><span class="sxs-lookup"><span data-stu-id="91d25-166">Accuracy</span></span>
<span data-ttu-id="91d25-167">Получение наиболее точного ответа необходимо не всегда.</span><span class="sxs-lookup"><span data-stu-id="91d25-167">Getting the most accurate answer possible isn't always necessary.</span></span>
<span data-ttu-id="91d25-168">Иногда достаточно приближенного ответа в зависимости от того, для чего он используется.</span><span class="sxs-lookup"><span data-stu-id="91d25-168">Sometimes an approximation is adequate, depending on what you want to use it for.</span></span> <span data-ttu-id="91d25-169">В этом случае можно значительно сократить время обработки, придерживаясь более приближенных методов.</span><span class="sxs-lookup"><span data-stu-id="91d25-169">If that's the case, you may be able to cut your processing time dramatically by sticking with more approximate methods.</span></span> <span data-ttu-id="91d25-170">Еще одним преимуществом более приближенных методов является то, что они естественным образом стремятся избежать [чрезмерно высокой точности](https://youtu.be/DQWI1kvmwRg).</span><span class="sxs-lookup"><span data-stu-id="91d25-170">Another advantage of more approximate methods is that they naturally tend to avoid [overfitting](https://youtu.be/DQWI1kvmwRg).</span></span>

### <a name="training-time"></a><span data-ttu-id="91d25-171">Время обучения</span><span class="sxs-lookup"><span data-stu-id="91d25-171">Training time</span></span>
<span data-ttu-id="91d25-172">Количество минут или часов, необходимых для обучения модели, сильно отличается для различных алгоритмов.</span><span class="sxs-lookup"><span data-stu-id="91d25-172">The number of minutes or hours necessary to train a model varies a great deal between algorithms.</span></span> <span data-ttu-id="91d25-173">Время обучения часто тесно связано с точностью — одно обычно сопутствует другому.</span><span class="sxs-lookup"><span data-stu-id="91d25-173">Training time is often closely tied to accuracy—one typically accompanies the other.</span></span> <span data-ttu-id="91d25-174">Кроме того, некоторые алгоритмы более чувствительны к количеству точек данных, чем другие.</span><span class="sxs-lookup"><span data-stu-id="91d25-174">In addition, some algorithms are more sensitive to the number of data points than others.</span></span>
<span data-ttu-id="91d25-175">Когда время ограничено, это может повлиять на выбор алгоритма, особенно с большим набором данных.</span><span class="sxs-lookup"><span data-stu-id="91d25-175">When time is limited it can drive the choice of algorithm, especially when the data set is large.</span></span>

### <a name="linearity"></a><span data-ttu-id="91d25-176">Линейность</span><span class="sxs-lookup"><span data-stu-id="91d25-176">Linearity</span></span>
<span data-ttu-id="91d25-177">Линейность используется во многих алгоритмах машинного обучения.</span><span class="sxs-lookup"><span data-stu-id="91d25-177">Lots of machine learning algorithms make use of linearity.</span></span> <span data-ttu-id="91d25-178">Алгоритмы линейной классификации предполагают, что классы могут быть разделены прямой линией (или ее аналогом для большего числа измерений).</span><span class="sxs-lookup"><span data-stu-id="91d25-178">Linear classification algorithms assume that classes can be separated by a straight line (or its higher-dimensional analog).</span></span> <span data-ttu-id="91d25-179">К ним относятся логистическая регрессия и метод опорных векторов (в том виде, в котором это реализовано в машинном обучении Azure).</span><span class="sxs-lookup"><span data-stu-id="91d25-179">These include logistic regression and support vector machines (as implemented in Azure Machine Learning).</span></span>
<span data-ttu-id="91d25-180">Алгоритмы линейной регрессии предполагают, что тренды данных следуют прямой линии.</span><span class="sxs-lookup"><span data-stu-id="91d25-180">Linear regression algorithms assume that data trends follow a straight line.</span></span> <span data-ttu-id="91d25-181">Эти предположения допустимы для ряда задач, но для других задач они приводят к снижению точности.</span><span class="sxs-lookup"><span data-stu-id="91d25-181">These assumptions aren't bad for some problems, but on others they bring accuracy down.</span></span>

![Граница нелинейного класса][1]

<span data-ttu-id="91d25-183">***Граница нелинейного класса*** *— использование алгоритма линейной классификации приведет к низкой точности*</span><span class="sxs-lookup"><span data-stu-id="91d25-183">***Non-linear class boundary*** *- relying on a linear classification algorithm would result in low accuracy*</span></span>

![Данные с нелинейным трендом][2]

<span data-ttu-id="91d25-185">***Данные с нелинейным трендом*** *— использование алгоритма линейной классификации приведет к появлению гораздо большего количества ошибок, чем необходимо*</span><span class="sxs-lookup"><span data-stu-id="91d25-185">***Data with a nonlinear trend*** *- using a linear regression method would generate much larger errors than necessary*</span></span>

<span data-ttu-id="91d25-186">Несмотря на их опасность, линейные алгоритмы очень популярны на первой линии атаки.</span><span class="sxs-lookup"><span data-stu-id="91d25-186">Despite their dangers, linear algorithms are very popular as a first line of attack.</span></span> <span data-ttu-id="91d25-187">Обычно они алгоритмически просты и быстро осваиваются.</span><span class="sxs-lookup"><span data-stu-id="91d25-187">They tend to be algorithmically simple and fast to train.</span></span>

### <a name="number-of-parameters"></a><span data-ttu-id="91d25-188">Количество параметров</span><span class="sxs-lookup"><span data-stu-id="91d25-188">Number of parameters</span></span>
<span data-ttu-id="91d25-189">Параметры являются теми регуляторами, которые специалист по данным поворачивает при настройке алгоритма.</span><span class="sxs-lookup"><span data-stu-id="91d25-189">Parameters are the knobs a data scientist gets to turn when setting up an algorithm.</span></span> <span data-ttu-id="91d25-190">Это числа, которые влияют на поведение алгоритма, например чувствительность к ошибкам или количество итераций, или на варианты поведения алгоритма.</span><span class="sxs-lookup"><span data-stu-id="91d25-190">They are numbers that affect the algorithm's behavior, such as error tolerance or number of iterations, or options between variants of how the algorithm behaves.</span></span> <span data-ttu-id="91d25-191">Время обучения и точность алгоритма иногда могут быть очень чувствительными к точности задания параметров.</span><span class="sxs-lookup"><span data-stu-id="91d25-191">The training time and accuracy of the algorithm can sometimes be quite sensitive to getting just the right settings.</span></span> <span data-ttu-id="91d25-192">Как правило, алгоритмы с большим числом параметров требуют большого количества проб и ошибок, чтобы определить удачное сочетание параметров.</span><span class="sxs-lookup"><span data-stu-id="91d25-192">Typically, algorithms with large numbers parameters require the most trial and error to find a good combination.</span></span>

<span data-ttu-id="91d25-193">Кроме того, в машинном обучении Azure есть блок модулей [корректировки параметров](machine-learning-algorithm-parameters-optimize.md) , который автоматически пробует все сочетания параметров с любой выбранной детализацией.</span><span class="sxs-lookup"><span data-stu-id="91d25-193">Alternatively, there is a [parameter sweeping](machine-learning-algorithm-parameters-optimize.md) module block in Azure Machine Learning that automatically tries all parameter combinations at whatever granularity you choose.</span></span> <span data-ttu-id="91d25-194">Хотя это отличный способ убедиться в том, что вы заполнили пространство параметров, с увеличением количества параметров экспоненциально возрастает время, необходимое для обучения модели.</span><span class="sxs-lookup"><span data-stu-id="91d25-194">While this is a great way to make sure you've spanned the parameter space, the time required to train a model increases exponentially with the number of parameters.</span></span>

<span data-ttu-id="91d25-195">Плюсом является то, что наличие большого количества параметров обычно означает, что алгоритм имеет большую гибкость.</span><span class="sxs-lookup"><span data-stu-id="91d25-195">The upside is that having many parameters typically indicates that an algorithm has greater flexibility.</span></span> <span data-ttu-id="91d25-196">Это часто позволяет добиваться очень хорошей точности.</span><span class="sxs-lookup"><span data-stu-id="91d25-196">It can often achieve very good accuracy.</span></span> <span data-ttu-id="91d25-197">При условии, что вы можете найти правильную комбинацию параметров.</span><span class="sxs-lookup"><span data-stu-id="91d25-197">Provided you can find the right combination of parameter settings.</span></span>

### <a name="number-of-features"></a><span data-ttu-id="91d25-198">Количество функций</span><span class="sxs-lookup"><span data-stu-id="91d25-198">Number of features</span></span>
<span data-ttu-id="91d25-199">Для некоторых типов данных количество функций может быть очень большим по сравнению с количеством точек данных.</span><span class="sxs-lookup"><span data-stu-id="91d25-199">For certain types of data, the number of features can be very large compared to the number of data points.</span></span> <span data-ttu-id="91d25-200">Это часто происходит с генетическими или текстовыми данными.</span><span class="sxs-lookup"><span data-stu-id="91d25-200">This is often the case with genetics or textual data.</span></span> <span data-ttu-id="91d25-201">Большое количество функций для некоторых алгоритмов обучения может привести к тому, что они увязнут и время обучения станет недопустимо большим.</span><span class="sxs-lookup"><span data-stu-id="91d25-201">The large number of features can bog down some learning algorithms, making training time unfeasibly long.</span></span> <span data-ttu-id="91d25-202">Для этого варианта особенно хорошо подходит метод опорных векторов (см. ниже).</span><span class="sxs-lookup"><span data-stu-id="91d25-202">Support Vector Machines are particularly well suited to this case (see below).</span></span>

### <a name="special-cases"></a><span data-ttu-id="91d25-203">Особые случаи</span><span class="sxs-lookup"><span data-stu-id="91d25-203">Special cases</span></span>
<span data-ttu-id="91d25-204">Некоторые алгоритмы обучения делают определенные предположения о структуре данных или желаемых результатов.</span><span class="sxs-lookup"><span data-stu-id="91d25-204">Some learning algorithms make particular assumptions about the structure of the data or the desired results.</span></span> <span data-ttu-id="91d25-205">Если вы сможете найти тот алгоритм, который соответствует вашим потребностям, с ним вы сможете получить более точные результаты, более точные прогнозы и сократить время обучения.</span><span class="sxs-lookup"><span data-stu-id="91d25-205">If you can find one that fits your needs, it can give you more useful results, more accurate predictions, or faster training times.</span></span>

| <span data-ttu-id="91d25-206">**Алгоритм**</span><span class="sxs-lookup"><span data-stu-id="91d25-206">**Algorithm**</span></span> | <span data-ttu-id="91d25-207">**Точность**</span><span class="sxs-lookup"><span data-stu-id="91d25-207">**Accuracy**</span></span> | <span data-ttu-id="91d25-208">**Время обучения**</span><span class="sxs-lookup"><span data-stu-id="91d25-208">**Training time**</span></span> | <span data-ttu-id="91d25-209">**Линейность**</span><span class="sxs-lookup"><span data-stu-id="91d25-209">**Linearity**</span></span> | <span data-ttu-id="91d25-210">**Параметры**</span><span class="sxs-lookup"><span data-stu-id="91d25-210">**Parameters**</span></span> | <span data-ttu-id="91d25-211">**Примечания**</span><span class="sxs-lookup"><span data-stu-id="91d25-211">**Notes**</span></span> |
| --- |:---:|:---:|:---:|:---:| --- |
| <span data-ttu-id="91d25-212">**Двуклассовая классификация**</span><span class="sxs-lookup"><span data-stu-id="91d25-212">**Two-class classification**</span></span> | | | | | |
| [<span data-ttu-id="91d25-213">логистическая регрессия</span><span class="sxs-lookup"><span data-stu-id="91d25-213">logistic regression</span></span>](https://msdn.microsoft.com/library/azure/dn905994.aspx) | |<span data-ttu-id="91d25-214">●</span><span class="sxs-lookup"><span data-stu-id="91d25-214">●</span></span> |<span data-ttu-id="91d25-215">●</span><span class="sxs-lookup"><span data-stu-id="91d25-215">●</span></span> |<span data-ttu-id="91d25-216">5</span><span class="sxs-lookup"><span data-stu-id="91d25-216">5</span></span> | |
| [<span data-ttu-id="91d25-217">лес решений</span><span class="sxs-lookup"><span data-stu-id="91d25-217">decision forest</span></span>](https://msdn.microsoft.com/library/azure/dn906008.aspx) |<span data-ttu-id="91d25-218">●</span><span class="sxs-lookup"><span data-stu-id="91d25-218">●</span></span> |<span data-ttu-id="91d25-219">○</span><span class="sxs-lookup"><span data-stu-id="91d25-219">○</span></span> | |<span data-ttu-id="91d25-220">6</span><span class="sxs-lookup"><span data-stu-id="91d25-220">6</span></span> | |
| [<span data-ttu-id="91d25-221">джунгли решений</span><span class="sxs-lookup"><span data-stu-id="91d25-221">decision jungle</span></span>](https://msdn.microsoft.com/library/azure/dn905976.aspx) |<span data-ttu-id="91d25-222">●</span><span class="sxs-lookup"><span data-stu-id="91d25-222">●</span></span> |<span data-ttu-id="91d25-223">○</span><span class="sxs-lookup"><span data-stu-id="91d25-223">○</span></span> | |<span data-ttu-id="91d25-224">6</span><span class="sxs-lookup"><span data-stu-id="91d25-224">6</span></span> |<span data-ttu-id="91d25-225">Низкий объем памяти</span><span class="sxs-lookup"><span data-stu-id="91d25-225">Low memory footprint</span></span> |
| [<span data-ttu-id="91d25-226">увеличивающееся дерево решений</span><span class="sxs-lookup"><span data-stu-id="91d25-226">boosted decision tree</span></span>](https://msdn.microsoft.com/library/azure/dn906025.aspx) |<span data-ttu-id="91d25-227">●</span><span class="sxs-lookup"><span data-stu-id="91d25-227">●</span></span> |<span data-ttu-id="91d25-228">○</span><span class="sxs-lookup"><span data-stu-id="91d25-228">○</span></span> | |<span data-ttu-id="91d25-229">6</span><span class="sxs-lookup"><span data-stu-id="91d25-229">6</span></span> |<span data-ttu-id="91d25-230">Большой объем памяти</span><span class="sxs-lookup"><span data-stu-id="91d25-230">Large memory footprint</span></span> |
| [<span data-ttu-id="91d25-231">нейронная сеть</span><span class="sxs-lookup"><span data-stu-id="91d25-231">neural network</span></span>](https://msdn.microsoft.com/library/azure/dn905947.aspx) |<span data-ttu-id="91d25-232">●</span><span class="sxs-lookup"><span data-stu-id="91d25-232">●</span></span> | | |<span data-ttu-id="91d25-233">9</span><span class="sxs-lookup"><span data-stu-id="91d25-233">9</span></span> |[<span data-ttu-id="91d25-234">Возможна дополнительная настройка</span><span class="sxs-lookup"><span data-stu-id="91d25-234">Additional customization is possible</span></span>](http://go.microsoft.com/fwlink/?LinkId=402867) |
| [<span data-ttu-id="91d25-235">усредненное восприятие</span><span class="sxs-lookup"><span data-stu-id="91d25-235">averaged perceptron</span></span>](https://msdn.microsoft.com/library/azure/dn906036.aspx) |<span data-ttu-id="91d25-236">○</span><span class="sxs-lookup"><span data-stu-id="91d25-236">○</span></span> |<span data-ttu-id="91d25-237">○</span><span class="sxs-lookup"><span data-stu-id="91d25-237">○</span></span> |<span data-ttu-id="91d25-238">●</span><span class="sxs-lookup"><span data-stu-id="91d25-238">●</span></span> |<span data-ttu-id="91d25-239">4.</span><span class="sxs-lookup"><span data-stu-id="91d25-239">4</span></span> | |
| [<span data-ttu-id="91d25-240">метод опорных векторов</span><span class="sxs-lookup"><span data-stu-id="91d25-240">support vector machine</span></span>](https://msdn.microsoft.com/library/azure/dn905835.aspx) | |<span data-ttu-id="91d25-241">○</span><span class="sxs-lookup"><span data-stu-id="91d25-241">○</span></span> |<span data-ttu-id="91d25-242">●</span><span class="sxs-lookup"><span data-stu-id="91d25-242">●</span></span> |<span data-ttu-id="91d25-243">5</span><span class="sxs-lookup"><span data-stu-id="91d25-243">5</span></span> |<span data-ttu-id="91d25-244">Подходит для больших наборов функций</span><span class="sxs-lookup"><span data-stu-id="91d25-244">Good for large feature sets</span></span> |
| [<span data-ttu-id="91d25-245">локально глубокий метод опорных векторов</span><span class="sxs-lookup"><span data-stu-id="91d25-245">locally deep support vector machine</span></span>](https://msdn.microsoft.com/library/azure/dn913070.aspx) |<span data-ttu-id="91d25-246">○</span><span class="sxs-lookup"><span data-stu-id="91d25-246">○</span></span> | | |<span data-ttu-id="91d25-247">8</span><span class="sxs-lookup"><span data-stu-id="91d25-247">8</span></span> |<span data-ttu-id="91d25-248">Подходит для больших наборов функций</span><span class="sxs-lookup"><span data-stu-id="91d25-248">Good for large feature sets</span></span> |
| [<span data-ttu-id="91d25-249">точечная машина Байеса</span><span class="sxs-lookup"><span data-stu-id="91d25-249">Bayes’ point machine</span></span>](https://msdn.microsoft.com/library/azure/dn905930.aspx) | |<span data-ttu-id="91d25-250">○</span><span class="sxs-lookup"><span data-stu-id="91d25-250">○</span></span> |<span data-ttu-id="91d25-251">●</span><span class="sxs-lookup"><span data-stu-id="91d25-251">●</span></span> |<span data-ttu-id="91d25-252">3</span><span class="sxs-lookup"><span data-stu-id="91d25-252">3</span></span> | |
| <span data-ttu-id="91d25-253">**Многоклассовая классификация**</span><span class="sxs-lookup"><span data-stu-id="91d25-253">**Multi-class classification**</span></span> | | | | | |
| [<span data-ttu-id="91d25-254">логистическая регрессия</span><span class="sxs-lookup"><span data-stu-id="91d25-254">logistic regression</span></span>](https://msdn.microsoft.com/library/azure/dn905853.aspx) | |<span data-ttu-id="91d25-255">●</span><span class="sxs-lookup"><span data-stu-id="91d25-255">●</span></span> |<span data-ttu-id="91d25-256">●</span><span class="sxs-lookup"><span data-stu-id="91d25-256">●</span></span> |<span data-ttu-id="91d25-257">5</span><span class="sxs-lookup"><span data-stu-id="91d25-257">5</span></span> | |
| [<span data-ttu-id="91d25-258">лес решений</span><span class="sxs-lookup"><span data-stu-id="91d25-258">decision forest</span></span>](https://msdn.microsoft.com/library/azure/dn906015.aspx) |<span data-ttu-id="91d25-259">●</span><span class="sxs-lookup"><span data-stu-id="91d25-259">●</span></span> |<span data-ttu-id="91d25-260">○</span><span class="sxs-lookup"><span data-stu-id="91d25-260">○</span></span> | |<span data-ttu-id="91d25-261">6</span><span class="sxs-lookup"><span data-stu-id="91d25-261">6</span></span> | |
| [<span data-ttu-id="91d25-262">джунгли решений </span><span class="sxs-lookup"><span data-stu-id="91d25-262">decision jungle </span></span>](https://msdn.microsoft.com/library/azure/dn905963.aspx) |<span data-ttu-id="91d25-263">●</span><span class="sxs-lookup"><span data-stu-id="91d25-263">●</span></span> |<span data-ttu-id="91d25-264">○</span><span class="sxs-lookup"><span data-stu-id="91d25-264">○</span></span> | |<span data-ttu-id="91d25-265">6</span><span class="sxs-lookup"><span data-stu-id="91d25-265">6</span></span> |<span data-ttu-id="91d25-266">Низкий объем памяти</span><span class="sxs-lookup"><span data-stu-id="91d25-266">Low memory footprint</span></span> |
| [<span data-ttu-id="91d25-267">нейронная сеть</span><span class="sxs-lookup"><span data-stu-id="91d25-267">neural network</span></span>](https://msdn.microsoft.com/library/azure/dn906030.aspx) |<span data-ttu-id="91d25-268">●</span><span class="sxs-lookup"><span data-stu-id="91d25-268">●</span></span> | | |<span data-ttu-id="91d25-269">9</span><span class="sxs-lookup"><span data-stu-id="91d25-269">9</span></span> |[<span data-ttu-id="91d25-270">Возможна дополнительная настройка</span><span class="sxs-lookup"><span data-stu-id="91d25-270">Additional customization is possible</span></span>](http://go.microsoft.com/fwlink/?LinkId=402867) |
| [<span data-ttu-id="91d25-271">one-v-all</span><span class="sxs-lookup"><span data-stu-id="91d25-271">one-v-all</span></span>](https://msdn.microsoft.com/library/azure/dn905887.aspx) |- |- |- |- |<span data-ttu-id="91d25-272">Просмотрите свойства выбранного двухклассового метода</span><span class="sxs-lookup"><span data-stu-id="91d25-272">See properties of the two-class method selected</span></span> |
| <span data-ttu-id="91d25-273">**Регрессия**</span><span class="sxs-lookup"><span data-stu-id="91d25-273">**Regression**</span></span> | | | | | |
| [<span data-ttu-id="91d25-274">линейная</span><span class="sxs-lookup"><span data-stu-id="91d25-274">linear</span></span>](https://msdn.microsoft.com/library/azure/dn905978.aspx) | |<span data-ttu-id="91d25-275">●</span><span class="sxs-lookup"><span data-stu-id="91d25-275">●</span></span> |<span data-ttu-id="91d25-276">●</span><span class="sxs-lookup"><span data-stu-id="91d25-276">●</span></span> |<span data-ttu-id="91d25-277">4</span><span class="sxs-lookup"><span data-stu-id="91d25-277">4</span></span> | |
| [<span data-ttu-id="91d25-278">Байесовская линейная</span><span class="sxs-lookup"><span data-stu-id="91d25-278">Bayesian linear</span></span>](https://msdn.microsoft.com/library/azure/dn906022.aspx) | |<span data-ttu-id="91d25-279">○</span><span class="sxs-lookup"><span data-stu-id="91d25-279">○</span></span> |<span data-ttu-id="91d25-280">●</span><span class="sxs-lookup"><span data-stu-id="91d25-280">●</span></span> |<span data-ttu-id="91d25-281">2</span><span class="sxs-lookup"><span data-stu-id="91d25-281">2</span></span> | |
| [<span data-ttu-id="91d25-282">лес решений</span><span class="sxs-lookup"><span data-stu-id="91d25-282">decision forest</span></span>](https://msdn.microsoft.com/library/azure/dn905862.aspx) |<span data-ttu-id="91d25-283">●</span><span class="sxs-lookup"><span data-stu-id="91d25-283">●</span></span> |<span data-ttu-id="91d25-284">○</span><span class="sxs-lookup"><span data-stu-id="91d25-284">○</span></span> | |<span data-ttu-id="91d25-285">6</span><span class="sxs-lookup"><span data-stu-id="91d25-285">6</span></span> | |
| [<span data-ttu-id="91d25-286">увеличивающееся дерево решений</span><span class="sxs-lookup"><span data-stu-id="91d25-286">boosted decision tree</span></span>](https://msdn.microsoft.com/library/azure/dn905801.aspx) |<span data-ttu-id="91d25-287">●</span><span class="sxs-lookup"><span data-stu-id="91d25-287">●</span></span> |<span data-ttu-id="91d25-288">○</span><span class="sxs-lookup"><span data-stu-id="91d25-288">○</span></span> | |<span data-ttu-id="91d25-289">5</span><span class="sxs-lookup"><span data-stu-id="91d25-289">5</span></span> |<span data-ttu-id="91d25-290">Большой объем памяти</span><span class="sxs-lookup"><span data-stu-id="91d25-290">Large memory footprint</span></span> |
| [<span data-ttu-id="91d25-291">квантильная регрессия быстрого леса</span><span class="sxs-lookup"><span data-stu-id="91d25-291">fast forest quantile</span></span>](https://msdn.microsoft.com/library/azure/dn913093.aspx) |<span data-ttu-id="91d25-292">●</span><span class="sxs-lookup"><span data-stu-id="91d25-292">●</span></span> |<span data-ttu-id="91d25-293">○</span><span class="sxs-lookup"><span data-stu-id="91d25-293">○</span></span> | |<span data-ttu-id="91d25-294">9</span><span class="sxs-lookup"><span data-stu-id="91d25-294">9</span></span> |<span data-ttu-id="91d25-295">Распределения, а не точечные прогнозы</span><span class="sxs-lookup"><span data-stu-id="91d25-295">Distributions rather than point predictions</span></span> |
| [<span data-ttu-id="91d25-296">нейронная сеть</span><span class="sxs-lookup"><span data-stu-id="91d25-296">neural network</span></span>](https://msdn.microsoft.com/library/azure/dn905924.aspx) |<span data-ttu-id="91d25-297">●</span><span class="sxs-lookup"><span data-stu-id="91d25-297">●</span></span> | | |<span data-ttu-id="91d25-298">9</span><span class="sxs-lookup"><span data-stu-id="91d25-298">9</span></span> |[<span data-ttu-id="91d25-299">Возможна дополнительная настройка</span><span class="sxs-lookup"><span data-stu-id="91d25-299">Additional customization is possible</span></span>](http://go.microsoft.com/fwlink/?LinkId=402867) |
| [<span data-ttu-id="91d25-300">регрессия Пуассона</span><span class="sxs-lookup"><span data-stu-id="91d25-300">Poisson</span></span>](https://msdn.microsoft.com/library/azure/dn905988.aspx) | | |<span data-ttu-id="91d25-301">●</span><span class="sxs-lookup"><span data-stu-id="91d25-301">●</span></span> |<span data-ttu-id="91d25-302">5</span><span class="sxs-lookup"><span data-stu-id="91d25-302">5</span></span> |<span data-ttu-id="91d25-303">С технической точки зрения логлинейная.</span><span class="sxs-lookup"><span data-stu-id="91d25-303">Technically log-linear.</span></span> <span data-ttu-id="91d25-304">Для прогнозирования количества</span><span class="sxs-lookup"><span data-stu-id="91d25-304">For predicting counts</span></span> |
| [<span data-ttu-id="91d25-305">порядковая</span><span class="sxs-lookup"><span data-stu-id="91d25-305">ordinal</span></span>](https://msdn.microsoft.com/library/azure/dn906029.aspx) | | | |<span data-ttu-id="91d25-306">0</span><span class="sxs-lookup"><span data-stu-id="91d25-306">0</span></span> |<span data-ttu-id="91d25-307">Для прогнозирования упорядочения за рангом</span><span class="sxs-lookup"><span data-stu-id="91d25-307">For predicting rank-ordering</span></span> |
| <span data-ttu-id="91d25-308">**Обнаружение аномалий**</span><span class="sxs-lookup"><span data-stu-id="91d25-308">**Anomaly detection**</span></span> | | | | | |
| [<span data-ttu-id="91d25-309">метод опорных векторов</span><span class="sxs-lookup"><span data-stu-id="91d25-309">support vector machine</span></span>](https://msdn.microsoft.com/library/azure/dn913103.aspx) |<span data-ttu-id="91d25-310">○</span><span class="sxs-lookup"><span data-stu-id="91d25-310">○</span></span> |<span data-ttu-id="91d25-311">○</span><span class="sxs-lookup"><span data-stu-id="91d25-311">○</span></span> | |<span data-ttu-id="91d25-312">2</span><span class="sxs-lookup"><span data-stu-id="91d25-312">2</span></span> |<span data-ttu-id="91d25-313">Особенно полезна для больших наборов функций</span><span class="sxs-lookup"><span data-stu-id="91d25-313">Especially good for large feature sets</span></span> |
| [<span data-ttu-id="91d25-314">Обнаружение аномалий на основе анализа первичных компонентов</span><span class="sxs-lookup"><span data-stu-id="91d25-314">PCA-based anomaly detection</span></span>](https://msdn.microsoft.com/library/azure/dn913102.aspx) | |<span data-ttu-id="91d25-315">○</span><span class="sxs-lookup"><span data-stu-id="91d25-315">○</span></span> |<span data-ttu-id="91d25-316">●</span><span class="sxs-lookup"><span data-stu-id="91d25-316">●</span></span> |<span data-ttu-id="91d25-317">3</span><span class="sxs-lookup"><span data-stu-id="91d25-317">3</span></span> | |
| [<span data-ttu-id="91d25-318">K-средних</span><span class="sxs-lookup"><span data-stu-id="91d25-318">K-means</span></span>](https://msdn.microsoft.com/library/azure/5049a09b-bd90-4c4e-9b46-7c87e3a36810/) | |<span data-ttu-id="91d25-319">○</span><span class="sxs-lookup"><span data-stu-id="91d25-319">○</span></span> |<span data-ttu-id="91d25-320">●</span><span class="sxs-lookup"><span data-stu-id="91d25-320">●</span></span> |<span data-ttu-id="91d25-321">4</span><span class="sxs-lookup"><span data-stu-id="91d25-321">4</span></span> |<span data-ttu-id="91d25-322">Алгоритм кластеризации</span><span class="sxs-lookup"><span data-stu-id="91d25-322">A clustering algorithm</span></span> |

<span data-ttu-id="91d25-323">**Свойства алгоритма:**</span><span class="sxs-lookup"><span data-stu-id="91d25-323">**Algorithm properties:**</span></span>

<span data-ttu-id="91d25-324">**●** — показывает высокую точность, быстрое время обучения и использует линейность</span><span class="sxs-lookup"><span data-stu-id="91d25-324">**●** - shows excellent accuracy, fast training times, and the use of linearity</span></span>

<span data-ttu-id="91d25-325">**○** — показывает хорошую точность и умеренное время обучения</span><span class="sxs-lookup"><span data-stu-id="91d25-325">**○** - shows good accuracy and moderate training times</span></span>

## <a name="algorithm-notes"></a><span data-ttu-id="91d25-326">Примечания к алгоритму</span><span class="sxs-lookup"><span data-stu-id="91d25-326">Algorithm notes</span></span>
### <a name="linear-regression"></a><span data-ttu-id="91d25-327">Linear regression</span><span class="sxs-lookup"><span data-stu-id="91d25-327">Linear regression</span></span>
<span data-ttu-id="91d25-328">Как упоминалось ранее, [линейная регрессия](https://msdn.microsoft.com/library/azure/dn905978.aspx) связывает с набором данных линию (либо плоскость или гиперплоскость).</span><span class="sxs-lookup"><span data-stu-id="91d25-328">As mentioned previously, [linear regression](https://msdn.microsoft.com/library/azure/dn905978.aspx) fits a line (or plane, or hyperplane) to the data set.</span></span> <span data-ttu-id="91d25-329">Это быстрая и простая "рабочая лошадка", но она может быть излишне простой для некоторых задач.</span><span class="sxs-lookup"><span data-stu-id="91d25-329">It's a workhorse, simple and fast, but it may be overly simplistic for some problems.</span></span>
<span data-ttu-id="91d25-330">Руководство по линейной регрессии можно найти [здесь](machine-learning-linear-regression-in-azure.md).</span><span class="sxs-lookup"><span data-stu-id="91d25-330">Check here for a [linear regression tutorial](machine-learning-linear-regression-in-azure.md).</span></span>

![Данные с линейным трендом][3]

<span data-ttu-id="91d25-332">***Данные с линейным трендом***</span><span class="sxs-lookup"><span data-stu-id="91d25-332">***Data with a linear trend***</span></span>

### <a name="logistic-regression"></a><span data-ttu-id="91d25-333">Логистическая регрессия</span><span class="sxs-lookup"><span data-stu-id="91d25-333">Logistic regression</span></span>
<span data-ttu-id="91d25-334">Несмотря на вводящее в заблуждение слово "регрессия" в названии, логистическая регрессия на самом деле является мощным инструментом [двухклассовой](https://msdn.microsoft.com/library/azure/dn905994.aspx) и [многоклассовой](https://msdn.microsoft.com/library/azure/dn905853.aspx) классификации.</span><span class="sxs-lookup"><span data-stu-id="91d25-334">Although it confusingly includes 'regression' in the name, logistic regression is actually a powerful tool for [two-class](https://msdn.microsoft.com/library/azure/dn905994.aspx) and [multiclass](https://msdn.microsoft.com/library/azure/dn905853.aspx) classification.</span></span> <span data-ttu-id="91d25-335">Это быстрый и простой метод.</span><span class="sxs-lookup"><span data-stu-id="91d25-335">It's fast and simple.</span></span> <span data-ttu-id="91d25-336">Тот факт, что в нем вместо прямой линии используется S-образная кривая, позволяет естественным образом использовать его для разделения данных на группы.</span><span class="sxs-lookup"><span data-stu-id="91d25-336">The fact that it uses an 'S'-shaped curve instead of a straight line makes it a natural fit for dividing data into groups.</span></span> <span data-ttu-id="91d25-337">Логистическая регрессия приводит к появлению линейных границ классов, поэтому при ее использовании убедитесь, что вам комфортно с линейной аппроксимацией.</span><span class="sxs-lookup"><span data-stu-id="91d25-337">Logistic regression gives linear class boundaries, so when you use it, make sure a linear approximation is something you can live with.</span></span>

![Логистическая регрессия для двухклассовых данных со всего одной функцией][4]

<span data-ttu-id="91d25-339">***Логистическая регрессия для двухклассовых данных со всего одной функцией*** *— граница класса является точкой, в которой логистическая кривая равноудалена от обоих классов*</span><span class="sxs-lookup"><span data-stu-id="91d25-339">***A logistic regression to two-class data with just one feature*** *- the class boundary is the point at which the logistic curve is just as close to both classes*</span></span>

### <a name="trees-forests-and-jungles"></a><span data-ttu-id="91d25-340">Деревья, леса и джунгли</span><span class="sxs-lookup"><span data-stu-id="91d25-340">Trees, forests, and jungles</span></span>
<span data-ttu-id="91d25-341">Леса решений ([регрессионные](https://msdn.microsoft.com/library/azure/dn905862.aspx), [двухклассовые](https://msdn.microsoft.com/library/azure/dn906008.aspx) и [многоклассовые](https://msdn.microsoft.com/library/azure/dn906015.aspx)), джунгли решений ([двухклассовые](https://msdn.microsoft.com/library/azure/dn905976.aspx) и [многоклассовые](https://msdn.microsoft.com/library/azure/dn905963.aspx)) и увеличивающиеся деревья решений ([регрессионные](https://msdn.microsoft.com/library/azure/dn905801.aspx) и [двухклассовые](https://msdn.microsoft.com/library/azure/dn906025.aspx)) основаны на деревьях решений, базовой концепции машинного обучения.</span><span class="sxs-lookup"><span data-stu-id="91d25-341">Decision forests ([regression](https://msdn.microsoft.com/library/azure/dn905862.aspx), [two-class](https://msdn.microsoft.com/library/azure/dn906008.aspx), and [multiclass](https://msdn.microsoft.com/library/azure/dn906015.aspx)), decision jungles ([two-class](https://msdn.microsoft.com/library/azure/dn905976.aspx) and [multiclass](https://msdn.microsoft.com/library/azure/dn905963.aspx)), and boosted decision trees ([regression](https://msdn.microsoft.com/library/azure/dn905801.aspx) and [two-class](https://msdn.microsoft.com/library/azure/dn906025.aspx)) are all based on decision trees, a foundational machine learning concept.</span></span> <span data-ttu-id="91d25-342">Существует множество вариантов деревьев решений, но все они делают одно и то же: подразделяют пространство функций на области с преимущественно одинаковыми метками.</span><span class="sxs-lookup"><span data-stu-id="91d25-342">There are many variants of decision trees, but they all do the same thing—subdivide the feature space into regions with mostly the same label.</span></span> <span data-ttu-id="91d25-343">Это могут быть области с одинаковой категорией или одинаковым значением в зависимости от того, проводится ли классификация или регрессия.</span><span class="sxs-lookup"><span data-stu-id="91d25-343">These can be regions of consistent category or of constant value, depending on whether you are doing classification or regression.</span></span>

![Дерево решений подразделяет пространство функций][5]

<span data-ttu-id="91d25-345">***Дерево решений подразделяет пространство функций на области примерно c одинаковыми значениями.***</span><span class="sxs-lookup"><span data-stu-id="91d25-345">***A decision tree subdivides a feature space into regions of roughly uniform values***</span></span>

<span data-ttu-id="91d25-346">Так как пространство функций можно подразделить на регионы произвольного размера, легко представить такое разделение, при котором в одном регионе будет только одна точка данных.</span><span class="sxs-lookup"><span data-stu-id="91d25-346">Because a feature space can be subdivided into arbitrarily small regions, it's easy to imagine dividing it finely enough to have one data point per region.</span></span> <span data-ttu-id="91d25-347">Это крайний пример чрезмерно высокой точности.</span><span class="sxs-lookup"><span data-stu-id="91d25-347">This is an extreme example of overfitting.</span></span> <span data-ttu-id="91d25-348">Чтобы этого избежать, большие наборы деревьев создаются с особой математической осторожностью, чтобы деревья не коррелировали друг с другом.</span><span class="sxs-lookup"><span data-stu-id="91d25-348">In order to avoid this, a large set of trees are constructed with special mathematical care taken that the trees are not correlated.</span></span> <span data-ttu-id="91d25-349">Средним для этого "леса решений" является дерево, что позволяет избежать чрезмерно высокой точности.</span><span class="sxs-lookup"><span data-stu-id="91d25-349">The average of this "decision forest" is a tree that avoids overfitting.</span></span> <span data-ttu-id="91d25-350">Леса решений могут использовать большой объем памяти.</span><span class="sxs-lookup"><span data-stu-id="91d25-350">Decision forests can use a lot of memory.</span></span> <span data-ttu-id="91d25-351">Джунгли решений — это вариант, который используют меньший объем памяти за счет небольшого увеличения времени обучения.</span><span class="sxs-lookup"><span data-stu-id="91d25-351">Decision jungles are a variant that consumes less memory at the expense of a slightly longer training time.</span></span>

<span data-ttu-id="91d25-352">В увеличивающихся деревьях решений во избежание чрезмерно высокой точности ограничиваются количество повторных делений и минимальное количество точек данных в каждом регионе.</span><span class="sxs-lookup"><span data-stu-id="91d25-352">Boosted decision trees avoid overfitting by limiting how many times they can subdivide and how few data points are allowed in each region.</span></span> <span data-ttu-id="91d25-353">Алгоритм создает последовательность деревьев, каждое из которых учится компенсировать ошибки, оставленные предыдущим деревом.</span><span class="sxs-lookup"><span data-stu-id="91d25-353">The algorithm constructs a sequence of trees, each of which learns to compensate for the error left by the tree before.</span></span> <span data-ttu-id="91d25-354">В результате мы получаем очень точный механизм обучения, который, как правило, использует большой объем памяти.</span><span class="sxs-lookup"><span data-stu-id="91d25-354">The result is a very accurate learner that tends to use a lot of memory.</span></span> <span data-ttu-id="91d25-355">Полное техническое описание см. в [исходном документе Фридмана](http://www-stat.stanford.edu/~jhf/ftp/trebst.pdf).</span><span class="sxs-lookup"><span data-stu-id="91d25-355">For the full technical description, check out [Friedman's original paper](http://www-stat.stanford.edu/~jhf/ftp/trebst.pdf).</span></span>

<span data-ttu-id="91d25-356">[Квантильная регрессия быстрого леса](https://msdn.microsoft.com/library/azure/dn913093.aspx) является разновидностью дерева решений для особого случая, в котором вы хотите знать не только типичное (среднее) значение данных в пределах региона, но его распределение в виде квантилей.</span><span class="sxs-lookup"><span data-stu-id="91d25-356">[Fast forest quantile regression](https://msdn.microsoft.com/library/azure/dn913093.aspx) is a variation of decision trees for the special case where you want to know not only the typical (median) value of the data within a region, but also its distribution in the form of quantiles.</span></span>

### <a name="neural-networks-and-perceptrons"></a><span data-ttu-id="91d25-357">Нейронные сети и восприятия</span><span class="sxs-lookup"><span data-stu-id="91d25-357">Neural networks and perceptrons</span></span>
<span data-ttu-id="91d25-358">Нейронные сети — это алгоритмы обучения, вдохновленные устройством человеческого мозга, которые охватывают [многоклассовые](https://msdn.microsoft.com/library/azure/dn906030.aspx), [двухклассовые](https://msdn.microsoft.com/library/azure/dn905947.aspx) и [регрессионные](https://msdn.microsoft.com/library/azure/dn905924.aspx) задачи.</span><span class="sxs-lookup"><span data-stu-id="91d25-358">Neural networks are brain-inspired learning algorithms covering [multiclass](https://msdn.microsoft.com/library/azure/dn906030.aspx), [two-class](https://msdn.microsoft.com/library/azure/dn905947.aspx), and [regression](https://msdn.microsoft.com/library/azure/dn905924.aspx) problems.</span></span> <span data-ttu-id="91d25-359">Разнообразие нейронных сетей очень велико, но в машинном обучении Azure все они имеют форму направленного ациклического графа.</span><span class="sxs-lookup"><span data-stu-id="91d25-359">They come in an infinite variety, but the neural networks within Azure Machine Learning are all of the form of directed acyclic graphs.</span></span> <span data-ttu-id="91d25-360">Это означает, что входные функции передаются вперед (и только вперед) по последовательности слоев, после чего превращаются в выходные данные.</span><span class="sxs-lookup"><span data-stu-id="91d25-360">That means that input features are passed forward (never backward) through a sequence of layers before being turned into outputs.</span></span> <span data-ttu-id="91d25-361">В каждом слое входные функции взвешиваются в различных сочетаниях, суммируются и передаются на следующий уровень.</span><span class="sxs-lookup"><span data-stu-id="91d25-361">In each layer, inputs are weighted in various combinations, summed, and passed on to the next layer.</span></span> <span data-ttu-id="91d25-362">Такое сочетание простых вычислений дает возможность как по волшебству изучать границы сложных классов и тренды данных.</span><span class="sxs-lookup"><span data-stu-id="91d25-362">This combination of simple calculations results in the ability to learn sophisticated class boundaries and data trends, seemingly by magic.</span></span> <span data-ttu-id="91d25-363">Многослойные сети такого типа выполняют "глубокое обучение", которое так широко представлено в технических отчетах и научно-фантастической литературе.</span><span class="sxs-lookup"><span data-stu-id="91d25-363">Many-layered networks of this sort perform the "deep learning" that fuels so much tech reporting and science fiction.</span></span>

<span data-ttu-id="91d25-364">Но такая высокая производительность имеет и обратную сторону.</span><span class="sxs-lookup"><span data-stu-id="91d25-364">This high performance doesn't come for free, though.</span></span> <span data-ttu-id="91d25-365">На обучение нейронных сетей может уходить длительное время, особенно для больших наборов данных с большим количеством функций.</span><span class="sxs-lookup"><span data-stu-id="91d25-365">Neural networks can take a long time to train, particularly for large data sets with lots of features.</span></span> <span data-ttu-id="91d25-366">Они также имеют больше параметров, чем большинство алгоритмов, что означает, что корректировка параметров значительно удлиняет время обучения.</span><span class="sxs-lookup"><span data-stu-id="91d25-366">They also have more parameters than most algorithms, which means that parameter sweeping expands the training time a great deal.</span></span>
<span data-ttu-id="91d25-367">А для тех, кто хочет превысить собственные достижения и [определить собственную структуру сети](http://go.microsoft.com/fwlink/?LinkId=402867), возможности нейронных сетей неисчерпаемы.</span><span class="sxs-lookup"><span data-stu-id="91d25-367">And for those overachievers who wish to [specify their own network structure](http://go.microsoft.com/fwlink/?LinkId=402867), the possibilities are inexhaustible.</span></span>

<span data-ttu-id="91d25-368">![Границы, изучаемые нейронными сетями][6]
***Границы, изучаемые нейронными сетями, могут быть сложными и нестандартными***</span><span class="sxs-lookup"><span data-stu-id="91d25-368">![Boundaries learned by neural networks][6]
***The boundaries learned by neural networks can be complex and irregular***</span></span>

<span data-ttu-id="91d25-369">[Двухклассное усредненное восприятие](https://msdn.microsoft.com/library/azure/dn906036.aspx) — ответ нейронных сетей на огромное увеличение времени обучения.</span><span class="sxs-lookup"><span data-stu-id="91d25-369">The [two-class averaged perceptron](https://msdn.microsoft.com/library/azure/dn906036.aspx) is neural networks' answer to skyrocketing training times.</span></span> <span data-ttu-id="91d25-370">В нем используется структура сети, предоставляющая линейные границы класса.</span><span class="sxs-lookup"><span data-stu-id="91d25-370">It uses a network structure that gives linear class boundaries.</span></span> <span data-ttu-id="91d25-371">Она почти примитивна по сегодняшним стандартам, но имеет долгую историю надежной работы и достаточно мала для быстрого изучения.</span><span class="sxs-lookup"><span data-stu-id="91d25-371">It is almost primitive by today's standards, but it has a long history of working robustly and is small enough to learn quickly.</span></span>

### <a name="svms"></a><span data-ttu-id="91d25-372">Методы опорных векторов</span><span class="sxs-lookup"><span data-stu-id="91d25-372">SVMs</span></span>
<span data-ttu-id="91d25-373">Методы опорных векторов находят границу, которая разделяет классы с как можно большей шириной.</span><span class="sxs-lookup"><span data-stu-id="91d25-373">Support vector machines (SVMs) find the boundary that separates classes by as wide a margin as possible.</span></span> <span data-ttu-id="91d25-374">Если два класса нельзя четко разделить, алгоритмы найдут наилучшую границу, которую смогут.</span><span class="sxs-lookup"><span data-stu-id="91d25-374">When the two classes can't be clearly separated, the algorithms find the best boundary they can.</span></span> <span data-ttu-id="91d25-375">Как записано в Машинном обучении Azure, [двухклассовые методы опорных векторов](https://msdn.microsoft.com/library/azure/dn905835.aspx) делают это только для прямой линии.</span><span class="sxs-lookup"><span data-stu-id="91d25-375">As written in Azure Machine Learning, the [two-class SVM](https://msdn.microsoft.com/library/azure/dn905835.aspx) does this with a straight line only.</span></span> <span data-ttu-id="91d25-376">(В терминах методов опорных векторов, они используют линейное ядро.) Так как это выполняется с помощью линейной аппроксимации, время выполнения достаточно мало.</span><span class="sxs-lookup"><span data-stu-id="91d25-376">(In SVM-speak, it uses a linear kernel.) Because it makes this linear approximation, it is able to run fairly quickly.</span></span> <span data-ttu-id="91d25-377">Эти методы действительно проявляют себя с данными с большим количеством функций, такими как текст или генетические данные.</span><span class="sxs-lookup"><span data-stu-id="91d25-377">Where it really shines is with feature-intense data, like text or genomic.</span></span> <span data-ttu-id="91d25-378">В этих случаях методы опорных векторов позволяют разделить классы быстрее и с меньшей избыточной точностью, чем большинство других алгоритмов; кроме того, они используют небольшой объем памяти.</span><span class="sxs-lookup"><span data-stu-id="91d25-378">In these cases SVMs are able to separate classes more quickly and with less overfitting than most other algorithms, in addition to requiring only a modest amount of memory.</span></span>

![Граница класса метода опорных векторов][7]

<span data-ttu-id="91d25-380">***Типичная граница класса для метода опорных векторов увеличивает ширину границы, разделяющей два класса.***</span><span class="sxs-lookup"><span data-stu-id="91d25-380">***A typical support vector machine class boundary maximizes the margin separating two classes***</span></span>

<span data-ttu-id="91d25-381">Другой продукт Microsoft Research, [двухклассовый локально глубокий метод опорных векторов](https://msdn.microsoft.com/library/azure/dn913070.aspx) , представляет собой нелинейный вариант метода опорных векторов, который сохраняет большую часть скорости и эффективного использования памяти линейной версии метода.</span><span class="sxs-lookup"><span data-stu-id="91d25-381">Another product of Microsoft Research, the [two-class locally deep SVM](https://msdn.microsoft.com/library/azure/dn913070.aspx) is a non-linear variant of SVM that retains most of the speed and memory efficiency of the linear version.</span></span> <span data-ttu-id="91d25-382">Он идеально подходит для случаев, в которых линейный подход не дает достаточно точных результатов.</span><span class="sxs-lookup"><span data-stu-id="91d25-382">It is ideal for cases where the linear approach doesn't give accurate enough answers.</span></span> <span data-ttu-id="91d25-383">Разработчики сохранили скорость метода путем разбиения задачи на несколько малых задач метода опорных векторов.</span><span class="sxs-lookup"><span data-stu-id="91d25-383">The developers kept it fast by breaking down the problem into a bunch of small linear SVM problems.</span></span> <span data-ttu-id="91d25-384">Подробнее узнать о том, как они это сделали, можно в [полном описании](http://research.microsoft.com/um/people/manik/pubs/Jose13.pdf) .</span><span class="sxs-lookup"><span data-stu-id="91d25-384">Read the [full description](http://research.microsoft.com/um/people/manik/pubs/Jose13.pdf) for the details on how they pulled off this trick.</span></span>

<span data-ttu-id="91d25-385">С помощью эффективного расширения нелинейных методов опорных векторов [одноклассовый метод опорных векторов](https://msdn.microsoft.com/library/azure/dn913103.aspx) проводит границу, которая плотно отделяет весь набор данных.</span><span class="sxs-lookup"><span data-stu-id="91d25-385">Using a clever extension of nonlinear SVMs, the [one-class SVM](https://msdn.microsoft.com/library/azure/dn913103.aspx) draws a boundary that tightly outlines the entire data set.</span></span> <span data-ttu-id="91d25-386">Это удобно для обнаружения аномалий.</span><span class="sxs-lookup"><span data-stu-id="91d25-386">It is useful for anomaly detection.</span></span> <span data-ttu-id="91d25-387">Все новые точки данных, которые выходят далеко за эту границу, достаточно необычны, чтобы обратить на них внимание.</span><span class="sxs-lookup"><span data-stu-id="91d25-387">Any new data points that fall far outside that boundary are unusual enough to be noteworthy.</span></span>

### <a name="bayesian-methods"></a><span data-ttu-id="91d25-388">Методы Байеса</span><span class="sxs-lookup"><span data-stu-id="91d25-388">Bayesian methods</span></span>
<span data-ttu-id="91d25-389">Методы Байеса имеют одно очень ценное качество: они не приводят к чрезмерному увеличению точности.</span><span class="sxs-lookup"><span data-stu-id="91d25-389">Bayesian methods have a highly desirable quality: they avoid overfitting.</span></span> <span data-ttu-id="91d25-390">Для этого они предварительно делают некоторые предположения о вероятном распределении ответа.</span><span class="sxs-lookup"><span data-stu-id="91d25-390">They do this by making some assumptions beforehand about the likely distribution of the answer.</span></span> <span data-ttu-id="91d25-391">Другим побочным эффектом этого подхода является то, что у этих методов очень мало параметров.</span><span class="sxs-lookup"><span data-stu-id="91d25-391">Another byproduct of this approach is that they have very few parameters.</span></span> <span data-ttu-id="91d25-392">В Машинном обучении Azure есть оба алгоритма Байеса для классификации ([двухклассная точечная машина Байеса](https://msdn.microsoft.com/library/azure/dn905930.aspx)) и регрессии ([линейная регрессия Байеса](https://msdn.microsoft.com/library/azure/dn906022.aspx)).</span><span class="sxs-lookup"><span data-stu-id="91d25-392">Azure Machine Learning has both Bayesian algorithms for both classification ([Two-class Bayes' point machine](https://msdn.microsoft.com/library/azure/dn905930.aspx)) and regression ([Bayesian linear regression](https://msdn.microsoft.com/library/azure/dn906022.aspx)).</span></span>
<span data-ttu-id="91d25-393">Обратите внимание, что в них предполагается, что данные можно разбить прямой линией или сопоставить ей.</span><span class="sxs-lookup"><span data-stu-id="91d25-393">Note that these assume that the data can be split or fit with a straight line.</span></span>

<span data-ttu-id="91d25-394">С исторической точки зрения точечные машины Байеса были разработаны в Microsoft Research.</span><span class="sxs-lookup"><span data-stu-id="91d25-394">On a historical note, Bayes' point machines were developed at Microsoft Research.</span></span> <span data-ttu-id="91d25-395">За ними стоит исключительная теоретическая работа.</span><span class="sxs-lookup"><span data-stu-id="91d25-395">They have some exceptionally beautiful theoretical work behind them.</span></span> <span data-ttu-id="91d25-396">Заинтересовавшиеся могут ознакомиться с [исходной статьей в JMLR](http://jmlr.org/papers/volume1/herbrich01a/herbrich01a.pdf) и [исчерпывающим блогом Криса Бишопа (Chris Bishop)](http://blogs.technet.com/b/machinelearning/archive/2014/10/30/embracing-uncertainty-probabilistic-inference.aspx).</span><span class="sxs-lookup"><span data-stu-id="91d25-396">The interested student is directed to the [original article in JMLR](http://jmlr.org/papers/volume1/herbrich01a/herbrich01a.pdf) and an [insightful blog by Chris Bishop](http://blogs.technet.com/b/machinelearning/archive/2014/10/30/embracing-uncertainty-probabilistic-inference.aspx).</span></span>

### <a name="specialized-algorithms"></a><span data-ttu-id="91d25-397">Специализированные алгоритмы</span><span class="sxs-lookup"><span data-stu-id="91d25-397">Specialized algorithms</span></span>
<span data-ttu-id="91d25-398">При наличии очень конкретной цели вам может повезти со специализированным алгоритмом.</span><span class="sxs-lookup"><span data-stu-id="91d25-398">If you have a very specific goal you may be in luck.</span></span> <span data-ttu-id="91d25-399">В коллекции машинного обучения Azure есть алгоритмы, которые специализируются на:</span><span class="sxs-lookup"><span data-stu-id="91d25-399">Within the Azure Machine Learning collection, there are algorithms that specialize in:</span></span>

- <span data-ttu-id="91d25-400">прогнозировании ранжирования ([порядковая регрессия](https://msdn.microsoft.com/library/azure/dn906029.aspx));</span><span class="sxs-lookup"><span data-stu-id="91d25-400">rank prediction ([ordinal regression](https://msdn.microsoft.com/library/azure/dn906029.aspx)),</span></span>
- <span data-ttu-id="91d25-401">количественных прогнозах ([регрессия Пуассона](https://msdn.microsoft.com/library/azure/dn905988.aspx));</span><span class="sxs-lookup"><span data-stu-id="91d25-401">count prediction ([Poisson regression](https://msdn.microsoft.com/library/azure/dn905988.aspx)),</span></span>
- <span data-ttu-id="91d25-402">обнаружении аномалий (на основе [анализа основных компонентов](https://msdn.microsoft.com/library/azure/dn913102.aspx) и на основе [метода опорных векторов](https://msdn.microsoft.com/library/azure/dn913103.aspx));</span><span class="sxs-lookup"><span data-stu-id="91d25-402">anomaly detection (one based on [principal components analysis](https://msdn.microsoft.com/library/azure/dn913102.aspx) and one based on [support vector machine](https://msdn.microsoft.com/library/azure/dn913103.aspx)s)</span></span>
- <span data-ttu-id="91d25-403">кластеризации ([K-средних](https://msdn.microsoft.com/library/azure/5049a09b-bd90-4c4e-9b46-7c87e3a36810/)).</span><span class="sxs-lookup"><span data-stu-id="91d25-403">clustering ([K-means](https://msdn.microsoft.com/library/azure/5049a09b-bd90-4c4e-9b46-7c87e3a36810/))</span></span>

![Обнаружение аномалий на основе анализа первичных компонентов][8]

<span data-ttu-id="91d25-405">***Обнаружение аномалий на основе анализа первичных компонентов*** *— большинство данных попадает в стереотипное распределение; подозрительными считаются точки, которые значительно отклоняются от этого распределения*</span><span class="sxs-lookup"><span data-stu-id="91d25-405">***PCA-based anomaly detection*** *- the vast majority of the data falls into a stereotypical distribution; points deviating dramatically from that distribution are suspect*</span></span>

![Набор данных, сгруппированный с использованием K-средних][9]

<span data-ttu-id="91d25-407">***Набор данных группируется в пять кластеров с использованием K-средних***</span><span class="sxs-lookup"><span data-stu-id="91d25-407">***A data set is grouped into five clusters using K-means***</span></span>

<span data-ttu-id="91d25-408">Также существует [многоклассовая классификация "один-все"](https://msdn.microsoft.com/library/azure/dn905887.aspx), которая разбивает проблему классификации класса N на проблемы двухклассовой классификации класса N-1.</span><span class="sxs-lookup"><span data-stu-id="91d25-408">There is also an ensemble [one-v-all multiclass classifier](https://msdn.microsoft.com/library/azure/dn905887.aspx), which breaks the N-class classification problem into N-1 two-class classification problems.</span></span> <span data-ttu-id="91d25-409">Точность, время обучения и свойства линейности определяются используемыми двухклассовыми классификаторами.</span><span class="sxs-lookup"><span data-stu-id="91d25-409">The accuracy, training time, and linearity properties are determined by the two-class classifiers used.</span></span>

![Двухклассные классификаторы объединяются для получения трехклассного классификатора][10]

<span data-ttu-id="91d25-411">***Два двухклассовых классификатора объединяются вместе для получения трехклассового классификатора.***</span><span class="sxs-lookup"><span data-stu-id="91d25-411">***A pair of two-class classifiers combine to form a three-class classifier***</span></span>

<span data-ttu-id="91d25-412">Машинное обучение Azure также включает доступ к мощной платформе машинного обучения под названием [Vowpal Wabbit](https://msdn.microsoft.com/library/azure/8383eb49-c0a3-45db-95c8-eb56a1fef5bf).</span><span class="sxs-lookup"><span data-stu-id="91d25-412">Azure Machine Learning also includes access to a powerful machine learning framework under the title of [Vowpal Wabbit](https://msdn.microsoft.com/library/azure/8383eb49-c0a3-45db-95c8-eb56a1fef5bf).</span></span>
<span data-ttu-id="91d25-413">Эта платформа пренебрегает приведенной здесь классификацией, так как может решать как классификационные, так и регрессионные задачи и даже обучаться на основе частично неразмеченных данных.</span><span class="sxs-lookup"><span data-stu-id="91d25-413">VW defies categorization here, since it can learn both classification and regression problems and can even learn from partially unlabeled data.</span></span> <span data-ttu-id="91d25-414">Ее можно настроить для использования любого алгоритма обучения, любой функции потери и любого алгоритма оптимизации.</span><span class="sxs-lookup"><span data-stu-id="91d25-414">You can configure it to use any one of a number of learning algorithms, loss functions, and optimization algorithms.</span></span> <span data-ttu-id="91d25-415">Эта система изначально разрабатывалась как эффективная, параллельная и очень быстрая.</span><span class="sxs-lookup"><span data-stu-id="91d25-415">It was designed from the ground up to be efficient, parallel, and extremely fast.</span></span> <span data-ttu-id="91d25-416">Она обрабатывает огромные наборы функций с минимальными усилиями.</span><span class="sxs-lookup"><span data-stu-id="91d25-416">It handles ridiculously large feature sets with little apparent effort.</span></span>
<span data-ttu-id="91d25-417">Запущенная и управляемая Джоном Лэнгфордом из Microsoft Research, Vowpal Wabbit — это "формула один" среди других алгоритмов.</span><span class="sxs-lookup"><span data-stu-id="91d25-417">Started and led by Microsoft Research's own John Langford, VW is a Formula One entry in a field of stock car algorithms.</span></span> <span data-ttu-id="91d25-418">С помощью Vowpal Wabbit можно решить не все задачи, но если система подходит для вашей задачи, возможно, стоит потратить время на изучение интерфейса системы.</span><span class="sxs-lookup"><span data-stu-id="91d25-418">Not every problem fits VW, but if yours does, it may be worth your while to climb the learning curve on its interface.</span></span> <span data-ttu-id="91d25-419">Система также доступна в виде [автономного открытого исходного кода](https://github.com/JohnLangford/vowpal_wabbit) на нескольких языках.</span><span class="sxs-lookup"><span data-stu-id="91d25-419">It's also available as [stand-alone open source code](https://github.com/JohnLangford/vowpal_wabbit) in several languages.</span></span>

## <a name="more-help-with-algorithms"></a><span data-ttu-id="91d25-420">Дополнительная помощь с алгоритмами</span><span class="sxs-lookup"><span data-stu-id="91d25-420">More help with algorithms</span></span>
* <span data-ttu-id="91d25-421">Сведения о скачиваемой инфографике с описанием алгоритмов и примерами см. в статье [Загружаемая инфографика по основам машинного обучения с примерами алгоритмов](machine-learning-basics-infographic-with-algorithm-examples.md).</span><span class="sxs-lookup"><span data-stu-id="91d25-421">For a downloadable infographic that describes algorithms and provides examples, see [Downloadable Infographic: Machine learning basics with algorithm examples](machine-learning-basics-infographic-with-algorithm-examples.md).</span></span>
* <span data-ttu-id="91d25-422">Список по категориям всех алгоритмов машинного обучения в студии машинного обучения Azure см. в разделе [модель инициализации] [ initialize-model] в алгоритм-Studio машинного обучения, а также помочь модуля.</span><span class="sxs-lookup"><span data-stu-id="91d25-422">For a list by category of all the machine learning algorithms available in Azure Machine Learning Studio, see [Initialize Model][initialize-model] in the Machine Learning Studio Algorithm and Module Help.</span></span>
* <span data-ttu-id="91d25-423">Полный алфавитный список алгоритмов и модули в студии машинного обучения Azure см. в разделе [A-Z список модулей студии машинного обучения] [ a-z-list] в Studio алгоритм машинного обучения, а также помочь модуля.</span><span class="sxs-lookup"><span data-stu-id="91d25-423">For a complete alphabetical list of algorithms and modules in Azure Machine Learning Studio, see [A-Z list of Machine Learning Studio modules][a-z-list] in Machine Learning Studio Algorithm and Module Help.</span></span>
* <span data-ttu-id="91d25-424">Чтобы скачать и распечатать схему, на которой представлены общие возможности Студии машинного обучения Azure, см. [обзорную схему возможностей Студии машинного обучения Azure](machine-learning-studio-overview-diagram.md).</span><span class="sxs-lookup"><span data-stu-id="91d25-424">To download and print a diagram that gives an overview of the capabilities of Azure Machine Learning Studio, see [Overview diagram of Azure Machine Learning Studio capabilities](machine-learning-studio-overview-diagram.md).</span></span>


<!-- Reference links -->
[initialize-model]: https://msdn.microsoft.com/library/azure/dn905812.aspx
[a-z-list]: https://msdn.microsoft.com/library/azure/dn906033.aspx

<!-- Media -->

[1]: ./media/machine-learning-algorithm-choice/image1.png
[2]: ./media/machine-learning-algorithm-choice/image2.png
[3]: ./media/machine-learning-algorithm-choice/image3.png
[4]: ./media/machine-learning-algorithm-choice/image4.png
[5]: ./media/machine-learning-algorithm-choice/image5.png
[6]: ./media/machine-learning-algorithm-choice/image6.png
[7]: ./media/machine-learning-algorithm-choice/image7.png
[8]: ./media/machine-learning-algorithm-choice/image8.png
[9]: ./media/machine-learning-algorithm-choice/image9.png
[10]: ./media/machine-learning-algorithm-choice/image10.png
