---
title: "aaaHow toochoose алгоритмов машинного обучения | Документы Microsoft"
description: "Как toochoose машинного обучения Azure алгоритмы для защищенных и незащищенных обучения в кластеризации, классификации или регрессии экспериментов."
services: machine-learning
documentationcenter: 
author: garyericson
manager: jhubbard
editor: cgronlun
tags: 
ms.assetid: a3b23d7f-f083-49c4-b6b1-3911cd69f1b4
ms.service: machine-learning
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: data-services
ms.date: 04/25/2017
ms.author: garye
ms.openlocfilehash: 367b2278acc2435f27f9d24ead8199db58aca283
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 10/06/2017
---
# <a name="how-toochoose-algorithms-for-microsoft-azure-machine-learning"></a>Как toochoose алгоритмы машинного обучения Microsoft Azure
Hello ответить на вопрос toohello «какие машинного обучения алгоритм следует использовать?» всегда звучит так: "Это зависит от ряда обстоятельств". Это зависит от размера hello, качества и характер данных hello. Это зависит от того, какие действия следует toodo ответ hello. Это зависит от того, преобразование hello математического алгоритма hello в инструкции для hello компьютера, которую вы используете. И это зависит от того, сколько времени у вас есть. Даже наиболее произошел hello специалистами по анализу данных не может определить, какой алгоритм будет показывают максимальную производительность, прежде чем их.

## <a name="hello-machine-learning-algorithm-cheat-sheet"></a>Hello машины обучения алгоритм Памятка
Hello **Microsoft Azure машины обучения алгоритм Памятка** помогает выбрать справа hello машины обучающий алгоритм для прогнозирующего анализа решений из библиотеки машинного обучения Microsoft Azure hello алгоритмов.
В этой статье описано, как toouse его.

> [!NOTE]
> toodownload hello памятку и следовать вместе с этой статьей, перейдите в слишком[машинного обучения алгоритм памятку для Microsoft студии машинного обучения Azure](machine-learning-algorithm-cheat-sheet.md).
> 
> 

Это памятку имеет очень конкретной аудитории в виду: начало специалист по анализу данных с уровня окончании учебного заведения машинного обучения, попытки toochoose toostart алгоритм с в студии машинного обучения Azure. Это означает, что в памятке используются некоторые обобщения и упрощения, но она направит вас в верном направлении. Это также означает, что существует множество алгоритмов, которые не описаны в памятке. При увеличении tooencompass более полный набор доступных методов машинного обучения Azure мы добавим их.

Эти рекомендации представляют собой объединенные отзывы и советы от большого количества специалистов по обработке и анализу данных, а также экспертов по машинному обучению. Мы не согласны на все элементы, но tooharmonize были проверены наши мысли в сложных согласие. Большинство инструкций hello разногласий начинаются с «Они зависят от...»

### <a name="how-toouse-hello-cheat-sheet"></a>Как Памятка toouse hello
Чтение hello и алгоритм меток на диаграмме hello как» для  *&lt;метка пути&gt;*, используйте  *&lt;алгоритм&gt;*.» Например, "для *скорости* используйте *двухклассную логистическую регрессию*". Иногда может использоваться более одной ветви алгоритма.
Иногда ни одна из ветвей алгоритма не подходит идеально. Они — предполагаемого toobe правило из thumb рекомендации, поэтому не стоит беспокоиться, точно.
Несколько специалистов по анализу данных я говорил с говорят, только что способом для определения наилучшего алгоритм hello, tootry hello их все.

Ниже приведен пример hello [коллекции аналитики Cortana](http://gallery.cortanaintelligence.com/) эксперимент, который предпринимает несколько алгоритмов для hello тем же данным и сравнивает hello результатов: [сравнения классификаторов несколькими классами: буква распознавания ](http://gallery.cortanaintelligence.com/Details/a635502fc98b402a890efe21cec65b92).

> [!TIP]
> toodownload и печати см. на диаграмме, которая позволяет получить представление о возможности hello студии машинного обучения [Обзорная схема возможностей студии машинного обучения Azure](machine-learning-studio-overview-diagram.md).
> 
> 

## <a name="flavors-of-machine-learning"></a>Разновидности машинного обучения
### <a name="supervised"></a>Контролируемое
Контролируемые алгоритмы обучения выполняют прогнозирование на основе набора примеров. Для экземпляра исторических акций может быть используется toohazard предположений в будущем цены. В каждом примере использовались для обучения помечается hello интересующее значение — в этом случае hello акций. Контролируемый алгоритм обучения выполняет поиск шаблонов в этих значениях. Он может использовать любые сведения, которые могут быть применимо — hello день недели hello, сезона hello, hello финансовых данных компании, тип hello отрасли, наличие hello нарушают работу геополитические события — и каждый алгоритм ищет различные виды шаблонов. После обнаружения hello лучше всего, он может hello алгоритм использует без метки проверочных данных, что шаблон toomake прогнозы для — завтра цены.

Контролируемое обучение — это популярный и полезный тип машинного обучения. За одним исключением все модули hello в машинном обучении Azure контролируемых алгоритмы обучения. В машинном обучении Azure существует несколько типов контролируемых алгоритмов обучения: классификация, регрессия и обнаружение аномалий.

* **Классификация**. Когда данные hello используется toopredict категорию, контролируемого обучения также называется классификации. Это случай hello назначение изображения в виде изображений «cat» и «dog». При наличии только двух вариантов такая классификация называется **двухклассной** или **биномиальной**. Если имеются дополнительные категории, как при прогнозировании hello победитель турнира кошмар марта NCAA hello, эта проблема известна как **многоклассовый классификатор**.
* **Регрессия**. При прогнозировании значения, например стоимости акций, контролируемое обучение называется регрессией.
* **Обнаружение аномалий**. Иногда hello целью является tooidentify точки данных, которые встречаются достаточно редко. Например, при выявлении мошенничества с кредитной картой подозрительными являются любые необычные операции оплаты. Возможные варианты Hello, поэтому много и hello обучающих примеров, поэтому несколько, что это не представляется возможной toolearn какие мошенничестве выглядит следующим образом. Подход, который обнаружение аномалий является toosimply узнать, какие обычную операцию выглядит следующим образом (с помощью журнала-мошеннические транзакции) и определить все, что существенно отличается.

### <a name="unsupervised"></a>Неконтролируемое
При неконтролируемом обучении точкам данных не присваиваются метки. Вместо этого задача hello незащищенных обучения, алгоритм предназначено для организации данных hello в некоторых способом или toodescribe ее структуру. Это может означать группировку данных в кластеры или поиск различных способов анализа сложных данных для их упрощения или улучшения их организации.

### <a name="reinforcement-learning"></a>Обучение с подкреплением
Усиление обучения, алгоритм hello возвращает toochoose действие в точке данных tooeach ответа. Hello обучающего алгоритма также получает сигнал вознаграждения, проведенное на короткое время более поздних версиях, позволяющее определить, насколько хорошо hello принятия решений.
На основе этого алгоритма hello изменяет его стратегии в порядке tooachieve hello наибольший вознаграждения. На данный момент в машинном обучении Azure модули алгоритмов обучения с подкреплением отсутствуют. Усиление обучения проявляется в robotics hello набор показания датчиков в один момент времени является точкой данных, куда hello алгоритм необходимо выбрать следующее действие hello робот. Кроме того, оно естественным образом подходит для приложений из Интернета вещей.

## <a name="considerations-when-choosing-an-algorithm"></a>Рекомендации по выбору алгоритма
### <a name="accuracy"></a>Точность
Получения наиболее точных ответов hello возможных не всегда обязательно.
Иногда достаточно приближенного ответа в зависимости от того, для чего он используется. Если это hello так, может быть может toocut время обработки значительно по использовать именно дополнительные методы приблизительное. Еще одним преимуществом более приближенных методов является то, что они естественным образом стремятся избежать [чрезмерно высокой точности](https://youtu.be/DQWI1kvmwRg).

### <a name="training-time"></a>Время обучения
Здравствуйте, количество минут или часов необходимые tootrain, модель может быть гораздо алгоритмов. Время на обучение часто тесно связана с точностью — один обычно сопровождающий hello других. Кроме того некоторые алгоритмы являются чувствительными номер toohello точек данных, чем другие.
При ограниченном времени, может управлять hello выбрать алгоритм, особенно в том случае, если задан большой набор данных hello.

### <a name="linearity"></a>Линейность
Линейность используется во многих алгоритмах машинного обучения. Алгоритмы линейной классификации предполагают, что классы могут быть разделены прямой линией (или ее аналогом для большего числа измерений). К ним относятся логистическая регрессия и метод опорных векторов (в том виде, в котором это реализовано в машинном обучении Azure).
Алгоритмы линейной регрессии предполагают, что тренды данных следуют прямой линии. Эти предположения допустимы для ряда задач, но для других задач они приводят к снижению точности.

![Граница нелинейного класса][1]

***Граница нелинейного класса*** *— использование алгоритма линейной классификации приведет к низкой точности*

![Данные с нелинейным трендом][2]

***Данные с нелинейным трендом*** *— использование алгоритма линейной классификации приведет к появлению гораздо большего количества ошибок, чем необходимо*

Несмотря на их опасность, линейные алгоритмы очень популярны на первой линии атаки. Они обычно toobe типовой простым и быстрым для обучения.

### <a name="number-of-parameters"></a>Количество параметров
Параметры являются элементы hello анализу данных, который возвращает tooturn при настройке алгоритма. Они являются числами, которые влияют на поведение hello алгоритм, например погрешность или число итераций и параметры между варианты поведения алгоритма hello. Hello время обучения и точности алгоритма hello иногда может быть довольно конфиденциальных toogetting просто hello нужные параметры. Как правило алгоритмы с большим числом параметров, требуется наиболее пробной hello и toofind ошибка хорошо сочетания.

Кроме того, в машинном обучении Azure есть блок модулей [корректировки параметров](machine-learning-algorithm-parameters-optimize.md) , который автоматически пробует все сочетания параметров с любой выбранной детализацией. Хотя это toomake хорошим способом, убедитесь, что охваченных hello параметр пространства, tootrain время, необходимое для hello модели растет в геометрической прогрессии с hello количеством параметров.

Hello плюсом — что наличие большого количества параметров обычно означает, что алгоритм большую гибкость. Это часто позволяет добиваться очень хорошей точности. При условии, что можно найти hello правильное сочетание параметров.

### <a name="number-of-features"></a>Количество функций
Для определенных типов данных число hello функций может быть очень больших сравниваемых toohello количество точек данных. Это часто относится hello genetics или текстовых данных. Hello большое количество функций можно освобождает вниз некоторые алгоритмы обучения, делая unfeasibly длинное время обучения. Машины опорных векторов, особенно хорошо подходит toothis регистр (см. ниже).

### <a name="special-cases"></a>Особые случаи
Некоторые алгоритмы обучения делать определенного предположения о hello структуру данных hello или hello требуемого результаты. Если вы сможете найти тот алгоритм, который соответствует вашим потребностям, с ним вы сможете получить более точные результаты, более точные прогнозы и сократить время обучения.

| **Алгоритм** | **Точность** | **Время обучения** | **Линейность** | **Параметры** | **Примечания** |
| --- |:---:|:---:|:---:|:---:| --- |
| **Двуклассовая классификация** | | | | | |
| [логистическая регрессия](https://msdn.microsoft.com/library/azure/dn905994.aspx) | |● |● |5 | |
| [лес решений](https://msdn.microsoft.com/library/azure/dn906008.aspx) |● |○ | |6 | |
| [джунгли решений](https://msdn.microsoft.com/library/azure/dn905976.aspx) |● |○ | |6 |Низкий объем памяти |
| [увеличивающееся дерево решений](https://msdn.microsoft.com/library/azure/dn906025.aspx) |● |○ | |6 |Большой объем памяти |
| [нейронная сеть](https://msdn.microsoft.com/library/azure/dn905947.aspx) |● | | |9 |[Возможна дополнительная настройка](http://go.microsoft.com/fwlink/?LinkId=402867) |
| [усредненное восприятие](https://msdn.microsoft.com/library/azure/dn906036.aspx) |○ |○ |● |4. | |
| [метод опорных векторов](https://msdn.microsoft.com/library/azure/dn905835.aspx) | |○ |● |5 |Подходит для больших наборов функций |
| [локально глубокий метод опорных векторов](https://msdn.microsoft.com/library/azure/dn913070.aspx) |○ | | |8 |Подходит для больших наборов функций |
| [точечная машина Байеса](https://msdn.microsoft.com/library/azure/dn905930.aspx) | |○ |● |3 | |
| **Многоклассовая классификация** | | | | | |
| [логистическая регрессия](https://msdn.microsoft.com/library/azure/dn905853.aspx) | |● |● |5 | |
| [лес решений](https://msdn.microsoft.com/library/azure/dn906015.aspx) |● |○ | |6 | |
| [джунгли решений ](https://msdn.microsoft.com/library/azure/dn905963.aspx) |● |○ | |6 |Низкий объем памяти |
| [нейронная сеть](https://msdn.microsoft.com/library/azure/dn906030.aspx) |● | | |9 |[Возможна дополнительная настройка](http://go.microsoft.com/fwlink/?LinkId=402867) |
| [one-v-all](https://msdn.microsoft.com/library/azure/dn905887.aspx) |- |- |- |- |Просмотреть свойства выбранного метода двух классов hello |
| **Регрессия** | | | | | |
| [линейная](https://msdn.microsoft.com/library/azure/dn905978.aspx) | |● |● |4 | |
| [Байесовская линейная](https://msdn.microsoft.com/library/azure/dn906022.aspx) | |○ |● |2 | |
| [лес решений](https://msdn.microsoft.com/library/azure/dn905862.aspx) |● |○ | |6 | |
| [увеличивающееся дерево решений](https://msdn.microsoft.com/library/azure/dn905801.aspx) |● |○ | |5 |Большой объем памяти |
| [квантильная регрессия быстрого леса](https://msdn.microsoft.com/library/azure/dn913093.aspx) |● |○ | |9 |Распределения, а не точечные прогнозы |
| [нейронная сеть](https://msdn.microsoft.com/library/azure/dn905924.aspx) |● | | |9 |[Возможна дополнительная настройка](http://go.microsoft.com/fwlink/?LinkId=402867) |
| [регрессия Пуассона](https://msdn.microsoft.com/library/azure/dn905988.aspx) | | |● |5 |С технической точки зрения логлинейная. Для прогнозирования количества |
| [порядковая](https://msdn.microsoft.com/library/azure/dn906029.aspx) | | | |0 |Для прогнозирования упорядочения за рангом |
| **Обнаружение аномалий** | | | | | |
| [метод опорных векторов](https://msdn.microsoft.com/library/azure/dn913103.aspx) |○ |○ | |2 |Особенно полезна для больших наборов функций |
| [Обнаружение аномалий на основе анализа первичных компонентов](https://msdn.microsoft.com/library/azure/dn913102.aspx) | |○ |● |3 | |
| [K-средних](https://msdn.microsoft.com/library/azure/5049a09b-bd90-4c4e-9b46-7c87e3a36810/) | |○ |● |4 |Алгоритм кластеризации |

**Свойства алгоритма:**

**●** -показывает высокую точность, время быстрого обучения и использования hello линейность

**○** — показывает хорошую точность и умеренное время обучения

## <a name="algorithm-notes"></a>Примечания к алгоритму
### <a name="linear-regression"></a>Linear regression
Как упоминалось ранее, [линейной регрессии](https://msdn.microsoft.com/library/azure/dn905978.aspx) соответствует toohello набора данных строки (или плоскости или гиперплоскостью). Это быстрая и простая "рабочая лошадка", но она может быть излишне простой для некоторых задач.
Руководство по линейной регрессии можно найти [здесь](machine-learning-linear-regression-in-azure.md).

![Данные с линейным трендом][3]

***Данные с линейным трендом***

### <a name="logistic-regression"></a>Логистическая регрессия
Несмотря на то, что его ввести в заблуждение содержится «Регрессия» в имени hello, логистическая Регрессия является фактически является мощным инструментом [двухклассовой](https://msdn.microsoft.com/library/azure/dn905994.aspx) и [мультиклассовых](https://msdn.microsoft.com/library/azure/dn905853.aspx) классификации. Это быстрый и простой метод. факт, что она использует Hello "-формы кривой вместо прямой упрощает разделение данных на группы естественным образом. Логистическая регрессия приводит к появлению линейных границ классов, поэтому при ее использовании убедитесь, что вам комфортно с линейной аппроксимацией.

![Алгоритм логистической регрессии tootwo класс данных с какой-либо функции][4]

***Класс tootwo данных логистической регрессии с какой-либо функции*** *-класс граница образована hello точку, в которой hello логистической кривой является так же, как закрыть tooboth классы*

### <a name="trees-forests-and-jungles"></a>Деревья, леса и джунгли
Леса решений ([регрессионные](https://msdn.microsoft.com/library/azure/dn905862.aspx), [двухклассовые](https://msdn.microsoft.com/library/azure/dn906008.aspx) и [многоклассовые](https://msdn.microsoft.com/library/azure/dn906015.aspx)), джунгли решений ([двухклассовые](https://msdn.microsoft.com/library/azure/dn905976.aspx) и [многоклассовые](https://msdn.microsoft.com/library/azure/dn905963.aspx)) и увеличивающиеся деревья решений ([регрессионные](https://msdn.microsoft.com/library/azure/dn905801.aspx) и [двухклассовые](https://msdn.microsoft.com/library/azure/dn906025.aspx)) основаны на деревьях решений, базовой концепции машинного обучения. Существует множество возможных дерева принятия решений, но все они выполняют то же самое — подразделять hello пространство признаков на области со основном hello одной метки. Это могут быть области с одинаковой категорией или одинаковым значением в зависимости от того, проводится ли классификация или регрессия.

![Дерево решений подразделяет пространство функций][5]

***Дерево решений подразделяет пространство функций на области примерно c одинаковыми значениями.***

Поскольку пространство признаков может быть разделен на произвольная небольшая регионах, это легко tooimagine делению точно достаточно toohave одна точка данных в одном регионе. Это крайний пример чрезмерно высокой точности. В порядке tooavoid это большой набор деревьев создаются осторожно специальные математические предпринято hello деревья не связаны. Среднее значение Hello «леса принятия решений» является деревом, чтобы избежать переобучения. Леса решений могут использовать большой объем памяти. Джунгли решений — это вариант, который потребляет меньше памяти за счет hello немного больше времени обучения.

В увеличивающихся деревьях решений во избежание чрезмерно высокой точности ограничиваются количество повторных делений и минимальное количество точек данных в каждом регионе. Алгоритм создает последовательность из дерева, каждый из которых узнает, чтобы компенсировать влево на дерево hello до ошибки hello. Hello результатом является очень точной ученик, который, как правило, toouse большого объема памяти. Для полной техническое описание hello, посетите [исходный документ Friedman](http://www-stat.stanford.edu/~jhf/ftp/trebst.pdf).

[Быстрая квантильная Регрессия леса](https://msdn.microsoft.com/library/azure/dn913093.aspx) является разновидностью дерева принятия решений для hello особый случай, где вы хотите знать не только hello типичные () значение медианы hello данных в пределах области, но его распространение в форме hello квантилей.

### <a name="neural-networks-and-perceptrons"></a>Нейронные сети и восприятия
Нейронные сети — это алгоритмы обучения, вдохновленные устройством человеческого мозга, которые охватывают [многоклассовые](https://msdn.microsoft.com/library/azure/dn906030.aspx), [двухклассовые](https://msdn.microsoft.com/library/azure/dn905947.aspx) и [регрессионные](https://msdn.microsoft.com/library/azure/dn905924.aspx) задачи. Они бывают безграничное разнообразие возможностей, но hello нейронных сетей в машинном обучении Azure — это все виды hello ациклического графа. Это означает, что входные функции передаются вперед (и только вперед) по последовательности слоев, после чего превращаются в выходные данные. В каждом слое входы снабжаются весовыми коэффициентами в различных сочетаниях, суммировать и передать следующий уровень hello. Такое сочетание результаты простых вычислений в toolearn возможности сложных тенденции класс границ и данных, первый взгляд магическая. Многоуровневая многие сетей такого рода выполнять hello «углубленного обучения», который fuels так много отчетов Технический и научной фантастики.

Но такая высокая производительность имеет и обратную сторону. Нейронной сети может занять длительное время tootrain, особенно для больших наборов данных с большим количеством функций. Они также имеют больше параметров, чем большинство алгоритмов, т. е. свертки параметров гораздо расширяет hello время обучения.
И для этих overachievers, которые хотите слишком[укажите свои собственные структуры сети](http://go.microsoft.com/fwlink/?LinkId=402867), возможны inexhaustible.

![Границы узнали нейронных сетей][6]
***границы hello узнали нейронных сетей могут быть сложными и нестандартные***

Hello [двухклассовый усредненный перцептрон](https://msdn.microsoft.com/library/azure/dn906036.aspx) — время обучения tooskyrocketing ответов нейронных сетей. В нем используется структура сети, предоставляющая линейные границы класса. Это почти примитивов, современных стандартов, но он имеет длинную историю работы надежно и достаточно малым toolearn быстро.

### <a name="svms"></a>Методы опорных векторов
Машины опорных векторов (SVM) найти hello границу, которая разделяет классы, как расширенный поля можно. При hello двух классов не могут быть четко отделены, алгоритмы hello найти границы наиболее hello, в которые они могут. Здравствуйте, как написано в машинном обучении Azure [SVM двухклассовой](https://msdn.microsoft.com/library/azure/dn905835.aspx) делает это с помощью прямой линии. (В терминах методов опорных векторов, они используют линейное ядро.) Поскольку это делает это линейной аппроксимации, это может toorun достаточно быстро. Эти методы действительно проявляют себя с данными с большим количеством функций, такими как текст или генетические данные. В таких случаях SVM — это классы могут tooseparate быстрее и с менее лжевзаимосвязей чем большинство других алгоритмов, кроме toorequiring небольшой объем памяти.

![Граница класса метода опорных векторов][7]

***Границе типичные поддержки машины вектора класса увеличивает поле hello, разделяющих два класса***

Другой продукт из Microsoft Research hello [SVM локальной глубиной двух классов](https://msdn.microsoft.com/library/azure/dn913070.aspx) нелинейного вариант SVM, сохраняет большинство hello памяти и эффективность линейной версии hello. Идеально подходит для случаев, где hello линейный подход не дает достаточно точных ответов. Разработчики Hello удалили его быстро разрывая проблемы hello в кучу небольших линейной SVM проблем. Чтение hello [полное описание](http://research.microsoft.com/um/people/manik/pubs/Jose13.pdf) hello сведения о том, как они извлечено off этот прием.

Здравствуйте, используя расширение некий нелинейный SVM, [Одноклассовой](https://msdn.microsoft.com/library/azure/dn913103.aspx) рисует границу, которая тесно описаны hello весь набор данных. Это удобно для обнаружения аномалий. Все новые точки данных, далеко выходящих за пределы границ, являются достаточно необычные toobe внимания.

### <a name="bayesian-methods"></a>Методы Байеса
Методы Байеса имеют одно очень ценное качество: они не приводят к чрезмерному увеличению точности. Это делается, делая некоторые предположения заранее об hello вероятность распределения hello ответов. Другим побочным эффектом этого подхода является то, что у этих методов очень мало параметров. В Машинном обучении Azure есть оба алгоритма Байеса для классификации ([двухклассная точечная машина Байеса](https://msdn.microsoft.com/library/azure/dn905930.aspx)) и регрессии ([линейная регрессия Байеса](https://msdn.microsoft.com/library/azure/dn906022.aspx)).
Обратите внимание, что эти предполагается hello данные можно разбить или сочетаются с прямой линии.

С исторической точки зрения точечные машины Байеса были разработаны в Microsoft Research. За ними стоит исключительная теоретическая работа. Hello интерес студента — расширенный toohello [оригинальная статья в JMLR](http://jmlr.org/papers/volume1/herbrich01a/herbrich01a.pdf) и [информативные блоге Криса Бишопа](http://blogs.technet.com/b/machinelearning/archive/2014/10/30/embracing-uncertainty-probabilistic-inference.aspx).

### <a name="specialized-algorithms"></a>Специализированные алгоритмы
При наличии очень конкретной цели вам может повезти со специализированным алгоритмом. В рамках hello коллекции машинного обучения Azure существуют алгоритмы, которые специализируются на:

- прогнозировании ранжирования ([порядковая регрессия](https://msdn.microsoft.com/library/azure/dn906029.aspx));
- количественных прогнозах ([регрессия Пуассона](https://msdn.microsoft.com/library/azure/dn905988.aspx));
- обнаружении аномалий (на основе [анализа основных компонентов](https://msdn.microsoft.com/library/azure/dn913102.aspx) и на основе [метода опорных векторов](https://msdn.microsoft.com/library/azure/dn913103.aspx));
- кластеризации ([K-средних](https://msdn.microsoft.com/library/azure/5049a09b-bd90-4c4e-9b46-7c87e3a36810/)).

![Обнаружение аномалий на основе анализа первичных компонентов][8]

***Обнаружение аномалий на основе PCA*** *-hello большинство данных hello попадает и стереотипном распространения; значительно уклониться от этой точки, как подозрительная*

![Набор данных, сгруппированный с использованием K-средних][9]

***Набор данных группируется в пять кластеров с использованием K-средних***

Имеется также совокупности [мультиклассового классификатора один v все](https://msdn.microsoft.com/library/azure/dn905887.aspx), какие проблемы классификации разрывов hello класс N в n-1 двухклассовой классификации проблем. Точность Hello, время обучения и линейность свойства определяются hello двухклассовых классификаторов используется.

![Двухклассовых классификаторов вместе tooform классификатор трех класс][10]

***Пара двухклассовых классификаторов объединить tooform классификатор трех класс***

Также Azure машинного обучения включает платформу tooa мощные машинного обучения доступа под названием hello объекта [Vowpal Wabbit](https://msdn.microsoft.com/library/azure/8383eb49-c0a3-45db-95c8-eb56a1fef5bf).
Эта платформа пренебрегает приведенной здесь классификацией, так как может решать как классификационные, так и регрессионные задачи и даже обучаться на основе частично неразмеченных данных. Можно настроить его toouse любому из ряд обучающих алгоритмов, потери функциях и алгоритмах оптимизации. Он был разработан с hello основание, toobe, параллельные и очень быстро. Она обрабатывает огромные наборы функций с минимальными усилиями.
Запущенная и управляемая Джоном Лэнгфордом из Microsoft Research, Vowpal Wabbit — это "формула один" среди других алгоритмов. Не все проблемы занимает VW, но, если указанное имя не, возможно, стоит этого tooclimb обучения для интерфейса. Система также доступна в виде [автономного открытого исходного кода](https://github.com/JohnLangford/vowpal_wabbit) на нескольких языках.

## <a name="more-help-with-algorithms"></a>Дополнительная помощь с алгоритмами
* Сведения о скачиваемой инфографике с описанием алгоритмов и примерами см. в статье [Загружаемая инфографика по основам машинного обучения с примерами алгоритмов](machine-learning-basics-infographic-with-algorithm-examples.md).
* Список по типам алгоритмов машинного обучения всех hello, доступные в студии машинного обучения Azure см. в разделе [модель инициализации] [ initialize-model] в hello машины обучения Studio алгоритм и модуль справки.
* Полный список всех алгоритмов и модулей машинного обучения, доступных в Студии машинного обучения, расположенных в алфавитном порядке, см. в справке по алгоритмам и модулям Студии машинного обучения [A-Z List of Machine Learning Studio Modules][a-z-list] (Полный список модулей Студии машинного обучения).
* toodownload и печати на диаграмме, которая позволяет получить представление о возможности hello студии машинного обучения Azure в разделе [Обзорная схема возможностей студии машинного обучения Azure](machine-learning-studio-overview-diagram.md).


<!-- Reference links -->
[initialize-model]: https://msdn.microsoft.com/library/azure/dn905812.aspx
[a-z-list]: https://msdn.microsoft.com/library/azure/dn906033.aspx

<!-- Media -->

[1]: ./media/machine-learning-algorithm-choice/image1.png
[2]: ./media/machine-learning-algorithm-choice/image2.png
[3]: ./media/machine-learning-algorithm-choice/image3.png
[4]: ./media/machine-learning-algorithm-choice/image4.png
[5]: ./media/machine-learning-algorithm-choice/image5.png
[6]: ./media/machine-learning-algorithm-choice/image6.png
[7]: ./media/machine-learning-algorithm-choice/image7.png
[8]: ./media/machine-learning-algorithm-choice/image8.png
[9]: ./media/machine-learning-algorithm-choice/image9.png
[10]: ./media/machine-learning-algorithm-choice/image10.png
