---
title: "aaaHow toochoose алгоритмов машинного обучения | Документы Microsoft"
description: "Как toochoose машинного обучения Azure алгоритмы для защищенных и незащищенных обучения в кластеризации, классификации или регрессии экспериментов."
services: machine-learning
documentationcenter: 
author: garyericson
manager: jhubbard
editor: cgronlun
tags: 
ms.assetid: a3b23d7f-f083-49c4-b6b1-3911cd69f1b4
ms.service: machine-learning
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: data-services
ms.date: 04/25/2017
ms.author: garye
ms.openlocfilehash: 367b2278acc2435f27f9d24ead8199db58aca283
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 10/06/2017
---
# <a name="how-toochoose-algorithms-for-microsoft-azure-machine-learning"></a><span data-ttu-id="907ca-103">Как toochoose алгоритмы машинного обучения Microsoft Azure</span><span class="sxs-lookup"><span data-stu-id="907ca-103">How toochoose algorithms for Microsoft Azure Machine Learning</span></span>
<span data-ttu-id="907ca-104">Hello ответить на вопрос toohello «какие машинного обучения алгоритм следует использовать?»</span><span class="sxs-lookup"><span data-stu-id="907ca-104">hello answer toohello question "What machine learning algorithm should I use?"</span></span> <span data-ttu-id="907ca-105">всегда звучит так: "Это зависит от ряда обстоятельств".</span><span class="sxs-lookup"><span data-stu-id="907ca-105">is always "It depends."</span></span> <span data-ttu-id="907ca-106">Это зависит от размера hello, качества и характер данных hello.</span><span class="sxs-lookup"><span data-stu-id="907ca-106">It depends on hello size, quality, and nature of hello data.</span></span> <span data-ttu-id="907ca-107">Это зависит от того, какие действия следует toodo ответ hello.</span><span class="sxs-lookup"><span data-stu-id="907ca-107">It depends on what you want toodo with hello answer.</span></span> <span data-ttu-id="907ca-108">Это зависит от того, преобразование hello математического алгоритма hello в инструкции для hello компьютера, которую вы используете.</span><span class="sxs-lookup"><span data-stu-id="907ca-108">It depends on how hello math of hello algorithm was translated into instructions for hello computer you are using.</span></span> <span data-ttu-id="907ca-109">И это зависит от того, сколько времени у вас есть.</span><span class="sxs-lookup"><span data-stu-id="907ca-109">And it depends on how much time you have.</span></span> <span data-ttu-id="907ca-110">Даже наиболее произошел hello специалистами по анализу данных не может определить, какой алгоритм будет показывают максимальную производительность, прежде чем их.</span><span class="sxs-lookup"><span data-stu-id="907ca-110">Even hello most experienced data scientists can't tell which algorithm will perform best before trying them.</span></span>

## <a name="hello-machine-learning-algorithm-cheat-sheet"></a><span data-ttu-id="907ca-111">Hello машины обучения алгоритм Памятка</span><span class="sxs-lookup"><span data-stu-id="907ca-111">hello Machine Learning Algorithm Cheat Sheet</span></span>
<span data-ttu-id="907ca-112">Hello **Microsoft Azure машины обучения алгоритм Памятка** помогает выбрать справа hello машины обучающий алгоритм для прогнозирующего анализа решений из библиотеки машинного обучения Microsoft Azure hello алгоритмов.</span><span class="sxs-lookup"><span data-stu-id="907ca-112">hello **Microsoft Azure Machine Learning Algorithm Cheat Sheet** helps you choose hello right machine learning algorithm for your predictive analytics solutions from hello Microsoft Azure Machine Learning library of algorithms.</span></span>
<span data-ttu-id="907ca-113">В этой статье описано, как toouse его.</span><span class="sxs-lookup"><span data-stu-id="907ca-113">This article walks you through how toouse it.</span></span>

> [!NOTE]
> <span data-ttu-id="907ca-114">toodownload hello памятку и следовать вместе с этой статьей, перейдите в слишком[машинного обучения алгоритм памятку для Microsoft студии машинного обучения Azure](machine-learning-algorithm-cheat-sheet.md).</span><span class="sxs-lookup"><span data-stu-id="907ca-114">toodownload hello cheat sheet and follow along with this article, go too[Machine learning algorithm cheat sheet for Microsoft Azure Machine Learning Studio](machine-learning-algorithm-cheat-sheet.md).</span></span>
> 
> 

<span data-ttu-id="907ca-115">Это памятку имеет очень конкретной аудитории в виду: начало специалист по анализу данных с уровня окончании учебного заведения машинного обучения, попытки toochoose toostart алгоритм с в студии машинного обучения Azure.</span><span class="sxs-lookup"><span data-stu-id="907ca-115">This cheat sheet has a very specific audience in mind: a beginning data scientist with undergraduate-level machine learning, trying toochoose an algorithm toostart with in Azure Machine Learning Studio.</span></span> <span data-ttu-id="907ca-116">Это означает, что в памятке используются некоторые обобщения и упрощения, но она направит вас в верном направлении.</span><span class="sxs-lookup"><span data-stu-id="907ca-116">That means that it makes some generalizations and oversimplifications, but it points you in a safe direction.</span></span> <span data-ttu-id="907ca-117">Это также означает, что существует множество алгоритмов, которые не описаны в памятке.</span><span class="sxs-lookup"><span data-stu-id="907ca-117">It also means that there are lots of algorithms not listed here.</span></span> <span data-ttu-id="907ca-118">При увеличении tooencompass более полный набор доступных методов машинного обучения Azure мы добавим их.</span><span class="sxs-lookup"><span data-stu-id="907ca-118">As Azure Machine Learning grows tooencompass a more complete set of available methods, we'll add them.</span></span>

<span data-ttu-id="907ca-119">Эти рекомендации представляют собой объединенные отзывы и советы от большого количества специалистов по обработке и анализу данных, а также экспертов по машинному обучению.</span><span class="sxs-lookup"><span data-stu-id="907ca-119">These recommendations are compiled feedback and tips from many data scientists and machine learning experts.</span></span> <span data-ttu-id="907ca-120">Мы не согласны на все элементы, но tooharmonize были проверены наши мысли в сложных согласие.</span><span class="sxs-lookup"><span data-stu-id="907ca-120">We didn't agree on everything, but I've tried tooharmonize our opinions into a rough consensus.</span></span> <span data-ttu-id="907ca-121">Большинство инструкций hello разногласий начинаются с «Они зависят от...»</span><span class="sxs-lookup"><span data-stu-id="907ca-121">Most of hello statements of disagreement begin with "It depends…"</span></span>

### <a name="how-toouse-hello-cheat-sheet"></a><span data-ttu-id="907ca-122">Как Памятка toouse hello</span><span class="sxs-lookup"><span data-stu-id="907ca-122">How toouse hello cheat sheet</span></span>
<span data-ttu-id="907ca-123">Чтение hello и алгоритм меток на диаграмме hello как» для  *&lt;метка пути&gt;*, используйте  *&lt;алгоритм&gt;*.»</span><span class="sxs-lookup"><span data-stu-id="907ca-123">Read hello path and algorithm labels on hello chart as "For *&lt;path label&gt;*, use *&lt;algorithm&gt;*."</span></span> <span data-ttu-id="907ca-124">Например, "для *скорости* используйте *двухклассную логистическую регрессию*".</span><span class="sxs-lookup"><span data-stu-id="907ca-124">For example, "For *speed*, use *two class logistic regression*."</span></span> <span data-ttu-id="907ca-125">Иногда может использоваться более одной ветви алгоритма.</span><span class="sxs-lookup"><span data-stu-id="907ca-125">Sometimes more than one branch applies.</span></span>
<span data-ttu-id="907ca-126">Иногда ни одна из ветвей алгоритма не подходит идеально.</span><span class="sxs-lookup"><span data-stu-id="907ca-126">Sometimes none of them are a perfect fit.</span></span> <span data-ttu-id="907ca-127">Они — предполагаемого toobe правило из thumb рекомендации, поэтому не стоит беспокоиться, точно.</span><span class="sxs-lookup"><span data-stu-id="907ca-127">They're intended toobe rule-of-thumb recommendations, so don't worry about it being exact.</span></span>
<span data-ttu-id="907ca-128">Несколько специалистов по анализу данных я говорил с говорят, только что способом для определения наилучшего алгоритм hello, tootry hello их все.</span><span class="sxs-lookup"><span data-stu-id="907ca-128">Several data scientists I talked with said that hello only sure way to find hello very best algorithm is tootry all of them.</span></span>

<span data-ttu-id="907ca-129">Ниже приведен пример hello [коллекции аналитики Cortana](http://gallery.cortanaintelligence.com/) эксперимент, который предпринимает несколько алгоритмов для hello тем же данным и сравнивает hello результатов: [сравнения классификаторов несколькими классами: буква распознавания ](http://gallery.cortanaintelligence.com/Details/a635502fc98b402a890efe21cec65b92).</span><span class="sxs-lookup"><span data-stu-id="907ca-129">Here's an example from hello [Cortana Intelligence Gallery](http://gallery.cortanaintelligence.com/) of an experiment that tries several algorithms against hello same data and compares hello results: [Compare Multi-class Classifiers: Letter recognition](http://gallery.cortanaintelligence.com/Details/a635502fc98b402a890efe21cec65b92).</span></span>

> [!TIP]
> <span data-ttu-id="907ca-130">toodownload и печати см. на диаграмме, которая позволяет получить представление о возможности hello студии машинного обучения [Обзорная схема возможностей студии машинного обучения Azure](machine-learning-studio-overview-diagram.md).</span><span class="sxs-lookup"><span data-stu-id="907ca-130">toodownload and print a diagram that gives an overview of hello capabilities of Machine Learning Studio, see [Overview diagram of Azure Machine Learning Studio capabilities](machine-learning-studio-overview-diagram.md).</span></span>
> 
> 

## <a name="flavors-of-machine-learning"></a><span data-ttu-id="907ca-131">Разновидности машинного обучения</span><span class="sxs-lookup"><span data-stu-id="907ca-131">Flavors of machine learning</span></span>
### <a name="supervised"></a><span data-ttu-id="907ca-132">Контролируемое</span><span class="sxs-lookup"><span data-stu-id="907ca-132">Supervised</span></span>
<span data-ttu-id="907ca-133">Контролируемые алгоритмы обучения выполняют прогнозирование на основе набора примеров.</span><span class="sxs-lookup"><span data-stu-id="907ca-133">Supervised learning algorithms make predictions based on a set of examples.</span></span> <span data-ttu-id="907ca-134">Для экземпляра исторических акций может быть используется toohazard предположений в будущем цены.</span><span class="sxs-lookup"><span data-stu-id="907ca-134">For instance, historical stock prices can be used toohazard guesses at future prices.</span></span> <span data-ttu-id="907ca-135">В каждом примере использовались для обучения помечается hello интересующее значение — в этом случае hello акций.</span><span class="sxs-lookup"><span data-stu-id="907ca-135">Each example used for training is labeled with hello value of interest—in this case hello stock price.</span></span> <span data-ttu-id="907ca-136">Контролируемый алгоритм обучения выполняет поиск шаблонов в этих значениях.</span><span class="sxs-lookup"><span data-stu-id="907ca-136">A supervised learning algorithm looks for patterns in those value labels.</span></span> <span data-ttu-id="907ca-137">Он может использовать любые сведения, которые могут быть применимо — hello день недели hello, сезона hello, hello финансовых данных компании, тип hello отрасли, наличие hello нарушают работу геополитические события — и каждый алгоритм ищет различные виды шаблонов.</span><span class="sxs-lookup"><span data-stu-id="907ca-137">It can use any information that might be relevant—hello day of hello week, hello season, hello company's financial data, hello type of industry, hello presence of disruptive geopolitical events—and each algorithm looks for different types of patterns.</span></span> <span data-ttu-id="907ca-138">После обнаружения hello лучше всего, он может hello алгоритм использует без метки проверочных данных, что шаблон toomake прогнозы для — завтра цены.</span><span class="sxs-lookup"><span data-stu-id="907ca-138">After hello algorithm has found hello best pattern it can, it uses that pattern toomake predictions for unlabeled testing data—tomorrow's prices.</span></span>

<span data-ttu-id="907ca-139">Контролируемое обучение — это популярный и полезный тип машинного обучения.</span><span class="sxs-lookup"><span data-stu-id="907ca-139">Supervised learning is a popular and useful type of machine learning.</span></span> <span data-ttu-id="907ca-140">За одним исключением все модули hello в машинном обучении Azure контролируемых алгоритмы обучения.</span><span class="sxs-lookup"><span data-stu-id="907ca-140">With one exception, all hello modules in Azure Machine Learning are supervised learning algorithms.</span></span> <span data-ttu-id="907ca-141">В машинном обучении Azure существует несколько типов контролируемых алгоритмов обучения: классификация, регрессия и обнаружение аномалий.</span><span class="sxs-lookup"><span data-stu-id="907ca-141">There are several specific types of supervised learning that are represented within Azure Machine Learning: classification, regression, and anomaly detection.</span></span>

* <span data-ttu-id="907ca-142">**Классификация**.</span><span class="sxs-lookup"><span data-stu-id="907ca-142">**Classification**.</span></span> <span data-ttu-id="907ca-143">Когда данные hello используется toopredict категорию, контролируемого обучения также называется классификации.</span><span class="sxs-lookup"><span data-stu-id="907ca-143">When hello data are being used toopredict a category, supervised learning is also called classification.</span></span> <span data-ttu-id="907ca-144">Это случай hello назначение изображения в виде изображений «cat» и «dog».</span><span class="sxs-lookup"><span data-stu-id="907ca-144">This is hello case when assigning an image as a picture of either a 'cat' or a 'dog'.</span></span> <span data-ttu-id="907ca-145">При наличии только двух вариантов такая классификация называется **двухклассной** или **биномиальной**.</span><span class="sxs-lookup"><span data-stu-id="907ca-145">When there are only two choices, it's called **two-class** or **binomial classification**.</span></span> <span data-ttu-id="907ca-146">Если имеются дополнительные категории, как при прогнозировании hello победитель турнира кошмар марта NCAA hello, эта проблема известна как **многоклассовый классификатор**.</span><span class="sxs-lookup"><span data-stu-id="907ca-146">When there are more categories, as when predicting hello winner of hello NCAA March Madness tournament, this problem is known as **multi-class classification**.</span></span>
* <span data-ttu-id="907ca-147">**Регрессия**.</span><span class="sxs-lookup"><span data-stu-id="907ca-147">**Regression**.</span></span> <span data-ttu-id="907ca-148">При прогнозировании значения, например стоимости акций, контролируемое обучение называется регрессией.</span><span class="sxs-lookup"><span data-stu-id="907ca-148">When a value is being predicted, as with stock prices, supervised learning is called regression.</span></span>
* <span data-ttu-id="907ca-149">**Обнаружение аномалий**.</span><span class="sxs-lookup"><span data-stu-id="907ca-149">**Anomaly detection**.</span></span> <span data-ttu-id="907ca-150">Иногда hello целью является tooidentify точки данных, которые встречаются достаточно редко.</span><span class="sxs-lookup"><span data-stu-id="907ca-150">Sometimes hello goal is tooidentify data points that are simply unusual.</span></span> <span data-ttu-id="907ca-151">Например, при выявлении мошенничества с кредитной картой подозрительными являются любые необычные операции оплаты.</span><span class="sxs-lookup"><span data-stu-id="907ca-151">In fraud detection, for example, any highly unusual credit card spending patterns are suspect.</span></span> <span data-ttu-id="907ca-152">Возможные варианты Hello, поэтому много и hello обучающих примеров, поэтому несколько, что это не представляется возможной toolearn какие мошенничестве выглядит следующим образом.</span><span class="sxs-lookup"><span data-stu-id="907ca-152">hello possible variations are so numerous and hello training examples so few, that it's not feasible toolearn what fraudulent activity looks like.</span></span> <span data-ttu-id="907ca-153">Подход, который обнаружение аномалий является toosimply узнать, какие обычную операцию выглядит следующим образом (с помощью журнала-мошеннические транзакции) и определить все, что существенно отличается.</span><span class="sxs-lookup"><span data-stu-id="907ca-153">The approach that anomaly detection takes is toosimply learn what normal activity looks like (using a history non-fraudulent transactions) and identify anything that is significantly different.</span></span>

### <a name="unsupervised"></a><span data-ttu-id="907ca-154">Неконтролируемое</span><span class="sxs-lookup"><span data-stu-id="907ca-154">Unsupervised</span></span>
<span data-ttu-id="907ca-155">При неконтролируемом обучении точкам данных не присваиваются метки.</span><span class="sxs-lookup"><span data-stu-id="907ca-155">In unsupervised learning, data points have no labels associated with them.</span></span> <span data-ttu-id="907ca-156">Вместо этого задача hello незащищенных обучения, алгоритм предназначено для организации данных hello в некоторых способом или toodescribe ее структуру.</span><span class="sxs-lookup"><span data-stu-id="907ca-156">Instead, hello goal of an unsupervised learning algorithm is to organize hello data in some way or toodescribe its structure.</span></span> <span data-ttu-id="907ca-157">Это может означать группировку данных в кластеры или поиск различных способов анализа сложных данных для их упрощения или улучшения их организации.</span><span class="sxs-lookup"><span data-stu-id="907ca-157">This can mean grouping it into clusters or finding different ways of looking at complex data so that it appears simpler or more organized.</span></span>

### <a name="reinforcement-learning"></a><span data-ttu-id="907ca-158">Обучение с подкреплением</span><span class="sxs-lookup"><span data-stu-id="907ca-158">Reinforcement learning</span></span>
<span data-ttu-id="907ca-159">Усиление обучения, алгоритм hello возвращает toochoose действие в точке данных tooeach ответа.</span><span class="sxs-lookup"><span data-stu-id="907ca-159">In reinforcement learning, hello algorithm gets toochoose an action in response tooeach data point.</span></span> <span data-ttu-id="907ca-160">Hello обучающего алгоритма также получает сигнал вознаграждения, проведенное на короткое время более поздних версиях, позволяющее определить, насколько хорошо hello принятия решений.</span><span class="sxs-lookup"><span data-stu-id="907ca-160">hello learning algorithm also receives a reward signal a short time later, indicating how good hello decision was.</span></span>
<span data-ttu-id="907ca-161">На основе этого алгоритма hello изменяет его стратегии в порядке tooachieve hello наибольший вознаграждения.</span><span class="sxs-lookup"><span data-stu-id="907ca-161">Based on this, hello algorithm modifies its strategy in order tooachieve hello highest reward.</span></span> <span data-ttu-id="907ca-162">На данный момент в машинном обучении Azure модули алгоритмов обучения с подкреплением отсутствуют.</span><span class="sxs-lookup"><span data-stu-id="907ca-162">Currently there are no reinforcement learning algorithm modules in Azure Machine Learning.</span></span> <span data-ttu-id="907ca-163">Усиление обучения проявляется в robotics hello набор показания датчиков в один момент времени является точкой данных, куда hello алгоритм необходимо выбрать следующее действие hello робот.</span><span class="sxs-lookup"><span data-stu-id="907ca-163">Reinforcement learning is common in robotics, where hello set of sensor readings at one point in time is a data point, and hello algorithm must choose hello robot's next action.</span></span> <span data-ttu-id="907ca-164">Кроме того, оно естественным образом подходит для приложений из Интернета вещей.</span><span class="sxs-lookup"><span data-stu-id="907ca-164">It is also a natural fit for Internet of Things applications.</span></span>

## <a name="considerations-when-choosing-an-algorithm"></a><span data-ttu-id="907ca-165">Рекомендации по выбору алгоритма</span><span class="sxs-lookup"><span data-stu-id="907ca-165">Considerations when choosing an algorithm</span></span>
### <a name="accuracy"></a><span data-ttu-id="907ca-166">Точность</span><span class="sxs-lookup"><span data-stu-id="907ca-166">Accuracy</span></span>
<span data-ttu-id="907ca-167">Получения наиболее точных ответов hello возможных не всегда обязательно.</span><span class="sxs-lookup"><span data-stu-id="907ca-167">Getting hello most accurate answer possible isn't always necessary.</span></span>
<span data-ttu-id="907ca-168">Иногда достаточно приближенного ответа в зависимости от того, для чего он используется.</span><span class="sxs-lookup"><span data-stu-id="907ca-168">Sometimes an approximation is adequate, depending on what you want to use it for.</span></span> <span data-ttu-id="907ca-169">Если это hello так, может быть может toocut время обработки значительно по использовать именно дополнительные методы приблизительное.</span><span class="sxs-lookup"><span data-stu-id="907ca-169">If that's hello case, you may be able toocut your processing time dramatically by sticking with more approximate methods.</span></span> <span data-ttu-id="907ca-170">Еще одним преимуществом более приближенных методов является то, что они естественным образом стремятся избежать [чрезмерно высокой точности](https://youtu.be/DQWI1kvmwRg).</span><span class="sxs-lookup"><span data-stu-id="907ca-170">Another advantage of more approximate methods is that they naturally tend to avoid [overfitting](https://youtu.be/DQWI1kvmwRg).</span></span>

### <a name="training-time"></a><span data-ttu-id="907ca-171">Время обучения</span><span class="sxs-lookup"><span data-stu-id="907ca-171">Training time</span></span>
<span data-ttu-id="907ca-172">Здравствуйте, количество минут или часов необходимые tootrain, модель может быть гораздо алгоритмов.</span><span class="sxs-lookup"><span data-stu-id="907ca-172">hello number of minutes or hours necessary tootrain a model varies a great deal between algorithms.</span></span> <span data-ttu-id="907ca-173">Время на обучение часто тесно связана с точностью — один обычно сопровождающий hello других.</span><span class="sxs-lookup"><span data-stu-id="907ca-173">Training time is often closely tied to accuracy—one typically accompanies hello other.</span></span> <span data-ttu-id="907ca-174">Кроме того некоторые алгоритмы являются чувствительными номер toohello точек данных, чем другие.</span><span class="sxs-lookup"><span data-stu-id="907ca-174">In addition, some algorithms are more sensitive toohello number of data points than others.</span></span>
<span data-ttu-id="907ca-175">При ограниченном времени, может управлять hello выбрать алгоритм, особенно в том случае, если задан большой набор данных hello.</span><span class="sxs-lookup"><span data-stu-id="907ca-175">When time is limited it can drive hello choice of algorithm, especially when hello data set is large.</span></span>

### <a name="linearity"></a><span data-ttu-id="907ca-176">Линейность</span><span class="sxs-lookup"><span data-stu-id="907ca-176">Linearity</span></span>
<span data-ttu-id="907ca-177">Линейность используется во многих алгоритмах машинного обучения.</span><span class="sxs-lookup"><span data-stu-id="907ca-177">Lots of machine learning algorithms make use of linearity.</span></span> <span data-ttu-id="907ca-178">Алгоритмы линейной классификации предполагают, что классы могут быть разделены прямой линией (или ее аналогом для большего числа измерений).</span><span class="sxs-lookup"><span data-stu-id="907ca-178">Linear classification algorithms assume that classes can be separated by a straight line (or its higher-dimensional analog).</span></span> <span data-ttu-id="907ca-179">К ним относятся логистическая регрессия и метод опорных векторов (в том виде, в котором это реализовано в машинном обучении Azure).</span><span class="sxs-lookup"><span data-stu-id="907ca-179">These include logistic regression and support vector machines (as implemented in Azure Machine Learning).</span></span>
<span data-ttu-id="907ca-180">Алгоритмы линейной регрессии предполагают, что тренды данных следуют прямой линии.</span><span class="sxs-lookup"><span data-stu-id="907ca-180">Linear regression algorithms assume that data trends follow a straight line.</span></span> <span data-ttu-id="907ca-181">Эти предположения допустимы для ряда задач, но для других задач они приводят к снижению точности.</span><span class="sxs-lookup"><span data-stu-id="907ca-181">These assumptions aren't bad for some problems, but on others they bring accuracy down.</span></span>

![Граница нелинейного класса][1]

<span data-ttu-id="907ca-183">***Граница нелинейного класса*** *— использование алгоритма линейной классификации приведет к низкой точности*</span><span class="sxs-lookup"><span data-stu-id="907ca-183">***Non-linear class boundary*** *- relying on a linear classification algorithm would result in low accuracy*</span></span>

![Данные с нелинейным трендом][2]

<span data-ttu-id="907ca-185">***Данные с нелинейным трендом*** *— использование алгоритма линейной классификации приведет к появлению гораздо большего количества ошибок, чем необходимо*</span><span class="sxs-lookup"><span data-stu-id="907ca-185">***Data with a nonlinear trend*** *- using a linear regression method would generate much larger errors than necessary*</span></span>

<span data-ttu-id="907ca-186">Несмотря на их опасность, линейные алгоритмы очень популярны на первой линии атаки.</span><span class="sxs-lookup"><span data-stu-id="907ca-186">Despite their dangers, linear algorithms are very popular as a first line of attack.</span></span> <span data-ttu-id="907ca-187">Они обычно toobe типовой простым и быстрым для обучения.</span><span class="sxs-lookup"><span data-stu-id="907ca-187">They tend toobe algorithmically simple and fast to train.</span></span>

### <a name="number-of-parameters"></a><span data-ttu-id="907ca-188">Количество параметров</span><span class="sxs-lookup"><span data-stu-id="907ca-188">Number of parameters</span></span>
<span data-ttu-id="907ca-189">Параметры являются элементы hello анализу данных, который возвращает tooturn при настройке алгоритма.</span><span class="sxs-lookup"><span data-stu-id="907ca-189">Parameters are hello knobs a data scientist gets tooturn when setting up an algorithm.</span></span> <span data-ttu-id="907ca-190">Они являются числами, которые влияют на поведение hello алгоритм, например погрешность или число итераций и параметры между варианты поведения алгоритма hello.</span><span class="sxs-lookup"><span data-stu-id="907ca-190">They are numbers that affect hello algorithm's behavior, such as error tolerance or number of iterations, or options between variants of how hello algorithm behaves.</span></span> <span data-ttu-id="907ca-191">Hello время обучения и точности алгоритма hello иногда может быть довольно конфиденциальных toogetting просто hello нужные параметры.</span><span class="sxs-lookup"><span data-stu-id="907ca-191">hello training time and accuracy of hello algorithm can sometimes be quite sensitive toogetting just hello right settings.</span></span> <span data-ttu-id="907ca-192">Как правило алгоритмы с большим числом параметров, требуется наиболее пробной hello и toofind ошибка хорошо сочетания.</span><span class="sxs-lookup"><span data-stu-id="907ca-192">Typically, algorithms with large numbers parameters require hello most trial and error toofind a good combination.</span></span>

<span data-ttu-id="907ca-193">Кроме того, в машинном обучении Azure есть блок модулей [корректировки параметров](machine-learning-algorithm-parameters-optimize.md) , который автоматически пробует все сочетания параметров с любой выбранной детализацией.</span><span class="sxs-lookup"><span data-stu-id="907ca-193">Alternatively, there is a [parameter sweeping](machine-learning-algorithm-parameters-optimize.md) module block in Azure Machine Learning that automatically tries all parameter combinations at whatever granularity you choose.</span></span> <span data-ttu-id="907ca-194">Хотя это toomake хорошим способом, убедитесь, что охваченных hello параметр пространства, tootrain время, необходимое для hello модели растет в геометрической прогрессии с hello количеством параметров.</span><span class="sxs-lookup"><span data-stu-id="907ca-194">While this is a great way toomake sure you've spanned hello parameter space, hello time required tootrain a model increases exponentially with hello number of parameters.</span></span>

<span data-ttu-id="907ca-195">Hello плюсом — что наличие большого количества параметров обычно означает, что алгоритм большую гибкость.</span><span class="sxs-lookup"><span data-stu-id="907ca-195">hello upside is that having many parameters typically indicates that an algorithm has greater flexibility.</span></span> <span data-ttu-id="907ca-196">Это часто позволяет добиваться очень хорошей точности.</span><span class="sxs-lookup"><span data-stu-id="907ca-196">It can often achieve very good accuracy.</span></span> <span data-ttu-id="907ca-197">При условии, что можно найти hello правильное сочетание параметров.</span><span class="sxs-lookup"><span data-stu-id="907ca-197">Provided you can find hello right combination of parameter settings.</span></span>

### <a name="number-of-features"></a><span data-ttu-id="907ca-198">Количество функций</span><span class="sxs-lookup"><span data-stu-id="907ca-198">Number of features</span></span>
<span data-ttu-id="907ca-199">Для определенных типов данных число hello функций может быть очень больших сравниваемых toohello количество точек данных.</span><span class="sxs-lookup"><span data-stu-id="907ca-199">For certain types of data, hello number of features can be very large compared toohello number of data points.</span></span> <span data-ttu-id="907ca-200">Это часто относится hello genetics или текстовых данных.</span><span class="sxs-lookup"><span data-stu-id="907ca-200">This is often hello case with genetics or textual data.</span></span> <span data-ttu-id="907ca-201">Hello большое количество функций можно освобождает вниз некоторые алгоритмы обучения, делая unfeasibly длинное время обучения.</span><span class="sxs-lookup"><span data-stu-id="907ca-201">hello large number of features can bog down some learning algorithms, making training time unfeasibly long.</span></span> <span data-ttu-id="907ca-202">Машины опорных векторов, особенно хорошо подходит toothis регистр (см. ниже).</span><span class="sxs-lookup"><span data-stu-id="907ca-202">Support Vector Machines are particularly well suited toothis case (see below).</span></span>

### <a name="special-cases"></a><span data-ttu-id="907ca-203">Особые случаи</span><span class="sxs-lookup"><span data-stu-id="907ca-203">Special cases</span></span>
<span data-ttu-id="907ca-204">Некоторые алгоритмы обучения делать определенного предположения о hello структуру данных hello или hello требуемого результаты.</span><span class="sxs-lookup"><span data-stu-id="907ca-204">Some learning algorithms make particular assumptions about hello structure of hello data or hello desired results.</span></span> <span data-ttu-id="907ca-205">Если вы сможете найти тот алгоритм, который соответствует вашим потребностям, с ним вы сможете получить более точные результаты, более точные прогнозы и сократить время обучения.</span><span class="sxs-lookup"><span data-stu-id="907ca-205">If you can find one that fits your needs, it can give you more useful results, more accurate predictions, or faster training times.</span></span>

| <span data-ttu-id="907ca-206">**Алгоритм**</span><span class="sxs-lookup"><span data-stu-id="907ca-206">**Algorithm**</span></span> | <span data-ttu-id="907ca-207">**Точность**</span><span class="sxs-lookup"><span data-stu-id="907ca-207">**Accuracy**</span></span> | <span data-ttu-id="907ca-208">**Время обучения**</span><span class="sxs-lookup"><span data-stu-id="907ca-208">**Training time**</span></span> | <span data-ttu-id="907ca-209">**Линейность**</span><span class="sxs-lookup"><span data-stu-id="907ca-209">**Linearity**</span></span> | <span data-ttu-id="907ca-210">**Параметры**</span><span class="sxs-lookup"><span data-stu-id="907ca-210">**Parameters**</span></span> | <span data-ttu-id="907ca-211">**Примечания**</span><span class="sxs-lookup"><span data-stu-id="907ca-211">**Notes**</span></span> |
| --- |:---:|:---:|:---:|:---:| --- |
| <span data-ttu-id="907ca-212">**Двуклассовая классификация**</span><span class="sxs-lookup"><span data-stu-id="907ca-212">**Two-class classification**</span></span> | | | | | |
| [<span data-ttu-id="907ca-213">логистическая регрессия</span><span class="sxs-lookup"><span data-stu-id="907ca-213">logistic regression</span></span>](https://msdn.microsoft.com/library/azure/dn905994.aspx) | |<span data-ttu-id="907ca-214">●</span><span class="sxs-lookup"><span data-stu-id="907ca-214">●</span></span> |<span data-ttu-id="907ca-215">●</span><span class="sxs-lookup"><span data-stu-id="907ca-215">●</span></span> |<span data-ttu-id="907ca-216">5</span><span class="sxs-lookup"><span data-stu-id="907ca-216">5</span></span> | |
| [<span data-ttu-id="907ca-217">лес решений</span><span class="sxs-lookup"><span data-stu-id="907ca-217">decision forest</span></span>](https://msdn.microsoft.com/library/azure/dn906008.aspx) |<span data-ttu-id="907ca-218">●</span><span class="sxs-lookup"><span data-stu-id="907ca-218">●</span></span> |<span data-ttu-id="907ca-219">○</span><span class="sxs-lookup"><span data-stu-id="907ca-219">○</span></span> | |<span data-ttu-id="907ca-220">6</span><span class="sxs-lookup"><span data-stu-id="907ca-220">6</span></span> | |
| [<span data-ttu-id="907ca-221">джунгли решений</span><span class="sxs-lookup"><span data-stu-id="907ca-221">decision jungle</span></span>](https://msdn.microsoft.com/library/azure/dn905976.aspx) |<span data-ttu-id="907ca-222">●</span><span class="sxs-lookup"><span data-stu-id="907ca-222">●</span></span> |<span data-ttu-id="907ca-223">○</span><span class="sxs-lookup"><span data-stu-id="907ca-223">○</span></span> | |<span data-ttu-id="907ca-224">6</span><span class="sxs-lookup"><span data-stu-id="907ca-224">6</span></span> |<span data-ttu-id="907ca-225">Низкий объем памяти</span><span class="sxs-lookup"><span data-stu-id="907ca-225">Low memory footprint</span></span> |
| [<span data-ttu-id="907ca-226">увеличивающееся дерево решений</span><span class="sxs-lookup"><span data-stu-id="907ca-226">boosted decision tree</span></span>](https://msdn.microsoft.com/library/azure/dn906025.aspx) |<span data-ttu-id="907ca-227">●</span><span class="sxs-lookup"><span data-stu-id="907ca-227">●</span></span> |<span data-ttu-id="907ca-228">○</span><span class="sxs-lookup"><span data-stu-id="907ca-228">○</span></span> | |<span data-ttu-id="907ca-229">6</span><span class="sxs-lookup"><span data-stu-id="907ca-229">6</span></span> |<span data-ttu-id="907ca-230">Большой объем памяти</span><span class="sxs-lookup"><span data-stu-id="907ca-230">Large memory footprint</span></span> |
| [<span data-ttu-id="907ca-231">нейронная сеть</span><span class="sxs-lookup"><span data-stu-id="907ca-231">neural network</span></span>](https://msdn.microsoft.com/library/azure/dn905947.aspx) |<span data-ttu-id="907ca-232">●</span><span class="sxs-lookup"><span data-stu-id="907ca-232">●</span></span> | | |<span data-ttu-id="907ca-233">9</span><span class="sxs-lookup"><span data-stu-id="907ca-233">9</span></span> |[<span data-ttu-id="907ca-234">Возможна дополнительная настройка</span><span class="sxs-lookup"><span data-stu-id="907ca-234">Additional customization is possible</span></span>](http://go.microsoft.com/fwlink/?LinkId=402867) |
| [<span data-ttu-id="907ca-235">усредненное восприятие</span><span class="sxs-lookup"><span data-stu-id="907ca-235">averaged perceptron</span></span>](https://msdn.microsoft.com/library/azure/dn906036.aspx) |<span data-ttu-id="907ca-236">○</span><span class="sxs-lookup"><span data-stu-id="907ca-236">○</span></span> |<span data-ttu-id="907ca-237">○</span><span class="sxs-lookup"><span data-stu-id="907ca-237">○</span></span> |<span data-ttu-id="907ca-238">●</span><span class="sxs-lookup"><span data-stu-id="907ca-238">●</span></span> |<span data-ttu-id="907ca-239">4.</span><span class="sxs-lookup"><span data-stu-id="907ca-239">4</span></span> | |
| [<span data-ttu-id="907ca-240">метод опорных векторов</span><span class="sxs-lookup"><span data-stu-id="907ca-240">support vector machine</span></span>](https://msdn.microsoft.com/library/azure/dn905835.aspx) | |<span data-ttu-id="907ca-241">○</span><span class="sxs-lookup"><span data-stu-id="907ca-241">○</span></span> |<span data-ttu-id="907ca-242">●</span><span class="sxs-lookup"><span data-stu-id="907ca-242">●</span></span> |<span data-ttu-id="907ca-243">5</span><span class="sxs-lookup"><span data-stu-id="907ca-243">5</span></span> |<span data-ttu-id="907ca-244">Подходит для больших наборов функций</span><span class="sxs-lookup"><span data-stu-id="907ca-244">Good for large feature sets</span></span> |
| [<span data-ttu-id="907ca-245">локально глубокий метод опорных векторов</span><span class="sxs-lookup"><span data-stu-id="907ca-245">locally deep support vector machine</span></span>](https://msdn.microsoft.com/library/azure/dn913070.aspx) |<span data-ttu-id="907ca-246">○</span><span class="sxs-lookup"><span data-stu-id="907ca-246">○</span></span> | | |<span data-ttu-id="907ca-247">8</span><span class="sxs-lookup"><span data-stu-id="907ca-247">8</span></span> |<span data-ttu-id="907ca-248">Подходит для больших наборов функций</span><span class="sxs-lookup"><span data-stu-id="907ca-248">Good for large feature sets</span></span> |
| [<span data-ttu-id="907ca-249">точечная машина Байеса</span><span class="sxs-lookup"><span data-stu-id="907ca-249">Bayes’ point machine</span></span>](https://msdn.microsoft.com/library/azure/dn905930.aspx) | |<span data-ttu-id="907ca-250">○</span><span class="sxs-lookup"><span data-stu-id="907ca-250">○</span></span> |<span data-ttu-id="907ca-251">●</span><span class="sxs-lookup"><span data-stu-id="907ca-251">●</span></span> |<span data-ttu-id="907ca-252">3</span><span class="sxs-lookup"><span data-stu-id="907ca-252">3</span></span> | |
| <span data-ttu-id="907ca-253">**Многоклассовая классификация**</span><span class="sxs-lookup"><span data-stu-id="907ca-253">**Multi-class classification**</span></span> | | | | | |
| [<span data-ttu-id="907ca-254">логистическая регрессия</span><span class="sxs-lookup"><span data-stu-id="907ca-254">logistic regression</span></span>](https://msdn.microsoft.com/library/azure/dn905853.aspx) | |<span data-ttu-id="907ca-255">●</span><span class="sxs-lookup"><span data-stu-id="907ca-255">●</span></span> |<span data-ttu-id="907ca-256">●</span><span class="sxs-lookup"><span data-stu-id="907ca-256">●</span></span> |<span data-ttu-id="907ca-257">5</span><span class="sxs-lookup"><span data-stu-id="907ca-257">5</span></span> | |
| [<span data-ttu-id="907ca-258">лес решений</span><span class="sxs-lookup"><span data-stu-id="907ca-258">decision forest</span></span>](https://msdn.microsoft.com/library/azure/dn906015.aspx) |<span data-ttu-id="907ca-259">●</span><span class="sxs-lookup"><span data-stu-id="907ca-259">●</span></span> |<span data-ttu-id="907ca-260">○</span><span class="sxs-lookup"><span data-stu-id="907ca-260">○</span></span> | |<span data-ttu-id="907ca-261">6</span><span class="sxs-lookup"><span data-stu-id="907ca-261">6</span></span> | |
| [<span data-ttu-id="907ca-262">джунгли решений </span><span class="sxs-lookup"><span data-stu-id="907ca-262">decision jungle </span></span>](https://msdn.microsoft.com/library/azure/dn905963.aspx) |<span data-ttu-id="907ca-263">●</span><span class="sxs-lookup"><span data-stu-id="907ca-263">●</span></span> |<span data-ttu-id="907ca-264">○</span><span class="sxs-lookup"><span data-stu-id="907ca-264">○</span></span> | |<span data-ttu-id="907ca-265">6</span><span class="sxs-lookup"><span data-stu-id="907ca-265">6</span></span> |<span data-ttu-id="907ca-266">Низкий объем памяти</span><span class="sxs-lookup"><span data-stu-id="907ca-266">Low memory footprint</span></span> |
| [<span data-ttu-id="907ca-267">нейронная сеть</span><span class="sxs-lookup"><span data-stu-id="907ca-267">neural network</span></span>](https://msdn.microsoft.com/library/azure/dn906030.aspx) |<span data-ttu-id="907ca-268">●</span><span class="sxs-lookup"><span data-stu-id="907ca-268">●</span></span> | | |<span data-ttu-id="907ca-269">9</span><span class="sxs-lookup"><span data-stu-id="907ca-269">9</span></span> |[<span data-ttu-id="907ca-270">Возможна дополнительная настройка</span><span class="sxs-lookup"><span data-stu-id="907ca-270">Additional customization is possible</span></span>](http://go.microsoft.com/fwlink/?LinkId=402867) |
| [<span data-ttu-id="907ca-271">one-v-all</span><span class="sxs-lookup"><span data-stu-id="907ca-271">one-v-all</span></span>](https://msdn.microsoft.com/library/azure/dn905887.aspx) |- |- |- |- |<span data-ttu-id="907ca-272">Просмотреть свойства выбранного метода двух классов hello</span><span class="sxs-lookup"><span data-stu-id="907ca-272">See properties of hello two-class method selected</span></span> |
| <span data-ttu-id="907ca-273">**Регрессия**</span><span class="sxs-lookup"><span data-stu-id="907ca-273">**Regression**</span></span> | | | | | |
| [<span data-ttu-id="907ca-274">линейная</span><span class="sxs-lookup"><span data-stu-id="907ca-274">linear</span></span>](https://msdn.microsoft.com/library/azure/dn905978.aspx) | |<span data-ttu-id="907ca-275">●</span><span class="sxs-lookup"><span data-stu-id="907ca-275">●</span></span> |<span data-ttu-id="907ca-276">●</span><span class="sxs-lookup"><span data-stu-id="907ca-276">●</span></span> |<span data-ttu-id="907ca-277">4</span><span class="sxs-lookup"><span data-stu-id="907ca-277">4</span></span> | |
| [<span data-ttu-id="907ca-278">Байесовская линейная</span><span class="sxs-lookup"><span data-stu-id="907ca-278">Bayesian linear</span></span>](https://msdn.microsoft.com/library/azure/dn906022.aspx) | |<span data-ttu-id="907ca-279">○</span><span class="sxs-lookup"><span data-stu-id="907ca-279">○</span></span> |<span data-ttu-id="907ca-280">●</span><span class="sxs-lookup"><span data-stu-id="907ca-280">●</span></span> |<span data-ttu-id="907ca-281">2</span><span class="sxs-lookup"><span data-stu-id="907ca-281">2</span></span> | |
| [<span data-ttu-id="907ca-282">лес решений</span><span class="sxs-lookup"><span data-stu-id="907ca-282">decision forest</span></span>](https://msdn.microsoft.com/library/azure/dn905862.aspx) |<span data-ttu-id="907ca-283">●</span><span class="sxs-lookup"><span data-stu-id="907ca-283">●</span></span> |<span data-ttu-id="907ca-284">○</span><span class="sxs-lookup"><span data-stu-id="907ca-284">○</span></span> | |<span data-ttu-id="907ca-285">6</span><span class="sxs-lookup"><span data-stu-id="907ca-285">6</span></span> | |
| [<span data-ttu-id="907ca-286">увеличивающееся дерево решений</span><span class="sxs-lookup"><span data-stu-id="907ca-286">boosted decision tree</span></span>](https://msdn.microsoft.com/library/azure/dn905801.aspx) |<span data-ttu-id="907ca-287">●</span><span class="sxs-lookup"><span data-stu-id="907ca-287">●</span></span> |<span data-ttu-id="907ca-288">○</span><span class="sxs-lookup"><span data-stu-id="907ca-288">○</span></span> | |<span data-ttu-id="907ca-289">5</span><span class="sxs-lookup"><span data-stu-id="907ca-289">5</span></span> |<span data-ttu-id="907ca-290">Большой объем памяти</span><span class="sxs-lookup"><span data-stu-id="907ca-290">Large memory footprint</span></span> |
| [<span data-ttu-id="907ca-291">квантильная регрессия быстрого леса</span><span class="sxs-lookup"><span data-stu-id="907ca-291">fast forest quantile</span></span>](https://msdn.microsoft.com/library/azure/dn913093.aspx) |<span data-ttu-id="907ca-292">●</span><span class="sxs-lookup"><span data-stu-id="907ca-292">●</span></span> |<span data-ttu-id="907ca-293">○</span><span class="sxs-lookup"><span data-stu-id="907ca-293">○</span></span> | |<span data-ttu-id="907ca-294">9</span><span class="sxs-lookup"><span data-stu-id="907ca-294">9</span></span> |<span data-ttu-id="907ca-295">Распределения, а не точечные прогнозы</span><span class="sxs-lookup"><span data-stu-id="907ca-295">Distributions rather than point predictions</span></span> |
| [<span data-ttu-id="907ca-296">нейронная сеть</span><span class="sxs-lookup"><span data-stu-id="907ca-296">neural network</span></span>](https://msdn.microsoft.com/library/azure/dn905924.aspx) |<span data-ttu-id="907ca-297">●</span><span class="sxs-lookup"><span data-stu-id="907ca-297">●</span></span> | | |<span data-ttu-id="907ca-298">9</span><span class="sxs-lookup"><span data-stu-id="907ca-298">9</span></span> |[<span data-ttu-id="907ca-299">Возможна дополнительная настройка</span><span class="sxs-lookup"><span data-stu-id="907ca-299">Additional customization is possible</span></span>](http://go.microsoft.com/fwlink/?LinkId=402867) |
| [<span data-ttu-id="907ca-300">регрессия Пуассона</span><span class="sxs-lookup"><span data-stu-id="907ca-300">Poisson</span></span>](https://msdn.microsoft.com/library/azure/dn905988.aspx) | | |<span data-ttu-id="907ca-301">●</span><span class="sxs-lookup"><span data-stu-id="907ca-301">●</span></span> |<span data-ttu-id="907ca-302">5</span><span class="sxs-lookup"><span data-stu-id="907ca-302">5</span></span> |<span data-ttu-id="907ca-303">С технической точки зрения логлинейная.</span><span class="sxs-lookup"><span data-stu-id="907ca-303">Technically log-linear.</span></span> <span data-ttu-id="907ca-304">Для прогнозирования количества</span><span class="sxs-lookup"><span data-stu-id="907ca-304">For predicting counts</span></span> |
| [<span data-ttu-id="907ca-305">порядковая</span><span class="sxs-lookup"><span data-stu-id="907ca-305">ordinal</span></span>](https://msdn.microsoft.com/library/azure/dn906029.aspx) | | | |<span data-ttu-id="907ca-306">0</span><span class="sxs-lookup"><span data-stu-id="907ca-306">0</span></span> |<span data-ttu-id="907ca-307">Для прогнозирования упорядочения за рангом</span><span class="sxs-lookup"><span data-stu-id="907ca-307">For predicting rank-ordering</span></span> |
| <span data-ttu-id="907ca-308">**Обнаружение аномалий**</span><span class="sxs-lookup"><span data-stu-id="907ca-308">**Anomaly detection**</span></span> | | | | | |
| [<span data-ttu-id="907ca-309">метод опорных векторов</span><span class="sxs-lookup"><span data-stu-id="907ca-309">support vector machine</span></span>](https://msdn.microsoft.com/library/azure/dn913103.aspx) |<span data-ttu-id="907ca-310">○</span><span class="sxs-lookup"><span data-stu-id="907ca-310">○</span></span> |<span data-ttu-id="907ca-311">○</span><span class="sxs-lookup"><span data-stu-id="907ca-311">○</span></span> | |<span data-ttu-id="907ca-312">2</span><span class="sxs-lookup"><span data-stu-id="907ca-312">2</span></span> |<span data-ttu-id="907ca-313">Особенно полезна для больших наборов функций</span><span class="sxs-lookup"><span data-stu-id="907ca-313">Especially good for large feature sets</span></span> |
| [<span data-ttu-id="907ca-314">Обнаружение аномалий на основе анализа первичных компонентов</span><span class="sxs-lookup"><span data-stu-id="907ca-314">PCA-based anomaly detection</span></span>](https://msdn.microsoft.com/library/azure/dn913102.aspx) | |<span data-ttu-id="907ca-315">○</span><span class="sxs-lookup"><span data-stu-id="907ca-315">○</span></span> |<span data-ttu-id="907ca-316">●</span><span class="sxs-lookup"><span data-stu-id="907ca-316">●</span></span> |<span data-ttu-id="907ca-317">3</span><span class="sxs-lookup"><span data-stu-id="907ca-317">3</span></span> | |
| [<span data-ttu-id="907ca-318">K-средних</span><span class="sxs-lookup"><span data-stu-id="907ca-318">K-means</span></span>](https://msdn.microsoft.com/library/azure/5049a09b-bd90-4c4e-9b46-7c87e3a36810/) | |<span data-ttu-id="907ca-319">○</span><span class="sxs-lookup"><span data-stu-id="907ca-319">○</span></span> |<span data-ttu-id="907ca-320">●</span><span class="sxs-lookup"><span data-stu-id="907ca-320">●</span></span> |<span data-ttu-id="907ca-321">4</span><span class="sxs-lookup"><span data-stu-id="907ca-321">4</span></span> |<span data-ttu-id="907ca-322">Алгоритм кластеризации</span><span class="sxs-lookup"><span data-stu-id="907ca-322">A clustering algorithm</span></span> |

<span data-ttu-id="907ca-323">**Свойства алгоритма:**</span><span class="sxs-lookup"><span data-stu-id="907ca-323">**Algorithm properties:**</span></span>

<span data-ttu-id="907ca-324">**●** -показывает высокую точность, время быстрого обучения и использования hello линейность</span><span class="sxs-lookup"><span data-stu-id="907ca-324">**●** - shows excellent accuracy, fast training times, and hello use of linearity</span></span>

<span data-ttu-id="907ca-325">**○** — показывает хорошую точность и умеренное время обучения</span><span class="sxs-lookup"><span data-stu-id="907ca-325">**○** - shows good accuracy and moderate training times</span></span>

## <a name="algorithm-notes"></a><span data-ttu-id="907ca-326">Примечания к алгоритму</span><span class="sxs-lookup"><span data-stu-id="907ca-326">Algorithm notes</span></span>
### <a name="linear-regression"></a><span data-ttu-id="907ca-327">Linear regression</span><span class="sxs-lookup"><span data-stu-id="907ca-327">Linear regression</span></span>
<span data-ttu-id="907ca-328">Как упоминалось ранее, [линейной регрессии](https://msdn.microsoft.com/library/azure/dn905978.aspx) соответствует toohello набора данных строки (или плоскости или гиперплоскостью).</span><span class="sxs-lookup"><span data-stu-id="907ca-328">As mentioned previously, [linear regression](https://msdn.microsoft.com/library/azure/dn905978.aspx) fits a line (or plane, or hyperplane) toohello data set.</span></span> <span data-ttu-id="907ca-329">Это быстрая и простая "рабочая лошадка", но она может быть излишне простой для некоторых задач.</span><span class="sxs-lookup"><span data-stu-id="907ca-329">It's a workhorse, simple and fast, but it may be overly simplistic for some problems.</span></span>
<span data-ttu-id="907ca-330">Руководство по линейной регрессии можно найти [здесь](machine-learning-linear-regression-in-azure.md).</span><span class="sxs-lookup"><span data-stu-id="907ca-330">Check here for a [linear regression tutorial](machine-learning-linear-regression-in-azure.md).</span></span>

![Данные с линейным трендом][3]

<span data-ttu-id="907ca-332">***Данные с линейным трендом***</span><span class="sxs-lookup"><span data-stu-id="907ca-332">***Data with a linear trend***</span></span>

### <a name="logistic-regression"></a><span data-ttu-id="907ca-333">Логистическая регрессия</span><span class="sxs-lookup"><span data-stu-id="907ca-333">Logistic regression</span></span>
<span data-ttu-id="907ca-334">Несмотря на то, что его ввести в заблуждение содержится «Регрессия» в имени hello, логистическая Регрессия является фактически является мощным инструментом [двухклассовой](https://msdn.microsoft.com/library/azure/dn905994.aspx) и [мультиклассовых](https://msdn.microsoft.com/library/azure/dn905853.aspx) классификации.</span><span class="sxs-lookup"><span data-stu-id="907ca-334">Although it confusingly includes 'regression' in hello name, logistic regression is actually a powerful tool for [two-class](https://msdn.microsoft.com/library/azure/dn905994.aspx) and [multiclass](https://msdn.microsoft.com/library/azure/dn905853.aspx) classification.</span></span> <span data-ttu-id="907ca-335">Это быстрый и простой метод.</span><span class="sxs-lookup"><span data-stu-id="907ca-335">It's fast and simple.</span></span> <span data-ttu-id="907ca-336">факт, что она использует Hello "-формы кривой вместо прямой упрощает разделение данных на группы естественным образом.</span><span class="sxs-lookup"><span data-stu-id="907ca-336">hello fact that it uses an 'S'-shaped curve instead of a straight line makes it a natural fit for dividing data into groups.</span></span> <span data-ttu-id="907ca-337">Логистическая регрессия приводит к появлению линейных границ классов, поэтому при ее использовании убедитесь, что вам комфортно с линейной аппроксимацией.</span><span class="sxs-lookup"><span data-stu-id="907ca-337">Logistic regression gives linear class boundaries, so when you use it, make sure a linear approximation is something you can live with.</span></span>

![Алгоритм логистической регрессии tootwo класс данных с какой-либо функции][4]

<span data-ttu-id="907ca-339">***Класс tootwo данных логистической регрессии с какой-либо функции*** *-класс граница образована hello точку, в которой hello логистической кривой является так же, как закрыть tooboth классы*</span><span class="sxs-lookup"><span data-stu-id="907ca-339">***A logistic regression tootwo-class data with just one feature*** *- the class boundary is hello point at which hello logistic curve is just as close tooboth classes*</span></span>

### <a name="trees-forests-and-jungles"></a><span data-ttu-id="907ca-340">Деревья, леса и джунгли</span><span class="sxs-lookup"><span data-stu-id="907ca-340">Trees, forests, and jungles</span></span>
<span data-ttu-id="907ca-341">Леса решений ([регрессионные](https://msdn.microsoft.com/library/azure/dn905862.aspx), [двухклассовые](https://msdn.microsoft.com/library/azure/dn906008.aspx) и [многоклассовые](https://msdn.microsoft.com/library/azure/dn906015.aspx)), джунгли решений ([двухклассовые](https://msdn.microsoft.com/library/azure/dn905976.aspx) и [многоклассовые](https://msdn.microsoft.com/library/azure/dn905963.aspx)) и увеличивающиеся деревья решений ([регрессионные](https://msdn.microsoft.com/library/azure/dn905801.aspx) и [двухклассовые](https://msdn.microsoft.com/library/azure/dn906025.aspx)) основаны на деревьях решений, базовой концепции машинного обучения.</span><span class="sxs-lookup"><span data-stu-id="907ca-341">Decision forests ([regression](https://msdn.microsoft.com/library/azure/dn905862.aspx), [two-class](https://msdn.microsoft.com/library/azure/dn906008.aspx), and [multiclass](https://msdn.microsoft.com/library/azure/dn906015.aspx)), decision jungles ([two-class](https://msdn.microsoft.com/library/azure/dn905976.aspx) and [multiclass](https://msdn.microsoft.com/library/azure/dn905963.aspx)), and boosted decision trees ([regression](https://msdn.microsoft.com/library/azure/dn905801.aspx) and [two-class](https://msdn.microsoft.com/library/azure/dn906025.aspx)) are all based on decision trees, a foundational machine learning concept.</span></span> <span data-ttu-id="907ca-342">Существует множество возможных дерева принятия решений, но все они выполняют то же самое — подразделять hello пространство признаков на области со основном hello одной метки.</span><span class="sxs-lookup"><span data-stu-id="907ca-342">There are many variants of decision trees, but they all do the same thing—subdivide hello feature space into regions with mostly hello same label.</span></span> <span data-ttu-id="907ca-343">Это могут быть области с одинаковой категорией или одинаковым значением в зависимости от того, проводится ли классификация или регрессия.</span><span class="sxs-lookup"><span data-stu-id="907ca-343">These can be regions of consistent category or of constant value, depending on whether you are doing classification or regression.</span></span>

![Дерево решений подразделяет пространство функций][5]

<span data-ttu-id="907ca-345">***Дерево решений подразделяет пространство функций на области примерно c одинаковыми значениями.***</span><span class="sxs-lookup"><span data-stu-id="907ca-345">***A decision tree subdivides a feature space into regions of roughly uniform values***</span></span>

<span data-ttu-id="907ca-346">Поскольку пространство признаков может быть разделен на произвольная небольшая регионах, это легко tooimagine делению точно достаточно toohave одна точка данных в одном регионе.</span><span class="sxs-lookup"><span data-stu-id="907ca-346">Because a feature space can be subdivided into arbitrarily small regions, it's easy tooimagine dividing it finely enough toohave one data point per region.</span></span> <span data-ttu-id="907ca-347">Это крайний пример чрезмерно высокой точности.</span><span class="sxs-lookup"><span data-stu-id="907ca-347">This is an extreme example of overfitting.</span></span> <span data-ttu-id="907ca-348">В порядке tooavoid это большой набор деревьев создаются осторожно специальные математические предпринято hello деревья не связаны.</span><span class="sxs-lookup"><span data-stu-id="907ca-348">In order tooavoid this, a large set of trees are constructed with special mathematical care taken that hello trees are not correlated.</span></span> <span data-ttu-id="907ca-349">Среднее значение Hello «леса принятия решений» является деревом, чтобы избежать переобучения.</span><span class="sxs-lookup"><span data-stu-id="907ca-349">hello average of this "decision forest" is a tree that avoids overfitting.</span></span> <span data-ttu-id="907ca-350">Леса решений могут использовать большой объем памяти.</span><span class="sxs-lookup"><span data-stu-id="907ca-350">Decision forests can use a lot of memory.</span></span> <span data-ttu-id="907ca-351">Джунгли решений — это вариант, который потребляет меньше памяти за счет hello немного больше времени обучения.</span><span class="sxs-lookup"><span data-stu-id="907ca-351">Decision jungles are a variant that consumes less memory at hello expense of a slightly longer training time.</span></span>

<span data-ttu-id="907ca-352">В увеличивающихся деревьях решений во избежание чрезмерно высокой точности ограничиваются количество повторных делений и минимальное количество точек данных в каждом регионе.</span><span class="sxs-lookup"><span data-stu-id="907ca-352">Boosted decision trees avoid overfitting by limiting how many times they can subdivide and how few data points are allowed in each region.</span></span> <span data-ttu-id="907ca-353">Алгоритм создает последовательность из дерева, каждый из которых узнает, чтобы компенсировать влево на дерево hello до ошибки hello.</span><span class="sxs-lookup"><span data-stu-id="907ca-353">The algorithm constructs a sequence of trees, each of which learns to compensate for hello error left by hello tree before.</span></span> <span data-ttu-id="907ca-354">Hello результатом является очень точной ученик, который, как правило, toouse большого объема памяти.</span><span class="sxs-lookup"><span data-stu-id="907ca-354">hello result is a very accurate learner that tends toouse a lot of memory.</span></span> <span data-ttu-id="907ca-355">Для полной техническое описание hello, посетите [исходный документ Friedman](http://www-stat.stanford.edu/~jhf/ftp/trebst.pdf).</span><span class="sxs-lookup"><span data-stu-id="907ca-355">For hello full technical description, check out [Friedman's original paper](http://www-stat.stanford.edu/~jhf/ftp/trebst.pdf).</span></span>

<span data-ttu-id="907ca-356">[Быстрая квантильная Регрессия леса](https://msdn.microsoft.com/library/azure/dn913093.aspx) является разновидностью дерева принятия решений для hello особый случай, где вы хотите знать не только hello типичные () значение медианы hello данных в пределах области, но его распространение в форме hello квантилей.</span><span class="sxs-lookup"><span data-stu-id="907ca-356">[Fast forest quantile regression](https://msdn.microsoft.com/library/azure/dn913093.aspx) is a variation of decision trees for hello special case where you want to know not only hello typical (median) value of hello data within a region, but also its distribution in hello form of quantiles.</span></span>

### <a name="neural-networks-and-perceptrons"></a><span data-ttu-id="907ca-357">Нейронные сети и восприятия</span><span class="sxs-lookup"><span data-stu-id="907ca-357">Neural networks and perceptrons</span></span>
<span data-ttu-id="907ca-358">Нейронные сети — это алгоритмы обучения, вдохновленные устройством человеческого мозга, которые охватывают [многоклассовые](https://msdn.microsoft.com/library/azure/dn906030.aspx), [двухклассовые](https://msdn.microsoft.com/library/azure/dn905947.aspx) и [регрессионные](https://msdn.microsoft.com/library/azure/dn905924.aspx) задачи.</span><span class="sxs-lookup"><span data-stu-id="907ca-358">Neural networks are brain-inspired learning algorithms covering [multiclass](https://msdn.microsoft.com/library/azure/dn906030.aspx), [two-class](https://msdn.microsoft.com/library/azure/dn905947.aspx), and [regression](https://msdn.microsoft.com/library/azure/dn905924.aspx) problems.</span></span> <span data-ttu-id="907ca-359">Они бывают безграничное разнообразие возможностей, но hello нейронных сетей в машинном обучении Azure — это все виды hello ациклического графа.</span><span class="sxs-lookup"><span data-stu-id="907ca-359">They come in an infinite variety, but hello neural networks within Azure Machine Learning are all of hello form of directed acyclic graphs.</span></span> <span data-ttu-id="907ca-360">Это означает, что входные функции передаются вперед (и только вперед) по последовательности слоев, после чего превращаются в выходные данные.</span><span class="sxs-lookup"><span data-stu-id="907ca-360">That means that input features are passed forward (never backward) through a sequence of layers before being turned into outputs.</span></span> <span data-ttu-id="907ca-361">В каждом слое входы снабжаются весовыми коэффициентами в различных сочетаниях, суммировать и передать следующий уровень hello.</span><span class="sxs-lookup"><span data-stu-id="907ca-361">In each layer, inputs are weighted in various combinations, summed, and passed on to hello next layer.</span></span> <span data-ttu-id="907ca-362">Такое сочетание результаты простых вычислений в toolearn возможности сложных тенденции класс границ и данных, первый взгляд магическая.</span><span class="sxs-lookup"><span data-stu-id="907ca-362">This combination of simple calculations results in the ability toolearn sophisticated class boundaries and data trends, seemingly by magic.</span></span> <span data-ttu-id="907ca-363">Многоуровневая многие сетей такого рода выполнять hello «углубленного обучения», который fuels так много отчетов Технический и научной фантастики.</span><span class="sxs-lookup"><span data-stu-id="907ca-363">Many-layered networks of this sort perform hello "deep learning" that fuels so much tech reporting and science fiction.</span></span>

<span data-ttu-id="907ca-364">Но такая высокая производительность имеет и обратную сторону.</span><span class="sxs-lookup"><span data-stu-id="907ca-364">This high performance doesn't come for free, though.</span></span> <span data-ttu-id="907ca-365">Нейронной сети может занять длительное время tootrain, особенно для больших наборов данных с большим количеством функций.</span><span class="sxs-lookup"><span data-stu-id="907ca-365">Neural networks can take a long time tootrain, particularly for large data sets with lots of features.</span></span> <span data-ttu-id="907ca-366">Они также имеют больше параметров, чем большинство алгоритмов, т. е. свертки параметров гораздо расширяет hello время обучения.</span><span class="sxs-lookup"><span data-stu-id="907ca-366">They also have more parameters than most algorithms, which means that parameter sweeping expands hello training time a great deal.</span></span>
<span data-ttu-id="907ca-367">И для этих overachievers, которые хотите слишком[укажите свои собственные структуры сети](http://go.microsoft.com/fwlink/?LinkId=402867), возможны inexhaustible.</span><span class="sxs-lookup"><span data-stu-id="907ca-367">And for those overachievers who wish too[specify their own network structure](http://go.microsoft.com/fwlink/?LinkId=402867), the possibilities are inexhaustible.</span></span>

<span data-ttu-id="907ca-368">![Границы узнали нейронных сетей][6]
***границы hello узнали нейронных сетей могут быть сложными и нестандартные***</span><span class="sxs-lookup"><span data-stu-id="907ca-368">![Boundaries learned by neural networks][6]
***hello boundaries learned by neural networks can be complex and irregular***</span></span>

<span data-ttu-id="907ca-369">Hello [двухклассовый усредненный перцептрон](https://msdn.microsoft.com/library/azure/dn906036.aspx) — время обучения tooskyrocketing ответов нейронных сетей.</span><span class="sxs-lookup"><span data-stu-id="907ca-369">hello [two-class averaged perceptron](https://msdn.microsoft.com/library/azure/dn906036.aspx) is neural networks' answer tooskyrocketing training times.</span></span> <span data-ttu-id="907ca-370">В нем используется структура сети, предоставляющая линейные границы класса.</span><span class="sxs-lookup"><span data-stu-id="907ca-370">It uses a network structure that gives linear class boundaries.</span></span> <span data-ttu-id="907ca-371">Это почти примитивов, современных стандартов, но он имеет длинную историю работы надежно и достаточно малым toolearn быстро.</span><span class="sxs-lookup"><span data-stu-id="907ca-371">It is almost primitive by today's standards, but it has a long history of working robustly and is small enough toolearn quickly.</span></span>

### <a name="svms"></a><span data-ttu-id="907ca-372">Методы опорных векторов</span><span class="sxs-lookup"><span data-stu-id="907ca-372">SVMs</span></span>
<span data-ttu-id="907ca-373">Машины опорных векторов (SVM) найти hello границу, которая разделяет классы, как расширенный поля можно.</span><span class="sxs-lookup"><span data-stu-id="907ca-373">Support vector machines (SVMs) find hello boundary that separates classes by as wide a margin as possible.</span></span> <span data-ttu-id="907ca-374">При hello двух классов не могут быть четко отделены, алгоритмы hello найти границы наиболее hello, в которые они могут.</span><span class="sxs-lookup"><span data-stu-id="907ca-374">When hello two classes can't be clearly separated, hello algorithms find hello best boundary they can.</span></span> <span data-ttu-id="907ca-375">Здравствуйте, как написано в машинном обучении Azure [SVM двухклассовой](https://msdn.microsoft.com/library/azure/dn905835.aspx) делает это с помощью прямой линии.</span><span class="sxs-lookup"><span data-stu-id="907ca-375">As written in Azure Machine Learning, hello [two-class SVM](https://msdn.microsoft.com/library/azure/dn905835.aspx) does this with a straight line only.</span></span> <span data-ttu-id="907ca-376">(В терминах методов опорных векторов, они используют линейное ядро.) Поскольку это делает это линейной аппроксимации, это может toorun достаточно быстро.</span><span class="sxs-lookup"><span data-stu-id="907ca-376">(In SVM-speak, it uses a linear kernel.) Because it makes this linear approximation, it is able toorun fairly quickly.</span></span> <span data-ttu-id="907ca-377">Эти методы действительно проявляют себя с данными с большим количеством функций, такими как текст или генетические данные.</span><span class="sxs-lookup"><span data-stu-id="907ca-377">Where it really shines is with feature-intense data, like text or genomic.</span></span> <span data-ttu-id="907ca-378">В таких случаях SVM — это классы могут tooseparate быстрее и с менее лжевзаимосвязей чем большинство других алгоритмов, кроме toorequiring небольшой объем памяти.</span><span class="sxs-lookup"><span data-stu-id="907ca-378">In these cases SVMs are able tooseparate classes more quickly and with less overfitting than most other algorithms, in addition toorequiring only a modest amount of memory.</span></span>

![Граница класса метода опорных векторов][7]

<span data-ttu-id="907ca-380">***Границе типичные поддержки машины вектора класса увеличивает поле hello, разделяющих два класса***</span><span class="sxs-lookup"><span data-stu-id="907ca-380">***A typical support vector machine class boundary maximizes hello margin separating two classes***</span></span>

<span data-ttu-id="907ca-381">Другой продукт из Microsoft Research hello [SVM локальной глубиной двух классов](https://msdn.microsoft.com/library/azure/dn913070.aspx) нелинейного вариант SVM, сохраняет большинство hello памяти и эффективность линейной версии hello.</span><span class="sxs-lookup"><span data-stu-id="907ca-381">Another product of Microsoft Research, hello [two-class locally deep SVM](https://msdn.microsoft.com/library/azure/dn913070.aspx) is a non-linear variant of SVM that retains most of hello speed and memory efficiency of hello linear version.</span></span> <span data-ttu-id="907ca-382">Идеально подходит для случаев, где hello линейный подход не дает достаточно точных ответов.</span><span class="sxs-lookup"><span data-stu-id="907ca-382">It is ideal for cases where hello linear approach doesn't give accurate enough answers.</span></span> <span data-ttu-id="907ca-383">Разработчики Hello удалили его быстро разрывая проблемы hello в кучу небольших линейной SVM проблем.</span><span class="sxs-lookup"><span data-stu-id="907ca-383">hello developers kept it fast by breaking down hello problem into a bunch of small linear SVM problems.</span></span> <span data-ttu-id="907ca-384">Чтение hello [полное описание](http://research.microsoft.com/um/people/manik/pubs/Jose13.pdf) hello сведения о том, как они извлечено off этот прием.</span><span class="sxs-lookup"><span data-stu-id="907ca-384">Read hello [full description](http://research.microsoft.com/um/people/manik/pubs/Jose13.pdf) for hello details on how they pulled off this trick.</span></span>

<span data-ttu-id="907ca-385">Здравствуйте, используя расширение некий нелинейный SVM, [Одноклассовой](https://msdn.microsoft.com/library/azure/dn913103.aspx) рисует границу, которая тесно описаны hello весь набор данных.</span><span class="sxs-lookup"><span data-stu-id="907ca-385">Using a clever extension of nonlinear SVMs, hello [one-class SVM](https://msdn.microsoft.com/library/azure/dn913103.aspx) draws a boundary that tightly outlines hello entire data set.</span></span> <span data-ttu-id="907ca-386">Это удобно для обнаружения аномалий.</span><span class="sxs-lookup"><span data-stu-id="907ca-386">It is useful for anomaly detection.</span></span> <span data-ttu-id="907ca-387">Все новые точки данных, далеко выходящих за пределы границ, являются достаточно необычные toobe внимания.</span><span class="sxs-lookup"><span data-stu-id="907ca-387">Any new data points that fall far outside that boundary are unusual enough toobe noteworthy.</span></span>

### <a name="bayesian-methods"></a><span data-ttu-id="907ca-388">Методы Байеса</span><span class="sxs-lookup"><span data-stu-id="907ca-388">Bayesian methods</span></span>
<span data-ttu-id="907ca-389">Методы Байеса имеют одно очень ценное качество: они не приводят к чрезмерному увеличению точности.</span><span class="sxs-lookup"><span data-stu-id="907ca-389">Bayesian methods have a highly desirable quality: they avoid overfitting.</span></span> <span data-ttu-id="907ca-390">Это делается, делая некоторые предположения заранее об hello вероятность распределения hello ответов.</span><span class="sxs-lookup"><span data-stu-id="907ca-390">They do this by making some assumptions beforehand about hello likely distribution of hello answer.</span></span> <span data-ttu-id="907ca-391">Другим побочным эффектом этого подхода является то, что у этих методов очень мало параметров.</span><span class="sxs-lookup"><span data-stu-id="907ca-391">Another byproduct of this approach is that they have very few parameters.</span></span> <span data-ttu-id="907ca-392">В Машинном обучении Azure есть оба алгоритма Байеса для классификации ([двухклассная точечная машина Байеса](https://msdn.microsoft.com/library/azure/dn905930.aspx)) и регрессии ([линейная регрессия Байеса](https://msdn.microsoft.com/library/azure/dn906022.aspx)).</span><span class="sxs-lookup"><span data-stu-id="907ca-392">Azure Machine Learning has both Bayesian algorithms for both classification ([Two-class Bayes' point machine](https://msdn.microsoft.com/library/azure/dn905930.aspx)) and regression ([Bayesian linear regression](https://msdn.microsoft.com/library/azure/dn906022.aspx)).</span></span>
<span data-ttu-id="907ca-393">Обратите внимание, что эти предполагается hello данные можно разбить или сочетаются с прямой линии.</span><span class="sxs-lookup"><span data-stu-id="907ca-393">Note that these assume that hello data can be split or fit with a straight line.</span></span>

<span data-ttu-id="907ca-394">С исторической точки зрения точечные машины Байеса были разработаны в Microsoft Research.</span><span class="sxs-lookup"><span data-stu-id="907ca-394">On a historical note, Bayes' point machines were developed at Microsoft Research.</span></span> <span data-ttu-id="907ca-395">За ними стоит исключительная теоретическая работа.</span><span class="sxs-lookup"><span data-stu-id="907ca-395">They have some exceptionally beautiful theoretical work behind them.</span></span> <span data-ttu-id="907ca-396">Hello интерес студента — расширенный toohello [оригинальная статья в JMLR](http://jmlr.org/papers/volume1/herbrich01a/herbrich01a.pdf) и [информативные блоге Криса Бишопа](http://blogs.technet.com/b/machinelearning/archive/2014/10/30/embracing-uncertainty-probabilistic-inference.aspx).</span><span class="sxs-lookup"><span data-stu-id="907ca-396">hello interested student is directed toohello [original article in JMLR](http://jmlr.org/papers/volume1/herbrich01a/herbrich01a.pdf) and an [insightful blog by Chris Bishop](http://blogs.technet.com/b/machinelearning/archive/2014/10/30/embracing-uncertainty-probabilistic-inference.aspx).</span></span>

### <a name="specialized-algorithms"></a><span data-ttu-id="907ca-397">Специализированные алгоритмы</span><span class="sxs-lookup"><span data-stu-id="907ca-397">Specialized algorithms</span></span>
<span data-ttu-id="907ca-398">При наличии очень конкретной цели вам может повезти со специализированным алгоритмом.</span><span class="sxs-lookup"><span data-stu-id="907ca-398">If you have a very specific goal you may be in luck.</span></span> <span data-ttu-id="907ca-399">В рамках hello коллекции машинного обучения Azure существуют алгоритмы, которые специализируются на:</span><span class="sxs-lookup"><span data-stu-id="907ca-399">Within hello Azure Machine Learning collection, there are algorithms that specialize in:</span></span>

- <span data-ttu-id="907ca-400">прогнозировании ранжирования ([порядковая регрессия](https://msdn.microsoft.com/library/azure/dn906029.aspx));</span><span class="sxs-lookup"><span data-stu-id="907ca-400">rank prediction ([ordinal regression](https://msdn.microsoft.com/library/azure/dn906029.aspx)),</span></span>
- <span data-ttu-id="907ca-401">количественных прогнозах ([регрессия Пуассона](https://msdn.microsoft.com/library/azure/dn905988.aspx));</span><span class="sxs-lookup"><span data-stu-id="907ca-401">count prediction ([Poisson regression](https://msdn.microsoft.com/library/azure/dn905988.aspx)),</span></span>
- <span data-ttu-id="907ca-402">обнаружении аномалий (на основе [анализа основных компонентов](https://msdn.microsoft.com/library/azure/dn913102.aspx) и на основе [метода опорных векторов](https://msdn.microsoft.com/library/azure/dn913103.aspx));</span><span class="sxs-lookup"><span data-stu-id="907ca-402">anomaly detection (one based on [principal components analysis](https://msdn.microsoft.com/library/azure/dn913102.aspx) and one based on [support vector machine](https://msdn.microsoft.com/library/azure/dn913103.aspx)s)</span></span>
- <span data-ttu-id="907ca-403">кластеризации ([K-средних](https://msdn.microsoft.com/library/azure/5049a09b-bd90-4c4e-9b46-7c87e3a36810/)).</span><span class="sxs-lookup"><span data-stu-id="907ca-403">clustering ([K-means](https://msdn.microsoft.com/library/azure/5049a09b-bd90-4c4e-9b46-7c87e3a36810/))</span></span>

![Обнаружение аномалий на основе анализа первичных компонентов][8]

<span data-ttu-id="907ca-405">***Обнаружение аномалий на основе PCA*** *-hello большинство данных hello попадает и стереотипном распространения; значительно уклониться от этой точки, как подозрительная*</span><span class="sxs-lookup"><span data-stu-id="907ca-405">***PCA-based anomaly detection*** *- hello vast majority of hello data falls into a stereotypical distribution; points deviating dramatically from that distribution are suspect*</span></span>

![Набор данных, сгруппированный с использованием K-средних][9]

<span data-ttu-id="907ca-407">***Набор данных группируется в пять кластеров с использованием K-средних***</span><span class="sxs-lookup"><span data-stu-id="907ca-407">***A data set is grouped into five clusters using K-means***</span></span>

<span data-ttu-id="907ca-408">Имеется также совокупности [мультиклассового классификатора один v все](https://msdn.microsoft.com/library/azure/dn905887.aspx), какие проблемы классификации разрывов hello класс N в n-1 двухклассовой классификации проблем.</span><span class="sxs-lookup"><span data-stu-id="907ca-408">There is also an ensemble [one-v-all multiclass classifier](https://msdn.microsoft.com/library/azure/dn905887.aspx), which breaks hello N-class classification problem into N-1 two-class classification problems.</span></span> <span data-ttu-id="907ca-409">Точность Hello, время обучения и линейность свойства определяются hello двухклассовых классификаторов используется.</span><span class="sxs-lookup"><span data-stu-id="907ca-409">hello accuracy, training time, and linearity properties are determined by hello two-class classifiers used.</span></span>

![Двухклассовых классификаторов вместе tooform классификатор трех класс][10]

<span data-ttu-id="907ca-411">***Пара двухклассовых классификаторов объединить tooform классификатор трех класс***</span><span class="sxs-lookup"><span data-stu-id="907ca-411">***A pair of two-class classifiers combine tooform a three-class classifier***</span></span>

<span data-ttu-id="907ca-412">Также Azure машинного обучения включает платформу tooa мощные машинного обучения доступа под названием hello объекта [Vowpal Wabbit](https://msdn.microsoft.com/library/azure/8383eb49-c0a3-45db-95c8-eb56a1fef5bf).</span><span class="sxs-lookup"><span data-stu-id="907ca-412">Azure Machine Learning also includes access tooa powerful machine learning framework under hello title of [Vowpal Wabbit](https://msdn.microsoft.com/library/azure/8383eb49-c0a3-45db-95c8-eb56a1fef5bf).</span></span>
<span data-ttu-id="907ca-413">Эта платформа пренебрегает приведенной здесь классификацией, так как может решать как классификационные, так и регрессионные задачи и даже обучаться на основе частично неразмеченных данных.</span><span class="sxs-lookup"><span data-stu-id="907ca-413">VW defies categorization here, since it can learn both classification and regression problems and can even learn from partially unlabeled data.</span></span> <span data-ttu-id="907ca-414">Можно настроить его toouse любому из ряд обучающих алгоритмов, потери функциях и алгоритмах оптимизации.</span><span class="sxs-lookup"><span data-stu-id="907ca-414">You can configure it toouse any one of a number of learning algorithms, loss functions, and optimization algorithms.</span></span> <span data-ttu-id="907ca-415">Он был разработан с hello основание, toobe, параллельные и очень быстро.</span><span class="sxs-lookup"><span data-stu-id="907ca-415">It was designed from hello ground up toobe efficient, parallel, and extremely fast.</span></span> <span data-ttu-id="907ca-416">Она обрабатывает огромные наборы функций с минимальными усилиями.</span><span class="sxs-lookup"><span data-stu-id="907ca-416">It handles ridiculously large feature sets with little apparent effort.</span></span>
<span data-ttu-id="907ca-417">Запущенная и управляемая Джоном Лэнгфордом из Microsoft Research, Vowpal Wabbit — это "формула один" среди других алгоритмов.</span><span class="sxs-lookup"><span data-stu-id="907ca-417">Started and led by Microsoft Research's own John Langford, VW is a Formula One entry in a field of stock car algorithms.</span></span> <span data-ttu-id="907ca-418">Не все проблемы занимает VW, но, если указанное имя не, возможно, стоит этого tooclimb обучения для интерфейса.</span><span class="sxs-lookup"><span data-stu-id="907ca-418">Not every problem fits VW, but if yours does, it may be worth your while tooclimb the learning curve on its interface.</span></span> <span data-ttu-id="907ca-419">Система также доступна в виде [автономного открытого исходного кода](https://github.com/JohnLangford/vowpal_wabbit) на нескольких языках.</span><span class="sxs-lookup"><span data-stu-id="907ca-419">It's also available as [stand-alone open source code](https://github.com/JohnLangford/vowpal_wabbit) in several languages.</span></span>

## <a name="more-help-with-algorithms"></a><span data-ttu-id="907ca-420">Дополнительная помощь с алгоритмами</span><span class="sxs-lookup"><span data-stu-id="907ca-420">More help with algorithms</span></span>
* <span data-ttu-id="907ca-421">Сведения о скачиваемой инфографике с описанием алгоритмов и примерами см. в статье [Загружаемая инфографика по основам машинного обучения с примерами алгоритмов](machine-learning-basics-infographic-with-algorithm-examples.md).</span><span class="sxs-lookup"><span data-stu-id="907ca-421">For a downloadable infographic that describes algorithms and provides examples, see [Downloadable Infographic: Machine learning basics with algorithm examples](machine-learning-basics-infographic-with-algorithm-examples.md).</span></span>
* <span data-ttu-id="907ca-422">Список по типам алгоритмов машинного обучения всех hello, доступные в студии машинного обучения Azure см. в разделе [модель инициализации] [ initialize-model] в hello машины обучения Studio алгоритм и модуль справки.</span><span class="sxs-lookup"><span data-stu-id="907ca-422">For a list by category of all hello machine learning algorithms available in Azure Machine Learning Studio, see [Initialize Model][initialize-model] in hello Machine Learning Studio Algorithm and Module Help.</span></span>
* <span data-ttu-id="907ca-423">Полный список всех алгоритмов и модулей машинного обучения, доступных в Студии машинного обучения, расположенных в алфавитном порядке, см. в справке по алгоритмам и модулям Студии машинного обучения [A-Z List of Machine Learning Studio Modules][a-z-list] (Полный список модулей Студии машинного обучения).</span><span class="sxs-lookup"><span data-stu-id="907ca-423">For a complete alphabetical list of algorithms and modules in Azure Machine Learning Studio, see [A-Z list of Machine Learning Studio modules][a-z-list] in Machine Learning Studio Algorithm and Module Help.</span></span>
* <span data-ttu-id="907ca-424">toodownload и печати на диаграмме, которая позволяет получить представление о возможности hello студии машинного обучения Azure в разделе [Обзорная схема возможностей студии машинного обучения Azure](machine-learning-studio-overview-diagram.md).</span><span class="sxs-lookup"><span data-stu-id="907ca-424">toodownload and print a diagram that gives an overview of hello capabilities of Azure Machine Learning Studio, see [Overview diagram of Azure Machine Learning Studio capabilities](machine-learning-studio-overview-diagram.md).</span></span>


<!-- Reference links -->
[initialize-model]: https://msdn.microsoft.com/library/azure/dn905812.aspx
[a-z-list]: https://msdn.microsoft.com/library/azure/dn906033.aspx

<!-- Media -->

[1]: ./media/machine-learning-algorithm-choice/image1.png
[2]: ./media/machine-learning-algorithm-choice/image2.png
[3]: ./media/machine-learning-algorithm-choice/image3.png
[4]: ./media/machine-learning-algorithm-choice/image4.png
[5]: ./media/machine-learning-algorithm-choice/image5.png
[6]: ./media/machine-learning-algorithm-choice/image6.png
[7]: ./media/machine-learning-algorithm-choice/image7.png
[8]: ./media/machine-learning-algorithm-choice/image8.png
[9]: ./media/machine-learning-algorithm-choice/image9.png
[10]: ./media/machine-learning-algorithm-choice/image10.png
