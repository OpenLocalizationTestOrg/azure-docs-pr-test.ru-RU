---
title: "Масштабирование кластера службы контейнеров Azure для машинного обучения | Документация Майкрософт"
description: "Масштабирование кластера ACS: автомасштабирование, статическое масштабирование, масштабирование количества узлов кластера"
services: machine-learning
author: raymondl
ms.author: raymondl
manager: mwinkle
ms.reviewer: garyericson, jasonwhowell, mldocs
ms.service: machine-learning
ms.workload: data-services
ms.custom: mvc
ms.topic: article
ms.date: 10/04/2017
ms.openlocfilehash: 8d709936bfba5c89091d7f26449d165bddb930de
ms.sourcegitcommit: b07d06ea51a20e32fdc61980667e801cb5db7333
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 12/08/2017
---
# <a name="scaling-the-cluster-to-manage-web-service-throughput"></a>Масштабирование кластера для управления пропускной способностью веб-службы

## <a name="why-scale-the-cluster"></a>Зачем нужно масштабировать кластер?

Масштабирование кластера службы контейнеров Azure (ACS) — это эффективный способ оптимизации пропускной способности службы с сохранением минимального размера кластера для уменьшения затрат. 

Чтобы узнать больше об автомасштабировании, ознакомьтесь со следующим примером кластера, в котором выполняются три веб-службы.

![Пример: три службы в кластере](media/how-to-scale-clusters/three-services.png)

В службах имеются различные пиковые нагрузки. При максимальной нагрузке службе 1 (синяя линия) требуется 40 модулей, службе 2 (оранжевая линия) — 38, а службе 3 (серая линия) — 50. Если необходимая максимальная емкость зарезервирована для каждой службы отдельно, то кластеру потребуется минимум 40 + 38 + 50 = 128 модулей.

Однако рассмотрим фактическое использование модулей в любой момент времени (черная пунктирная линия на схеме). В этом случае *максимальное количество используемых модулей в любой момент времени* — 64 (в 20:00, когда служба 3 находится на пике). В это время служба 3 использует 50 модулей, а служба 2 и 1 используют 9 и 5 модулей соответственно. Обратите внимание, что это *пиковое использование* для этого кластера. Это означает, что кластер никогда не использует более 64 модулей (половину вычисленного требуемого количества (128 модулей) для трех служб, масштабируемых независимо для максимального использования).

Размер кластера можно уменьшить, перераспределив модули в кластере, то есть изменив масштаб в соответствии с текущими требованиями каждой службы, а не обеспечив достаточно ресурсов для пикового спроса всех служб. В этом простом примере автоматическое масштабирование уменьшает необходимое количество модулей с 128 до 64, сокращая требуемый размер кластера в два раза.

Процесс масштабирования числа модулей выполняется относительно быстро (меньше 1 минуты), поэтому скорость реагирования службы не сильно меняется.

> [!NOTE]
> Масштабирование кластера не поможет решить проблемы с задержкой выполнения запроса. В целях практического применения при масштабировании должно увеличиться количество успешных заданий и уменьшиться количество ошибок типа "Служба недоступна". 

## <a name="how-to-scale-web-services-on-your-acs-cluster"></a>Масштабирование веб-служб в кластере ACS

Во время установки кластера интерфейса командной строки управления моделями по умолчанию в среде настраивается два агента и один модуль, а также устанавливается интерфейс командной строки Kubernetes.

Вы можете масштабировать веб-службы, развернутые в ACS, скорректировав следующие показатели:

* количество узлов агента в кластере;
* количество реплик модуля Kubernetes, работающих на узлах агента.

### <a name="scaling-the-number-of-nodes-in-the-cluster"></a>Масштабирование количества узлов кластера

Следующая команда задает количество узлов агента в кластере:

```
az acs scale -g <resource group> -n <cluster name> --new-agent-count <new scale>
```

Ее выполнение может занять несколько минут. Дополнительные сведения о масштабировании количества узлов кластера см. в статье [Масштабирование узлов агента в кластере службы контейнеров](https://docs.microsoft.com/azure/container-service/container-service-scale).

### <a name="scaling-the-number-of-kubernetes-pod-replicas-in-a-cluster"></a>Масштабирование числа реплик модуля Kubernetes кластера
 
Количество реплик модулей, присвоенных кластеру, можно масштабировать с помощью интерфейса командной строки службы "Машинное обучение Azure" или [панели мониторинга Kubernetes] (https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/).

Дополнительные сведения о репликах модулей Kubernetes см. в документации по [модулям Kubernetes](https://kubernetes.io/docs/concepts/workloads/pods/pod/).

#### <a name="scaling-a-cluster-with-the-azure-machine-learning-cli"></a>Масштабирование кластера с помощью интерфейса командной строки службы "Машинное обучение Azure"

Масштабировать кластер с помощью интерфейса командной строки можно двумя способами:

- Autoscale
- Статическое масштабирование

Автомасштабирование при создании службы активно по умолчанию. В большинстве случаев рекомендуется использовать этот метод масштабирования.

##### <a name="autoscale"></a>Autoscale

Следующая команда включает автомасштабирование и задает минимальное и максимальное количество реплик для службы.

```
az ml service update realtime -i <service id> --autoscale-enabled true --autoscale-min-replicas <positive number> --autoscale-max-replicas <positive number>
```

Например, если в `autoscale-min-replicas` задать значение 5, то это приведет к созданию пяти реплик. Чтобы получить оптимальное количество для веб-службы, установите необходимое значение (например, 10) и проверьте количество сообщений об ошибке 503. Затем измените число соответствующим образом.


| Имя параметра | type | ОПИСАНИЕ |
|--------------------|--------------------|--------------------|
| `autoscale-enabled` | Логическое | Указывает, включено ли автомасштабирование. Значение по умолчанию: True. |
| `autoscale-min-replicas` | целое число | Указывает минимальное количество модулей. Должно быть указано значение не меньше 0. Значение по умолчанию: 1. |
| `autoscale-max-replicas` | целое число | Указывает максимальное количество модулей. Должно быть указано значение не меньше 1. Значение параметра autoscale-max-replicas не учитывается, если оно меньше значения autoscale-min-replicas. Значение по умолчанию: 10. |
| `autoscale-refresh-period-seconds` | целое число | Указывает время между операциями обновления автомасштабирования (в секундах). Значение по умолчанию: 1. |
| `autoscale-target-utilization` | целое число | Указывает процент использования, предназначенный для автомасштабирования (от 1 до 100). Значение по умолчанию: 70. |

Автомасштабирование предназначено для обеспечения следующих двух условий:

1. Соответствие целевому показателю использования.
2. Предотвращение превышения минимального и максимального значения при масштабировании.

Службы кластера конкурируют за его ресурсы. Автомасштабированная служба увеличит использование ресурсов кластера по мере увеличения числа запросов в секунду (RPS) и будет медленно освобождать ресурсы по мере уменьшения этого показателя. Кластерные ресурсы будут запрашиваться по требованию до тех пор, пока существуют ресурсы для запроса службы.

Дополнительные сведения об использовании параметров автомасштабирования см. в статье [Справочник по интерфейсу командной строки для службы управления моделями](model-management-cli-reference.md).

##### <a name="static-scale"></a>Статическое масштабирование

В большинстве случаев следует избегать статического масштабирования, так как оно не позволяет уменьшить размер кластера при автомасштабировании. Тем не менее, в некоторых ситуациях рекомендуется использовать статическое масштабирование. Например, когда кластер предназначен для одной службы, автомасштабирование не дает никакой пользы. В таком случае все ресурсы кластера необходимо назначить этой службе.

Для статического масштабирования кластера необходимо отключить автомасштабирование, используя следующую команду:

```
az ml service update realtime -i <service id> --autoscale-enabled false
```

После отключения автомасштабирования следующая команда непосредственно масштабирует количество реплик для службы.

```
az ml service update realtime -i <service id> -z <replica count>
```
 
Дополнительные сведения о масштабировании количества узлов кластера см. в статье "Масштабирование узлов агента в кластере службы контейнеров".

#### <a name="scaling-number-of-replicas-using-the-kubernetes-dashboard"></a>Масштабирование количества реплик с помощью панели мониторинга Kubernetes

В командной строке введите:

```
kubectl proxy
```

В Windows расположение установки Kubernetes не добавляется к пути автоматически. Сначала перейдите к папке установки:

```
c:\users\<user name>\bin
```

После выполнения команды должно отобразиться следующее информационное сообщение:

```
Starting to serve on 127.0.0.1:8001
```

Если порт уже используется, появится сообщение, подобное приведенному ниже:

```
F0612 21:49:22.459111   59621 proxy.go:137] listen tcp 127.0.0.1:8001: bind: address already in use
```

Вы можете указать альтернативный номер порта с помощью параметра *--port*.

```
kubectl proxy --port=8010
Starting to serve on 127.0.0.1:8010
```

После запуска сервера панели мониторинга откройте браузер и введите следующий URL-адрес.

```
127.0.0.1:<port number>/ui
```

На главном экране панели мониторинга на левой панели навигации щелкните **Развернутые приложения**. Если панель навигации не отображается, выберите этот значок ![Меню, состоящее из трех коротких горизонтальных линий](media/how-to-scale-clusters/icon-hamburger.png) в левом верхнем углу.

Найдите развертывание, которое необходимо изменить, и щелкните этот значок ![Значок меню, состоящий из трех вертикальных точек](media/how-to-scale-clusters/icon-kebab.png) справа, а затем нажмите **View/edit YAML** (Просмотр или изменение YAML).

На экране редактирования развертывания, найдите узел *spec*, измените значения *реплик* и щелкните **Обновить**.
