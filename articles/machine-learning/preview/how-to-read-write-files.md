---
title: "Чтение и запись больших файлов данных | Документация Майкрософт"
description: "Чтение и запись больших файлов в экспериментах Машинного обучения Azure."
services: machine-learning
author: hning86
ms.author: haining
manager: mwinkle
ms.reviewer: garyericson, jasonwhowell, mldocs
ms.service: machine-learning
ms.workload: data-services
ms.topic: article
ms.date: 09/10/2017
ms.openlocfilehash: fb3158ef786ad73440a59c07b38476a98ced0768
ms.sourcegitcommit: 6699c77dcbd5f8a1a2f21fba3d0a0005ac9ed6b7
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 10/11/2017
---
# <a name="persisting-changes-and-dealing-with-large-files"></a>Сохранение изменений и работа с большими файлами

## <a name="execution-isolation-portability-and-reproducibility"></a>Изоляция, переносимость и воспроизводимость выполнения
Служба "Экспериментирование в Машинном обучении Azure" позволяет настроить разные целевые объекты выполнения, часть которых будут локальными (например, локальный компьютер или контейнер Docker на локальном компьютере), а другие — удаленными (например, контейнер Docker на удаленном компьютере или кластер HDInsight). Дополнительные сведения см. в статье [Overview of Azure Machine Learning experiment execution service](experiment-execution-configuration.md) (Обзор службы выполнения экспериментов в Машинном обучении Azure). Прежде чем начнется любое выполнение, папка проекта копируется на целевой объект вычислений. Это выполняется даже при локальном выполнении, и для этой цели тогда используется временная локальная папка. 

Это нужно для того, чтобы обеспечить изоляцию, повторяемость и переносимость выполнения. Если вы дважды выполнить один и тот же скрипт на одном или на разных объектах вычислений, вы гарантированно получите одинаковые результаты. Изменения, внесенные во время первого выполнения, не должны влиять на второе выполнение. Такая схема работы позволяет использовать целевые объекты вычислений как вычислительные ресурсы без сохранения состояния и без сопоставления с уже завершенными заданиями.

## <a name="challenges"></a>Сложности
Наряду с преимуществами переносимости и повторяемости такой подход вызывает некоторые уникальные трудности.
### <a name="persisting-state-changes"></a>Сохранение изменений состояния
Если скрипт изменяет состояние в контексте вычислений, эти изменения не сохраняются для следующего выполнения и не распространяются автоматически обратно на клиентский компьютер. 

Например, если ваш скрипт создает вложенную папку или записывает данные в новый файл, вы не найдете этот файл или папку в каталоге проекта после выполнения скрипта. Они остаются во временной папке на целевом объекте вычислений, где бы он ни находился. Их можно использовать для отладки, но никак нельзя полагаться на их существование.

### <a name="dealing-with-large-files-in-project-folder"></a>Работа с большими файлами в папке проекта

Если папка проекта содержит большие файлы, это увеличит задержку при копировании папки проекта на целевой объект вычислений перед началом каждого выполнения. Даже если выполнение происходит локально, это приводит к ненужной нагрузке на диск, которой нужно избежать. Поэтому на текущий момент действует ограничение в 25 МБ на максимальный размер проекта.

## <a name="option-1-use-the-outputs-folder"></a>Вариант 1. Папка выходных данных
Это предпочтительный вариант, если скрипт создает файлы и вы намерены изменять эти файлы при каждом запуске эксперимента и сохранять эти изменения. Предположим, вы обучаете модель, создаете набор данных или строите график в графическом файле в процессе обучения модели. Затем вы хотите сравнить выходные данные разных запусков или выбрать файл выходных данных (например, модель) предыдущего запуска, чтобы использовать его для следующей задачи (например, для оценки модели).

В таком сценарии вы можете сохранять нужные файлы в папку с именем `outputs`, расположенную в корневом каталоге проекта. Это особая папка, с которой служба "Экспериментирование" взаимодействует особо. После завершения выполнения все _артефакты_, которые создаются в ней во время выполнения скрипта (файл модели, файл данных или файл изображения), будут скопированы в учетную запись хранения больших двоичных объектов, связанную с учетной записью службы "Экспериментирование". Они становятся частью записи в журнале выполнения.

Вот небольшой пример для сохранения модели в папке `outputs`.
```python
import os
import pickle

# m is a scikit-learn model. 
# we serialize it into a mode.plk file under the ./outputs folder.
with open(os.path.join('.', 'outputs', 'model.pkl'), 'wb') as f:    
    pickle.dump(m, f)
```
Вы можете скачать все _артефакты_ в разделе **Выходные файлы** на странице информации о конкретном выполнении в среде Машинного обучения Azure. Выберите нужные артефакты и щелкните кнопку **Загрузить**. Также можно выполнить команду `az ml asset download` в окне CLI.

Более подробный пример можно изучить в скрипте Python `iris_sklearn.py` в образце проекта _Классификация цветков ириса_.

## <a name="option-2-use-the-shared-folder"></a>Вариант 2. Общая папка
В некоторых случаях очень удобно использовать общую папку, к которой можно обращаться из разных запусков, если вам не нужно сохранять в журнале состояние этих файлов после каждого запуска. 
- Ваш скрипт использует данные для обучения или тестирования из локальных файлов, например CSV-файлов, текстовых или графических файлов. 
- Ваш скрипт принимает необработанные данные и сохраняет промежуточные результаты, например для присвоения признаков по обучающим данным из текстовых или графических файлов, и эти сохраненные результаты используются в последующих обучающих запусках. 
- Ваш скрипт выдает модель, а следующий скрипт оценки выбирает одну из нескольких моделей и использует ее для оценки. 

Есть одно важное ограничение: общая папка должна быть размещена локально на выбранном целевом объекте вычислений. Это значит, что общую папку могут использовать только скрипты, выполняемые на одном целевом объекте вычислений, и нельзя выполнять очистку целевого объекта между запусками.

Функция общей папки позволяет выполнять чтение и запись в специальную папку, путь к которой определяется переменной среды `AZUREML_NATIVE_SHARE_DIRECTORY`. 

### <a name="example"></a>Пример
Ниже приведен пример кода Python для чтения и записи текстового файл в общей папке.
```python
import os

# write to the shared folder
with open(os.environ['AZUREML_NATIVE_SHARE_DIRECTORY'] + 'test.txt', 'wb') as f:
    f.write(“Hello World”)

# read from the shared folder
with open(os.environ['AZUREML_NATIVE_SHARE_DIRECTORY'] + 'test.txt', 'r') as f:
    text = file.read()
```

Более подробный пример можно изучить в файле `iris_sklearn_shared_folder.py` в образце проекта _Классификация цветков ириса_.

Прежде чем использовать эту функцию, нужно внести в файл `.compute` несколько несложных изменений, которые описывают целевой контекст выполнения в папке `aml_config`. Фактический путь к этой папке вы можете настроить произвольно с учетом особенностей целевого объекта вычислений.

### <a name="configure-local-compute-context"></a>Настройка локального контекста вычислений

Чтобы включить эту функцию для локального контекста вычислений, просто добавьте в файл `.compute` следующую строку, которая описывает _локальную_ среду (обычно с именем `local.compute`).
```
# local.runconfig
...
nativeSharedDirectory: ~/.azureml/share
...
```

По умолчанию используется путь `~/.azureml/share` к базовой папке. Вы можете указать вместо него любой полный локальный путь, к которому есть доступ у выполняемого скрипта. Чтобы получить полный путь к общей папке, к имени базовой папки автоматически добавляются имя учетной записи службы "Экспериментирование", имя рабочей области и имя проекта. Например, если вы сохраните указанное выше значение по умолчанию, файлы можно будет записывать в папку по следующему пути (и потом считывать оттуда):

```
# on Windows
C:\users\<username>\.azureml\share\<exp_acct_name>\<workspace_name>\<proj_name>\

# on macOS
/Users/<username>/.azureml/share/<exp_acct_name>/<workspace_name>/<proj_name>/
```

### <a name="configure-docker-compute-context-local-or-remote"></a>Настройка контекста вычислений Docker (локального или удаленного)
Чтобы включить эту функцию в контексте вычислений Docker, следует добавить следующие две строки в файл _.compute_ для локального или удаленного Docker.

```
# docker.compute
...
sharedVolumes: true
nativeSharedDirectory: ~/.azureml/share
...
```
>[!IMPORTANT]
>Параметр `sharedVolume` должен иметь значение `true`, если вы используете переменную среды `AZUREML_NATIVE_SHARE_DIRECTORY` для доступа к общей папке, в противном случае произойдет сбой выполнения.

Код, выполняющийся в контейнере Docker, всегда видит эту общую папку по адресу `/azureml-share/`. Путь к папке, который используется в контейнере Docker, настроить нельзя. Кроме того, не следует использовать в коде имя папки напрямую. Для обращения к этой папке всегда используйте значение переменной среды `AZUREML_NATIVE_SHARE_DIRECTORY`. Это значение сопоставляется с локальной папкой в контексте компьютера и узла вычислений Docker. Имя базовой папки для этой локальной папки можно настроить в параметре `nativeSharedDirectory` в файле `.compute`. Если используется указанное выше значение по умолчанию, локальный путь к общей папке на хост-компьютере выглядит следующим образом:
```
# Windows
C:\users\<username>\.azureml\share\<exp_acct_name>\<workspace_name>\<proj_name>\

# macOS
/Users/<username>/.azureml/share/<exp_acct_name>/<workspace_name>/<proj_name>/

# Ubuntu Linux
/home/<username>/.azureml/share/<exp_acct_name>/<workspace_name>/<proj_name>/
```

>[!TIP]
>Обратите внимание, что путь к общей папке на локальном диске совпадает в локальном контексте вычислений и в контексте вычислений для локального Docker. Это позволяет даже совместно использовать файлы из запусков в локальном контексте и в локальном Docker.

Вы можете напрямую поместить входные данные в эти папки, и тогда выполняемые локально или в локальном Docker скрипты смогут обратиться к этим данным. И наоборот, выполняемые локально или в локальном Docker скрипты могут записывать файлы в эту папку, чтобы сохранить данные после завершения выполнения.

Дополнительные сведения о файлах конфигурации в службе Экспериментирование в Машинном обучении Azure можно найти в этой статье: [Azure Machine Learning Workbench execution configuration files](experiment-execution-configuration-reference.md) (Файлы конфигурации выполнения в Azure Machine Learning Workbench).

>[!NOTE]
>Переменная среды `AZUREML_NATIVE_SHARE_DIRECTORY` не поддерживается в контексте вычислений HDInsight. Но вы можете легко получить аналогичный результат, используя абсолютный путь WASB для чтения данных из присоединенного хранилища больших двоичных объектов и записи в него.

## <a name="option-3-use-external-durable-storage"></a>Вариант 3. Внешнее долговременное хранилище

Вы всегда можете применить внешнее долговременное хранилище для сохранения состояний между выполнениями. Это может пригодиться в следующих сценариях.
- Входные данные уже хранятся в долгосрочном хранилище, которое доступно из целевой среды вычислений.
- Эти файлы не нужны в записях журнала выполнения.
- Эти файлы нужно использовать совместно при выполнениях из разных вычислительных сред.
- Эти файлы должны сохраняться даже после удаления контекста вычислений.

Например, вы можете использовать хранилище BLOB-объектов Azure из кода Python или PySpark.

Ниже приведен простой пример работы с хранилищем больших двоичных объектов Azure из кода Python.
```python
from azure.storage.blob import BlockBlobService
import glob
import os

ACCOUNT_NAME = "<your blob storage account name>"
ACCOUNT_KEY = "<account key>"
CONTAINER_NAME = "<container name>"

blob_service = BlockBlobService(account_name=ACCOUNT_NAME, account_key=ACCOUNT_KEY)

## Create a new container if necessary, or use an existing one
my_service.create_container(CONTAINER_NAME, fail_on_exist=False, public_access=PublicAccess.Container)

# df is a pandas DataFrame
df.to_csv('mydata.csv', sep='\t', index=False)

# Export the mydata.csv file to blob storage.
for name in glob.iglob('mydata.csv'):
    blob_service.create_blob_from_path(CONTAINER_NAME, 'single_file.csv', name)
```

А это краткий пример для присоединения любого хранилища больших двоичных объектов к среде выполнения HDI Spark.
```python
def attach_storage_container(spark, account, key):
    config = spark._sc._jsc.hadoopConfiguration()
    setting = "fs.azure.account.key." + account + ".blob.core.windows.net"
    if not config.get(setting):
        config.set(setting, key)
 
attach_storage_container(spark, "<storage account name>", "<storage key>”)
```

## <a name="conclusion"></a>Заключение
Поскольку Машинное обучение Azure выполняет скрипты с предварительным копированием всего проекта на целевой объект вычислений, следует уделить особое внимание большим входным данным, выходным и временным файлам. Для транзакций с большими файлами вы можете использовать специальную папку `outputs`, общую папку, путь к которой хранится в переменной среды `AZUREML_NATIVE_SHARE_DIRECTORY` или внешне долговременное хранилище. 

## <a name="next-steps"></a>Дальнейшие действия
- Изучите статью [Azure Machine Learning Workbench execution configuration files](experiment-execution-configuration-reference.md) (Файлы конфигурации выполнения в Azure Machine Learning Workbench).
- Посмотрите, как в учебном проекте [классификации цветков ириса](tutorial-classifying-iris-part-1.md) используется папка `outputs` для долговременного сохранения обученной модели.