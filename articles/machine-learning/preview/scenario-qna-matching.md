---
title: "Сопоставление вопросов и ответов с помощью Azure Machine Learning Workbench | Документация Майкрософт"
description: "Как использовать различные действующие методы машинного обучения для сопоставления открытых запросов с уже существующими парами часто задаваемых вопросов и ответов."
services: machine-learning
documentationcenter: 
author: mezmicrosoft
editor: mezmicrosoft
ms.assetid: 
ms.reviewer: garyericson, jasonwhowell, mldocs
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 09/15/2017
ms.author: mez
manager: tihazen
ms.openlocfilehash: 33f807a4a0bbc4afd1f2fbe017f8913eccacc34b
ms.sourcegitcommit: 68aec76e471d677fd9a6333dc60ed098d1072cfc
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 12/18/2017
---
#  <a name="q--a-matching-using-azure-machine-learning-workbench"></a>Сопоставление вопросов и ответов с помощью Azure Machine Learning Workbench
На открытые вопросы часто трудно найти ответ, и для этого требуются ручные действия профильных специалистов. Чтобы сократить нагрузку на внутренних специалистов, компании часто создают списки часто задаваемых вопросов (FAQ) для помощи пользователям. В этом примере показаны различные действующие методы машинного обучения, которые сопоставляют открытые запросы и уже существующие пары часто задаваемых вопросов и ответов на них. В этом примере показан несложный процесс разработки, позволяющий создать такое решение с использованием Azure Machine Learning Workbench. 

## <a name="link-to-the-gallery-github-repository"></a>Ссылка на репозиторий коллекции на GitHub
[https://github.com/Azure/MachineLearningSamples-QnAMatching](https://github.com/Azure/MachineLearningSamples-QnAMatching)

## <a name="overview"></a>Обзор

В этом примере решается проблема сопоставления пользовательских вопросов с существующими парами вопросов и ответов, которые обычно размещаются на веб-сайтах в виде списка часто задаваемых вопросов или пар вопросов и ответов, как, например, на сайте [Stack Overflow](https://stackoverflow.com/). Существует множество подходов для сопоставления вопросов с правильными ответами, например поиск ответа, наиболее похожего на вопрос. Но в этом примере для сопоставления открытых вопросов с вопросами, заданными ранее, используется предположение, что каждый из ответов в списке может соответствовать нескольким семантически эквивалентным вопросам.

Ниже приведены основные действия, необходимые для создания такого решения.

1. Очистка и предварительная обработка текстовых данных.
2. Изучение информативных фраз, то есть последовательностей из нескольких слов, которые при расположении в определенном порядке содержат больше информации, чем при обработке независимо друг от друга.
3. Извлечение признаков из текстовых данных.
4. Обучение моделей классификации текста и оценка их эффективности.


## <a name="prerequisites"></a>Технические условия

Предварительные требования для выполнения этого сценария:

1. [Учетная запись Azure](https://azure.microsoft.com/free/) (доступны бесплатные пробные версии).
2. Установленная копия [Azure Machine Learning Workbench](./overview-what-is-azure-ml.md). Чтобы установить эту программу и создать рабочую область, выполните инструкции из [краткого руководства по установке](./quickstart-installation.md).
3. Этот пример можно выполнить в любом контексте вычислений. Но мы рекомендуем использовать компьютер с несколькими ядрами, как минимум с 16 ГБ памяти и 5 ГБ дискового пространства.

## <a name="create-a-new-workbench-project"></a>Создание проекта в Workbench

Создайте проект, используя в качестве шаблона следующий пример:
1.  Откройте Azure Machine Learning Workbench.
2.  На странице **Projects** (Проекты) щелкните знак **+** и выберите **New Project** (Создать проект).
3.  В области **Create New Project** (Создание проекта) введите информацию о новом проекте.
4.  В поле поиска **Search Project Templates** (Поиск шаблонов проектов) введите Q & A Matching (Сопоставление вопросов и ответов) и выберите шаблон.
5.  Нажмите кнопку **Создать**.

## <a name="data-description"></a>Описание данных

Используемый в этом примере набор данных представляет собой дамп данных Stack Exchange, который хранится на сайте [archive.org](https://archive.org/details/stackexchange). Это анонимный дамп всего содержимого, предоставленного пользователями в [сети Stack Exchange](https://stackexchange.com/). Каждый сайт сети отформатирован в виде отдельного архива, состоящего из XML-файлов, сжатых с помощью архиватора 7-Zip и технологии сжатия BZIP2. Каждый архив сайта включает в себя сведения о записях, пользователях, голосах, комментариях, журнале записей и ссылках на записи. 

### <a name="data-source"></a>Источник данных

В этом примере используются данные [о записях (10 ГБ)](https://archive.org/download/stackexchange/stackoverflow.com-Posts.7z) и [ссылках на записи (515 МБ)](https://archive.org/download/stackexchange/stackoverflow.com-PostLinks.7z) с сайта Stack Overflow. Полную схему данных см. в файле [readme.txt](https://ia800500.us.archive.org/22/items/stackexchange/readme.txt). 

Поле `PostTypeId` в данных о записях указывает, является ли запись вопросом (`Question`) или ответом (`Answer`). Поле `PostLinkTypeId` в данных о ссылках на записи указывает, являются ли записи связанными или дублирующимися. Записи с вопросами обычно содержат несколько тегов, то есть ключевых слов, которые позволяют включить вопрос в категорию похожих и (или) дублирующихся вопросов. Некоторые теги с высокой частотой, такие как `javascript`, `java`, `c#`, `php` и т. д., встречаются в большом количестве записей с вопросами. Для нашего примера извлекается подмножество пар "вопрос — ответ" с тегом `javascript`.

Кроме того, запись с вопросом может сопоставляться с несколькими записями с ответами или с дублирующимися вопросами. Чтобы создать список вопросов и ответов на основе этих двух наборов данных, рассматриваются некоторые критерии коллекции данных. Выбираются три набора скомпилированных данных с помощью скрипта SQL, который не включен в этот пример. В результате получаются данные, соответствующие приведенному ниже описанию.

- `Original Questions (Q)`: записи с вопросами и ответами, размещенные на сайте Stack Overflow.
- `Duplications (D)`: записи с вопросами, дублирующие ранее заданные вопросы (`PostLinkTypeId = 3`), которые считаются исходными вопросами. Дубликаты считаются семантически эквивалентными исходным вопросам, если ответ на исходный вопрос является также ответом на новый (дублирующийся) вопрос.
- `Answers (A)`: каждый исходный вопрос и его дубликаты могут быть связаны с несколькими записями с ответами. Для этого примера отобраны только такие записи с вопросами, в которых автор подтвердил ответ (при фильтрации по `AcceptedAnswerId`), или исходный вопрос имеет наивысший рейтинг (при сортировке по `Score`). 

Сочетание этих трех наборов данных создает пары вопросов и ответов, где каждый ответ (A) сопоставлен с одним исходным вопросом (Q) и несколькими дублирующимися вопросами (D), как показано на следующей схеме данных.

<table><tr><td><img id ="data_diagram" src="media/scenario-qna-matching/data_diagram.png"></td></tr></table>

### <a name="data-structure"></a>Структура данных

Схема данных и ссылки для прямого скачивания этих трех наборов представлены в следующей таблице.

| Выборка | Поле | type | ОПИСАНИЕ
| ----------|------------|------------|--------
| [questions](https://bostondata.blob.core.windows.net/stackoverflow/orig-q.tsv.gz) | Идентификатор | Строка | Уникальный идентификатор вопроса (первичный ключ)
|  | AnswerId | Строка | Уникальный идентификатор ответа на вопрос
|  | Text0 | Строка | Необработанные текстовые данные, включающие заголовок и текст вопроса
|  | CreationDate | Timestamp | Метка времени, обозначающая время отправки вопроса
| [dupes](https://bostondata.blob.core.windows.net/stackoverflow/dup-q.tsv.gz) | Идентификатор | Строка | Уникальный идентификатор дубликата (первичный ключ)
|  | AnswerId | Строка | Идентификатор ответа, связанного с дубликатом
|  | Text0 | Строка | Необработанные текстовые данные, включающие заголовок и текст дубликата
|  | CreationDate | Timestamp | Метка времени, обозначающая время отправки дубликата
| [answers](https://bostondata.blob.core.windows.net/stackoverflow/ans.tsv.gz)  | Идентификатор | Строка | Уникальный идентификатор ответа (первичный ключ)
|  | text0 | Строка | Необработанные текстовые данные ответа


## <a name="scenario-structure"></a>Структура сценария

Пример сопоставления вопросов и ответов представлен тремя типами файлов. Первый тип — серия записных книжек Jupyter с пошаговым описанием всего рабочего процесса. Второй тип — набор файлов Python с пользовательскими модулями Python для изучения фраз и извлечения признаков. Эти модули Python довольно универсальны, то есть применимы не только для этого примера, но и для других вариантов использования. Третий тип — это набор файлов Python для настройки гиперпараметров и контроля производительности модели с помощью Azure Machine Learning Workbench.

Файлы в этом примере упорядочены следующим образом:

| Имя файла | type | ОПИСАНИЕ
| ----------|------------|--------
| `Image` | Папка | Папка, используемая для сохранения изображений для файла README
| `notebooks` | Папка | Папка для записных книжек Jupyter.
| `modules` | Папка | Папка для модулей Python
| `scripts` | Папка | Папка для файлов Python
| `notebooks/Part_1_Data_Preparation.ipynb` | Портативный компьютер Jupyter | Доступ к данным примера, предварительная обработка текста и подготовка учебных и тестовых наборов данных
| `notebooks/Part_2_Phrase_Learning.ipynb` | Портативный компьютер Jupyter | Изучение информативных фраз и разбиение текста на лексемы для представления наборов слов
| `notebooks/Part_3_Model_Training_and_Evaluation.ipynb` | Портативный компьютер Jupyter | Извлечение признаков, обучение моделей классификации текста и оценка их эффективности
| `modules/__init__.py` | Файл Python | Файл инициализации пакета Python.
| `modules/phrase_learning.py` | Файл Python | Модули Python, используемые для преобразования необработанных данных и изучения информативных фраз
| `modules/feature_extractor.py` | Файл Python | Модули Python, извлекающие признаки для обучения модели
| `scripts/naive_bayes.py` | Файл Python | Код Python для настройки гиперпараметров в модели наивного байесовского классификатора
| `scripts/random_forest.py` | Файл Python | Код Python для настройки гиперпараметров в модели случайного леса
| `README.md` | Файл Markdown | Файл сведений в формате Markdown

> [!NOTE]
> Серия записных книжек создана в Python 3.5.
> 

### <a name="data-ingestion-and-transformation"></a>Прием и преобразование данных

Три скомпилированных набора данных хранятся в хранилище BLOB-объектов и извлекаются из записной книжки `Part_1_Data_Preparation.ipynb`.  

Перед обучением моделей классификации текста выполняется очистка и предварительная обработка текста вопросов, чтобы исключить фрагменты кода. Для учебных материалов выполняется неконтролируемое изучение фраз для запоминания информативных последовательностей слов. Эти фразы представляются в виде единых составных слов при присвоении признаков нисходящего набора слов, которое используется в моделях классификации текста.

Подробные пошаговые описания предварительной обработки текста и изучения фраз можно найти в записных книжках `Part_1_Data_Preparation.ipynb` и `Part_2_Phrase_Learning.ipynb`соответственно.

### <a name="modeling"></a>Моделирование

Этот пример разработан для сравнения новых вопросов с существующими парами вопросов и ответов. Для этого выполняется обучение моделей классификации, при котором каждая существующая пара "вопрос — ответ" обозначается уникальным классом, а часть дублирующихся вопросов для каждой пары "вопрос — ответ" используется в качестве учебного материала. В этом примере все исходные вопросы и 75 % дублирующихся вопросов сохраняются для обучения, а 25 % самых свежих из дублирующихся вопросов используются как контрольные данные для последующей оценки.

Модель классификации использует ансамблевый метод для объединения оценок по трем базовым классификаторам, к которым относятся **наивный байесовский классификатор**, **метод опорных векторов** и **метод случайного леса**. В каждом из базовых классификаторов в качестве признаков используются метка класса `AnswerId` и представление наборов слов.

Процесс обучения модели демонстрируется в файле `Part_3_Model_Training_and_Evaluation.ipynb`.

### <a name="evaluation"></a>Оценка

Для оценки эффективности используются две разные метрики оценки. 
1. `Average Rank (AR)`: указывает среднее положение, на котором находится правильный ответ в полученном списке пар "вопрос — ответ" (из полного набора 103 классов ответов). 
2. `Top 3 Percentage`: указывает процент тестовых вопросов, для которых правильный ответ возвращается в числе трех первых в отсортированном списке. 

Эта оценка демонстрируется в файле `Part_3_Model_Training_and_Evaluation.ipynb`.


## <a name="conclusion"></a>Заключение

Этот пример демонстрирует, как создать надежную модель с применением хорошо известных методов текстового анализа, таких как изучение фраз и классификация текста. Он также подтверждает полезность применения Azure Machine Learning Workbench в процессах интерактивной разработки решений и отслеживания эффективности модели. 

Вот несколько важных выводов по этому примеру.

- Проблема сопоставления вопросов и ответов эффективно решается с помощью моделей изучения фраз и классификации текста.
- Azure Machine Learning Workbench и записная книжка Jupyter позволяют интерактивно разрабатывать модели.
- Azure Machine Learning Workbench управляет журналом выполнения и обученными моделями, записывая метрики оценки для целей сравнения. Эти признаки позволяют быстро выполнить настройку гиперпараметров и определить наиболее эффективную модель.


## <a name="references"></a>Ссылки

Тимоти Дж. Хейзен (Timothy J. Hazen), Фред Ричардсон (Fred Richardson). [_Modeling Multiword Phrases with Constrained Phrases Trees for Improved Topic Modeling of Conversational Speech_](http://people.csail.mit.edu/hazen/publications/Hazen-SLT-2012.pdf) (Моделирование фраз из нескольких слов с использованием ограниченных деревьев фраз для эффективного тематического моделирования разговорной речи). Семинар IEEE по технологиям анализа разговорной речи, 2012 г. IEEE, 2012 г.

Тимоти Дж. Хейзен (Timothy J. Hazen). [ _MCE Training Techniques for Topic Identification of Spoken Audio Documents_](http://ieeexplore.ieee.org/abstract/document/5742980/) (Методы обучения MCE для определения темы в аудиодокументах с устной речью). Материалы конференции IEEE по обработке аудио, речи и естественного языка, том 19, №8, стр. 2451–2460, ноябрь 2011 г.
