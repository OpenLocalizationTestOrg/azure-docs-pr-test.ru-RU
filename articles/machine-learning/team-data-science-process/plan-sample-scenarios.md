---
title: "Определение сценариев углубленной аналитики для Машинного обучения Azure | Документация Майкрософт"
description: "Выберите оптимальные сценарии использования процесса обработки и анализа данных группы для расширенной прогнозной аналитики."
services: machine-learning
documentationcenter: 
author: bradsev
manager: cgronlun
editor: cgronlun
ms.assetid: 53aecc1e-5089-42cf-8d44-77678653f92d
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 11/13/2017
ms.author: bradsev
ms.openlocfilehash: 3b6a92f4f4615954902124c59adca25560182de6
ms.sourcegitcommit: 659cc0ace5d3b996e7e8608cfa4991dcac3ea129
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 11/13/2017
---
# <a name="scenarios-for-advanced-analytics-in-azure-machine-learning"></a>Сценарии для расширенной аналитики в Машинном обучении Azure
В этой статье описаны различные источники примеров данных и типовые сценарии, в которых можно использовать [процесс обработки и анализа данных группы (TDSP)](overview.md). Процесс TDSP предоставляет систематический подход для совместной работы групп над созданием интеллектуальных приложений. В представленных сценариях продемонстрированы варианты рабочих процессов обработки данных на основе характеристик данных, исходных расположений и целевых репозиториев в Azure.

В последнем разделе представлено **дерево принятия решений** для выбора сценариев, соответствующих вашим данным и задачам.

> [!INCLUDE [machine-learning-free-trial](../../../includes/machine-learning-free-trial.md)]
> 
> 

В каждом из следующих разделов представлен один из сценариев. Для каждого сценария перечислены возможные последовательности операций процесса обработки и анализа или расширенного анализа данных, а также вспомогательные ресурсы Azure.

> [!NOTE]
> **Для каждого из них вам понадобится:**
> <br/>
> 
> * [создать учетную запись хранения](../../storage/common/storage-create-storage-account.md)
>   ;<br/>
> * [Создание рабочей области машинного обучения Azure](../studio/create-workspace.md)
> 
> 

## <a name="smalllocal"></a>Сценарий \#№1. Набор табличных данных небольшого и среднего размера в локальных файлах
![Локальные файлы небольшого и среднего размера][1]

#### <a name="additional-azure-resources-none"></a>Дополнительные ресурсы Azure: отсутствуют
1. Войдите в [Студию машинного обучения Azure](https://studio.azureml.net/).
2. Отправьте набор данных.
3. Создайте последовательность операций эксперимента Машинного обучения Azure, начиная с отправленных наборов данных.

## <a name="smalllocalprocess"></a>Сценарий \#№2. Набор данных небольшого и среднего размера в локальных файлах, требующий обработки
![Локальные файлы небольшого и среднего размера, требующие обработки][2]

#### <a name="additional-azure-resources-azure-virtual-machine-ipython-notebook-server"></a>Дополнительные ресурсы Azure: виртуальная машина Azure (сервер IPython Notebook)
1. Создайте виртуальную машину Azure с IPython Notebook.
2. Отправьте данные в контейнер хранилища Azure.
3. Предварительно обработайте и очистите данные в IPython Notebook из контейнера хранилища Azure.
4. Очистите данные и преобразуйте их в табличную форму.
5. Сохраните преобразованные данные в большие двоичные объекты Azure.
6. Войдите в [Студию машинного обучения Azure](https://studio.azureml.net/).
7. Считайте данные из больших двоичных объектов Azure с помощью модуля [Импорт данных][import-data].
8. Создайте последовательность операций эксперимента Машинного обучения Azure, начиная с принятых наборов данных.

## <a name="largelocal"></a>Сценарий\# №3. Большой набор данных в локальных файлах, загружаемый в большие двоичные объекты Azure
![Локальные файлы большого размера][3]

#### <a name="additional-azure-resources-azure-virtual-machine-ipython-notebook-server"></a>Дополнительные ресурсы Azure: виртуальная машина Azure (сервер IPython Notebook)
1. Создайте виртуальную машину Azure с IPython Notebook.
2. Отправьте данные в контейнер хранилища Azure.
3. Предварительно обработайте и очистите данные в IPython Notebook из больших двоичных объектов Azure.
4. Очистите данные и при необходимости преобразуйте их в табличную форму.
5. Просмотрите данные и при необходимости создайте компоненты.
6. Извлеките пример данных небольшого или среднего размера.
7. Сохраните пример данных в большие двоичные объекты Azure.
8. Войдите в [Студию машинного обучения Azure](https://studio.azureml.net/).
9. Считайте данные из больших двоичных объектов Azure с помощью модуля [Импорт данных][import-data].
10. Создайте последовательность операций эксперимента Машинного обучения Azure, начиная с принятых наборов данных.

## <a name="smalllocaltodb"></a>Сценарий \#№4. Набор данных небольшого и среднего размера в локальных файлах, загружаемый на сервер SQL Server в виртуальной машине Azure
![Локальные файлы небольшого и среднего размера для базы данных SQL в Azure][4]

#### <a name="additional-azure-resources-azure-virtual-machine-sql-server--ipython-notebook-server"></a>Дополнительные ресурсы Azure: виртуальная машина Azure (сервер SQL Server и IPython Notebook)
1. Создайте виртуальную машину Azure с SQL Server и IPython Notebook.
2. Отправьте данные в контейнер хранилища Azure.
3. Предварительно обработайте и очистите данные в контейнере хранилища Azure с помощью IPython Notebook.
4. Очистите данные и при необходимости преобразуйте их в табличную форму.
5. Сохраните данные в локальных файлах виртуальной машины (IPython Notebook запущен на виртуальной машине, и в качестве локальных дисков используются диски виртуальной машины).
6. Загрузите данные в базу данных SQL Server на виртуальной машине Azure.
   
   Вариант \# №1. Использование SQL Server Management Studio.
   
   * Войдите в виртуальную машину SQL Server.
   * Запустите среду SQL Server Management Studio.
   * Создайте базу данных и целевые таблицы.
   * Используйте один из методов массового импорта для загрузки локальных файлов виртуальной машины.
   
   Вариант \# №2. Использование IPython Notebook (не рекомендуется использовать этот вариант для средних и больших наборов данных).
   
   <!-- -->    
   * Используйте строку подключения ODBC для доступа к SQL Server на виртуальной машине.
   * Создайте базу данных и целевые таблицы.
   * Используйте один из методов массового импорта для загрузки локальных файлов виртуальной машины.
7. Просмотрите данные и при необходимости создайте компоненты. Обратите внимание, что компоненты не требуется материализовать в таблицах базы данных. Необходимо указать только запросы, требуемые для их создания.
8. При необходимости выберите размер примера данных.
9. Войдите в [Студию машинного обучения Azure](https://studio.azureml.net/).
10. Считайте данные непосредственно из SQL Server с помощью модуля [Импорт данных][import-data]. При необходимости вставьте требуемый запрос, который извлекает поля, создает признаки и примеры данных, непосредственно в запрос модуля [Импорт данных][import-data].
11. Создайте последовательность операций эксперимента Машинного обучения Azure, начиная с принятых наборов данных.

## <a name="largelocaltodb"></a>Сценарий \#№5. Большой набор данных в локальных файлах, загружаемый на сервер SQL Server в виртуальной машине Azure
![Локальные файлы большого размера для базы данных SQL в Azure][5]

#### <a name="additional-azure-resources-azure-virtual-machine-sql-server--ipython-notebook-server"></a>Дополнительные ресурсы Azure: виртуальная машина Azure (сервер SQL Server и IPython Notebook)
1. Создайте виртуальную машину Azure с SQL Server и IPython Notebook.
2. Отправьте данные в контейнер хранилища Azure.
3. Предварительно обработайте и очистите данные (необязательно).
   
   а.  Предварительно обработайте и очистите данные в IPython Notebook из Azure.
   
       blobs.
   
   b.  Очистите данные и при необходимости преобразуйте их в табличную форму.
   
   c.  Сохраните данные в локальных файлах виртуальной машины (IPython Notebook запущен на виртуальной машине, и в качестве локальных дисков используются диски виртуальной машины).
4. Загрузите данные в базу данных SQL Server на виртуальной машине Azure.
   
   а.  Войдите в виртуальную машину SQL Server.
   
   b.  Если данные еще не сохранены, скачайте файлы данных из Azure.
   
       storage container to local-VM folder.
   
   В.  Запустите среду SQL Server Management Studio.
   
   г)  Создайте базу данных и целевые таблицы.
   
   д.  Загрузите данные, используя один из методов массового импорта.
   
   Е.  Если требуется объединить таблицы, создайте индексы, чтобы ускорить этот процесс.
   
   > [!NOTE]
   > Чтобы ускорить загрузку данных большого размера, мы советуем создать секционированные таблицы и массово импортировать данные в параллельном режиме. Дополнительные сведения см. в статье [Параллельный массовый импорт данных с использованием таблиц секционирования SQL](parallel-load-sql-partitioned-tables.md).
   > 
   > 
5. Просмотрите данные и при необходимости создайте компоненты. Обратите внимание, что компоненты не требуется материализовать в таблицах базы данных. Необходимо указать только запросы, требуемые для их создания.
6. При необходимости выберите размер примера данных.
7. Войдите в [Студию машинного обучения Azure](https://studio.azureml.net/).
8. Считайте данные непосредственно из SQL Server с помощью модуля [Импорт данных][import-data]. При необходимости вставьте требуемый запрос, который извлекает поля, создает признаки и примеры данных, непосредственно в запрос модуля [Импорт данных][import-data].
9. Создайте простую последовательность операций эксперимента Машинного обучения Azure, начиная с отправленного набора данных.

## <a name="largedbtodb"></a>Сценарий\# №6. Большой набор данных в локальной базе данных SQL Server, загружаемый на сервер SQL Server в виртуальной машине Azure
![Большая локальная база данных SQL для базы данных SQL в Azure][6]

#### <a name="additional-azure-resources-azure-virtual-machine-sql-server--ipython-notebook-server"></a>Дополнительные ресурсы Azure: виртуальная машина Azure (сервер SQL Server и IPython Notebook)
1. Создайте виртуальную машину Azure с SQL Server и IPython Notebook.
2. Экспортируйте данные из SQL Server в файлы дампа, используя один из методов экспорта данных.
   
   > [!NOTE]
   > Если вы хотите перенести все данные из локальной базы данных, воспользуйтесь альтернативным (быстрым) методом, чтобы переместить всю базу данных в экземпляр SQL Server в Azure. Пропустите шаги для экспорта данных, создайте базу данных, загрузите или импортируйте данные в целевую базу данных и воспользуйтесь альтернативным методом.
   > 
   > 
3. Отправьте файлы дампа в контейнер хранилища Azure.
4. Загрузите данные в базу данных SQL Server на виртуальной машине Azure.
   
   а.  Войдите в виртуальную машину SQL Server.
   
   b.  Скачайте файлы данных из контейнера хранилища Azure в локальную папку виртуальной машины.
   
   c.  Запустите среду SQL Server Management Studio.
   
   г)  Создайте базу данных и целевые таблицы.
   
   д.  Загрузите данные, используя один из методов массового импорта.
   
   Е.  Если требуется объединить таблицы, создайте индексы, чтобы ускорить этот процесс.
   
   > [!NOTE]
   > Чтобы быстрее загружать данные большого размера, создайте секционированные таблицы и массово импортируйте данные в параллельном режиме. Дополнительные сведения см. в статье [Параллельный массовый импорт данных с использованием таблиц секционирования SQL](parallel-load-sql-partitioned-tables.md).
   > 
   > 
5. Просмотрите данные и при необходимости создайте компоненты. Обратите внимание, что компоненты не требуется материализовать в таблицах базы данных. Необходимо указать только запросы, требуемые для их создания.
6. При необходимости выберите размер примера данных.
7. Войдите в [Студию машинного обучения Azure](https://studio.azureml.net/).
8. Считайте данные непосредственно из SQL Server с помощью модуля [Импорт данных][import-data]. При необходимости вставьте требуемый запрос, который извлекает поля, создает признаки и примеры данных, непосредственно в запрос модуля [Импорт данных][import-data].
9. Создайте простую последовательность операций эксперимента Машинного обучения Azure, начиная с отправленного набора данных.

### <a name="alternate-method-to-copy-a-full-database-from-an-on-premises--sql-server-to-azure-sql-database"></a>Альтернативный метод копирования всей базы данных из локальной системы SQL Server в базу данных SQL Azure
![Отсоединение локальной базы данных и присоединение к базе данных SQL в Azure][7]

#### <a name="additional-azure-resources-azure-virtual-machine-sql-server--ipython-notebook-server"></a>Дополнительные ресурсы Azure: виртуальная машина Azure (сервер SQL Server и IPython Notebook)
Чтобы реплицировать всю базу данных SQL Server в виртуальной машине SQL Server, вам следует скопировать базу данных из одного расположения или сервера в другое (на другой) при условии, что база данных может временно работать в автономном режиме. Это можно сделать в обозревателе объектов SQL Server Management Studio или с помощью эквивалентных команд Transact-SQL.

1. Отсоедините базу данных в исходном расположении. Дополнительные сведения см. в статье [Отсоединение базы данных](https://technet.microsoft.com/library/ms191491\(v=sql.110\).aspx).
2. В окне проводника Windows или командной строки Windows скопируйте файлы отсоединенной базы данных и файлы журнала в целевое расположение на виртуальной машине SQL Server в Azure.
3. Присоедините скопированные файлы к целевому экземпляру SQL Server. Дополнительные сведения см. в статье [Присоединение базы данных](https://technet.microsoft.com/library/ms190209\(v=sql.110\).aspx).

[Перенос базы данных путем отсоединения и присоединения (язык Transact-SQL)](https://technet.microsoft.com/library/ms187858\(v=sql.110\).aspx)

## <a name="largedbtohive"></a>Сценарий \# №7. Данные большого размера в локальных файлах, загружаемые в базу данных Hive в кластерах Azure HDInsight Hadoop
![Данные большого размера в локальных файлах для базы данных Hive][9]

#### <a name="additional-azure-resources-azure-hdinsight-hadoop-cluster-and-azure-virtual-machine-ipython-notebook-server"></a>Дополнительные ресурсы Azure: кластер Azure HDInsight Hadoop и виртуальная машина Azure (сервер IPython Notebook)
1. Создайте виртуальную машину Azure с сервером IPython Notebook.
2. Создайте кластер Azure HDInsight Hadoop.
3. Предварительно обработайте и очистите данные (необязательно).
   
   а.  Предварительно обработайте и очистите данные в IPython Notebook из Azure.
   
       blobs.
   
   b.  Очистите данные и при необходимости преобразуйте их в табличную форму.
   
   c.  Сохраните данные в локальных файлах виртуальной машины (IPython Notebook запущен на виртуальной машине, и в качестве локальных дисков используются диски виртуальной машины).
4. Отправьте данные в контейнер по умолчанию для кластера Hadoop, выбранный на шаге 2.
5. Загрузите данные в базу данных Hive в кластере Azure HDInsight Hadoop.
   
   а.  Войдите на головной узел кластера Hadoop.
   
   b.  Откройте командную строку Hadoop.
   
   c.  Введите корневой каталог Hive в командной строке Hadoop с помощью команды `cd %hive_home%\bin`.
   
   г)  Выполните запросы Hive, чтобы создать базы данных и таблицы и загрузить данные из хранилища больших двоичных объектов в таблицы Hive.
   
   > [!NOTE]
   > При загрузке больших данных пользователи могут создавать таблицы Hive с разделами. Затем они могут использовать цикл `for` в командной строке Hadoop на головном узле, чтобы загрузить данные в таблицу Hive, секционированную на разделы.
   > 
   > 
6. Просмотрите данные и при необходимости создайте компоненты в командной строке Hadoop. Обратите внимание, что компоненты не требуется материализовать в таблицах базы данных. Необходимо указать только запросы, требуемые для их создания.
   
   а.  Войдите на головной узел кластера Hadoop.
   
   b.  Откройте командную строку Hadoop.
   
   c.  Введите корневой каталог Hive в командной строке Hadoop с помощью команды `cd %hive_home%\bin`.
   
   г)  Выполните запросы Hive в командной строке Hadoop на головном узле кластера Hadoop, чтобы просмотреть данные и при необходимости создать компоненты.
7. При необходимости создайте пример данных для Студии машинного обучения Azure.
8. Войдите в [Студию машинного обучения Azure](https://studio.azureml.net/).
9. Считайте данные непосредственно из `Hive Queries` с помощью модуля [Импорт данных][import-data]. При необходимости вставьте требуемый запрос, который извлекает поля, создает признаки и примеры данных, непосредственно в запрос модуля [Импорт данных][import-data].
10. Создайте простую последовательность операций эксперимента Машинного обучения Azure, начиная с отправленного набора данных.

## <a name="decisiontree"></a>Дерево принятия решений для выбора сценариев
- - -
На следующей схеме показаны сценарии, описанные выше, и варианты, выбранные в каждом сценарии ADAPT. Обратите внимание на то, что обработка и просмотр данных, а также разработка компонентов и создание примеров могут применяться в одном или нескольких методах или средах (в исходной, промежуточной или целевой среде) и при необходимости выполняться по несколько раз. Схема иллюстрирует только некоторые из возможных последовательностей операций и не является исчерпывающей.

![Примеры сценариев с пошаговыми действиями процесса обработки и анализа данных][8]

### <a name="advanced-analytics-in-action-examples"></a>Практические примеры расширенного анализа
Полные пошаговые примеры моделей машинного обучения Azure, в которых демонстрируется применение ADAPT на базе общедоступных наборов данных, см. в перечисленных ниже статьях.

* [Процесс обработки и анализа данных группы на практике: использование SQL Server](sql-walkthrough.md).
* [Процесс обработки и анализа данных группы на практике: использование кластеров HDInsight Hadoop](hive-walkthrough.md).

[1]: ./media/plan-sample-scenarios/dsp-plan-small-in-aml.png
[2]: ./media/plan-sample-scenarios/dsp-plan-local-with-processing.png
[3]: ./media/plan-sample-scenarios/dsp-plan-local-large.png
[4]: ./media/plan-sample-scenarios/dsp-plan-local-to-db.png
[5]: ./media/plan-sample-scenarios/dsp-plan-large-to-db.png
[6]: ./media/plan-sample-scenarios/dsp-plan-db-to-db.png
[7]: ./media/plan-sample-scenarios/dsp-plan-attach-db.png
[8]: ./media/plan-sample-scenarios/dsp-plan-sample-scenarios.png
[9]: ./media/plan-sample-scenarios/dsp-plan-local-to-hive.png


<!-- Module References -->
[import-data]: https://msdn.microsoft.com/library/azure/4e1b0fe6-aded-4b3f-a36f-39b8862b9004/
