---
title: "Что представляет собой процесс обработки и анализа данных группы (TDSP)?  | Документация Майкрософт"
description: "Процесс обработки и анализа данных группы — это системный метод для создания интеллектуальных приложений, которые используют расширенную аналитику."
services: machine-learning
documentationcenter: 
author: bradsev
manager: jhubbard
editor: cgronlun
ms.assetid: a098aa2e-fd79-4543-8e15-9aae9d8b3ee6
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 01/18/2017
ms.author: bradsev
ROBOTS: NOINDEX
redirect_url: data-science-process-overview
redirect_document_id: TRUE
ms.openlocfilehash: d1ec602b2a69b0bd01bf7b43ef5fed9b8c2781c7
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 07/11/2017
---
# <a name="what-is-the-team-data-science-process-tdsp"></a>Что такое процесс обработки и анализа данных группы (TDSP)?
[Процесс обработки и анализа данных группы (TDSP)](data-science-process-overview.md) — это системный подход к созданию интеллектуальных приложений, который позволяет группам специалистов, работающих с данными, эффективно взаимодействовать друг с другом в течение всего жизненного цикла действий, необходимых для превращения этих приложений в готовые продукты. В процессе TDSP обозначена последовательность шагов, которые представляют собой **рекомендации** о том, как определить проблему, настроить необходимые инструменты и среду, проанализировать соответствующие данные, создать и оценить прогнозные модели, а затем развернуть эти модели в корпоративных приложениях. 

Ниже приведены шаги **процесса обработки и анализа данных группы**.  

![Рабочий процесс CAP](./media/machine-learning-data-science-the-cortana-analytics-process/CAP-workflow.png)

Это **циклический**процесс: понимание новых или существующих улучшений модели развивается и требует исправления действий, ранее выполненных в этой последовательности. Существующие организационные разработки и процессы планирования проектов можно **легко адаптировать** для внедрения в процесс TDSP. 

Действия данной процедуры пояснены схемами в [схеме обучения TDSP](https://azure.microsoft.com/documentation/learning-paths/cortana-analytics-process/) и описаны ниже.  

## <a name="preparation-steps"></a>Этапы подготовки
## <a name="p1-plan-the-analytics-project"></a>P1. Планирование проекта аналитики
Проект аналитики начинается с определения бизнес-целей и проблем. Они обозначаются в соответствии с **бизнес-требованиями**. Основная цель этого этапа — определить основные бизнес-переменные (например, прогноз продаж или вероятность ложного заказа), которые анализ должен спрогнозировать для выполнения этих требований. Дополнительное планирование имеет большое значение для развития понимания **источников данных**, необходимого для достижения целей проекта с точки зрения аналитики. Например, редко встречаются системы, в которых для решения проблемы и достижения целей проекта собираются и регистрируются дополнительные типы данных. Рекомендации см. в статьях [Как определить сценарии и план для расширенной аналитической обработки данных](machine-learning-data-science-plan-your-environment.md) и [Сценарии для расширенной аналитики в Машинном обучении Azure](machine-learning-data-science-plan-sample-scenarios.md).  

## <a name="p2-setup-analytics-environment"></a>P2. Настройка среды аналитики
Среда аналитики для процесса обработки и анализа данных группы состоит из нескольких компонентов: 

* **рабочие области данных** , которые являются местом промежуточного хранения данных для анализа и моделирования; 
* **инфраструктура обработки** для предварительной обработки, просмотра и моделирования данных;
* **инфраструктура среды выполнения** для ввода в эксплуатацию аналитических моделей и запуска интеллектуальных клиентских приложений, использующих модели.  

Инфраструктура аналитики, которую нужно настроить, часто является частью среды, изолированной от основных операционных систем. Однако обычно она использует данные из нескольких систем предприятия, а также данные из внешних источников. Инфраструктура аналитики может быть сугубо облачной, локальной или гибридной. Различные возможные варианты описаны в статье [Настройка сред обработки и анализа данных для использования в процессе обработки и анализа данных группы](machine-learning-data-science-environment-setup.md).

## <a name="analytics-steps"></a>Этапы аналитики.
## <a name="1-ingest-data-into-the-analytical-environment"></a>1. Прием данных в среду аналитики
Первый шаг — передать соответствующие данные из различных источников, которые находятся в рамках предприятия или за его пределами, в среду аналитики, предназначенную для обработки данных. **Формат** данных в источнике может отличаться от формата, необходимого для целевой среды. Поэтому могут также потребоваться некоторые преобразования данных с помощью инструментов приема. Параметры см. в статье [Загрузка данных в среды хранения для аналитики](machine-learning-data-science-ingest-data.md).

Помимо начального приема данных, многие интеллектуальные приложения должны регулярно обновлять данные в рамках непрерывного процесса обучения. Для этого можно настроить **конвейер данных** или рабочий процесс. Этот циклическая часть процесса, включающего повторные сборку и оценку аналитических моделей, используемых интеллектуальным приложением, которое развертывает решение. Например, см. статью [Перенос данных из локального SQL Server в SQL Azure с фабрикой данных Azure](machine-learning-data-science-move-sql-azure-adf.md).

## <a name="2-explore-and-pre-process-data"></a>2. Исследование и предварительная обработка данных
Следующий шаг заключается в достижении более глубокого понимания данных. Для этого исследуются их **сводная статистика** и связи, а также используются техники **визуализации**. На этом этапе также решаются проблемы целостности и **качества данных**, например отсутствующие значения, несоответствия типов данных и связи несогласованных данных. Прежде чем данные будут использоваться для аналитики и моделирования, необработанные данные очищают путем преобразований на этапе предварительной обработки. Описание см. в статье [Задачи по подготовке данных для расширенного машинного обучения](machine-learning-data-science-prepare-data.md).

## <a name="3-develop-features"></a>3. Разработка функций
Специалисты по обработке и анализу данных совместно с узкими специалистами должны определить функции, которые отражают основные свойства набора данных и которые лучше всего использовать для прогнозирования ключевых бизнес-переменных, определенных во время планирования. Эти новые функции могут быть производными от существующих данных, или для них может потребоваться сбор дополнительных данных. Этот процесс называется **проектированием функций** и является одним из ключевых этапов построения эффективной системы прогнозной аналитики. На этом этапе требуется творческое сочетание опыта и информации, полученной на этапе исследования данных. Разобраться в этом вам поможет статья [Реконструирование характеристик в процессе аналитики Кортаны](machine-learning-data-science-create-features.md).

## <a name="4-create-predictive-models"></a>4. Создание моделей прогнозирования
Используя очищенные и распределенные по функциям данные, специалисты по обработке и анализу данных строят аналитические модели для прогнозирования ключевых переменных, определенных бизнес-требованиями на этапе планирования. Системы машинного обучения поддерживают несколько **алгоритмов моделирования**, применимых для разнообразных ситуаций. Указания см. в статье [Выбор алгоритмов машинного обучения Microsoft Azure](machine-learning-algorithm-choice.md).

Специалисты по обработке и анализу данных должны выбрать наиболее подходящую модель для задачи прогнозирования. Часто для получения наилучших результатов необходимо объединить результаты нескольких моделей. Как правило, входные данные для моделирования произвольно делятся на три части:

* набор данных для обучения; 
* набор данных для проверки; 
* набор данных для тестирования. 

Модели создаются с помощью **набора данных для обучения**. Оптимальное сочетание моделей (с настроенными параметрами) определяется путем запуска моделей и измерения ошибок в прогнозировании для **набора данных для проверки**. Наконец, **набор данных для тестирования** используется для оценки производительности выбранной модели на независимых данных, которые не использовались для обучения или проверки модели.  Процедуры см. в статье [Оценка эффективности модели в Машинном обучении Microsoft Azure](machine-learning-evaluate-model-performance.md).

## <a name="5-deploy-and-consume-models"></a>5. Развертывание и использование моделей
Создав эффективно работающие модели, можно **ввести их в эксплуатацию** для использования с другими приложениями. В зависимости от бизнес-требований прогнозы выполняются в режиме **реального времени** или в **пакетном** режиме. Модель готова к вводу в эксплуатацию, если она оснащена **открытым API-интерфейсом**, с которым без проблем могут взаимодействовать самые разные приложения, включая веб-сайты, электронные таблицы, панели мониторинга, бизнес-приложения и серверные приложения. См. статью [Развертывание веб-службы машинного обучения Azure](machine-learning-publish-a-machine-learning-web-service.md).

## <a name="summary-and-next-steps"></a>Сводка и дальнейшие действия
[Процесс обработки и анализа данных группы](https://azure.microsoft.com/documentation/learning-paths/cortana-analytics-process/) моделируется как последовательность циклических этапов, которая **содержит руководство** по выполнению задач, необходимых для использования расширенной аналитики для построения интеллектуальных приложений. На каждом этапе также предоставляется информация об использовании различных технологий Майкрософт для выполнения описанных задач. 

Хотя процесс TDSP не предписывает конкретные типы **документации** , рекомендуется документировать результаты исследований, моделирования и оценки данных и сохранять соответствующий код, чтобы при необходимости можно было повторить анализ. Это также позволит повторно использовать результаты аналитики во время работы с другими приложениями, использующими похожие данные и задачи прогнозирования.

Также предоставляются полные пошаговые руководства, которые демонстрируют все этапы процесса для **конкретных сценариев** . Например, ознакомьтесь со следующими статьями:

* [Процесс обработки и анализа данных группы на практике: использование SQL Server](machine-learning-data-science-process-sql-walkthrough.md)
* [Процесс обработки и анализа данных группы на практике: использование кластеров HDInsight Hadoop](machine-learning-data-science-process-hive-walkthrough.md)
* [Общие сведения об обработке и анализе данных с помощью платформы Spark в Azure HDInsight.](machine-learning-data-science-spark-overview.md)
* [Полное пошаговое руководство по масштабируемому анализу данных в озере данных Azure](machine-learning-data-science-process-data-lake-walkthrough.md)

