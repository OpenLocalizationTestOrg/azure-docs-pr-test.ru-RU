---
title: "Руководство по языку спецификаций нейронных сетей Net# | Документация Майкрософт"
description: "Синтаксис языка Net # нейронной сети спецификацию языка, а также примеры того, как создать модель настраиваемой нейронной сети в Microsoft Azure ML, используя язык Net #"
services: machine-learning
documentationcenter: 
author: jeannt
manager: jhubbard
editor: cgronlun
ms.assetid: cfd1454b-47df-4745-b064-ce5f9b3be303
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 03/31/2017
ms.author: jeannt
ms.openlocfilehash: 965c60ffde55041cc3864d06d81f5590c7ea1c11
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 07/11/2017
---
# <a name="guide-to-net-neural-network-specification-language-for-azure-machine-learning"></a><span data-ttu-id="4cac8-103">Руководство по языку спецификаций нейронных сетей Net# для машинного обучения Azure</span><span class="sxs-lookup"><span data-stu-id="4cac8-103">Guide to Net# neural network specification language for Azure Machine Learning</span></span>
## <a name="overview"></a><span data-ttu-id="4cac8-104">Обзор</span><span class="sxs-lookup"><span data-stu-id="4cac8-104">Overview</span></span>
<span data-ttu-id="4cac8-105">Net# — это язык, разработанный корпорацией Майкрософт, который используется при определении архитектур нейронных сетей.</span><span class="sxs-lookup"><span data-stu-id="4cac8-105">Net# is a language developed by Microsoft that is used to define neural network architectures.</span></span> <span data-ttu-id="4cac8-106">Его можно использовать в модулях нейронной сети Машинного обучения Microsoft Azure.</span><span class="sxs-lookup"><span data-stu-id="4cac8-106">You can use Net# in neural network modules in Microsoft Azure Machine Learning.</span></span>

<!-- This function doesn't currentlyappear in the MicrosoftML documentation. If it is added in a future update, we can uncomment this text.

, or in the `rxNeuralNetwork()` function in [MicrosoftML](https://msdn.microsoft.com/microsoft-r/microsoftml/microsoftml). 

-->

<span data-ttu-id="4cac8-107">В этой статье вы узнаете основные понятия, необходимые для разработки настраиваемой нейронной сети:</span><span class="sxs-lookup"><span data-stu-id="4cac8-107">In this article, you will learn basic concepts needed to develop a custom neural network:</span></span> 

* <span data-ttu-id="4cac8-108">Требования к нейронным сетям и определения основных компонентов</span><span class="sxs-lookup"><span data-stu-id="4cac8-108">Neural network requirements and how to define the primary components</span></span>
* <span data-ttu-id="4cac8-109">Синтаксис и ключевые слова языка спецификаций Net#</span><span class="sxs-lookup"><span data-stu-id="4cac8-109">The syntax and keywords of the Net# specification language</span></span>
* <span data-ttu-id="4cac8-110">Примеры пользовательских нейронных сетей, созданных с помощью Net #</span><span class="sxs-lookup"><span data-stu-id="4cac8-110">Examples of custom neural networks created using Net#</span></span> 

[!INCLUDE [machine-learning-free-trial](../../includes/machine-learning-free-trial.md)]

## <a name="neural-network-basics"></a><span data-ttu-id="4cac8-111">Основы нейронных сетей</span><span class="sxs-lookup"><span data-stu-id="4cac8-111">Neural network basics</span></span>
<span data-ttu-id="4cac8-112">Структура нейронной сети состоит из ***узлов***, организованных в ***слои***, и взвешенных ***подключений*** (или ***переходов***) между узлами.</span><span class="sxs-lookup"><span data-stu-id="4cac8-112">A neural network structure consists of ***nodes*** that are organized in ***layers***, and weighted ***connections*** (or ***edges***) between the nodes.</span></span> <span data-ttu-id="4cac8-113">Подключения при этом являются направленными, и для каждого из них определено по узлу ***источника*** и ***назначения***.</span><span class="sxs-lookup"><span data-stu-id="4cac8-113">The connections are directional, and each connection has a ***source*** node and a ***destination*** node.</span></span>  

<span data-ttu-id="4cac8-114">Каждый ***обучаемый слой*** (скрытый или выходной) включает один или несколько ***пакетов подключений***.</span><span class="sxs-lookup"><span data-stu-id="4cac8-114">Each ***trainable layer*** (a hidden or an output layer) has one or more ***connection bundles***.</span></span> <span data-ttu-id="4cac8-115">Пакет подключений состоит из слоя источника и спецификации подключений из этого слоя источника.</span><span class="sxs-lookup"><span data-stu-id="4cac8-115">A connection bundle consists of a source layer and a specification of the connections from that source layer.</span></span> <span data-ttu-id="4cac8-116">Все подключения в любом пакете совместно используют одни и те же ***слой источника*** и ***слой назначения***.</span><span class="sxs-lookup"><span data-stu-id="4cac8-116">All the connections in a given bundle share the same ***source layer*** and the same ***destination layer***.</span></span> <span data-ttu-id="4cac8-117">В Net# считается, что пакет подключений относится к слою назначения пакета.</span><span class="sxs-lookup"><span data-stu-id="4cac8-117">In Net#, a connection bundle is considered as belonging to the bundle's destination layer.</span></span>  

<span data-ttu-id="4cac8-118">Net# поддерживает различные виды пакетов подключений, которые позволяют настраивать способ сопоставления входов со скрытыми слоями и выходами.</span><span class="sxs-lookup"><span data-stu-id="4cac8-118">Net# supports various kinds of connection bundles, which lets you customize the way inputs are mapped to hidden layers and mapped to the outputs.</span></span>   

<span data-ttu-id="4cac8-119">Пакет по умолчанию или стандартный пакет называется **полным**. В таком пакете каждый узел в слое источника подключается к каждому узлу в слое назначения.</span><span class="sxs-lookup"><span data-stu-id="4cac8-119">The default or standard bundle is a **full bundle**, in which each node in the source layer is connected to every node in the destination layer.</span></span>  

<span data-ttu-id="4cac8-120">В дополнение к этому, Net# поддерживает следующие четыре типа дополнительных пакетов подключения:</span><span class="sxs-lookup"><span data-stu-id="4cac8-120">Additionally, Net# supports the following four kinds of advanced connection bundles:</span></span>  

* <span data-ttu-id="4cac8-121">**Фильтрованные пакеты**.</span><span class="sxs-lookup"><span data-stu-id="4cac8-121">**Filtered bundles**.</span></span> <span data-ttu-id="4cac8-122">Пользователь может задавать предикат с использованием мест назначения узла слоя источника и узла слоя назначения.</span><span class="sxs-lookup"><span data-stu-id="4cac8-122">The user can define a predicate by using the locations of the source layer node and the destination layer node.</span></span> <span data-ttu-id="4cac8-123">Узлы подключаются, если предикат имеет значение True.</span><span class="sxs-lookup"><span data-stu-id="4cac8-123">Nodes are connected whenever the predicate is True.</span></span>
* <span data-ttu-id="4cac8-124">**Сверточные пакеты**.</span><span class="sxs-lookup"><span data-stu-id="4cac8-124">**Convolutional bundles**.</span></span> <span data-ttu-id="4cac8-125">Пользователь может задавать небольшие окрестности узлов в слое источника.</span><span class="sxs-lookup"><span data-stu-id="4cac8-125">The user can define small neighborhoods of nodes in the source layer.</span></span> <span data-ttu-id="4cac8-126">Каждый узел в слое назначения подключается к одной окрестности узлов в слое источника.</span><span class="sxs-lookup"><span data-stu-id="4cac8-126">Each node in the destination layer is connected to one neighborhood of nodes in the source layer.</span></span>
* <span data-ttu-id="4cac8-127">**Группирующие пакеты** и **пакеты нормализации ответов**.</span><span class="sxs-lookup"><span data-stu-id="4cac8-127">**Pooling bundles** and **Response normalization bundles**.</span></span> <span data-ttu-id="4cac8-128">Эти пакеты аналогичны сверточным пакетам в том смысле, что пользователь определяет небольшие окрестности узлов в слое источника.</span><span class="sxs-lookup"><span data-stu-id="4cac8-128">These are similar to convolutional bundles in that the user defines small neighborhoods of nodes in the source layer.</span></span> <span data-ttu-id="4cac8-129">Различие заключается в том, что в таких пакетах не поддерживается обучение по весам переходов.</span><span class="sxs-lookup"><span data-stu-id="4cac8-129">The difference is that the weights of the edges in these bundles are not trainable.</span></span> <span data-ttu-id="4cac8-130">Вместо этого для определения значения узла назначения к узлу источника применяется предопределенная функция.</span><span class="sxs-lookup"><span data-stu-id="4cac8-130">Instead, a predefined function is applied to the source node values to determine the destination node value.</span></span>  

<span data-ttu-id="4cac8-131">Использование Net# для определения структуры нейронной сети позволяет задавать такие сложные структуры, как глубокие нейронные сети или свертки произвольных размеров для улучшения обучения на основе данных — изображений, аудио и видео.</span><span class="sxs-lookup"><span data-stu-id="4cac8-131">Using Net# to define the structure of a neural network makes it possible to define complex structures such as deep neural networks or convolutions of arbitrary dimensions, which are known to improve learning on data such as image, audio, or video.</span></span>  

## <a name="supported-customizations"></a><span data-ttu-id="4cac8-132">Поддерживаемые настройки</span><span class="sxs-lookup"><span data-stu-id="4cac8-132">Supported customizations</span></span>
<span data-ttu-id="4cac8-133">Архитектура моделей нейронных сетей, создаваемых в Машинном обучении Azure, может широко настраиваться с помощью Net#.</span><span class="sxs-lookup"><span data-stu-id="4cac8-133">The architecture of neural network models that you create in Azure Machine Learning can be extensively customized by using Net#.</span></span> <span data-ttu-id="4cac8-134">Вы можете:</span><span class="sxs-lookup"><span data-stu-id="4cac8-134">You can:</span></span>  

* <span data-ttu-id="4cac8-135">Создавать скрытые слои и управлять количеством узлов в каждом слое.</span><span class="sxs-lookup"><span data-stu-id="4cac8-135">Create hidden layers and control the number of nodes in each layer.</span></span>
* <span data-ttu-id="4cac8-136">Задавать способ подключения слоев друг к другу.</span><span class="sxs-lookup"><span data-stu-id="4cac8-136">Specify how layers are to be connected to each other.</span></span>
* <span data-ttu-id="4cac8-137">Определять специальные структуры подключения, такие как свертки и пакеты с распределением весов.</span><span class="sxs-lookup"><span data-stu-id="4cac8-137">Define special connectivity structures, such as convolutions and weight sharing bundles.</span></span>
* <span data-ttu-id="4cac8-138">Задавать различные функции активации.</span><span class="sxs-lookup"><span data-stu-id="4cac8-138">Specify different activation functions.</span></span>  

<span data-ttu-id="4cac8-139">Дополнительные сведения о синтаксисе языка спецификаций см. в разделе [Спецификация структуры](#Structure-specifications).</span><span class="sxs-lookup"><span data-stu-id="4cac8-139">For details of the specification language syntax, see [Structure Specification](#Structure-specifications).</span></span>  

<span data-ttu-id="4cac8-140">Примеры определения нейронных сетей для некоторых общих задач машинного обучения (от простого к сложному) см. в разделе [Примеры](#Examples-of-Net#-usage).</span><span class="sxs-lookup"><span data-stu-id="4cac8-140">For examples of defining neural networks for some common machine learning tasks, from simplex to complex, see [Examples](#Examples-of-Net#-usage).</span></span>  

## <a name="general-requirements"></a><span data-ttu-id="4cac8-141">Общие требования</span><span class="sxs-lookup"><span data-stu-id="4cac8-141">General requirements</span></span>
* <span data-ttu-id="4cac8-142">Должен быть точно один выходной слой, как минимум один входной слой, а также ноль или более скрытых слоев.</span><span class="sxs-lookup"><span data-stu-id="4cac8-142">There must be exactly one output layer, at least one input layer, and zero or more hidden layers.</span></span> 
* <span data-ttu-id="4cac8-143">Каждый слой имеет фиксированное количество узлов, концептуально организованных в прямоугольную матрицу произвольных размеров.</span><span class="sxs-lookup"><span data-stu-id="4cac8-143">Each layer has a fixed number of nodes, conceptually arranged in a rectangular array of arbitrary dimensions.</span></span> 
* <span data-ttu-id="4cac8-144">Входные слои не имеют связанных обученных параметров и представляют собой точку, в которой данные экземпляра входят в сеть.</span><span class="sxs-lookup"><span data-stu-id="4cac8-144">Input layers have no associated trained parameters and represent the point where instance data enters the network.</span></span> 
* <span data-ttu-id="4cac8-145">С обучаемыми слоями (скрытыми и выходными) связаны обученные параметры, известные как веса и смещения.</span><span class="sxs-lookup"><span data-stu-id="4cac8-145">Trainable layers (the hidden and output layers) have associated trained parameters, known as weights and biases.</span></span> 
* <span data-ttu-id="4cac8-146">Узлы источника и назначения должны находиться в отдельных слоях.</span><span class="sxs-lookup"><span data-stu-id="4cac8-146">The source and destination nodes must be in separate layers.</span></span> 
* <span data-ttu-id="4cac8-147">Подключения должны быть ациклическими. Другими словами, не должно быть цепочки подключений, ведущей назад к исходному узлу источника.</span><span class="sxs-lookup"><span data-stu-id="4cac8-147">Connections must be acyclic; in other words, there cannot be a chain of connections leading back to the initial source node.</span></span>
* <span data-ttu-id="4cac8-148">Выходной слой не должен быть слоем источника пакета подключений.</span><span class="sxs-lookup"><span data-stu-id="4cac8-148">The output layer cannot be a source layer of a connection bundle.</span></span>  

## <a name="structure-specifications"></a><span data-ttu-id="4cac8-149">Спецификация структуры</span><span class="sxs-lookup"><span data-stu-id="4cac8-149">Structure specifications</span></span>
<span data-ttu-id="4cac8-150">Спецификация структуры нейронной сети состоит из трех разделов: **объявления констант**, **объявления слоев**, **объявления подключений**,</span><span class="sxs-lookup"><span data-stu-id="4cac8-150">A neural network structure specification is composed of three sections: the **constant declaration**, the **layer declaration**, the **connection declaration**.</span></span> <span data-ttu-id="4cac8-151">а также дополнительного раздела **объявления общего доступа**.</span><span class="sxs-lookup"><span data-stu-id="4cac8-151">There is also an optional **share declaration** section.</span></span> <span data-ttu-id="4cac8-152">Указанные разделы могут задаваться в любом порядке.</span><span class="sxs-lookup"><span data-stu-id="4cac8-152">The sections can be specified in any order.</span></span>  

## <a name="constant-declaration"></a><span data-ttu-id="4cac8-153">Объявление констант</span><span class="sxs-lookup"><span data-stu-id="4cac8-153">Constant declaration</span></span>
<span data-ttu-id="4cac8-154">Объявление констант является необязательным.</span><span class="sxs-lookup"><span data-stu-id="4cac8-154">A constant declaration is optional.</span></span> <span data-ttu-id="4cac8-155">Этот раздел предоставляет средство, позволяющее задать значения, используемые в определении нейронной сети.</span><span class="sxs-lookup"><span data-stu-id="4cac8-155">It provides a means to define values used elsewhere in the neural network definition.</span></span> <span data-ttu-id="4cac8-156">Оператор объявления состоит из идентификатора, за которым следует знак равенства и выражение значения.</span><span class="sxs-lookup"><span data-stu-id="4cac8-156">The declaration statement consists of an identifier followed by an equal sign and a value expression.</span></span>   

<span data-ttu-id="4cac8-157">Например, следующий оператор задает константу **х**:</span><span class="sxs-lookup"><span data-stu-id="4cac8-157">For example, the following statement defines a constant **x**:</span></span>  

    Const X = 28;  

<span data-ttu-id="4cac8-158">Для одновременного определения двух или более констант заключите имена и значения идентификаторов в кавычки и разделите их точками с запятой.</span><span class="sxs-lookup"><span data-stu-id="4cac8-158">To define two or more constants simultaneously, enclose the identifier names and values in braces, and separate them by using semicolons.</span></span> <span data-ttu-id="4cac8-159">Например:</span><span class="sxs-lookup"><span data-stu-id="4cac8-159">For example:</span></span>  

    Const { X = 28; Y = 4; }  

<span data-ttu-id="4cac8-160">Правая сторона каждого выражения присваивания может быть целым числом, вещественным числом, логическим значением (true/false (истина/ ложь)) или математическим выражением.</span><span class="sxs-lookup"><span data-stu-id="4cac8-160">The right-hand side of each assignment expression can be an integer, a real number, a Boolean value (True or False), or a mathematical expression.</span></span> <span data-ttu-id="4cac8-161">Например:</span><span class="sxs-lookup"><span data-stu-id="4cac8-161">For example:</span></span>  

    Const { X = 17 * 2; Y = true; }  

## <a name="layer-declaration"></a><span data-ttu-id="4cac8-162">Объявление слоев</span><span class="sxs-lookup"><span data-stu-id="4cac8-162">Layer declaration</span></span>
<span data-ttu-id="4cac8-163">Слои нужно обязательно объявить.</span><span class="sxs-lookup"><span data-stu-id="4cac8-163">The layer declaration is required.</span></span> <span data-ttu-id="4cac8-164">При этом определяется размер и источник слоя, в том числе его пакеты подключений и атрибуты.</span><span class="sxs-lookup"><span data-stu-id="4cac8-164">It defines the size and source of the layer, including its connection bundles and attributes.</span></span> <span data-ttu-id="4cac8-165">Определение начинается с имени слоя (входной, скрытый или выходной), за которым следует размер слоя (набор целых положительных чисел).</span><span class="sxs-lookup"><span data-stu-id="4cac8-165">The declaration statement starts with the name of the layer (input, hidden, or output), followed by the dimensions of the layer (a tuple of positive integers).</span></span> <span data-ttu-id="4cac8-166">Например:</span><span class="sxs-lookup"><span data-stu-id="4cac8-166">For example:</span></span>  

    input Data auto;
    hidden Hidden[5,20] from Data all;
    output Result[2] from Hidden all;  

* <span data-ttu-id="4cac8-167">Произведение измерений представляет собой количество узлов слоя.</span><span class="sxs-lookup"><span data-stu-id="4cac8-167">The product of the dimensions is the number of nodes in the layer.</span></span> <span data-ttu-id="4cac8-168">В нашем примере указано два измерения [5,20]. Это означает, что в слое есть 100 узлов.</span><span class="sxs-lookup"><span data-stu-id="4cac8-168">In this example, there are two dimensions [5,20], which means there are  100 nodes in the layer.</span></span>
* <span data-ttu-id="4cac8-169">Слои можно объявлять в любом порядке, с одним исключением: если определяется более одного входного слоя, порядок, в котором они объявляются, должен соответствовать порядку признаков во входных данных.</span><span class="sxs-lookup"><span data-stu-id="4cac8-169">The layers can be declared in any order, with one exception: If more than one input layer is defined, the order in which they are declared must match the order of features in the input data.</span></span>  

<span data-ttu-id="4cac8-170">Чтобы задать автоматическое определение числа узлов в слое, используйте ключевое слово **auto**.</span><span class="sxs-lookup"><span data-stu-id="4cac8-170">To specify that the number of nodes in a layer be determined automatically, use the **auto** keyword.</span></span> <span data-ttu-id="4cac8-171">Ключевое слово **auto** выполняет разные действия в зависимости от слоя.</span><span class="sxs-lookup"><span data-stu-id="4cac8-171">The **auto** keyword has different effects, depending on the layer:</span></span>  

* <span data-ttu-id="4cac8-172">При объявлении входного слоя количество узлов представляет собой количество функций во входных данных.</span><span class="sxs-lookup"><span data-stu-id="4cac8-172">In an input layer declaration, the number of nodes is the number of features in the input data.</span></span>
* <span data-ttu-id="4cac8-173">При объявлении скрытого слоя число узлов определяется значением параметра **Количество скрытых узлов**.</span><span class="sxs-lookup"><span data-stu-id="4cac8-173">In a hidden layer declaration, the number of nodes is the number that is specified by the parameter value for **Number of hidden nodes**.</span></span> 
* <span data-ttu-id="4cac8-174">При объявлении выходного слоя количество узлов равняется 2 для двухклассной классификации, 1 — для регрессии и равно количеству выходных узлов для многоклассовой классификации.</span><span class="sxs-lookup"><span data-stu-id="4cac8-174">In an output layer declaration, the number of nodes is 2 for two-class classification, 1 for regression, and equal to the number of output nodes for multiclass classification.</span></span>   

<span data-ttu-id="4cac8-175">Например, следующее определение сети позволяет автоматически определять размер всех слоев:</span><span class="sxs-lookup"><span data-stu-id="4cac8-175">For example, the following network definition allows the size of all layers to be automatically determined:</span></span>  

    input Data auto;
    hidden Hidden auto from Data all;
    output Result auto from Hidden all;  


<span data-ttu-id="4cac8-176">Определение слоя для обучаемого слоя (скрытого или выходного) может содержать выходную функцию (также называемую функцией активации). По умолчанию для моделей классификации используется функция **sigmoid**, а для моделей регрессии — функция **linear**.</span><span class="sxs-lookup"><span data-stu-id="4cac8-176">A layer declaration for a trainable layer (the hidden or output layers) can optionally include the output function (also called an activation function), which defaults to **sigmoid** for classification models, and **linear** for regression models.</span></span> <span data-ttu-id="4cac8-177">(Даже если используется значение по умолчанию, при желании можно указать функцию активации явно для ясности.)</span><span class="sxs-lookup"><span data-stu-id="4cac8-177">(Even if you use the default, you can explicitly state the activation function, if desired for clarity.)</span></span>

<span data-ttu-id="4cac8-178">Поддерживаются следующие выходные функции:</span><span class="sxs-lookup"><span data-stu-id="4cac8-178">The following output functions are supported:</span></span>  

* <span data-ttu-id="4cac8-179">sigmoid</span><span class="sxs-lookup"><span data-stu-id="4cac8-179">sigmoid</span></span>
* <span data-ttu-id="4cac8-180">linear</span><span class="sxs-lookup"><span data-stu-id="4cac8-180">linear</span></span>
* <span data-ttu-id="4cac8-181">softmax</span><span class="sxs-lookup"><span data-stu-id="4cac8-181">softmax</span></span>
* <span data-ttu-id="4cac8-182">rlinear</span><span class="sxs-lookup"><span data-stu-id="4cac8-182">rlinear</span></span>
* <span data-ttu-id="4cac8-183">square</span><span class="sxs-lookup"><span data-stu-id="4cac8-183">square</span></span>
* <span data-ttu-id="4cac8-184">sqrt</span><span class="sxs-lookup"><span data-stu-id="4cac8-184">sqrt</span></span>
* <span data-ttu-id="4cac8-185">srlinear</span><span class="sxs-lookup"><span data-stu-id="4cac8-185">srlinear</span></span>
* <span data-ttu-id="4cac8-186">abs</span><span class="sxs-lookup"><span data-stu-id="4cac8-186">abs</span></span>
* <span data-ttu-id="4cac8-187">tanh</span><span class="sxs-lookup"><span data-stu-id="4cac8-187">tanh</span></span> 
* <span data-ttu-id="4cac8-188">brlinear</span><span class="sxs-lookup"><span data-stu-id="4cac8-188">brlinear</span></span>  

<span data-ttu-id="4cac8-189">Например, в следующем объявлении используется функция **softmax**:</span><span class="sxs-lookup"><span data-stu-id="4cac8-189">For example, the following declaration uses the **softmax** function:</span></span>  

    output Result [100] softmax from Hidden all;  

## <a name="connection-declaration"></a><span data-ttu-id="4cac8-190">Объявление подключений</span><span class="sxs-lookup"><span data-stu-id="4cac8-190">Connection declaration</span></span>
<span data-ttu-id="4cac8-191">Сразу после определения обучаемого слоя необходимо объявить подключения среди слоев, которые были определены.</span><span class="sxs-lookup"><span data-stu-id="4cac8-191">Immediately after defining the trainable layer, you must declare connections among the layers you have defined.</span></span> <span data-ttu-id="4cac8-192">Пакет подключений начинается с ключевого слова **from**, за которым следует имя слоя источника пакета, а также указывается вид создаваемого пакета подключений.</span><span class="sxs-lookup"><span data-stu-id="4cac8-192">The connection bundle declaration starts with the keyword **from**, followed by the name of the bundle's source layer and the kind of connection bundle to create.</span></span>   

<span data-ttu-id="4cac8-193">В настоящее время поддерживается пять видов пакетов подключений:</span><span class="sxs-lookup"><span data-stu-id="4cac8-193">Currently, five kinds of connection bundles are supported:</span></span>  

* <span data-ttu-id="4cac8-194">**Полные** пакеты, обозначаемые ключевым словом **all**.</span><span class="sxs-lookup"><span data-stu-id="4cac8-194">**Full** bundles, indicated by the keyword **all**</span></span>
* <span data-ttu-id="4cac8-195">**Фильтрованные** пакеты, обозначаемые ключевым словом **where**, за которым следует выражение предиката.</span><span class="sxs-lookup"><span data-stu-id="4cac8-195">**Filtered** bundles, indicated by the keyword **where**, followed by a predicate expression</span></span>
* <span data-ttu-id="4cac8-196">**Сверточные** пакеты, обозначаемые ключевым словом **convolve**, за которым следуют атрибуты свертки.</span><span class="sxs-lookup"><span data-stu-id="4cac8-196">**Convolutional** bundles, indicated by the keyword **convolve**, followed by the convolution attributes</span></span>
* <span data-ttu-id="4cac8-197">**Группирующие** пакеты, обозначаемые ключевым словом **max pool** или **mean pool**.</span><span class="sxs-lookup"><span data-stu-id="4cac8-197">**Pooling** bundles, indicated by the keywords **max pool** or **mean pool**</span></span>
* <span data-ttu-id="4cac8-198">Пакеты **нормализации ответов**, обозначаемые ключевым словом **response norm**.</span><span class="sxs-lookup"><span data-stu-id="4cac8-198">**Response normalization** bundles, indicated by the keyword **response norm**</span></span>      

## <a name="full-bundles"></a><span data-ttu-id="4cac8-199">Полные пакеты</span><span class="sxs-lookup"><span data-stu-id="4cac8-199">Full bundles</span></span>
<span data-ttu-id="4cac8-200">Полный пакет подключения содержит подключение от каждого узла слоя источника к каждому узлу слоя назначения.</span><span class="sxs-lookup"><span data-stu-id="4cac8-200">A full connection bundle includes a connection from each node in the source layer to each node in the destination layer.</span></span> <span data-ttu-id="4cac8-201">Это тип сетевого подключения по умолчанию.</span><span class="sxs-lookup"><span data-stu-id="4cac8-201">This is the default network connection type.</span></span>  

## <a name="filtered-bundles"></a><span data-ttu-id="4cac8-202">Фильтрованные пакеты</span><span class="sxs-lookup"><span data-stu-id="4cac8-202">Filtered bundles</span></span>
<span data-ttu-id="4cac8-203">Спецификация фильтрованного пакета подключений содержит предикат, выраженный синтаксически, практически так же, как лямбда-выражение в C#.</span><span class="sxs-lookup"><span data-stu-id="4cac8-203">A filtered connection bundle specification includes a predicate, expressed syntactically, much like a C# lambda expression.</span></span> <span data-ttu-id="4cac8-204">В следующем примере определены два фильтрованных пакета:</span><span class="sxs-lookup"><span data-stu-id="4cac8-204">The following example defines two filtered bundles:</span></span>  

    input Pixels [10, 20];
    hidden ByRow[10, 12] from Pixels where (s,d) => s[0] == d[0];
    hidden ByCol[5, 20] from Pixels where (s,d) => abs(s[1] - d[1]) <= 1;  

* <span data-ttu-id="4cac8-205">В предикате для *ByRow* **s** — параметр, который представляет индекс прямоугольного массива узлов входного слоя *Pixels*, а **d** — параметр, который представляет индекс массива узлов скрытого слоя *ByRow*.</span><span class="sxs-lookup"><span data-stu-id="4cac8-205">In the predicate for *ByRow*, **s** is a parameter representing an index into the rectangular array of nodes of the input layer, *Pixels*, and **d** is a parameter representing an index into the array of nodes of the hidden layer, *ByRow*.</span></span> <span data-ttu-id="4cac8-206">Тип двух этих параметров (**s** и **d**) представляет кортеж целых чисел со значением длины 2.</span><span class="sxs-lookup"><span data-stu-id="4cac8-206">The type of both **s** and **d** is a tuple of integers of length two.</span></span> <span data-ttu-id="4cac8-207">По сути, параметр **s** находится в диапазоне всех пар целых чисел с условиями *0 <= s[0] < 10* и *0 <= s[1] < 20*, а параметр **d** — в диапазоне всех пар целых чисел с условиями *0 <= d[0] < 10* и *0 <= d[1] < 12*.</span><span class="sxs-lookup"><span data-stu-id="4cac8-207">Conceptually, **s** ranges over all pairs of integers with *0 <= s[0] < 10* and *0 <= s[1] < 20*, and **d** ranges over all pairs of integers, with *0 <= d[0] < 10* and *0 <= d[1] < 12*.</span></span> 
* <span data-ttu-id="4cac8-208">На правой стороне выражения предиката находится условие.</span><span class="sxs-lookup"><span data-stu-id="4cac8-208">On the right-hand side of the predicate expression, there is a condition.</span></span> <span data-ttu-id="4cac8-209">В этом примере для каждого значения **s** и **d**, условие которого имеет значение True, предусмотрен переход из узла слоя источника в узел слоя назначения.</span><span class="sxs-lookup"><span data-stu-id="4cac8-209">In this example, for every value of **s** and **d** such that the condition is True, there is an edge from the source layer node to the destination layer node.</span></span> <span data-ttu-id="4cac8-210">Таким образом, это выражение фильтра указывает, что пакет содержит подключение от узла, определенного параметром **s**, к узлу, определенному параметром **d**, во всех случаях, где s[0] равно d[0].</span><span class="sxs-lookup"><span data-stu-id="4cac8-210">Thus, this filter expression indicates that the bundle includes a connection from the node defined by **s** to the node defined by **d** in all cases where s[0] is equal to d[0].</span></span>  

<span data-ttu-id="4cac8-211">Дополнительно можно указать набор весов фильтрованного пакета.</span><span class="sxs-lookup"><span data-stu-id="4cac8-211">Optionally, you can specify a set of weights for a filtered bundle.</span></span> <span data-ttu-id="4cac8-212">Значение атрибута **Weights** должно быть кортежем значений с плавающей запятой, длина которых соответствует числу подключений, определенных пакетом.</span><span class="sxs-lookup"><span data-stu-id="4cac8-212">The value for the **Weights** attribute must be a tuple of floating point values with a length that matches the number of connections defined by the bundle.</span></span> <span data-ttu-id="4cac8-213">По умолчанию веса генерируются случайно.</span><span class="sxs-lookup"><span data-stu-id="4cac8-213">By default, weights are randomly generated.</span></span>  

<span data-ttu-id="4cac8-214">Значения весов группируются по индексу узла назначения.</span><span class="sxs-lookup"><span data-stu-id="4cac8-214">Weight values are grouped by the destination node index.</span></span> <span data-ttu-id="4cac8-215">То есть, если первый узел назначения подключен к узлам источника K, первые *K* элементов кортежа **Weights** — это веса для первого узла назначения в порядке индексов узла источника.</span><span class="sxs-lookup"><span data-stu-id="4cac8-215">That is, if the first destination node is connected to K source nodes, the first *K* elements of the **Weights** tuple are the weights for the first destination node, in source index order.</span></span> <span data-ttu-id="4cac8-216">Это же правило применяется к остальным узлам назначения.</span><span class="sxs-lookup"><span data-stu-id="4cac8-216">The same applies for the remaining destination nodes.</span></span>  

<span data-ttu-id="4cac8-217">Параметры веса можно также задать как постоянные величины.</span><span class="sxs-lookup"><span data-stu-id="4cac8-217">It's possible to specify weights directly as constant values.</span></span> <span data-ttu-id="4cac8-218">Например, если параметры веса вам уже известны, вы можете указать их как постоянные величины, используя следующий синтаксис:</span><span class="sxs-lookup"><span data-stu-id="4cac8-218">For example, if you learned the weights previously, you can specify them as constants using this syntax:</span></span>

    const Weights_1 = [0.0188045055, 0.130500451, ...]


## <a name="convolutional-bundles"></a><span data-ttu-id="4cac8-219">Сверточные пакеты</span><span class="sxs-lookup"><span data-stu-id="4cac8-219">Convolutional bundles</span></span>
<span data-ttu-id="4cac8-220">В случаях, когда данные для обучения имеют однородную структуру, сверточные подключения широко используются для обучения высокоуровневых признаков данных.</span><span class="sxs-lookup"><span data-stu-id="4cac8-220">When the training data has a homogeneous structure, convolutional connections are commonly used to learn high-level features of the data.</span></span> <span data-ttu-id="4cac8-221">Например, изображение, аудио- или видеоданные, пространственная или временная размерность могут быть достаточно однородными.</span><span class="sxs-lookup"><span data-stu-id="4cac8-221">For example, in image, audio, or video data, spatial or temporal dimensionality can be fairly uniform.</span></span>  

<span data-ttu-id="4cac8-222">Сверточные пакеты используют прямоугольные **ядра**, которые перемещаются по измерениям.</span><span class="sxs-lookup"><span data-stu-id="4cac8-222">Convolutional bundles employ rectangular **kernels** that are slid through the dimensions.</span></span> <span data-ttu-id="4cac8-223">По сути, каждое ядро определяет набор весов, применяемый в локальных окрестностях, которые называются **приложениями ядра**.</span><span class="sxs-lookup"><span data-stu-id="4cac8-223">Essentially, each kernel defines a set of weights applied in local neighborhoods, referred to as **kernel applications**.</span></span> <span data-ttu-id="4cac8-224">Каждое приложение ядра соответствует узлу в слое источника, который называется **центральным узлом**.</span><span class="sxs-lookup"><span data-stu-id="4cac8-224">Each kernel application corresponds to a node in the source layer, which is referred to as the **central node**.</span></span> <span data-ttu-id="4cac8-225">Веса ядра используются совместно во многих подключениях.</span><span class="sxs-lookup"><span data-stu-id="4cac8-225">The weights of a kernel are shared among many connections.</span></span> <span data-ttu-id="4cac8-226">В сверточных пакетах каждое ядро представляет собой прямоугольник, а все приложения ядра имеют одинаковый размер.</span><span class="sxs-lookup"><span data-stu-id="4cac8-226">In a convolutional bundle, each kernel is rectangular and all kernel applications are the same size.</span></span>  

<span data-ttu-id="4cac8-227">Сверточные пакеты поддерживают следующие атрибуты:</span><span class="sxs-lookup"><span data-stu-id="4cac8-227">Convolutional bundles support the following attributes:</span></span>

<span data-ttu-id="4cac8-228">**InputShape** — определяет размерность слоя источника для этого сверточного пакета.</span><span class="sxs-lookup"><span data-stu-id="4cac8-228">**InputShape** defines the dimensionality of the source layer for the purposes of this convolutional bundle.</span></span> <span data-ttu-id="4cac8-229">Значение должно быть кортежем целых чисел.</span><span class="sxs-lookup"><span data-stu-id="4cac8-229">The value must be a tuple of positive integers.</span></span> <span data-ttu-id="4cac8-230">Произведение целых чисел должно равняться количеству узлов слоя источника, однако в противном случае необязательно должно соответствовать размерности, объявленной для слоя источника.</span><span class="sxs-lookup"><span data-stu-id="4cac8-230">The product of the integers must equal the number of nodes in the source layer, but otherwise, it does not need to match the dimensionality declared for the source layer.</span></span> <span data-ttu-id="4cac8-231">Длина этого кортежа становится значением **арности** для сверточного пакета.</span><span class="sxs-lookup"><span data-stu-id="4cac8-231">The length of this tuple becomes the **arity** value for the convolutional bundle.</span></span> <span data-ttu-id="4cac8-232">(Как правило, арность относится к количеству аргументов или операндов, которое может принимать функция.)</span><span class="sxs-lookup"><span data-stu-id="4cac8-232">(Typically arity refers to the number of arguments or operands that a function can take.)</span></span>  

<span data-ttu-id="4cac8-233">Чтобы определить форму и расположение ядер, используйте атрибуты **KernelShape**, **Stride**, **Padding**, **LowerPad** и **UpperPad**.</span><span class="sxs-lookup"><span data-stu-id="4cac8-233">To define the shape and locations of the kernels, use the attributes **KernelShape**, **Stride**, **Padding**, **LowerPad**, and **UpperPad**:</span></span>   

* <span data-ttu-id="4cac8-234">**KernelShape** (обязательный): определяет размерность каждого ядра сверточного пакета.</span><span class="sxs-lookup"><span data-stu-id="4cac8-234">**KernelShape**: (required) Defines the dimensionality of each kernel for the convolutional bundle.</span></span> <span data-ttu-id="4cac8-235">Значение должно быть кортежем положительных целых чисел, длина которых равна арности пакета.</span><span class="sxs-lookup"><span data-stu-id="4cac8-235">The value must be a tuple of positive integers with a length that equals the arity of the bundle.</span></span> <span data-ttu-id="4cac8-236">Каждый компонент этого кортежа не должен быть больше соответствующего компонента атрибута **InputShape**.</span><span class="sxs-lookup"><span data-stu-id="4cac8-236">Each component of this tuple must be no greater than the corresponding component of **InputShape**.</span></span> 
* <span data-ttu-id="4cac8-237">**Stride** (необязательный): определяет размер шага скольжения свертки (размер одного шага для каждого измерения), т. е. расстояние между центральными узлами.</span><span class="sxs-lookup"><span data-stu-id="4cac8-237">**Stride**: (optional) Defines the sliding step sizes of the convolution (one step size for each dimension), that is the distance between the central nodes.</span></span> <span data-ttu-id="4cac8-238">Значение должно быть кортежем положительных целых чисел, длина которых равна арности пакета.</span><span class="sxs-lookup"><span data-stu-id="4cac8-238">The value must be a tuple of positive integers with a length that is the arity of the bundle.</span></span> <span data-ttu-id="4cac8-239">Каждый компонент этого кортежа не должен больше соответствующего компонента атрибута **KernelShape**.</span><span class="sxs-lookup"><span data-stu-id="4cac8-239">Each component of this tuple must be no greater than the corresponding component of **KernelShape**.</span></span> <span data-ttu-id="4cac8-240">Значение по умолчанию: кортеж со всеми компонентами, равными единице.</span><span class="sxs-lookup"><span data-stu-id="4cac8-240">The default value is a tuple with all components equal to one.</span></span> 
* <span data-ttu-id="4cac8-241">**Sharing** (необязательный): определяет вес, общий для каждого измерения свертки.</span><span class="sxs-lookup"><span data-stu-id="4cac8-241">**Sharing**: (optional) Defines the weight sharing for each dimension of the convolution.</span></span> <span data-ttu-id="4cac8-242">Значение может быть одним логическим значением или кортежем логических значений, длина которых представляет собой арность пакета.</span><span class="sxs-lookup"><span data-stu-id="4cac8-242">The value can be a single Boolean value or a tuple of Boolean values with a length that is the arity of the bundle.</span></span> <span data-ttu-id="4cac8-243">Одно логическое значение расширяется до кортежа нужной длины со всеми компонентами, равными определенному значению.</span><span class="sxs-lookup"><span data-stu-id="4cac8-243">A single Boolean value is extended to be a tuple of the correct length with all components equal to the specified value.</span></span> <span data-ttu-id="4cac8-244">Значение по умолчанию — кортеж, состоящий из всех значений True.</span><span class="sxs-lookup"><span data-stu-id="4cac8-244">The default value is a tuple that consists of all True values.</span></span> 
* <span data-ttu-id="4cac8-245">**MapCount** (необязательный): определяет число карт функций для сверточного пакета.</span><span class="sxs-lookup"><span data-stu-id="4cac8-245">**MapCount**: (optional) Defines the number of feature maps for the convolutional bundle.</span></span> <span data-ttu-id="4cac8-246">Значение может быть одним положительным целым числом или кортежем положительных целых, длина которых представляет собой арность пакета.</span><span class="sxs-lookup"><span data-stu-id="4cac8-246">The value can be a single positive integer or a tuple of positive integers with a length that is the arity of the bundle.</span></span> <span data-ttu-id="4cac8-247">Одно целое значение расширяется до кортежа нужной длины с первыми компонентами, равными определенному значению, а оставшимися компонентами, равными единице.</span><span class="sxs-lookup"><span data-stu-id="4cac8-247">A single integer value is extended to be a tuple of the correct length with the first components equal to the specified value and all the remaining components equal to one.</span></span> <span data-ttu-id="4cac8-248">По умолчанию значение равно единице.</span><span class="sxs-lookup"><span data-stu-id="4cac8-248">The default value is one.</span></span> <span data-ttu-id="4cac8-249">Общее количество карт функций представляет собой произведение компонентов кортежа.</span><span class="sxs-lookup"><span data-stu-id="4cac8-249">The total number of feature maps is the product of the components of the tuple.</span></span> <span data-ttu-id="4cac8-250">Разложение этого общего количества по компонентам определяет, каким образом группируются значения карт функций в узлах назначения.</span><span class="sxs-lookup"><span data-stu-id="4cac8-250">The factoring of this total number across the components determines how the feature map values are grouped in the destination nodes.</span></span> 
* <span data-ttu-id="4cac8-251">**Weights** (необязательный) определяет исходные веса для пакета.</span><span class="sxs-lookup"><span data-stu-id="4cac8-251">**Weights**: (optional) Defines the initial weights for the bundle.</span></span> <span data-ttu-id="4cac8-252">Значение должно быть кортежем значений с плавающей запятой, длина которых представляет собой количество ядер, умноженное на количество весов на ядро, как указано ниже в этой статье.</span><span class="sxs-lookup"><span data-stu-id="4cac8-252">The value must be a tuple of floating point values with a length that is the number of kernels times the number of weights per kernel, as defined later in this article.</span></span> <span data-ttu-id="4cac8-253">Веса по умолчанию генерируются случайно.</span><span class="sxs-lookup"><span data-stu-id="4cac8-253">The default weights are randomly generated.</span></span>  

<span data-ttu-id="4cac8-254">Существует два набора свойств для управления заполнением, которые являются взаимоисключающими.</span><span class="sxs-lookup"><span data-stu-id="4cac8-254">There are two sets of properties that control padding, the properties being mutually exclusive:</span></span>

* <span data-ttu-id="4cac8-255">**Padding** (необязательно): определяет, должен ли вход заполняться с использованием **схемы заполнения по умолчанию**.</span><span class="sxs-lookup"><span data-stu-id="4cac8-255">**Padding**: (optional) Determines whether the input should be padded by using a **default padding scheme**.</span></span> <span data-ttu-id="4cac8-256">Значение может быть одним логическим значением или кортежем логических значений, длина которых представляет собой арность пакета.</span><span class="sxs-lookup"><span data-stu-id="4cac8-256">The value can be a single Boolean value, or it can be a tuple of Boolean values with a length that is the arity of the bundle.</span></span> <span data-ttu-id="4cac8-257">Одно логическое значение расширяется до кортежа нужной длины со всеми компонентами, равными определенному значению.</span><span class="sxs-lookup"><span data-stu-id="4cac8-257">A single Boolean value is extended to be a tuple of the correct length with all components equal to the specified value.</span></span> <span data-ttu-id="4cac8-258">Если измерение имеет значение True, источник логически заполняется в этом измерении ячейками с нулевыми значениями для поддержки дополнительных приложений ядра таким образом, чтобы центральные узлы первого и последнего ядер в этом измерении представляли собой первый и последний узел в этом измерении слоя источника.</span><span class="sxs-lookup"><span data-stu-id="4cac8-258">If the value for a dimension is True, the source is logically padded in that dimension with zero-valued cells to support additional kernel applications, such that the central nodes of the first and last kernels in that dimension are the first and last nodes in that dimension in the source layer.</span></span> <span data-ttu-id="4cac8-259">Таким образом, число пустых узлов в каждом измерении определяется автоматически, чтобы точно соответствовать ядрам *(InputShape[d] - 1) / Stride[d] + 1* в заполненном слое источника.</span><span class="sxs-lookup"><span data-stu-id="4cac8-259">Thus, the number of "dummy" nodes in each dimension is determined automatically, to fit exactly *(InputShape[d] - 1) / Stride[d] + 1* kernels into the padded source layer.</span></span> <span data-ttu-id="4cac8-260">Если измерение имеет значение False, ядра определяются таким образом, чтобы количество оставшихся узлов на каждой стороне было одинаковым (до разницы в 1).</span><span class="sxs-lookup"><span data-stu-id="4cac8-260">If the value for a dimension is False, the kernels are defined so that the number of nodes on each side that are left out is the same (up to a difference of 1).</span></span> <span data-ttu-id="4cac8-261">Значение по умолчанию этого атрибута: кортеж со всеми компонентами, равными False.</span><span class="sxs-lookup"><span data-stu-id="4cac8-261">The default value of this attribute is a tuple with all components equal to False.</span></span>
* <span data-ttu-id="4cac8-262">**UpperPad** и **LowerPad** (необязательно): позволяют более тонко управлять объемом заполнения.</span><span class="sxs-lookup"><span data-stu-id="4cac8-262">**UpperPad** and **LowerPad**: (optional) Provide greater control over the amount of padding to use.</span></span> <span data-ttu-id="4cac8-263">**Важно!** Эти атрибуты могут задаваться тогда и только тогда, когда свойство **Padding** выше ***не*** задается.</span><span class="sxs-lookup"><span data-stu-id="4cac8-263">**Important:** These attributes can be defined if and only if the **Padding** property above is ***not*** defined.</span></span> <span data-ttu-id="4cac8-264">Значения должны быть кортежами с целыми значениями, длина которых представляет собой арность пакета.</span><span class="sxs-lookup"><span data-stu-id="4cac8-264">The values should be integer-valued tuples with lengths that are the arity of the bundle.</span></span> <span data-ttu-id="4cac8-265">При задании этих атрибутов «пустые» узлы добавляются к нижнему и верхнему концам каждого измерения входного слоя.</span><span class="sxs-lookup"><span data-stu-id="4cac8-265">When these attributes are specified, "dummy" nodes are added to the lower and upper ends of each dimension of the input layer.</span></span> <span data-ttu-id="4cac8-266">Число узлов, добавленных к нижнему и верхнему концам в каждом измерении, определяется атрибутами **LowerPad[i]** и **UpperPad[i]** соответственно.</span><span class="sxs-lookup"><span data-stu-id="4cac8-266">The number of nodes added to the lower and upper ends in each dimension is determined by **LowerPad**[i] and **UpperPad**[i] respectively.</span></span> <span data-ttu-id="4cac8-267">Чтобы обеспечить соответствие количества ядер только количеству «реальных», а не «пустых» узлов, должны выполняться следующие условия.</span><span class="sxs-lookup"><span data-stu-id="4cac8-267">To ensure that kernels correspond only to "real" nodes and not to "dummy" nodes, the following conditions must be met:</span></span>
  * <span data-ttu-id="4cac8-268">Каждый компонент атрибута **LowerPad** должен быть строго меньше, чем KernelShape[d]/2.</span><span class="sxs-lookup"><span data-stu-id="4cac8-268">Each component of **LowerPad** must be strictly less than KernelShape[d]/2.</span></span> 
  * <span data-ttu-id="4cac8-269">Каждый компонент атрибута **UpperPad** должен быть не больше, чем KernelShape[d]/2.</span><span class="sxs-lookup"><span data-stu-id="4cac8-269">Each component of **UpperPad** must be no greater than KernelShape[d]/2.</span></span> 
  * <span data-ttu-id="4cac8-270">Значение по умолчанию этих атрибутов: кортеж со всеми компонентами, равными 0.</span><span class="sxs-lookup"><span data-stu-id="4cac8-270">The default value of these attributes is a tuple with all components equal to 0.</span></span> 

<span data-ttu-id="4cac8-271">Значение **Padding** = true позволяет осуществить заполнение, необходимое для сохранения центра ядра в пределах реального входа.</span><span class="sxs-lookup"><span data-stu-id="4cac8-271">The setting **Padding** = true allows as much padding as is needed to keep the "center" of the kernel inside the "real" input.</span></span> <span data-ttu-id="4cac8-272">Поэтому формула для вычисления выходного размера немного изменяется.</span><span class="sxs-lookup"><span data-stu-id="4cac8-272">This changes the math a bit for computing the output size.</span></span> <span data-ttu-id="4cac8-273">Обычно выходной размер *D* вычисляется как *D = (I - K) / S + 1*, где *I* — входной размер, *K* — размер ядра, *S* —- шаг и */* — целочисленное деление (с округлением до нуля).</span><span class="sxs-lookup"><span data-stu-id="4cac8-273">Generally, the output size *D* is computed as *D = (I - K) / S + 1*, where *I* is the input size, *K* is the kernel size, *S* is the stride, and */* is integer division (round toward zero).</span></span> <span data-ttu-id="4cac8-274">Если задать значение UpperPad = [1, 1], входной размер *I* будет равен 29; следовательно, *D = (29 - 5) / 2 + 1 = 13*.</span><span class="sxs-lookup"><span data-stu-id="4cac8-274">If you set UpperPad = [1, 1], the input size *I* is effectively 29, and thus *D = (29 - 5) / 2 + 1 = 13*.</span></span> <span data-ttu-id="4cac8-275">Но если **Padding** = true, тогда и *I* фактически вытесняется *K - 1*; следовательно *D = ((28 + 4) - 5) / 2 + 1 = 27 / 2 + 1 = 13 + 1 = 14*.</span><span class="sxs-lookup"><span data-stu-id="4cac8-275">However, when **Padding** = true, essentially *I* gets bumped up by *K - 1*; hence *D = ((28 + 4) - 5) / 2 + 1 = 27 / 2 + 1 = 13 + 1 = 14*.</span></span> <span data-ttu-id="4cac8-276">Присвоив значения параметрам **UpperPad** и **LowerPad**, вы сможете более точно управлять заполнением, чем это позволяет сделать определение только одного параметра **Padding** = true.</span><span class="sxs-lookup"><span data-stu-id="4cac8-276">By specifying values for **UpperPad** and **LowerPad** you get much more control over the padding than if you just set **Padding** = true.</span></span>

<span data-ttu-id="4cac8-277">Дополнительную информацию о сверточных сетях и их приложениях см. в следующих статьях:</span><span class="sxs-lookup"><span data-stu-id="4cac8-277">For more information about convolutional networks and their applications, see these articles:</span></span>  

* [<span data-ttu-id="4cac8-278">http://deeplearning.net/tutorial/lenet.html </span><span class="sxs-lookup"><span data-stu-id="4cac8-278">http://deeplearning.net/tutorial/lenet.html </span></span>](http://deeplearning.net/tutorial/lenet.html)
* [<span data-ttu-id="4cac8-279">http://research.microsoft.com/pubs/68920/icdar03.pdf</span><span class="sxs-lookup"><span data-stu-id="4cac8-279">http://research.microsoft.com/pubs/68920/icdar03.pdf</span></span>](http://research.microsoft.com/pubs/68920/icdar03.pdf) 
* [<span data-ttu-id="4cac8-280">http://people.csail.mit.edu/jvb/papers/cnn_tutorial.pdf</span><span class="sxs-lookup"><span data-stu-id="4cac8-280">http://people.csail.mit.edu/jvb/papers/cnn_tutorial.pdf</span></span>](http://people.csail.mit.edu/jvb/papers/cnn_tutorial.pdf)  

## <a name="pooling-bundles"></a><span data-ttu-id="4cac8-281">Группирующие пакеты</span><span class="sxs-lookup"><span data-stu-id="4cac8-281">Pooling bundles</span></span>
<span data-ttu-id="4cac8-282">**Группирующий пакет** применяет геометрию, аналогичную сверточному подключению, но использует предопределенные функции для значений узла источника, чтобы извлечь значение узла назначения.</span><span class="sxs-lookup"><span data-stu-id="4cac8-282">A **pooling bundle** applies geometry similar to convolutional connectivity, but it uses predefined functions to source node values to derive the destination node value.</span></span> <span data-ttu-id="4cac8-283">Следовательно, группирующие пакеты не имеют обучаемого состояния (весов или смещений).</span><span class="sxs-lookup"><span data-stu-id="4cac8-283">Hence, pooling bundles have no trainable state (weights or biases).</span></span> <span data-ttu-id="4cac8-284">Группирующие пакеты поддерживают все сверточные атрибуты, кроме **Sharing**, **MapCount** и **Weights**.</span><span class="sxs-lookup"><span data-stu-id="4cac8-284">Pooling bundles support all the convolutional attributes except **Sharing**, **MapCount**, and **Weights**.</span></span>  

<span data-ttu-id="4cac8-285">Как правило, ядра, суммированные соседними группирующими модулями, не перекрываются.</span><span class="sxs-lookup"><span data-stu-id="4cac8-285">Typically, the kernels summarized by adjacent pooling units do not overlap.</span></span> <span data-ttu-id="4cac8-286">Если Stride[d] равен KernelShape[d] в каждом измерении, то полученный слой представляет собой традиционный локальный группирующий слой, который обычно используется в сверточных нейронных сетях.</span><span class="sxs-lookup"><span data-stu-id="4cac8-286">If Stride[d] is equal to KernelShape[d] in each dimension, the layer obtained is the traditional local pooling layer, which is commonly employed in convolutional neural networks.</span></span> <span data-ttu-id="4cac8-287">Каждый узел назначения вычисляет максимальное или среднее значение действий своего ядра в слое источника.</span><span class="sxs-lookup"><span data-stu-id="4cac8-287">Each destination node computes the maximum or the mean of the activities of its kernel in the source layer.</span></span>  

<span data-ttu-id="4cac8-288">В следующем примере проиллюстрирован группирующий пакет:</span><span class="sxs-lookup"><span data-stu-id="4cac8-288">The following example illustrates a pooling bundle:</span></span> 

    hidden P1 [5, 12, 12]
      from C1 max pool {
        InputShape  = [ 5, 24, 24];
        KernelShape = [ 1,  2,  2];
        Stride      = [ 1,  2,  2];
      }  

* <span data-ttu-id="4cac8-289">Арность пакета равна 3 (длина кортежей **InputShape**, **KernelShape** и **Stride**).</span><span class="sxs-lookup"><span data-stu-id="4cac8-289">The arity of the bundle is 3 (the length of the tuples **InputShape**, **KernelShape**, and **Stride**).</span></span> 
* <span data-ttu-id="4cac8-290">Число узлов в слое источника: *5 * 24 * 24 = 2880*.</span><span class="sxs-lookup"><span data-stu-id="4cac8-290">The number of nodes in the source layer is *5 * 24 * 24 = 2880*.</span></span> 
* <span data-ttu-id="4cac8-291">Это стандартный локальный группирующий слой, так как **KernelShape** = **Stride**.</span><span class="sxs-lookup"><span data-stu-id="4cac8-291">This is a traditional local pooling layer because **KernelShape** and **Stride** are equal.</span></span> 
* <span data-ttu-id="4cac8-292">Число узлов в слое назначения: *5 * 12 * 12 = 1440*.</span><span class="sxs-lookup"><span data-stu-id="4cac8-292">The number of nodes in the destination layer is *5 * 12 * 12 = 1440*.</span></span>  

<span data-ttu-id="4cac8-293">Дополнительную информацию о группирующих слоях см. в статьях:</span><span class="sxs-lookup"><span data-stu-id="4cac8-293">For more information about pooling layers, see these articles:</span></span>  

* <span data-ttu-id="4cac8-294">[http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf](http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf) (Section 3.4)</span><span class="sxs-lookup"><span data-stu-id="4cac8-294">[http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf](http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf) (Section 3.4)</span></span>
* [<span data-ttu-id="4cac8-295">http://cs.nyu.edu/~koray/publis/lecun-iscas-10.pdf</span><span class="sxs-lookup"><span data-stu-id="4cac8-295">http://cs.nyu.edu/~koray/publis/lecun-iscas-10.pdf</span></span>](http://cs.nyu.edu/~koray/publis/lecun-iscas-10.pdf) 
* [<span data-ttu-id="4cac8-296">http://cs.nyu.edu/~koray/publis/jarrett-iccv-09.pdf</span><span class="sxs-lookup"><span data-stu-id="4cac8-296">http://cs.nyu.edu/~koray/publis/jarrett-iccv-09.pdf</span></span>](http://cs.nyu.edu/~koray/publis/jarrett-iccv-09.pdf)

## <a name="response-normalization-bundles"></a><span data-ttu-id="4cac8-297">Пакеты нормализации ответов</span><span class="sxs-lookup"><span data-stu-id="4cac8-297">Response normalization bundles</span></span>
<span data-ttu-id="4cac8-298">**Нормализация ответов** — это локальная схема нормализации, которая впервые была предложена Джеффри Хинтоном (Geoffrey Hinton) и др. в статье [ImageNet Classiﬁcation with Deep Convolutional Neural Networks](http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf) (Классификация ImageNet с помощью глубоких сверточных нейронных сетей).</span><span class="sxs-lookup"><span data-stu-id="4cac8-298">**Response normalization** is a local normalization scheme that was first introduced by Geoffrey Hinton, et al, in the paper [ImageNet Classiﬁcation with Deep Convolutional Neural Networks](http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf).</span></span> <span data-ttu-id="4cac8-299">Нормализация ответов используется для облегчения обобщения в нейронных сетях.</span><span class="sxs-lookup"><span data-stu-id="4cac8-299">Response normalization is used to aid generalization in neural nets.</span></span> <span data-ttu-id="4cac8-300">Когда один нейрон срабатывает при очень высоком уровне активации, локальный слой нормализации ответа подавляет уровень активации окружающих нейронов.</span><span class="sxs-lookup"><span data-stu-id="4cac8-300">When one neuron is firing at a very high activation level, a local response normalization layer suppresses the activation level of the surrounding neurons.</span></span> <span data-ttu-id="4cac8-301">Это выполняется с помощью трех параметров (***α***, ***β*** и ***k***) и сверточной структуры (или формы окрестности).</span><span class="sxs-lookup"><span data-stu-id="4cac8-301">This is done by using three parameters (***α***, ***β***, and ***k***) and a convolutional structure (or neighborhood shape).</span></span> <span data-ttu-id="4cac8-302">Каждый нейрон в слое назначения ***y*** соответствует нейрону ***x*** в слое источника.</span><span class="sxs-lookup"><span data-stu-id="4cac8-302">Every neuron in the destination layer ***y*** corresponds to a neuron ***x*** in the source layer.</span></span> <span data-ttu-id="4cac8-303">Уровень активации ***y*** задается следующей формулой, где ***f*** — уровень активации нейрона, ***Nx*** — ядро (или набор, содержащий нейроны в окрестности ***x***), как определяется сверточной структурой.</span><span class="sxs-lookup"><span data-stu-id="4cac8-303">The activation level of ***y*** is given by the following formula, where ***f*** is the activation level of a neuron, and ***Nx*** is the kernel (or the set that contains the neurons in the neighborhood of ***x***), as defined by the following convolutional structure:</span></span>  

![][1]  

<span data-ttu-id="4cac8-304">Пакеты нормализации ответов поддерживают все сверточные атрибуты, кроме **Sharing**, **MapCount** и **Weights**.</span><span class="sxs-lookup"><span data-stu-id="4cac8-304">Response normalization bundles support all the convolutional attributes except **Sharing**, **MapCount**, and **Weights**.</span></span>  

* <span data-ttu-id="4cac8-305">Если ядро содержит нейроны в той же карте, что и ***x***, схема нормализации называется **нормализацией в той же карте**.</span><span class="sxs-lookup"><span data-stu-id="4cac8-305">If the kernel contains neurons in the same map as ***x***, the normalization scheme is referred to as **same map normalization**.</span></span> <span data-ttu-id="4cac8-306">Чтобы определить нормализацию в той же карте, первая координата в **InputShape** должна иметь значение 1.</span><span class="sxs-lookup"><span data-stu-id="4cac8-306">To define same map normalization, the first coordinate in **InputShape** must have the value 1.</span></span>
* <span data-ttu-id="4cac8-307">Если ядро содержит нейроны в той же пространственной позиции, что и ***x***, но нейроны находятся в других картах, схема нормализации называется **нормализацией между картами**.</span><span class="sxs-lookup"><span data-stu-id="4cac8-307">If the kernel contains neurons in the same spatial position as ***x***, but the neurons are in other maps, the normalization scheme is called **across maps normalization**.</span></span> <span data-ttu-id="4cac8-308">Этот тип нормализации ответа реализует форму латерального торможения, похожую на форму, найденную у реальных нейронов, создавая конкуренцию за большие уровни активации среди выходов нейронов, вычисленных на различных картах.</span><span class="sxs-lookup"><span data-stu-id="4cac8-308">This type of response normalization implements a form of lateral inhibition inspired by the type found in real neurons, creating competition for big activation levels amongst neuron outputs computed on different maps.</span></span> <span data-ttu-id="4cac8-309">Чтобы задать межкарточную нормализацию, первая координата должна быть целым числом (больше единицы и не больше количества карт), а остальные координаты должны иметь значения, равные 1.</span><span class="sxs-lookup"><span data-stu-id="4cac8-309">To define across maps normalization, the first coordinate must be an integer greater than one and no greater than the number of maps, and the rest of the coordinates must have the value 1.</span></span>  

<span data-ttu-id="4cac8-310">Так как пакеты нормализации ответов применяют предопределенную функцию к значениям узла источника для определения значения узла назначения, они не имеют обучаемого состояния (веса или смещения)</span><span class="sxs-lookup"><span data-stu-id="4cac8-310">Because response normalization bundles apply a predefined function to source node values to determine the destination node value, they have no trainable state (weights or biases).</span></span>   

<span data-ttu-id="4cac8-311">**Alert**: узлы в слое назначения соответствуют нейронам, которые представляют центральные узлы ядер.</span><span class="sxs-lookup"><span data-stu-id="4cac8-311">**Alert**: The nodes in the destination layer correspond to neurons that are the central nodes of the kernels.</span></span> <span data-ttu-id="4cac8-312">Например, если KernelShape[d] имеет нечетное значение, *KernelShape[d]/2* соответствует центральному узлу ядра.</span><span class="sxs-lookup"><span data-stu-id="4cac8-312">For example, if KernelShape[d] is odd, then *KernelShape[d]/2* corresponds to the central kernel node.</span></span> <span data-ttu-id="4cac8-313">Если значение *KernelShape[d]* четное, центральный узел находится в *KernelShape[d]/2 - 1*.</span><span class="sxs-lookup"><span data-stu-id="4cac8-313">If *KernelShape[d]* is even, the central node is at *KernelShape[d]/2 - 1*.</span></span> <span data-ttu-id="4cac8-314">Таким образом, если для параметра **Padding**[d] задано значение False, первый и последний узлы *KernelShape[d]/2* не имеют соответствующих узлов в слое назначения.</span><span class="sxs-lookup"><span data-stu-id="4cac8-314">Therefore, if **Padding**[d] is False, the first and the last *KernelShape[d]/2* nodes do not have corresponding nodes in the destination layer.</span></span> <span data-ttu-id="4cac8-315">Чтобы исключить эту ситуацию, определите атрибут **Padding** как [true, true, …, true].</span><span class="sxs-lookup"><span data-stu-id="4cac8-315">To avoid this situation, define **Padding** as [true, true, …, true].</span></span>  

<span data-ttu-id="4cac8-316">В дополнение к четырем атрибутам, описанным выше, пакеты нормализации ответов также поддерживают следующие атрибуты.</span><span class="sxs-lookup"><span data-stu-id="4cac8-316">In addition to the four attributes described earlier, response normalization bundles also support the following attributes:</span></span>  

* <span data-ttu-id="4cac8-317">**Alpha** (обязательный): определяет значение с плавающей запятой, соответствующее ***α*** в указанной выше формуле.</span><span class="sxs-lookup"><span data-stu-id="4cac8-317">**Alpha**: (required) Specifies a floating-point value that corresponds to ***α*** in the previous formula.</span></span> 
* <span data-ttu-id="4cac8-318">**Beta** (обязательный): определяет значение с плавающей запятой, соответствующее ***β*** в указанной выше формуле.</span><span class="sxs-lookup"><span data-stu-id="4cac8-318">**Beta**: (required) Specifies a floating-point value that corresponds to ***β*** in the previous formula.</span></span> 
* <span data-ttu-id="4cac8-319">**Offset** (необязательный): определяет значение с плавающей запятой, соответствующее ***k*** в указанной выше формуле.</span><span class="sxs-lookup"><span data-stu-id="4cac8-319">**Offset**: (optional) Specifies a floating-point value that corresponds to ***k*** in the previous formula.</span></span> <span data-ttu-id="4cac8-320">Его значение по умолчанию равно 1.</span><span class="sxs-lookup"><span data-stu-id="4cac8-320">It defaults to 1.</span></span>  

<span data-ttu-id="4cac8-321">В следующем примере определяется пакет нормализации ответов с использованием этих атрибутов:</span><span class="sxs-lookup"><span data-stu-id="4cac8-321">The following example defines a response normalization bundle using these attributes:</span></span>  

    hidden RN1 [5, 10, 10]
      from P1 response norm {
        InputShape  = [ 5, 12, 12];
        KernelShape = [ 1,  3,  3];
        Alpha = 0.001;
        Beta = 0.75;
      }  

* <span data-ttu-id="4cac8-322">Слой источника содержит пять карт, каждая размером 12 x 12, и в общей сложности насчитывает 1440 узлов.</span><span class="sxs-lookup"><span data-stu-id="4cac8-322">The source layer includes five maps, each with aof dimension of 12x12, totaling in 1440 nodes.</span></span> 
* <span data-ttu-id="4cac8-323">Значение **KernelShape** указывает, что это та же карта слоя нормализации, в которой окрестность представлена прямоугольником 3 x 3.</span><span class="sxs-lookup"><span data-stu-id="4cac8-323">The value of **KernelShape** indicates that this is a same map normalization layer, where the neighborhood is a 3x3 rectangle.</span></span> 
* <span data-ttu-id="4cac8-324">По умолчанию атрибут **Padding** имеет значение False, следовательно, у слоя назначения в каждом измерении буде только 10 узлов.</span><span class="sxs-lookup"><span data-stu-id="4cac8-324">The default value of **Padding** is False, thus the destination layer has only 10 nodes in each dimension.</span></span> <span data-ttu-id="4cac8-325">Чтобы включить один узел в слое назначения, соответствующий каждому узлу в слое источника, добавьте Padding = [true, true, true] и измените размер RN1 на [5, 12, 12].</span><span class="sxs-lookup"><span data-stu-id="4cac8-325">To include one node in the destination layer that corresponds to every node in the source layer, add Padding = [true, true, true]; and change the size of RN1 to [5, 12, 12].</span></span>  

## <a name="share-declaration"></a><span data-ttu-id="4cac8-326">Объявление общего доступа</span><span class="sxs-lookup"><span data-stu-id="4cac8-326">Share declaration</span></span>
<span data-ttu-id="4cac8-327">Net# дополнительно поддерживает определение нескольких пакетов с общими весами.</span><span class="sxs-lookup"><span data-stu-id="4cac8-327">Net# optionally supports defining multiple bundles with shared weights.</span></span> <span data-ttu-id="4cac8-328">Веса любых двух пакетов могут быть общими, если их структуры одинаковы.</span><span class="sxs-lookup"><span data-stu-id="4cac8-328">The weights of any two bundles can be shared if their structures are the same.</span></span> <span data-ttu-id="4cac8-329">Далее описывается синтаксис определения пакетов с общими весами:</span><span class="sxs-lookup"><span data-stu-id="4cac8-329">The following syntax defines bundles with shared weights:</span></span>  

    share-declaration:
        share    {    layer-list    }
        share    {    bundle-list    }
       share    {    bias-list    }

    layer-list:
        layer-name    ,    layer-name
        layer-list    ,    layer-name

    bundle-list:
       bundle-spec    ,    bundle-spec
        bundle-list    ,    bundle-spec

    bundle-spec:
       layer-name    =>     layer-name

    bias-list:
        bias-spec    ,    bias-spec
        bias-list    ,    bias-spec

    bias-spec:
        1    =>    layer-name

    layer-name:
        identifier  

<span data-ttu-id="4cac8-330">Например, следующее объявление общего доступа определяет имена слоев, указывая, что веса и смещения должны быть общими.</span><span class="sxs-lookup"><span data-stu-id="4cac8-330">For example, the following share-declaration specifies the layer names, indicating that both weights and biases should be shared:</span></span>  

    Const {
      InputSize = 37;
      HiddenSize = 50;
    }
    input {
      Data1 [InputSize];
      Data2 [InputSize];
    }
    hidden {
      H1 [HiddenSize] from Data1 all;
      H2 [HiddenSize] from Data2 all;
    }
    output Result [2] {
      from H1 all;
      from H2 all;
    }
    share { H1, H2 } // share both weights and biases  

* <span data-ttu-id="4cac8-331">Входные функции разделяются на два входных слоя одинаковых размеров.</span><span class="sxs-lookup"><span data-stu-id="4cac8-331">The input features are partitioned into two equal sized input layers.</span></span> 
* <span data-ttu-id="4cac8-332">Скрытые слои далее вычисляют функции более высокого уровня на двух входных слоях.</span><span class="sxs-lookup"><span data-stu-id="4cac8-332">The hidden layers then compute higher level features on the two input layers.</span></span> 
* <span data-ttu-id="4cac8-333">Объявление общего доступа определяет, что *H1* и *H2* должны вычисляться одинаково из соответствующих входов.</span><span class="sxs-lookup"><span data-stu-id="4cac8-333">The share-declaration specifies that *H1* and *H2* must be computed in the same way from their respective inputs.</span></span>  

<span data-ttu-id="4cac8-334">В качестве альтернативы это можно задать с помощью двух отдельных объявлений общего доступа следующим образом:</span><span class="sxs-lookup"><span data-stu-id="4cac8-334">Alternatively, this could be specified with two separate share-declarations as follows:</span></span>  

    share { Data1 => H1, Data2 => H2 } // share weights  

<!-- -->

    share { 1 => H1, 1 => H2 } // share biases  

<span data-ttu-id="4cac8-335">Краткую форму можно использовать только, если слои содержат один пакет.</span><span class="sxs-lookup"><span data-stu-id="4cac8-335">You can use the short form only when the layers contain a single bundle.</span></span> <span data-ttu-id="4cac8-336">Как правило, общий доступ возможен, только если соответствующие структуры идентичны, то есть имеют один размер, одинаковую сверточную геометрию и т. д.</span><span class="sxs-lookup"><span data-stu-id="4cac8-336">In general, sharing is possible only when the relevant structure is identical, meaning that they have the same size, same convolutional geometry, and so forth.</span></span>  

## <a name="examples-of-net-usage"></a><span data-ttu-id="4cac8-337">Примеры использования Net#</span><span class="sxs-lookup"><span data-stu-id="4cac8-337">Examples of Net# usage</span></span>
<span data-ttu-id="4cac8-338">В этом разделе приводится несколько примеров использования Net# для добавления скрытых слоев, определения способов взаимодействия скрытых слоев с другими слоями и построения сверточных сетей.</span><span class="sxs-lookup"><span data-stu-id="4cac8-338">This section provides some examples of how you can use Net# to add hidden layers, define the way that hidden layers interact with other layers, and build convolutional networks.</span></span>   

### <a name="define-a-simple-custom-neural-network-hello-world-example"></a><span data-ttu-id="4cac8-339">Определение простой настраиваемой нейронной сети: пример «Привет, мир!»</span><span class="sxs-lookup"><span data-stu-id="4cac8-339">Define a simple custom neural network: "Hello World" example</span></span>
<span data-ttu-id="4cac8-340">В этом простом примере показано, как создавать модель нейронной сети с одним скрытым слоем.</span><span class="sxs-lookup"><span data-stu-id="4cac8-340">This simple example demonstrates how to create a neural network model that has a single hidden layer.</span></span>  

    input Data auto;
    hidden H [200] from Data all;
    output Out [10] sigmoid from H all;  

<span data-ttu-id="4cac8-341">В примере проиллюстрированы некоторые базовые команды и их порядок.</span><span class="sxs-lookup"><span data-stu-id="4cac8-341">The example illustrates some basic commands as follows:</span></span>  

* <span data-ttu-id="4cac8-342">В первой строке определяется входной слой (с именем *Data*).</span><span class="sxs-lookup"><span data-stu-id="4cac8-342">The first line defines the input layer (named *Data*).</span></span> <span data-ttu-id="4cac8-343">При использовании ключевого слова **auto** в нейронную сеть автоматически включаются все столбцы функций в примерах ввода.</span><span class="sxs-lookup"><span data-stu-id="4cac8-343">When you use the  **auto** keyword, the neural network automatically includes all feature columns in the input examples.</span></span> 
* <span data-ttu-id="4cac8-344">Вторая строка создает скрытый слой.</span><span class="sxs-lookup"><span data-stu-id="4cac8-344">The second line creates the hidden layer.</span></span> <span data-ttu-id="4cac8-345">Имя *H* назначается скрытому слою с 200 узлами.</span><span class="sxs-lookup"><span data-stu-id="4cac8-345">The name *H* is assigned to the hidden layer, which has 200 nodes.</span></span> <span data-ttu-id="4cac8-346">Этот слой полностью подключен ко входному слою.</span><span class="sxs-lookup"><span data-stu-id="4cac8-346">This layer is fully connected to the input layer.</span></span>
* <span data-ttu-id="4cac8-347">Третья строка определяет выходной слой (с именем *O*), который содержит 10 выходных узлов.</span><span class="sxs-lookup"><span data-stu-id="4cac8-347">The third line defines the output layer (named *O*), which contains 10 output nodes.</span></span> <span data-ttu-id="4cac8-348">Для классификации нейронных сетей используется по одному выходному узлу на класс.</span><span class="sxs-lookup"><span data-stu-id="4cac8-348">If the neural network is used for classification, there is one output node per class.</span></span> <span data-ttu-id="4cac8-349">Ключевое слово **sigmoid** указывает выходную функцию, примененную к выходному слою.</span><span class="sxs-lookup"><span data-stu-id="4cac8-349">The keyword **sigmoid** indicates that the output function is applied to the output layer.</span></span>   

### <a name="define-multiple-hidden-layers-computer-vision-example"></a><span data-ttu-id="4cac8-350">Определение нескольких скрытых слоев: пример машинного зрения</span><span class="sxs-lookup"><span data-stu-id="4cac8-350">Define multiple hidden layers: computer vision example</span></span>
<span data-ttu-id="4cac8-351">В следующем примере показано, как определять немного более сложную нейронную сеть с несколькими настраиваемыми скрытыми слоями.</span><span class="sxs-lookup"><span data-stu-id="4cac8-351">The following example demonstrates how to define a slightly more complex neural network, with multiple custom hidden layers.</span></span>  

    // Define the input layers 
    input Pixels [10, 20];
    input MetaData [7];

    // Define the first two hidden layers, using data only from the Pixels input
    hidden ByRow [10, 12] from Pixels where (s,d) => s[0] == d[0];
    hidden ByCol [5, 20] from Pixels where (s,d) => abs(s[1] - d[1]) <= 1;

    // Define the third hidden layer, which uses as source the hidden layers ByRow and ByCol
    hidden Gather [100] 
    {
      from ByRow all;
      from ByCol all;
    }

    // Define the output layer and its sources
    output Result [10]  
    {
      from Gather all;
      from MetaData all;
    }  

<span data-ttu-id="4cac8-352">В примере проиллюстрировано несколько признаков языка спецификаций нейронных сетей</span><span class="sxs-lookup"><span data-stu-id="4cac8-352">This example illustrates several features of the neural networks specification language:</span></span>  

* <span data-ttu-id="4cac8-353">Структура имеет два входных слоя: *Pixels* и *MetaData*.</span><span class="sxs-lookup"><span data-stu-id="4cac8-353">The structure has two input layers, *Pixels* and *MetaData*.</span></span>
* <span data-ttu-id="4cac8-354">Слой *Pixels* — это слой источника для двух пакетов подключений со слоями назначения: *ByRow* и *ByCol*.</span><span class="sxs-lookup"><span data-stu-id="4cac8-354">The *Pixels* layer is a source layer for two connection bundles, with destination layers, *ByRow* and *ByCol*.</span></span>
* <span data-ttu-id="4cac8-355">Слои *Gather* и *Result* — это слои назначения в нескольких пакетах подключений.</span><span class="sxs-lookup"><span data-stu-id="4cac8-355">The layers *Gather* and *Result* are destination layers in multiple connection bundles.</span></span>
* <span data-ttu-id="4cac8-356">Выходной слой *Result* — это слой назначения в двух пакетах подключений. Один содержит скрытый слой второго уровня (Gather) в качестве слоя назначения, а другой — входной слой (MetaData) в качестве слоя назначения.</span><span class="sxs-lookup"><span data-stu-id="4cac8-356">The output layer, *Result*, is a destination layer in two connection bundles; one with the second level hidden (Gather) as a destination layer, and the other with the input layer (MetaData) as a destination layer.</span></span>
* <span data-ttu-id="4cac8-357">Скрытые слои *ByRow* и *ByCol* определяют отфильтрованные подключения с использованием выражений предиката.</span><span class="sxs-lookup"><span data-stu-id="4cac8-357">The hidden layers, *ByRow* and *ByCol*, specify filtered connectivity by using predicate expressions.</span></span> <span data-ttu-id="4cac8-358">Точнее говоря, узел в *ByRow* с координатами [x, y] подключается к тем узлам в *Pixels*, у которых первая координата индекса равна первой координате узла (x).</span><span class="sxs-lookup"><span data-stu-id="4cac8-358">More precisely, the node in *ByRow* at [x, y] is connected to the nodes in *Pixels* that have the first index coordinate equal to the node's first coordinate, x.</span></span> <span data-ttu-id="4cac8-359">Аналогично узел *ByCol с координатами [x, y] подключается к тем узлам в _Pixels*, у которых вторая координата индекса находится в пределах единицы от второй координаты узла (у).</span><span class="sxs-lookup"><span data-stu-id="4cac8-359">Similarly, the node in *ByCol at [x, y] is connected to the nodes in _Pixels* that have the second index coordinate within one of the node's second coordinate, y.</span></span>  

### <a name="define-a-convolutional-network-for-multiclass-classification-digit-recognition-example"></a><span data-ttu-id="4cac8-360">Определение сверточной сети для многоклассовой классификации: пример распознавания цифр</span><span class="sxs-lookup"><span data-stu-id="4cac8-360">Define a convolutional network for multiclass classification: digit recognition example</span></span>
<span data-ttu-id="4cac8-361">Определение следующей сети, разработанной для распознавания цифр, показывает некоторые усовершенствованные методы настройки нейронных сетей.</span><span class="sxs-lookup"><span data-stu-id="4cac8-361">The definition of the following network is designed to recognize numbers, and it illustrates some advanced techniques for customizing a neural network.</span></span>  

    input Image [29, 29];
    hidden Conv1 [5, 13, 13] from Image convolve 
    {
       InputShape  = [29, 29];
       KernelShape = [ 5,  5];
       Stride      = [ 2,  2];
       MapCount    = 5;
    }
    hidden Conv2 [50, 5, 5]
    from Conv1 convolve 
    {
       InputShape  = [ 5, 13, 13];
       KernelShape = [ 1,  5,  5];
       Stride      = [ 1,  2,  2];
       Sharing     = [false, true, true];
       MapCount    = 10;
    }
    hidden Hid3 [100] from Conv2 all;
    output Digit [10] from Hid3 all;  


* <span data-ttu-id="4cac8-362">Структура имеет один входной слой — *Image*.</span><span class="sxs-lookup"><span data-stu-id="4cac8-362">The structure has a single input layer, *Image*.</span></span>
* <span data-ttu-id="4cac8-363">Ключевое слово **convolve** указывает, что *Conv1* и *Conv2* — это сверточные слои.</span><span class="sxs-lookup"><span data-stu-id="4cac8-363">The keyword **convolve** indicates that the layers named *Conv1* and *Conv2* are convolutional layers.</span></span> <span data-ttu-id="4cac8-364">За объявлением каждого из этих слоев следует список атрибутов свертки.</span><span class="sxs-lookup"><span data-stu-id="4cac8-364">Each of these layer declarations is followed by a list of the convolution attributes.</span></span>
* <span data-ttu-id="4cac8-365">У сети имеется третий скрытый слой *Hid3*, который полностью подключен ко второму скрытому слою *Conv2*.</span><span class="sxs-lookup"><span data-stu-id="4cac8-365">The net has a third hidden layer, *Hid3*, which is fully connected to the second hidden layer, *Conv2*.</span></span>
* <span data-ttu-id="4cac8-366">Выходной слой *Digit* подключен к третьему скрытому слою *Hid3*.</span><span class="sxs-lookup"><span data-stu-id="4cac8-366">The output layer, *Digit*, is connected only to the third hidden layer, *Hid3*.</span></span> <span data-ttu-id="4cac8-367">Ключевое слово **all** указывает, что выходной слой полностью подключен к *Hid3*.</span><span class="sxs-lookup"><span data-stu-id="4cac8-367">The keyword **all** indicates that the output layer is fully connected to *Hid3*.</span></span>
* <span data-ttu-id="4cac8-368">Арность свертки: 3 (длина кортежей **InputShape**, **KernelShape**, **Stride** и **Sharing**).</span><span class="sxs-lookup"><span data-stu-id="4cac8-368">The arity of the convolution is three (the length of the tuples **InputShape**, **KernelShape**, **Stride**, and **Sharing**).</span></span> 
* <span data-ttu-id="4cac8-369">Число весов на ядро: *1 + **KernelShape**\[0] * **KernelShape**\[1] * **KernelShape**\[2] = 1 + 1 * 5 * 5 = 26. Или 26 * 50 = 1300*.</span><span class="sxs-lookup"><span data-stu-id="4cac8-369">The number of weights per kernel is *1 + **KernelShape**\[0] * **KernelShape**\[1] * **KernelShape**\[2] = 1 + 1 * 5 * 5 = 26. Or 26 * 50 = 1300*.</span></span>
* <span data-ttu-id="4cac8-370">Количество узлов в каждом скрытом слое можно вычислить следующим образом:</span><span class="sxs-lookup"><span data-stu-id="4cac8-370">You can calculate the nodes in each hidden layer as follows:</span></span>
  * <span data-ttu-id="4cac8-371">**NodeCount**\[0] = (5 - 1) / 1 + 1 = 5.</span><span class="sxs-lookup"><span data-stu-id="4cac8-371">**NodeCount**\[0] = (5 - 1) / 1 + 1 = 5.</span></span>
  * <span data-ttu-id="4cac8-372">**NodeCount**\[1] = (13 - 5) / 2 + 1 = 5.</span><span class="sxs-lookup"><span data-stu-id="4cac8-372">**NodeCount**\[1] = (13 - 5) / 2 + 1 = 5.</span></span> 
  * <span data-ttu-id="4cac8-373">**NodeCount**\[2] = (13 - 5) / 2 + 1 = 5.</span><span class="sxs-lookup"><span data-stu-id="4cac8-373">**NodeCount**\[2] = (13 - 5) / 2 + 1 = 5.</span></span> 
* <span data-ttu-id="4cac8-374">Общее число узлов можно определить, используя объявленную размерность слоя [50, 5, 5]: ***MapCount**  *  **NodeCount**\[0] * **NodeCount**\[1] * **NodeCount**\[2] = 10 * 5 * 5 * 5*</span><span class="sxs-lookup"><span data-stu-id="4cac8-374">The total number of nodes can be calculated by using the declared dimensionality of the layer, [50, 5, 5], as follows: ***MapCount** * **NodeCount**\[0] * **NodeCount**\[1] * **NodeCount**\[2] = 10 * 5 * 5 * 5*</span></span>
* <span data-ttu-id="4cac8-375">Так как **Sharing**[d] имеет значение False только для *d == 0*, число ядер равно ***MapCount**  *  **NodeCount**\[0] = 10 * 5 = 50*.</span><span class="sxs-lookup"><span data-stu-id="4cac8-375">Because **Sharing**[d] is False only for *d == 0*, the number of kernels is ***MapCount** * **NodeCount**\[0] = 10 * 5 = 50*.</span></span> 

## <a name="acknowledgements"></a><span data-ttu-id="4cac8-376">Благодарности</span><span class="sxs-lookup"><span data-stu-id="4cac8-376">Acknowledgements</span></span>
<span data-ttu-id="4cac8-377">Язык Net# для изменения архитектуры нейронных сетей был разработан в корпорации Майкрософт Шоном Катценбергером Shon Katzenberger (архитектор, машинное обучение) и Алексеем Каменевым (разработчик программного обеспечения, Microsoft Research).</span><span class="sxs-lookup"><span data-stu-id="4cac8-377">The Net# language for customizing the architecture of neural networks was developed at Microsoft by Shon Katzenberger (Architect, Machine Learning) and Alexey Kamenev (Software Engineer, Microsoft Research).</span></span> <span data-ttu-id="4cac8-378">Он используется внутри компании для проектов машинного обучения и различных приложений от приложений распознавания образов до приложений анализа текста.</span><span class="sxs-lookup"><span data-stu-id="4cac8-378">It is used internally for machine learning projects and applications ranging from image detection to text analytics.</span></span> <span data-ttu-id="4cac8-379">Дополнительные сведения см. в статье [Neural Nets in Azure ML – Introduction to Net#](http://blogs.technet.com/b/machinelearning/archive/2015/02/16/neural-nets-in-azure-ml-introduction-to-net.aspx) (Нейронные сети в машинном обучении Azure. Введение в Net#)</span><span class="sxs-lookup"><span data-stu-id="4cac8-379">For more information, see [Neural Nets in Azure ML - Introduction to Net#](http://blogs.technet.com/b/machinelearning/archive/2015/02/16/neural-nets-in-azure-ml-introduction-to-net.aspx)</span></span>

<span data-ttu-id="4cac8-380">[1]:./media/machine-learning-azure-ml-netsharp-reference-guide/formula_large.gif</span><span class="sxs-lookup"><span data-stu-id="4cac8-380">[1]:./media/machine-learning-azure-ml-netsharp-reference-guide/formula_large.gif</span></span>

