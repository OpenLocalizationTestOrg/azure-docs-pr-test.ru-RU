---
title: "Параметры контекста вычислений для R Server в HDInsight — Azure | Документы Майкрософт"
description: "Сведения о разных вариантах контекста вычислений, доступных для пользователей R Server в HDInsight."
services: HDInsight
documentationcenter: 
author: bradsev
manager: jhubbard
editor: cgronlun
ms.assetid: 0deb0b1c-4094-459b-94fc-ec9b774c1f8a
ms.service: HDInsight
ms.custom: hdinsightactive
ms.devlang: R
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: data-services
ms.date: 06/19/2017
ms.author: bradsev
ms.openlocfilehash: 4c839bf0c39bf10855f8a31770b82a04ed1ca457
ms.sourcegitcommit: 7136d06474dd20bb8ef6a821c8d7e31edf3a2820
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 12/05/2017
---
# <a name="compute-context-options-for-r-server-on-hdinsight"></a>Варианты контекста вычислений для R Server в HDInsight

Microsoft R Server в Azure HDInsight управляет выполнением вызовов, задавая контекст вычисления. В этой статье приведены параметры, которые доступны для указания необходимости и способа выполнения параллелизации между ядрами граничного узла или кластера HDInsight.

Для подключения к кластеру и выполнения скриптов на языке R удобно использовать граничный узел кластеров. На граничном узле вы можете выполнять распараллеленные распределенные функции ScaleR на ядрах сервера граничного узла. Кроме того, вы можете выполнять эти функции на узлах кластера с помощью контекста вычислений Hadoop Map Reduce или Spark ScaleR.

## <a name="microsoft-r-server-on-azure-hdinsight"></a>Microsoft R Server в Azure HDInsight
[Microsoft R Server в кластере Azure HDInsight](r-server-overview.md) предоставляет новейшие возможности для анализа на основе R. Это решение может использовать данные, хранящиеся в контейнере HDFS, размещенном в учетной записи хранения [BLOB-объектов Azure](../../storage/common/storage-introduction.md "хранилище BLOB-объектов Azure"), Data Lake Store или локальной файловой системе Linux. Так как R Server основывается на R с открытым кодом, вы сможете использовать в своих приложениях на основе R любые из более чем 8000 пакетов R с открытым исходным кодом. Также вы можете использовать подпрограммы [RevoScaleR](https://msdn.microsoft.com/microsoft-r/scaler/scaler), пакета аналитики больших данных от корпорации Майкрософт, который предоставляется вместе с R Server.  

## <a name="compute-contexts-for-an-edge-node"></a>Контексты вычислений для граничного узла
Как правило, сценарий R, выполняемый на R Server на граничном узле, выполняется в интерпретаторе R на этом узле. Исключением являются те действия, которые вызывают функцию ScaleR. Вызовы ScaleR будут осуществляться в среде вычислений с учетом настройки контекста вычислений ScaleR.  При выполнении скрипта R из граничного узла возможны следующие значения контекста вычислений:

- локальный последовательный (*local*);
- локальный параллельный (*localpar*);
- Map Reduce
- Spark

Значения *local* и *localpar* отличаются только способом выполнения вызовов **rxExec**. Они оба выполняют другие вызовы функций RX параллельно по всем доступным ядрам, если только не указаны другие действия посредством параметра ScaleR **numCoresToUse**, например `rxOptions(numCoresToUse=6)`. Параметры параллельного выполнения обеспечивают оптимальную производительность.

В таблице ниже приведена сводка различных параметров контекста вычислений, определяющих способ выполнения вызовов.

| Контекст вычислений  | Метод настройки                      | Контекст выполнения                        |
| ---------------- | ------------------------------- | ---------------------------------------- |
| Локальный последовательный | rxSetComputeContext('local')    | Распараллеленное выполнение во всех ядрах сервера граничного узла, за исключением вызовов rxExec, которые выполняются последовательно. |
| Локальный параллельный   | rxSetComputeContext('localpar') | Распараллеленное выполнение во всех ядрах сервера граничного узла. |
| Spark            | RxSpark()                       | Распараллеленное распределенное выполнение с использованием Spark во всех узлах кластера HDI |
| Map Reduce       | RxHadoopMR()                    | Распараллеленное распределенное выполнение с использованием Map Reduce во всех узлах кластера HDI |

## <a name="guidelines-for-deciding-on-a-compute-context"></a>Рекомендации по выбору контекста вычислений

Выбор варианта распараллеленного выполнения зависит от характера задач анализа, а также размера и местонахождения данных. Простого правила для выбора контекста вычислений нет. Однако есть некоторые базовые принципы, которые помогут вам определиться или хотя бы сузить выбор еще до запуска теста производительности. К ним относятся следующие:

- Локальная файловая система Linux работает быстрее, чем HDFS.
- Повторный анализ выполняется быстрее для данных в локальной среде, особенно в формате XDF.
- Из текстовых источников данных желательно передавать небольшие объемы данных. Если данные имеют большой объем, преобразуйте их в формат XDF перед анализом.
- При копировании или потоковой передаче на граничный узел больших объемов данных для анализа нагрузка быстро становится запредельной.
- Spark работает быстрее, чем MapReduce для анализа в Hadoop.

С учетом этих принципов в следующем разделе приведены некоторые общие правила выбора контекста вычислений.

### <a name="local"></a>Local
* Если нужно проанализировать данные небольшого объема и не требуется повторный анализ, их следует направить потоком прямо в подпрограмму анализа и использовать контекст *local* или *localpar*.
* Если нужно проанализировать данные небольшого или среднего объема, для которых потребуется повторный анализ, скопируйте их в локальную файловую систему, импортируйте в XDF-формат и проанализируйте в контексте *local* или *localpar*.

### <a name="hadoop-spark"></a>Hadoop Spark
* Если нужно проанализировать большой объем данных, импортируйте их в Spark DataFrame с помощью **RxHiveData** или **RxParquetData** либо в XDF-файл в файловой системе HDFS (при наличии достаточного пространства для хранения) и проанализируйте эти данные в контексте вычислений Spark.

### <a name="hadoop-map-reduce"></a>Hadoop Map Reduce
* Используйте контекст вычислений Map Reduce только для проблем, которые не решаются с использованием контекста вычислений Spark из-за снижения производительности.  

## <a name="inline-help-on-rxsetcomputecontext"></a>Встроенная справка по rxSetComputeContext
Чтобы получить дополнительные сведения по контекстам вычислений ScaleR с соответствующими примерами, воспользуйтесь встроенной справкой в консоли R с помощью метода rxSetComputeContext, например:

    > ?rxSetComputeContext

Можно также просмотреть [руководство по распределенным вычислениям ScaleR](https://msdn.microsoft.com/microsoft-r/scaler-distributed-computing), доступное в библиотеке [R Server MSDN](https://msdn.microsoft.com/library/mt674634.aspx).

## <a name="next-steps"></a>Дальнейшие действия
В этой статье вы ознакомились с параметрами, которые доступны для указания необходимости и способа выполнения параллелизации между ядрами граничного узла или кластера HDInsight. Дополнительные сведения об использовании R Server для работы с кластерами HDInsight см. в следующих статьях:

* [Общие сведения об R Server в HDInsight (предварительная версия)](r-server-overview.md)
* [Приступая к работе с R Server в HDInsight (предварительная версия)](r-server-get-started.md)
* [Параметры службы хранилища Azure для R Server в HDInsight (предварительная версия)](r-server-storage.md)

