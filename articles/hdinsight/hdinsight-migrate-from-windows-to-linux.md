---
title: "Миграция из кластера HDInsight под управлением Windows в кластер HDInsight под управлением Linux в Azure | Документы Майкрософт"
description: "Узнайте, как выполнить миграцию из кластера HDInsight под управлением Windows на кластер HDInsight под управлением Linux."
services: hdinsight
documentationcenter: 
author: Blackmist
manager: jhubbard
editor: cgronlun
ms.assetid: ff35be59-bae3-42fd-9edc-77f0041bab93
ms.service: hdinsight
ms.custom: hdinsightactive
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 12/05/2017
ms.author: larryfr
ms.openlocfilehash: 764a41dc9e890de85c3bfab3d2f78d5a07b39dff
ms.sourcegitcommit: a48e503fce6d51c7915dd23b4de14a91dd0337d8
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 12/05/2017
---
# <a name="migrate-from-a-windows-based-hdinsight-cluster-to-a-linux-based-cluster"></a>Миграция из кластера HDInsight под управлением Windows на кластер под управлением Linux

Этот документ содержит сведения о различиях между HDInsight в Windows и Linux. Он также включает в себя инструкции по переносу существующих рабочих нагрузок в кластер под управлением Linux.

Хотя HDInsight на основе Windows упрощает использование Hadoop в облаке, вам может потребоваться перейти на кластер под управлением Linux. Например, чтобы воспользоваться преимуществами инструментов и технологий на основе Linux, которые необходимы для вашего решения. Многие компоненты в экосистеме Hadoop разрабатываются в системах под управлением Linux, и они могут быть недоступны в HDInsight под управлением Windows. Во многих книгах, видеороликах и других учебных материалах предполагается, что при работе с Hadoop вы используете Linux.

> [!NOTE]
> В кластерах HDInsight в качестве операционной системы узлов используется Ubuntu Long Term Support (LTS). Сведения о версии Ubuntu с поддержкой HDInsight, а также другие сведения об управлении версиями компонента см. в описании [версий компонента HDInsight](hdinsight-component-versioning.md).

## <a name="migration-tasks"></a>Задачи миграции

Общий рабочий процесс для миграции выглядит следующим образом.

![Схема рабочего процесса миграции](./media/hdinsight-migrate-from-windows-to-linux/workflow.png)

1. Ознакомьтесь со всеми разделами этого документа. В них описаны изменения, внести которые может потребоваться при переносе.

2. Создайте кластер под управлением Linux как среду тестирования и контроля качества. Дополнительные сведения о создании кластера под управлением Linux см. в статье [Создание кластеров под управлением Linux в HDInsight](hdinsight-hadoop-provision-linux-clusters.md).

3. Скопируйте в новую среду существующие задания, источники данных и приемники.

4. Выполните проверочное тестирование, чтобы убедиться, что задания должным образом работают новом кластере.

Убедившись, что все работает правильно, запланируйте время простоя для миграции. Во время этого простоя выполните следующие действия.

1. Создайте резервную копию всех временных данных, хранящихся локально на узлах кластера. Например, к ним могут относиться данные, которые хранятся непосредственно на головном узле.

2. Удалите кластер под управлением Windows.

3. Создайте кластер под управлением Linux, используя то же хранилище данных по умолчанию, которое использовалось кластером под управлением Windows. Кластер Linux может продолжить работу с существующими рабочими данными.

4. Импортируйте все временные данные из резервной копии.

5. Запустите задания и продолжите обработку с помощью нового кластера.

### <a name="copy-data-to-the-test-environment"></a>Копирование данных в среду тестирования

Существует множество методов для копирования данных и заданий. В этом разделе рассматриваются два простейших метода перемещения файлов непосредственно в кластер тестирования.

#### <a name="hdfs-copy"></a>Копирование HDFS

Чтобы скопировать данные из рабочего кластера в тестовый кластер, выполните приведенные ниже действия. Для их выполнения используется служебная программа `hdfs dfs`, которая входит в состав HDInsight.

1. Определите учетную запись хранения и контейнер по умолчанию для существующего кластера. В следующем примере для извлечения этой информации используется PowerShell.

    ```powershell
    $clusterName="Your existing HDInsight cluster name"
    $clusterInfo = Get-AzureRmHDInsightCluster -ClusterName $clusterName
    write-host "Storage account name: $clusterInfo.DefaultStorageAccount.split('.')[0]"
    write-host "Default container: $clusterInfo.DefaultStorageContainer"
    ```

2. Чтобы создать среду тестирования, выполните действия, описанные в документе "Создание кластеров под управлением Linux в HDInsight". Остановитесь перед созданием кластера и вместо этого выберите **Необязательная конфигурация**.

3. В разделе "Необязательная конфигурация" выберите **Связанные учетные записи хранения**.

4. Выберите **Добавить ключ к хранилищу данных**и при появлении запроса выберите учетную запись хранения, которая была определена с помощью сценария PowerShell на шаге 1. Щелкните **Выбрать** в каждом разделе. Наконец, создайте кластер.

5. После создания кластера подключитесь к нему с помощью протокола **SSH**. Дополнительные сведения см. в статье [Использование SSH с Hadoop на основе Linux в HDInsight из Linux, Unix или OS X](hdinsight-hadoop-linux-use-ssh-unix.md).

6. В сеансе SSH используйте следующую команду для копирования файлов из связанной учетной записи хранения в новую учетную запись хранения по умолчанию. Замените CONTAINER данными контейнера, возвращенными PowerShell. Замените __ACCOUNT__ именем учетной записи. Замените путь к данным на путь к файлу данных.

    ```bash
    hdfs dfs -cp wasb://CONTAINER@ACCOUNT.blob.core.windows.net/path/to/old/data /path/to/new/location
    ```

    > [!NOTE]
    > Если структура каталогов, которая содержит данные, не существует в тестовой среде, ее можно создать с помощью следующей команды.

    ```bash
    hdfs dfs -mkdir -p /new/path/to/create
    ```

    При указании параметра `-p` будут созданы все каталоги в пути.

#### <a name="direct-copy-between-blobs-in-azure-storage"></a>Прямое копирование между большими двоичными объектами в службе хранилища Azure

При желании также можно использовать командлет Azure PowerShell `Start-AzureStorageBlobCopy`, чтобы скопировать большие двоичные объекты между учетными записями хранения вне HDInsight. Дополнительные сведения см. в разделе "Управление большими двоичными объектами Azure" статьи "Использование Azure PowerShell с хранилищем Azure".

## <a name="client-side-technologies"></a>Технологии на стороне клиента

Клиентские технологии, в том числе [командлеты Azure PowerShell](/powershell/azureps-cmdlets-docs), [Azure CLI](../cli-install-nodejs.md) или [пакет SDK .NET для Hadoop](https://hadoopsdk.codeplex.com/), продолжают работать в кластерах Linux. Эти технологии основаны на интерфейсах REST API, которые одинаковы для обоих типов ОС кластера.

## <a name="server-side-technologies"></a>Технологии на стороне сервера

В следующей таблице приведены рекомендации по переносу серверных компонентов, относящихся к Windows.

| Если вы используете эту технологию... | Выполните это действие... |
| --- | --- |
| **PowerShell** (сценарии на стороне сервера, включая действия сценариев, используемые во время создания кластера) |Перепишите эти сценарии как скрипты Bash. Сведения о действиях сценариев см. в разделах [Настройка кластеров HDInsight под управлением Linux с помощью действия сценария](hdinsight-hadoop-customize-cluster-linux.md) и [Разработка действий сценариев с помощью HDInsight](hdinsight-hadoop-script-actions-linux.md). |
| **Azure CLI** (сценарии на стороне сервера) |Хотя интерфейс командной строки Azure доступен в Linux, он не предустановлен на головных узлах кластера HDInsight. Дополнительные сведения об установке Azure CLI см. в статье [Get started with Azure CLI 2.0](https://docs.microsoft.com/cli/azure/get-started-with-azure-cli) (Приступая к работе с Azure CLI 2.0). |
| **Компоненты .NET** |.NET поддерживается в кластерах HDInsight под управлением Linux посредством [Mono](https://mono-project.com). Дополнительные сведения см. в разделе [Перенос решений .NET из HDInsight под управлением Windows в HDInsight под управлением Linux](hdinsight-hadoop-migrate-dotnet-to-linux.md). |
| **Компоненты Win32 или другая технология, которая существует только для Windows** |Точные действия зависят от компонента или технологии. Возможно, вы сможете найти версию, совместимую с Linux. В противном случае необходимо найти альтернативное решение или повторно создать этот компонент. |

> [!IMPORTANT]
> Пакет SDK для управления HDInsight не полностью совместим с Mono. Не используйте его как часть решений, которые развертываются в кластер HDInsight.

## <a name="cluster-creation"></a>Создание кластера

В этом разделе приведены сведения о различиях при создании кластера.

### <a name="ssh-user"></a>Пользователь SSH

Кластеры HDInsight под управлением Linux используют протокол **Secure Shell (SSH)** для предоставления удаленного доступа к узлам кластера. В отличие клиентов удаленного рабочего стола для кластеров Windows, большинство SSH-клиентов не обеспечивает графический пользовательский интерфейс. Вместо этого SSH-клиенты предоставляют командную строку, которая позволяет выполнять команды в кластере. Некоторые клиенты (например, [MobaXterm](http://mobaxterm.mobatek.net/)) в дополнение к удаленной командной строке предоставляют графический проводник файловой системы.

Во время создания кластера необходимо указать имя пользователя SSH и **пароль** или **сертификат открытого ключа** для аутентификации.

Мы рекомендуем использовать сертификат открытого ключа, так как он более безопасен по сравнению с паролем. При использовании сертификата создается пара подписанных ключей (открытый и закрытый), после чего открытый ключ указывается при создании кластера. При подключении к серверу с помощью SSH проверка подлинности подключения выполняется с помощью закрытого ключа на клиентском компьютере.

Дополнительные сведения см. в статье [Использование SSH с Hadoop на основе Linux в HDInsight из Linux, Unix или OS X](hdinsight-hadoop-linux-use-ssh-unix.md).

### <a name="cluster-customization"></a>Настройка кластера

**Действия сценария**, используемые в кластерах под управлением Linux, должны быть записаны в сценарий Bash. Для кластеров на основе Linux можно использовать действия сценариев, выполняемые во время или после создания кластера. Дополнительные сведения см. в разделах [Настройка кластеров HDInsight под управлением Linux с помощью действия сценария](hdinsight-hadoop-customize-cluster-linux.md) и [Разработка действий сценариев с помощью HDInsight](hdinsight-hadoop-script-actions-linux.md).

Еще одна возможность настройки — **начальная загрузка**. Для кластеров Windows эта функция позволяет указать расположение дополнительных библиотек для использования с Hive. После создания кластера эти библиотеки автоматически становятся доступными для Hive без необходимости использования `ADD JAR`.

Для кластеров под управлением Linux функция начальной загрузки не предоставляет такой возможности. Вместо этого используйте действие сценария, указанное в статье [Добавление библиотек Hive во время создания кластера HDInsight](hdinsight-hadoop-add-hive-libraries.md).

### <a name="virtual-networks"></a>Виртуальные сети

Кластеры HDInsight под управлением Windows работают только с классическими виртуальными сетями, а для кластеров HDInsight под управлением Linux требуются виртуальные сети Resource Manager. Если в классической виртуальной сети имеются ресурсы, к которым должен подключаться кластер HDInsight под управлением Linux, обратитесь к разделу [Подключение классических виртуальных сетей к новым виртуальным сетям](../vpn-gateway/vpn-gateway-connect-different-deployment-models-portal.md).

Дополнительные сведения о требованиях к конфигурации см. в документе [Расширение возможностей HDInsight с помощью виртуальной сети Azure](hdinsight-extend-hadoop-virtual-network.md).

## <a name="management-and-monitoring"></a>Управление и мониторинг

Многие веб-интерфейсы, которыми вы могли пользоваться в HDInsight под управлением Windows, например журнал заданий или пользовательский интерфейс Yarn, доступны в Ambari. Кроме того, представление Hive Ambari позволяет выполнять запросы Hive с помощью веб-браузера. Пользовательский веб-интерфейс Ambari доступен в кластерах HDInsight на платформе Linux по адресу: https://CLUSTERNAME.azurehdinsight.net.

Дополнительные сведения о работе с Ambari см. в следующих документах:

* [Веб-интерфейс Ambari](hdinsight-hadoop-manage-ambari.md)
* [Ambari REST API](hdinsight-hadoop-manage-ambari-rest-api.md)

### <a name="ambari-alerts"></a>Предупреждения Ambari

Ambari имеет систему предупреждений, которые могут сообщить вам о возможных проблемах с кластером. Предупреждения выделяются красным или желтым цветом в веб-интерфейсе Ambari. Их также можно получить с помощью интерфейса API REST.

> [!IMPORTANT]
> Предупреждения Ambari указывают на то, что проблема *возможна*, а не на то, что она уже *присутствует*. Например, может появиться предупреждение о том, что сервер HiveServer2 недоступен. При этом вы можете обратиться к нему обычным образом.
>
> Многие предупреждения реализованы в качестве запросов к службе и ожидают ответа в течение определенного промежутка времени. Поэтому предупреждение не обязательно означает, что служба не работает — оно означает лишь то, что служба не возвратила результаты в течение ожидаемого интервала времени.

## <a name="file-system-locations"></a>Структура файловой системы

Для кластеров под управлением Linux структура файловой системы отличается от кластеров HDInsight под управлением Windows. Используйте следующую таблицу для поиска часто используемых файлов.

| Необходимо найти... | Это находится в папке... |
| --- | --- |
| Конфигурация |`/etc`. Например, `/etc/hadoop/conf/core-site.xml` |
| Файлы журналов |`/var/logs` |
| Платформа данных Hortonworks Data Platform (HDP) |`/usr/hdp`. Здесь расположены два каталога — каталог с текущей версией HDP и каталог `current`. Каталог `current` содержит символьные ссылки на файлы и папки, размещенные в каталоге номера версии. Каталог `current` предоставляется для удобного доступа к файлам HDP, так как при обновлении версии HDP номер версии меняется. |
| hadoop-streaming.jar |`/usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming.jar` |

В общем случае, если вам известно имя файла, можно выполнить следующую команду в сеансе SSH, чтобы определить путь к файлу:

    find / -name FILENAME 2>/dev/null

В имени файла также можно использовать подстановочные знаки. Например, `find / -name *streaming*.jar 2>/dev/null` возвращает путь ко всем JAR-файлам, содержащим слово streaming в имени файла.

## <a name="hive-pig-and-mapreduce"></a>Hive, Pig и MapReduce

Рабочие нагрузки Pig и MapReduce на кластерах Linux похожи. Однако кластеры HDInsight под управлением Linux можно создать с помощью более новых версий Hadoop, Hive и Pig. Эти отличия версий могут повлиять на функционирование существующих решений. Дополнительные сведения о версиях компонентов в составе HDInsight см. в разделе [Что представляют собой различные компоненты Hadoop, доступные в HDInsight?](hdinsight-component-versioning.md)

Кластеры HDInsight под управлением Linux не предоставляют функцию удаленного рабочего стола. Вместо этого можно использовать протокол SSH для удаленного подключения к головным узлам кластера. Дополнительные сведения см. в следующих документах:

* [Использование Hive с Hadoop в HDInsight с применением Beeline](hdinsight-hadoop-use-hive-ssh.md)
* [Использование Pig с SSH](hadoop/apache-hadoop-use-pig-ssh.md)
* [Использование MapReduce с SSH](hadoop/apache-hadoop-use-mapreduce-ssh.md)

### <a name="hive"></a>Hive

> [!IMPORTANT]
> При использовании внешнего хранилища метаданных Hive следует создать резервную копию этого хранилища, прежде чем использовать его с HDInsight под управлением Linux. В HDInsight под управлением Linux используются более новые версии Hive, что может привести к проблемам совместимости с хранилищами метаданных, созданными с использованием предыдущих версий.

Следующая схема содержит рекомендации по переносу рабочих нагрузок Hive.

| В кластерах под управлением Windows я пользуюсь... | В кластерах под управлением Linux... |
| --- | --- |
| **редактор Hive;** |[используйте представление Hive в Ambari](hadoop/apache-hadoop-use-hive-ambari-view.md) |
| `set hive.execution.engine=tez;` для включения Tez. |Tez — ядро выполнения по умолчанию для кластеров под управлением Linux, поэтому инструкция set больше не требуется. |
| Определяемые пользователем функции C# | Сведения о проверке компонентов C# с помощью HDInsight под управлением Linux см. в разделе [Перенос решений .NET из HDInsight под управлением Windows в HDInsight под управлением Linux](hdinsight-hadoop-migrate-dotnet-to-linux.md). |
| CMD-файлами или сценариями на сервере, вызываемыми как часть задания Hive |используйте скрипты Bash |
| `hive` из удаленного рабочего стола. |используйте [Beeline](hadoop/apache-hadoop-use-hive-beeline.md) или [Hive из сеанса SSH](hdinsight-hadoop-use-hive-ssh.md). |

### <a name="pig"></a>Pig,

| В кластерах под управлением Windows я пользуюсь... | В кластерах под управлением Linux... |
| --- | --- |
| Определяемые пользователем функции C# | Сведения о проверке компонентов C# с помощью HDInsight под управлением Linux см. в разделе [Перенос решений .NET из HDInsight под управлением Windows в HDInsight под управлением Linux](hdinsight-hadoop-migrate-dotnet-to-linux.md). |
| CMD-файлы или сценарии на сервере, вызываемые как часть задания Hive |используйте скрипты Bash |

### <a name="mapreduce"></a>MapReduce

| В кластерах под управлением Windows я пользуюсь... | В кластерах под управлением Linux... |
| --- | --- |
| Компоненты C# для сопоставления и редукции | Сведения о проверке компонентов C# с помощью HDInsight под управлением Linux см. в разделе [Перенос решений .NET из HDInsight под управлением Windows в HDInsight под управлением Linux](hdinsight-hadoop-migrate-dotnet-to-linux.md). |
| CMD-файлами или сценариями на сервере, вызываемыми как часть задания Hive |используйте скрипты Bash |

## <a name="oozie"></a>Oozie

> [!IMPORTANT]
> При использовании внешнего хранилища метаданных Oozie следует создать резервную копию этого хранилища, прежде чем использовать его с HDInsight под управлением Linux. В HDInsight под управлением Linux используются более новые версии Oozie, что может привести к проблемам совместимости с хранилищами метаданных, созданными с использованием предыдущих версий.

Рабочие процессы Oozie позволяют использовать действия оболочки. Эти действия используют оболочку по умолчанию операционной системы для выполнения команд командной строки. Если имеются рабочие процессы Oozie, зависящие от оболочки Windows, необходимо переписать их, использовав оболочку Linux (Bash). Дополнительные сведения об использовании действий оболочки с Oozie см. в разделе [Oozie shell action extension](http://oozie.apache.org/docs/3.3.0/DG_ShellActionExtension.html) (Расширение действий оболочки Oozie).

Если у вас есть рабочий процесс, который использует приложение C#, проверьте эти приложения в среде Linux. Дополнительные сведения см. в разделе [Перенос решений .NET из HDInsight под управлением Windows в HDInsight под управлением Linux](hdinsight-hadoop-migrate-dotnet-to-linux.md).

## <a name="storm"></a>Storm

| В кластерах под управлением Windows я пользуюсь... | В кластерах под управлением Linux... |
| --- | --- |
| Панель мониторинга Storm |Панель мониторинга Storm недоступна. Сведения об отправке топологий приведены в разделе [Развертывание и управление топологиями Storm в HDInsight под управлением Linux](storm/apache-storm-deploy-monitor-topology-linux.md) . |
| Пользовательский интерфейс Storm |Пользовательский интерфейс Storm доступен по адресу https://CLUSTERNAME.azurehdinsight.net/stormui. |
| Visual Studio для создания, развертывания и управления C# или гибридными топологиями |Visual Studio можно использовать для создания, развертывания топологий C# (SCP.NET) или гибридных топологий и управления ими в кластерах Storm в HDInsight под управлением Linux. Visual Studio можно использовать только для кластеров, созданных после 28 октября 2016 года. |

## <a name="hbase"></a>HBase

На кластерах под управлением Linux родительским Z-узлом для HBase является `/hbase-unsecure`. Задайте это значение в конфигурации для всех клиентских приложений Java, которые используют собственный API Java для HBase.

Пример клиента, который устанавливает это значение, см. в разделе [Использование Maven для сборки приложений Java, которые используют HBase с HDInsight (Hadoop)](hdinsight-hbase-build-java-maven.md).

## <a name="spark"></a>Spark

Кластеры Spark были доступны в кластерах Windows на этапе предварительной версии. Общедоступная версия Spark доступна только в кластерах Linux. Способа миграции кластера Spark под управлением Windows в предварительной версии в кластер Spark под управлением Linux основной версии не существует.

## <a name="known-issues"></a>Известные проблемы

### <a name="azure-data-factory-custom-net-activities"></a>Пользовательские действия .NET фабрики данных Azure

Пользовательские действия .NET фабрики данных Azure в настоящее время не поддерживаются в кластерах HDInsight под управлением Linux. Вместо этого следует использовать один из следующих методов для реализации пользовательских действий в рамках конвейера ADF.

* Выполните действия .NET в пуле пакетной службы Azure. Ознакомьтесь с разделом "Использование связанной пакетной службы Azure" статьи [Использование настраиваемых действий в конвейере фабрики данных Azure](../data-factory/transform-data-using-dotnet-custom-activity.md).
* Реализуйте действие как действие MapReduce. Дополнительные сведения см. в разделе [Вызов программы MapReduce из фабрики данных](../data-factory/transform-data-using-hadoop-map-reduce.md).

### <a name="line-endings"></a>Символы конца строки

Как правило, в качестве символов конца строки в Windows используется CRLF, а в Linux — LF. Может потребоваться изменить существующие поставщики и объекты-получатели данных для работы с LF.

Например, при выполнении запроса к HDInsight с использованием Azure PowerShell в кластере под управлением Windows будут возвращены данные с символами конца строки CRLF. Тот же запрос к кластеру под управлением Linux возвратит данные с символами конца строки LF. Проверьте, вызывает ли символ конца строки ошибки в работе решения, прежде чем переходить на кластер Linux.

Всегда используйте LF в конце строки в сценариях, запускаемых на узлах кластера. Если использовать CRLF, могут возникнуть ошибки при выполнении сценариев в кластере под управлением Linux.

Если в сценариях нет строк, содержащих встроенные знаки CR, можно выполнить массовую замену символов конца строк с помощью одного из следующих методов.

* **Перед передачей в кластер**: используйте следующие инструкции PowerShell для замены символов конца строк с CRLF на LF перед передачей сценариев в кластер.

    ```powershell
    $original_file ='c:\path\to\script.py'
    $text = [IO.File]::ReadAllText($original_file) -replace "`r`n", "`n"
    [IO.File]::WriteAllText($original_file, $text)
    ```

* **После передачи в кластер**: используйте приведенную ниже команду в сеансе SSH-подключения к кластеру Linux для изменения сценария.

    ```bash
    hdfs dfs -get wasb:///path/to/script.py oldscript.py
    tr -d '\r' < oldscript.py > script.py
    hdfs dfs -put -f script.py wasb:///path/to/script.py
    ```

## <a name="next-steps"></a>Дальнейшие действия

* [Узнайте, как создавать кластеры HDInsight под управлением Linux](hdinsight-hadoop-provision-linux-clusters.md)
* [Подключитесь к HDInsight с помощью протокола SSH](hdinsight-hadoop-linux-use-ssh-unix.md).
* [Выполняйте управление кластером под управлением Linux с помощью Ambari](hdinsight-hadoop-manage-ambari.md)
