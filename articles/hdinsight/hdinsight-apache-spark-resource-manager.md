---
title: "Управление ресурсами для кластера Apache Spark в Azure HDInsight | Документы Майкрософт"
description: "Узнайте, как управлять ресурсами для кластеров Spark в Azure HDInsight для повышения производительности."
services: hdinsight
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: 9da7d4e3-458e-4296-a628-77b14643f7e4
ms.service: hdinsight
ms.custom: hdinsightactive
ms.workload: big-data
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 07/21/2017
ms.author: nitinme
ms.openlocfilehash: 952fa15162a40bccb3f8c7a88508556757ca6675
ms.sourcegitcommit: 02e69c4a9d17645633357fe3d46677c2ff22c85a
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 08/03/2017
---
# <a name="manage-resources-for-apache-spark-cluster-on-azure-hdinsight"></a><span data-ttu-id="f28be-103">Управление ресурсами для кластера Apache Spark в Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="f28be-103">Manage resources for Apache Spark cluster on Azure HDInsight</span></span> 

<span data-ttu-id="f28be-104">Из этой статьи вы узнаете, как получать доступ к разным интерфейсам, связанным с кластером Spark, включая пользовательский интерфейс Ambari, пользовательский интерфейс YARN и сервер журнала Spark.</span><span class="sxs-lookup"><span data-stu-id="f28be-104">In this article you will learn how to access the interfaces like Ambari UI, YARN UI, and the Spark History Server associated with your Spark cluster.</span></span> <span data-ttu-id="f28be-105">Также вы узнаете, как настроить конфигурацию кластера для оптимальной производительности.</span><span class="sxs-lookup"><span data-stu-id="f28be-105">You will also learn about how to tune the cluster configuration for optimal performance.</span></span>

<span data-ttu-id="f28be-106">**Предварительные требования:**</span><span class="sxs-lookup"><span data-stu-id="f28be-106">**Prerequisites:**</span></span>

<span data-ttu-id="f28be-107">Необходимо следующее:</span><span class="sxs-lookup"><span data-stu-id="f28be-107">You must have the following:</span></span>

* <span data-ttu-id="f28be-108">Подписка Azure.</span><span class="sxs-lookup"><span data-stu-id="f28be-108">An Azure subscription.</span></span> <span data-ttu-id="f28be-109">Ознакомьтесь с [бесплатной пробной версией Azure](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span><span class="sxs-lookup"><span data-stu-id="f28be-109">See [Get Azure free trial](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span></span>
* <span data-ttu-id="f28be-110">Кластер Apache Spark в HDInsight.</span><span class="sxs-lookup"><span data-stu-id="f28be-110">An Apache Spark cluster on HDInsight.</span></span> <span data-ttu-id="f28be-111">Инструкции см. в статье [Начало работы. Создание кластера Apache Spark в HDInsight на платформе Linux и выполнение интерактивных запросов с помощью SQL Spark](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="f28be-111">For instructions, see [Create Apache Spark clusters in Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span>

## <a name="how-do-i-launch-the-ambari-web-ui"></a><span data-ttu-id="f28be-112">Как запустить веб-интерфейс Ambari?</span><span class="sxs-lookup"><span data-stu-id="f28be-112">How do I launch the Ambari Web UI?</span></span>
1. <span data-ttu-id="f28be-113">На начальной панели [портала Azure](https://portal.azure.com/)щелкните элемент кластера Spark (если он закреплен на начальной панели).</span><span class="sxs-lookup"><span data-stu-id="f28be-113">From the [Azure Portal](https://portal.azure.com/), from the startboard, click the tile for your Spark cluster (if you pinned it to the startboard).</span></span> <span data-ttu-id="f28be-114">Кроме того, вы можете перейти к кластеру, последовательно щелкнув **Просмотреть все** > **Кластеры HDInsight**.</span><span class="sxs-lookup"><span data-stu-id="f28be-114">You can also navigate to your cluster under **Browse All** > **HDInsight Clusters**.</span></span>
2. <span data-ttu-id="f28be-115">В колонке кластера Spark нажмите **Панель мониторинга**.</span><span class="sxs-lookup"><span data-stu-id="f28be-115">From the Spark cluster blade, click **Dashboard**.</span></span> <span data-ttu-id="f28be-116">При появлении запроса введите учетные данные администратора для кластера Spark.</span><span class="sxs-lookup"><span data-stu-id="f28be-116">When prompted, enter the admin credentials for the Spark cluster.</span></span>

    <span data-ttu-id="f28be-117">![Запуск Ambari](./media/hdinsight-apache-spark-resource-manager/hdinsight-launch-cluster-dashboard.png "Запуск Resource Manager")</span><span class="sxs-lookup"><span data-stu-id="f28be-117">![Launch Ambari](./media/hdinsight-apache-spark-resource-manager/hdinsight-launch-cluster-dashboard.png "Start Resource Manager")</span></span>
3. <span data-ttu-id="f28be-118">В результате должен запуститься веб-интерфейс Ambari, как показано ниже.</span><span class="sxs-lookup"><span data-stu-id="f28be-118">This should launch the Ambari Web UI, as shown below.</span></span>

    <span data-ttu-id="f28be-119">![Веб-интерфейс Ambari](./media/hdinsight-apache-spark-resource-manager/ambari-web-ui.png "Веб-интерфейс Ambari")</span><span class="sxs-lookup"><span data-stu-id="f28be-119">![Ambari Web UI](./media/hdinsight-apache-spark-resource-manager/ambari-web-ui.png "Ambari Web UI")</span></span>   

## <a name="how-do-i-launch-the-spark-history-server"></a><span data-ttu-id="f28be-120">Как запустить сервер журнала Spark?</span><span class="sxs-lookup"><span data-stu-id="f28be-120">How do I launch the Spark History Server?</span></span>
1. <span data-ttu-id="f28be-121">На начальной панели [портала Azure](https://portal.azure.com/)щелкните элемент кластера Spark (если он закреплен на начальной панели).</span><span class="sxs-lookup"><span data-stu-id="f28be-121">From the [Azure Portal](https://portal.azure.com/), from the startboard, click the tile for your Spark cluster (if you pinned it to the startboard).</span></span>
2. <span data-ttu-id="f28be-122">В разделе **Быстрые ссылки** колонки кластера щелкните **Панель мониторинга кластера**.</span><span class="sxs-lookup"><span data-stu-id="f28be-122">From the cluster blade, under **Quick Links**, click **Cluster Dashboard**.</span></span> <span data-ttu-id="f28be-123">В колонке **Панель мониторинга кластера** щелкните **Сервер журнала Spark**.</span><span class="sxs-lookup"><span data-stu-id="f28be-123">In the **Cluster Dashboard** blade, click **Spark History Server**.</span></span>

    <span data-ttu-id="f28be-124">![Сервер журнала Spark](./media/hdinsight-apache-spark-resource-manager/launch-history-server.png "Сервер журнала Spark")</span><span class="sxs-lookup"><span data-stu-id="f28be-124">![Spark History Server](./media/hdinsight-apache-spark-resource-manager/launch-history-server.png "Spark History Server")</span></span>

    <span data-ttu-id="f28be-125">При появлении запроса введите учетные данные администратора для кластера Spark.</span><span class="sxs-lookup"><span data-stu-id="f28be-125">When prompted, enter the admin credentials for the Spark cluster.</span></span>

## <a name="how-do-i-launch-the-yarn-ui"></a><span data-ttu-id="f28be-126">Как запустить пользовательский интерфейс Yarn?</span><span class="sxs-lookup"><span data-stu-id="f28be-126">How do I launch the Yarn UI?</span></span>
<span data-ttu-id="f28be-127">Вы можете использовать пользовательский интерфейс YARN для мониторинга приложений, которые выполняются в кластере Spark в настоящее время.</span><span class="sxs-lookup"><span data-stu-id="f28be-127">You can use the YARN UI to monitor applications that are currently running on the Spark cluster.</span></span>

1. <span data-ttu-id="f28be-128">В колонке кластера щелкните **Панель мониторинга кластера**, а затем выберите пункт **YARN**.</span><span class="sxs-lookup"><span data-stu-id="f28be-128">From the cluster blade, click **Cluster Dashboard**, and then click **YARN**.</span></span>

    ![Запуск пользовательского интерфейса YARN](./media/hdinsight-apache-spark-resource-manager/launch-yarn-ui.png)

   > [!TIP]
   > <span data-ttu-id="f28be-130">Также пользовательский интерфейс YARN можно открыть из пользовательского интерфейса Ambari.</span><span class="sxs-lookup"><span data-stu-id="f28be-130">Alternatively, you can also launch the YARN UI from the Ambari UI.</span></span> <span data-ttu-id="f28be-131">Чтобы открыть пользовательский интерфейс Ambari, выберите в колонке кластера **Панель мониторинга кластера**, а затем щелкните **Панель мониторинга кластера HDInsight**.</span><span class="sxs-lookup"><span data-stu-id="f28be-131">To launch the Ambari UI, from the cluster blade, click **Cluster Dashboard**, and then click **HDInsight Cluster Dashboard**.</span></span> <span data-ttu-id="f28be-132">В пользовательском интерфейсе Ambari щелкните **YARN**, затем — **Быстрые ссылки**. Щелкните активный менеджер ресурсов и нажмите кнопку **ResourceManager UI** (Пользовательский интерфейс диспетчера ресурсов).</span><span class="sxs-lookup"><span data-stu-id="f28be-132">From the Ambari UI, click **YARN**, click **Quick Links**, click the active resource manager, and then click **ResourceManager UI**.</span></span>
   >
   >

## <a name="what-is-the-optimum-cluster-configuration-to-run-spark-applications"></a><span data-ttu-id="f28be-133">Какая конфигурация кластера будет оптимальной для запуска приложений Spark?</span><span class="sxs-lookup"><span data-stu-id="f28be-133">What is the optimum cluster configuration to run Spark applications?</span></span>
<span data-ttu-id="f28be-134">В зависимости от требований приложения можно изменять три основных параметра Spark: `spark.executor.instances`, `spark.executor.cores` и `spark.executor.memory`.</span><span class="sxs-lookup"><span data-stu-id="f28be-134">The three key parameters that can be used for Spark configuration depending on application requirements are `spark.executor.instances`, `spark.executor.cores`, and `spark.executor.memory`.</span></span> <span data-ttu-id="f28be-135">Исполнитель — это процесс, запущенный для приложения Spark.</span><span class="sxs-lookup"><span data-stu-id="f28be-135">An Executor is a process launched for a Spark application.</span></span> <span data-ttu-id="f28be-136">Он выполняется на рабочем узле и отвечает за выполнение задач этого приложения.</span><span class="sxs-lookup"><span data-stu-id="f28be-136">It runs on the worker node and is responsible to carry out the tasks for the application.</span></span> <span data-ttu-id="f28be-137">Число исполнителей по умолчанию и размеры исполнителя для каждого кластера определяются с учетом числа рабочих узлов и размера каждого рабочего узла.</span><span class="sxs-lookup"><span data-stu-id="f28be-137">The default number of executors and the executor sizes for each cluster is calculated based on the number of worker nodes and the worker node size.</span></span> <span data-ttu-id="f28be-138">Эти значения хранятся в файле `spark-defaults.conf` на головных узлах кластера.</span><span class="sxs-lookup"><span data-stu-id="f28be-138">These are stored in `spark-defaults.conf` on the cluster head nodes.</span></span>

<span data-ttu-id="f28be-139">Эти три параметра конфигурации можно настроить на уровне кластера (для всех приложений, работающих в кластере) или для каждого отдельного приложения.</span><span class="sxs-lookup"><span data-stu-id="f28be-139">The three configuration parameters can be configured at the cluster level (for all applications that run on the cluster) or can be specified for each individual application as well.</span></span>

### <a name="change-the-parameters-using-ambari-ui"></a><span data-ttu-id="f28be-140">Изменение параметров с помощью пользовательского интерфейса Ambari</span><span class="sxs-lookup"><span data-stu-id="f28be-140">Change the parameters using Ambari UI</span></span>
1. <span data-ttu-id="f28be-141">В пользовательском интерфейсе Ambari щелкните **Spark**, выберите пункт **Конфигурации** и разверните категорию **Custom spark-defaults**.</span><span class="sxs-lookup"><span data-stu-id="f28be-141">From the Ambari UI click **Spark**, click **Configs**, and then expand **Custom spark-defaults**.</span></span>

    ![Изменение параметров с помощью Ambari](./media/hdinsight-apache-spark-resource-manager/set-parameters-using-ambari.png)
2. <span data-ttu-id="f28be-143">Значения по умолчанию позволяют запустить в кластере одновременно четыре приложения Spark.</span><span class="sxs-lookup"><span data-stu-id="f28be-143">The default values are good to have 4 Spark applications run concurrently on the cluster.</span></span> <span data-ttu-id="f28be-144">Вы можете изменять эти значения из пользовательского интерфейса, как показано ниже.</span><span class="sxs-lookup"><span data-stu-id="f28be-144">You can changes these values from the user interface, as shown below.</span></span>

    ![Изменение параметров с помощью Ambari](./media/hdinsight-apache-spark-resource-manager/set-executor-parameters.png)
3. <span data-ttu-id="f28be-146">Чтобы сохранить изменения конфигурации, нажмите кнопку **Сохранить** .</span><span class="sxs-lookup"><span data-stu-id="f28be-146">Click **Save** to save the configuration changes.</span></span> <span data-ttu-id="f28be-147">В верхней части страницы вы увидите предложение перезапустить все используемые службы.</span><span class="sxs-lookup"><span data-stu-id="f28be-147">At the top of the page, you will be prompted to restart all the affected services.</span></span> <span data-ttu-id="f28be-148">Щелкните **Перезапустить**.</span><span class="sxs-lookup"><span data-stu-id="f28be-148">Click **Restart**.</span></span>

    ![Перезапуск служб](./media/hdinsight-apache-spark-resource-manager/restart-services.png)

### <a name="change-the-parameters-for-an-application-running-in-jupyter-notebook"></a><span data-ttu-id="f28be-150">Изменение параметров для приложения, запущенного в записной книжке Jupyter</span><span class="sxs-lookup"><span data-stu-id="f28be-150">Change the parameters for an application running in Jupyter notebook</span></span>
<span data-ttu-id="f28be-151">Чтобы изменить конфигурацию для приложений, запущенных в записной книжке Jupyter, можно использовать волшебную команду `%%configure` .</span><span class="sxs-lookup"><span data-stu-id="f28be-151">For applications running in the Jupyter notebook, you can use the `%%configure` magic to make the configuration changes.</span></span> <span data-ttu-id="f28be-152">Желательно вносить такие изменения в начале приложения, перед запуском первой ячейки кода.</span><span class="sxs-lookup"><span data-stu-id="f28be-152">Ideally, you must make such changes at the beginning of the application, before you run your first code cell.</span></span> <span data-ttu-id="f28be-153">Это гарантирует, что конфигурация будет применена к сеансу Livy, когда он будет создан.</span><span class="sxs-lookup"><span data-stu-id="f28be-153">This ensures that the configuration is applied to the Livy session, when it gets created.</span></span> <span data-ttu-id="f28be-154">Если вы хотите изменить конфигурацию на более позднем этапе выполнения приложения, следует использовать параметр `-f` .</span><span class="sxs-lookup"><span data-stu-id="f28be-154">If you want to change the configuration at a later stage in the application, you must use the `-f` parameter.</span></span> <span data-ttu-id="f28be-155">Но при этом будут потеряны все результаты, полученные в приложении.</span><span class="sxs-lookup"><span data-stu-id="f28be-155">However, by doing so all progress in the application will be lost.</span></span>

<span data-ttu-id="f28be-156">В следующем фрагменте показано, как изменить конфигурацию для приложения, работающего в Jupyter.</span><span class="sxs-lookup"><span data-stu-id="f28be-156">The snippet below shows how to change the configuration for an application running in Jupyter.</span></span>

    %%configure
    {"executorMemory": "3072M", "executorCores": 4, "numExecutors":10}

<span data-ttu-id="f28be-157">Параметры конфигурации следует передавать в виде строки JSON, расположенной сразу после команды magic, как показано в столбце примера.</span><span class="sxs-lookup"><span data-stu-id="f28be-157">Configuration parameters must be passed in as a JSON string and must be on the next line after the magic, as shown in the example column.</span></span>

### <a name="change-the-parameters-for-an-application-submitted-using-spark-submit"></a><span data-ttu-id="f28be-158">Изменение параметров для приложения, отправленного с помощью spark-submit</span><span class="sxs-lookup"><span data-stu-id="f28be-158">Change the parameters for an application submitted using spark-submit</span></span>
<span data-ttu-id="f28be-159">Следующая команда демонстрирует, как можно изменять параметры конфигурации для приложения пакетной службы, отправленного с помощью `spark-submit`.</span><span class="sxs-lookup"><span data-stu-id="f28be-159">Following command is an example of how to change the configuration parameters for a batch application that is submitted using `spark-submit`.</span></span>

    spark-submit --class <the application class to execute> --executor-memory 3072M --executor-cores 4 –-num-executors 10 <location of application jar file> <application parameters>

### <a name="change-the-parameters-for-an-application-submitted-using-curl"></a><span data-ttu-id="f28be-160">Изменение параметров для приложения, отправленного с помощью cURL</span><span class="sxs-lookup"><span data-stu-id="f28be-160">Change the parameters for an application submitted using cURL</span></span>
<span data-ttu-id="f28be-161">Следующая команда демонстрирует, как можно изменять параметры конфигурации для приложения пакетной службы, отправленного с помощью cURL.</span><span class="sxs-lookup"><span data-stu-id="f28be-161">Following command is an example of how to change the configuration parameters for a batch application that is submitted using using cURL.</span></span>

    curl -k -v -H 'Content-Type: application/json' -X POST -d '{"file":"<location of application jar file>", "className":"<the application class to execute>", "args":[<application parameters>], "numExecutors":10, "executorMemory":"2G", "executorCores":5' localhost:8998/batches

### <a name="how-do-i-change-these-parameters-on-a-spark-thrift-server"></a><span data-ttu-id="f28be-162">Как изменить эти параметры на сервере Thrift Spark?</span><span class="sxs-lookup"><span data-stu-id="f28be-162">How do I change these parameters on a Spark Thrift Server?</span></span>
<span data-ttu-id="f28be-163">Сервер Thrift Spark предоставляет доступ JDBC и ODBC к кластеру Spark.</span><span class="sxs-lookup"><span data-stu-id="f28be-163">Spark Thrift Server provides JDBC/ODBC access to a Spark cluster and is used to service Spark SQL queries.</span></span> <span data-ttu-id="f28be-164">Он используется для обслуживания запросов к службе Spark SQL.</span><span class="sxs-lookup"><span data-stu-id="f28be-164">Tools like Power BI, Tableau etc.</span></span> <span data-ttu-id="f28be-165">Разные средства, такие как Power BI, Tableau и др., используют протокол ODBC для обмена данными с сервером Thrift Spark и выполнения запросов Spark SQL в виде приложения Spark.</span><span class="sxs-lookup"><span data-stu-id="f28be-165">use ODBC protocol to communicate with Spark Thrift Server to execute Spark SQL queries as a Spark Application.</span></span> <span data-ttu-id="f28be-166">Когда вы создаете кластер Spark, запускаются два экземпляра сервера Thrift Spark, по одному на каждый головной узел.</span><span class="sxs-lookup"><span data-stu-id="f28be-166">When a Spark cluster is created, two instances of the Spark Thrift Server are started, one on each head node.</span></span> <span data-ttu-id="f28be-167">Каждый сервер Thrift Spark отображается в пользовательском интерфейсе YARN как приложение Spark.</span><span class="sxs-lookup"><span data-stu-id="f28be-167">Each Spark Thrift Server is visible as a Spark application in the YARN UI.</span></span>

<span data-ttu-id="f28be-168">Сервер Thrift Spark использует динамическое выделение исполнителей Spark, поэтому `spark.executor.instances` не используется.</span><span class="sxs-lookup"><span data-stu-id="f28be-168">Spark Thrift Server uses Spark dynamic executor allocation and hence the `spark.executor.instances` is not used.</span></span> <span data-ttu-id="f28be-169">Вместо этого сервер Thrift Spark использует `spark.dynamicAllocation.minExecutors` и `spark.dynamicAllocation.maxExecutors`, чтобы указать число исполнителей.</span><span class="sxs-lookup"><span data-stu-id="f28be-169">Instead, Spark Thrift Server uses `spark.dynamicAllocation.minExecutors` and `spark.dynamicAllocation.maxExecutors` to specify the executor count.</span></span> <span data-ttu-id="f28be-170">Параметры конфигурации `spark.executor.cores` и `spark.executor.memory` используются для изменения размера исполнителя.</span><span class="sxs-lookup"><span data-stu-id="f28be-170">The configuration parameters `spark.executor.cores` and `spark.executor.memory` is used to modify the executor size.</span></span> <span data-ttu-id="f28be-171">Все эти параметры вы можете изменять, как показано ниже.</span><span class="sxs-lookup"><span data-stu-id="f28be-171">You can change these parameters as shown below.</span></span>

* <span data-ttu-id="f28be-172">Разверните категорию **Advanced spark-thrift-sparkconf**, чтобы обновить параметры `spark.dynamicAllocation.minExecutors`, `spark.dynamicAllocation.maxExecutors` и `spark.executor.memory`.</span><span class="sxs-lookup"><span data-stu-id="f28be-172">Expand the **Advanced spark-thrift-sparkconf** category to update the parameters `spark.dynamicAllocation.minExecutors`, `spark.dynamicAllocation.maxExecutors`, and `spark.executor.memory`.</span></span>

    ![Настройка сервера Thrift Spark](./media/hdinsight-apache-spark-resource-manager/spark-thrift-server-1.png)    
* <span data-ttu-id="f28be-174">Разверните категорию **Custom spark-thrift-sparkconf**, чтобы изменить параметр `spark.executor.cores`.</span><span class="sxs-lookup"><span data-stu-id="f28be-174">Expand the **Custom spark-thrift-sparkconf** category to update the parameter `spark.executor.cores`.</span></span>

    ![Настройка сервера Thrift Spark](./media/hdinsight-apache-spark-resource-manager/spark-thrift-server-2.png)

### <a name="how-do-i-change-the-driver-memory-of-the-spark-thrift-server"></a><span data-ttu-id="f28be-176">Как можно изменить память драйверов для сервера Thrift Spark?</span><span class="sxs-lookup"><span data-stu-id="f28be-176">How do I change the driver memory of the Spark Thrift Server?</span></span>
<span data-ttu-id="f28be-177">Память драйверов сервера Thrift Spark настроена так, что она использует 25 % от размера ОЗУ головного узла, при условии, что общий объем ОЗУ головного узла превышает 14 ГБ.</span><span class="sxs-lookup"><span data-stu-id="f28be-177">Spark Thrift Server driver memory is configured to 25% of the head node RAM size, provided the total RAM size of the head node is greater than 14GB.</span></span> <span data-ttu-id="f28be-178">Конфигурацию памяти драйверов можно изменить с помощью пользовательского интерфейса Ambari, как показано ниже.</span><span class="sxs-lookup"><span data-stu-id="f28be-178">You can use the Ambari UI to change the driver memory configuration, as shown below.</span></span>

* <span data-ttu-id="f28be-179">В пользовательском интерфейсе Ambari щелкните **Spark**, нажмите **Конфигурации**, разверните категорию **Advanced spark-env** и введите значение для параметра **spark_thrift_cmd_opts**.</span><span class="sxs-lookup"><span data-stu-id="f28be-179">From the Ambari UI click **Spark**, click **Configs**, expand **Advanced spark-env**, and then provide the value for **spark_thrift_cmd_opts**.</span></span>

    ![Настройка памяти сервера Thrift Spark](./media/hdinsight-apache-spark-resource-manager/spark-thrift-server-ram.png)

## <a name="i-do-not-use-bi-with-spark-cluster-how-do-i-take-the-resources-back"></a><span data-ttu-id="f28be-181">Я не использую бизнес-аналитику с кластером Spark.</span><span class="sxs-lookup"><span data-stu-id="f28be-181">I do not use BI with Spark cluster.</span></span> <span data-ttu-id="f28be-182">Как получить ресурсы обратно?</span><span class="sxs-lookup"><span data-stu-id="f28be-182">How do I take the resources back?</span></span>
<span data-ttu-id="f28be-183">Так как мы используем динамическое выделение Spark, сервер Thrift потребляет только ресурсы, предназначенные для двух главных серверов приложений.</span><span class="sxs-lookup"><span data-stu-id="f28be-183">Since we use Spark dynamic allocation, the only resources that are consumed by thrift server are the resources for the two application masters.</span></span> <span data-ttu-id="f28be-184">Чтобы освободить эти ресурсы, следует остановить службы сервера Thrift, запущенные в кластере.</span><span class="sxs-lookup"><span data-stu-id="f28be-184">To reclaim these resources you must stop the Thrift Server services running on the cluster.</span></span>

1. <span data-ttu-id="f28be-185">В пользовательском интерфейсе Ambari на панели слева щелкните **Spark**.</span><span class="sxs-lookup"><span data-stu-id="f28be-185">From the Ambari UI, from the left pane, click **Spark**.</span></span>
2. <span data-ttu-id="f28be-186">На следующей странице щелкните **Серверы Thrift Spark**.</span><span class="sxs-lookup"><span data-stu-id="f28be-186">In the next page, click **Spark Thrift Servers**.</span></span>

    ![Перезапуск сервера Thrift](./media/hdinsight-apache-spark-resource-manager/restart-thrift-server-1.png)
3. <span data-ttu-id="f28be-188">Вы увидите два головных узла, на которых запущен сервер Thrift Spark.</span><span class="sxs-lookup"><span data-stu-id="f28be-188">You should see the two headnodes on which the Spark Thrift Server is running.</span></span> <span data-ttu-id="f28be-189">Выберите один из этих головных узлов.</span><span class="sxs-lookup"><span data-stu-id="f28be-189">Click one of the headnodes.</span></span>

    ![Перезапуск сервера Thrift](./media/hdinsight-apache-spark-resource-manager/restart-thrift-server-2.png)
4. <span data-ttu-id="f28be-191">На следующей странице перечислены все службы, запущенные на выбранном головном узле.</span><span class="sxs-lookup"><span data-stu-id="f28be-191">The next page lists all the services running on that headnode.</span></span> <span data-ttu-id="f28be-192">Нажмите в этом списке кнопку раскрывающегося списка рядом с сервером Thrift Spark, затем нажмите кнопку **Остановить**.</span><span class="sxs-lookup"><span data-stu-id="f28be-192">From the list click the drop-down button next to Spark Thrift Server, and then click **Stop**.</span></span>

    ![Перезапуск сервера Thrift](./media/hdinsight-apache-spark-resource-manager/restart-thrift-server-3.png)
5. <span data-ttu-id="f28be-194">Повторите эти действия на другом головном узле.</span><span class="sxs-lookup"><span data-stu-id="f28be-194">Repeat these steps on the other headnode as well.</span></span>

## <a name="my-jupyter-notebooks-are-not-running-as-expected-how-can-i-restart-the-service"></a><span data-ttu-id="f28be-195">Мои записные книжки Jupyter работают не так, как ожидалось.</span><span class="sxs-lookup"><span data-stu-id="f28be-195">My Jupyter notebooks are not running as expected.</span></span> <span data-ttu-id="f28be-196">Как я могу перезапустить службу?</span><span class="sxs-lookup"><span data-stu-id="f28be-196">How can I restart the service?</span></span>
<span data-ttu-id="f28be-197">Запустите веб-интерфейс Ambari, как показано выше.</span><span class="sxs-lookup"><span data-stu-id="f28be-197">Launch the Ambari Web UI as shown above.</span></span> <span data-ttu-id="f28be-198">В левой области навигации щелкните **Jupyter**, **Service Actions** (Действия службы), а затем — **Перезапустить все**.</span><span class="sxs-lookup"><span data-stu-id="f28be-198">From the left navigation pane, click **Jupyter**, click **Service Actions**, and then click **Restart All**.</span></span> <span data-ttu-id="f28be-199">При этом служба Jupyter запускается на всех головных узлах.</span><span class="sxs-lookup"><span data-stu-id="f28be-199">This will start the Jupyter service on all the headnodes.</span></span>

    ![Restart Jupyter](./media/hdinsight-apache-spark-resource-manager/restart-jupyter.png "Restart Jupyter")

## <a name="how-do-i-know-if-i-am-running-out-of-resources"></a><span data-ttu-id="f28be-200">Как узнать, что ресурсы заканчиваются?</span><span class="sxs-lookup"><span data-stu-id="f28be-200">How do I know if I am running out of resources?</span></span>
<span data-ttu-id="f28be-201">Запустите пользовательский интерфейс Yarn, как показано выше.</span><span class="sxs-lookup"><span data-stu-id="f28be-201">Launch the Yarn UI as shown above.</span></span> <span data-ttu-id="f28be-202">В таблице метрик кластера в верхней части экрана проверьте значения столбцов **Memory Used** (Используемая память) и **Memory Total** (Всего памяти).</span><span class="sxs-lookup"><span data-stu-id="f28be-202">In Cluster Metrics table on top of the screen, check values of **Memory Used** and **Memory Total** columns.</span></span> <span data-ttu-id="f28be-203">Если эти два значения очень близки, то для запуска следующего приложения может не хватить ресурсов.</span><span class="sxs-lookup"><span data-stu-id="f28be-203">If the 2 values are very close, there might not be enough resources to start the next application.</span></span> <span data-ttu-id="f28be-204">То же самое относится к столбцам **VCores Used** (Используемые ядра VCore) и **VCores Total** (Всего ядер VCore).</span><span class="sxs-lookup"><span data-stu-id="f28be-204">The same applies to the **VCores Used** and **VCores Total** columns.</span></span> <span data-ttu-id="f28be-205">Кроме того, если в главном представлении есть приложение с состоянием **ACCEPTED** (Принято), которое не переходит в состояние **RUNNING** (Выполняется) или **FAILED** (Сбой), то это также может означать, что для его запуска недостаточно ресурсов.</span><span class="sxs-lookup"><span data-stu-id="f28be-205">Also, in the main view, if there is an application stayed in **ACCEPTED** state and not transitioning into **RUNNING** nor **FAILED** state, this could also be an indication that it is not getting enough resources to start.</span></span>

    ![Resource Limit](./media/hdinsight-apache-spark-resource-manager/resource-limit.png "Resource Limit")

## <a name="how-do-i-kill-a-running-application-to-free-up-resource"></a><span data-ttu-id="f28be-206">Как завершить работу запущенного приложения, чтобы освободить ресурс?</span><span class="sxs-lookup"><span data-stu-id="f28be-206">How do I kill a running application to free up resource?</span></span>
1. <span data-ttu-id="f28be-207">В пользовательском интерфейсе Yarn на левой панели щелкните **Running** (Выполняется).</span><span class="sxs-lookup"><span data-stu-id="f28be-207">In the Yarn UI, from the left panel, click **Running**.</span></span> <span data-ttu-id="f28be-208">В списке выполняющихся приложений определите приложение, работу которого необходимо завершить, и щелкните **ID** (Идентификатор).</span><span class="sxs-lookup"><span data-stu-id="f28be-208">From the list of running applications, determine the application to be killed and click on the **ID**.</span></span>

    <span data-ttu-id="f28be-209">![Завершение работы приложения 1](./media/hdinsight-apache-spark-resource-manager/kill-app1.png "Завершение работы приложения 1")</span><span class="sxs-lookup"><span data-stu-id="f28be-209">![Kill App1](./media/hdinsight-apache-spark-resource-manager/kill-app1.png "Kill App1")</span></span>

2. <span data-ttu-id="f28be-210">В правом верхнем углу щелкните **Kill Application** (Завершить работу приложения), а затем нажмите кнопку **ОК**.</span><span class="sxs-lookup"><span data-stu-id="f28be-210">Click **Kill Application** on the top right corner, then click **OK**.</span></span>

    <span data-ttu-id="f28be-211">![Завершение работы приложения 2](./media/hdinsight-apache-spark-resource-manager/kill-app2.png "Завершение работы приложения 2")</span><span class="sxs-lookup"><span data-stu-id="f28be-211">![Kill App2](./media/hdinsight-apache-spark-resource-manager/kill-app2.png "Kill App2")</span></span>

## <a name="see-also"></a><span data-ttu-id="f28be-212">См. также</span><span class="sxs-lookup"><span data-stu-id="f28be-212">See also</span></span>
* [<span data-ttu-id="f28be-213">Отслеживание и отладка заданий в кластере Apache Spark в HDInsight на платформе Linux</span><span class="sxs-lookup"><span data-stu-id="f28be-213">Track and debug jobs running on an Apache Spark cluster in HDInsight</span></span>](hdinsight-apache-spark-job-debugging.md)

### <a name="for-data-analysts"></a><span data-ttu-id="f28be-214">Для специалистов по анализу данных</span><span class="sxs-lookup"><span data-stu-id="f28be-214">For data analysts</span></span>

* [<span data-ttu-id="f28be-215">Использование Spark с машинным обучением. Использование Spark в HDInsight для анализа температуры в здании на основе данных системы кондиционирования</span><span class="sxs-lookup"><span data-stu-id="f28be-215">Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)
* [<span data-ttu-id="f28be-216">Использование Spark с машинным обучением. Использование Spark в HDInsight для прогнозирования результатов контроля качества пищевых продуктов</span><span class="sxs-lookup"><span data-stu-id="f28be-216">Spark with Machine Learning: Use Spark in HDInsight to predict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)
* [<span data-ttu-id="f28be-217">Анализ журнала веб-сайта с использованием Spark в HDInsight</span><span class="sxs-lookup"><span data-stu-id="f28be-217">Website log analysis using Spark in HDInsight</span></span>](hdinsight-apache-spark-custom-library-website-log-analysis.md)
* [<span data-ttu-id="f28be-218">Analyze Application Insights telemetry logs with Spark on HDInsight (Анализ журналов телеметрии Application Insights с помощью Spark в HDInsight)</span><span class="sxs-lookup"><span data-stu-id="f28be-218">Application Insight telemetry data analysis using Spark in HDInsight</span></span>](hdinsight-spark-analyze-application-insight-logs.md)
* [<span data-ttu-id="f28be-219">Использование Caffe в кластере Azure HDInsight Spark для распределенного глубокого обучения</span><span class="sxs-lookup"><span data-stu-id="f28be-219">Use Caffe on Azure HDInsight Spark for distributed deep learning</span></span>](hdinsight-deep-learning-caffe-spark.md)

### <a name="for-spark-developers"></a><span data-ttu-id="f28be-220">Для разработчиков Spark</span><span class="sxs-lookup"><span data-stu-id="f28be-220">For Spark developers</span></span>

* [<span data-ttu-id="f28be-221">Создание автономного приложения с использованием Scala</span><span class="sxs-lookup"><span data-stu-id="f28be-221">Create a standalone application using Scala</span></span>](hdinsight-apache-spark-create-standalone-application.md)
* [<span data-ttu-id="f28be-222">Удаленный запуск заданий с помощью Livy в кластере Spark</span><span class="sxs-lookup"><span data-stu-id="f28be-222">Run jobs remotely on a Spark cluster using Livy</span></span>](hdinsight-apache-spark-livy-rest-interface.md)
* [<span data-ttu-id="f28be-223">Использование подключаемого модуля средств HDInsight для IntelliJ IDEA для создания и отправки приложений Spark Scala</span><span class="sxs-lookup"><span data-stu-id="f28be-223">Use HDInsight Tools Plugin for IntelliJ IDEA to create and submit Spark Scala applications</span></span>](hdinsight-apache-spark-intellij-tool-plugin.md)
* [<span data-ttu-id="f28be-224">Потоковая передача Spark. Использование Spark в HDInsight для сборки приложений потоковой передачи данных в режиме реального времени</span><span class="sxs-lookup"><span data-stu-id="f28be-224">Spark Streaming: Use Spark in HDInsight for building real-time streaming applications</span></span>](hdinsight-apache-spark-eventhub-streaming.md)
* [<span data-ttu-id="f28be-225">Удаленная отладка приложений Spark в кластере HDInsight Spark Linux с помощью подключаемого модуля средств HDInsight для IntelliJ IDEA</span><span class="sxs-lookup"><span data-stu-id="f28be-225">Use HDInsight Tools Plugin for IntelliJ IDEA to debug Spark applications remotely</span></span>](hdinsight-apache-spark-intellij-tool-plugin-debug-jobs-remotely.md)
* [<span data-ttu-id="f28be-226">Использование записных книжек Zeppelin с кластером Spark в HDInsight</span><span class="sxs-lookup"><span data-stu-id="f28be-226">Use Zeppelin notebooks with a Spark cluster on HDInsight</span></span>](hdinsight-apache-spark-zeppelin-notebook.md)
* [<span data-ttu-id="f28be-227">Ядра, доступные для записной книжки Jupyter в кластере Spark в HDInsight</span><span class="sxs-lookup"><span data-stu-id="f28be-227">Kernels available for Jupyter notebook in Spark cluster for HDInsight</span></span>](hdinsight-apache-spark-jupyter-notebook-kernels.md)
* [<span data-ttu-id="f28be-228">Использование внешних пакетов с записными книжками Jupyter</span><span class="sxs-lookup"><span data-stu-id="f28be-228">Use external packages with Jupyter notebooks</span></span>](hdinsight-apache-spark-jupyter-notebook-use-external-packages.md)
* [<span data-ttu-id="f28be-229">Установка записной книжки Jupyter на компьютере и ее подключение к кластеру Apache Spark в Azure HDInsight (предварительная версия)</span><span class="sxs-lookup"><span data-stu-id="f28be-229">Install Jupyter on your computer and connect to an HDInsight Spark cluster</span></span>](hdinsight-apache-spark-jupyter-notebook-install-locally.md)
