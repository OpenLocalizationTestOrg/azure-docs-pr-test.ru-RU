---
title: "кластер aaaManage ресурсы для Apache Spark на Azure HDInsight | Документы Microsoft"
description: "Узнайте, как toouse управления ресурсами для кластеров Spark на Azure HDInsight для повышения производительности."
services: hdinsight
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: 9da7d4e3-458e-4296-a628-77b14643f7e4
ms.service: hdinsight
ms.custom: hdinsightactive
ms.workload: big-data
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 07/21/2017
ms.author: nitinme
ms.openlocfilehash: e18682a24f77494db884105f9db03c0a350ddad6
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 10/06/2017
---
# <a name="manage-resources-for-apache-spark-cluster-on-azure-hdinsight"></a><span data-ttu-id="24941-103">Управление ресурсами для кластера Apache Spark в Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="24941-103">Manage resources for Apache Spark cluster on Azure HDInsight</span></span> 

<span data-ttu-id="24941-104">В этой статье вы узнаете, как интерфейсы hello tooaccess Ambari пользовательского интерфейса, YARN пользовательского интерфейса и hello Spark журнала сервера связан с свой кластер Spark.</span><span class="sxs-lookup"><span data-stu-id="24941-104">In this article you will learn how tooaccess hello interfaces like Ambari UI, YARN UI, and hello Spark History Server associated with your Spark cluster.</span></span> <span data-ttu-id="24941-105">Вы также узнаете о как tootune hello конфигурации кластера для обеспечения оптимальной производительности.</span><span class="sxs-lookup"><span data-stu-id="24941-105">You will also learn about how tootune hello cluster configuration for optimal performance.</span></span>

<span data-ttu-id="24941-106">**Предварительные требования:**</span><span class="sxs-lookup"><span data-stu-id="24941-106">**Prerequisites:**</span></span>

<span data-ttu-id="24941-107">Необходимо иметь следующие hello.</span><span class="sxs-lookup"><span data-stu-id="24941-107">You must have hello following:</span></span>

* <span data-ttu-id="24941-108">Подписка Azure.</span><span class="sxs-lookup"><span data-stu-id="24941-108">An Azure subscription.</span></span> <span data-ttu-id="24941-109">Ознакомьтесь с [бесплатной пробной версией Azure](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span><span class="sxs-lookup"><span data-stu-id="24941-109">See [Get Azure free trial](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span></span>
* <span data-ttu-id="24941-110">Кластер Apache Spark в HDInsight.</span><span class="sxs-lookup"><span data-stu-id="24941-110">An Apache Spark cluster on HDInsight.</span></span> <span data-ttu-id="24941-111">Инструкции см. в статье [Начало работы. Создание кластера Apache Spark в HDInsight на платформе Linux и выполнение интерактивных запросов с помощью SQL Spark](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="24941-111">For instructions, see [Create Apache Spark clusters in Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span>

## <a name="how-do-i-launch-hello-ambari-web-ui"></a><span data-ttu-id="24941-112">Как запустить hello Ambari веб-интерфейса?</span><span class="sxs-lookup"><span data-stu-id="24941-112">How do I launch hello Ambari Web UI?</span></span>
1. <span data-ttu-id="24941-113">Из hello [портала Azure](https://portal.azure.com/), hello начальной панели, щелкните плитку hello свой кластер Spark (Если вы закрепили toohello начальной панели).</span><span class="sxs-lookup"><span data-stu-id="24941-113">From hello [Azure Portal](https://portal.azure.com/), from hello startboard, click hello tile for your Spark cluster (if you pinned it toohello startboard).</span></span> <span data-ttu-id="24941-114">Вы также можете переходить tooyour кластера в списке **просмотреть все** > **кластеров HDInsight**.</span><span class="sxs-lookup"><span data-stu-id="24941-114">You can also navigate tooyour cluster under **Browse All** > **HDInsight Clusters**.</span></span>
2. <span data-ttu-id="24941-115">В колонке кластера Spark hello, выберите **мониторинга**.</span><span class="sxs-lookup"><span data-stu-id="24941-115">From hello Spark cluster blade, click **Dashboard**.</span></span> <span data-ttu-id="24941-116">При появлении запроса введите учетные данные администратора hello кластера Spark hello.</span><span class="sxs-lookup"><span data-stu-id="24941-116">When prompted, enter hello admin credentials for hello Spark cluster.</span></span>

    <span data-ttu-id="24941-117">![Запуск Ambari](./media/hdinsight-apache-spark-resource-manager/hdinsight-launch-cluster-dashboard.png "Запуск Resource Manager")</span><span class="sxs-lookup"><span data-stu-id="24941-117">![Launch Ambari](./media/hdinsight-apache-spark-resource-manager/hdinsight-launch-cluster-dashboard.png "Start Resource Manager")</span></span>
3. <span data-ttu-id="24941-118">Это должен быть запущен hello Ambari веб-интерфейса, как показано ниже.</span><span class="sxs-lookup"><span data-stu-id="24941-118">This should launch hello Ambari Web UI, as shown below.</span></span>

    <span data-ttu-id="24941-119">![Веб-интерфейс Ambari](./media/hdinsight-apache-spark-resource-manager/ambari-web-ui.png "Веб-интерфейс Ambari")</span><span class="sxs-lookup"><span data-stu-id="24941-119">![Ambari Web UI](./media/hdinsight-apache-spark-resource-manager/ambari-web-ui.png "Ambari Web UI")</span></span>   

## <a name="how-do-i-launch-hello-spark-history-server"></a><span data-ttu-id="24941-120">Как запустить hello Spark журнала сервера?</span><span class="sxs-lookup"><span data-stu-id="24941-120">How do I launch hello Spark History Server?</span></span>
1. <span data-ttu-id="24941-121">Из hello [портала Azure](https://portal.azure.com/), hello начальной панели, щелкните плитку hello свой кластер Spark (Если вы закрепили toohello начальной панели).</span><span class="sxs-lookup"><span data-stu-id="24941-121">From hello [Azure Portal](https://portal.azure.com/), from hello startboard, click hello tile for your Spark cluster (if you pinned it toohello startboard).</span></span>
2. <span data-ttu-id="24941-122">Из hello кластера колонки, в разделе **быстрые ссылки**, нажмите кнопку **мониторинга кластера**.</span><span class="sxs-lookup"><span data-stu-id="24941-122">From hello cluster blade, under **Quick Links**, click **Cluster Dashboard**.</span></span> <span data-ttu-id="24941-123">В hello **мониторинга кластера** колонка, щелкните **Spark журнала сервера**.</span><span class="sxs-lookup"><span data-stu-id="24941-123">In hello **Cluster Dashboard** blade, click **Spark History Server**.</span></span>

    <span data-ttu-id="24941-124">![Сервер журнала Spark](./media/hdinsight-apache-spark-resource-manager/launch-history-server.png "Сервер журнала Spark")</span><span class="sxs-lookup"><span data-stu-id="24941-124">![Spark History Server](./media/hdinsight-apache-spark-resource-manager/launch-history-server.png "Spark History Server")</span></span>

    <span data-ttu-id="24941-125">При появлении запроса введите учетные данные администратора hello кластера Spark hello.</span><span class="sxs-lookup"><span data-stu-id="24941-125">When prompted, enter hello admin credentials for hello Spark cluster.</span></span>

## <a name="how-do-i-launch-hello-yarn-ui"></a><span data-ttu-id="24941-126">Как запустить hello Yarn пользовательского интерфейса?</span><span class="sxs-lookup"><span data-stu-id="24941-126">How do I launch hello Yarn UI?</span></span>
<span data-ttu-id="24941-127">Можно использовать hello пользовательского интерфейса YARN toomonitor приложений, запущенных на кластере Spark hello.</span><span class="sxs-lookup"><span data-stu-id="24941-127">You can use hello YARN UI toomonitor applications that are currently running on hello Spark cluster.</span></span>

1. <span data-ttu-id="24941-128">Из колонки hello кластера, нажмите кнопку **мониторинга кластера**, а затем нажмите кнопку **YARN**.</span><span class="sxs-lookup"><span data-stu-id="24941-128">From hello cluster blade, click **Cluster Dashboard**, and then click **YARN**.</span></span>

    ![Запуск пользовательского интерфейса YARN](./media/hdinsight-apache-spark-resource-manager/launch-yarn-ui.png)

   > [!TIP]
   > <span data-ttu-id="24941-130">Кроме того вы можете запустить hello YARN пользовательского интерфейса из hello Ambari пользовательского интерфейса.</span><span class="sxs-lookup"><span data-stu-id="24941-130">Alternatively, you can also launch hello YARN UI from hello Ambari UI.</span></span> <span data-ttu-id="24941-131">hello toolaunch Ambari пользовательского интерфейса, из колонки hello кластера, нажмите кнопку **мониторинга кластера**, а затем нажмите кнопку **мониторинга кластера HDInsight**.</span><span class="sxs-lookup"><span data-stu-id="24941-131">toolaunch hello Ambari UI, from hello cluster blade, click **Cluster Dashboard**, and then click **HDInsight Cluster Dashboard**.</span></span> <span data-ttu-id="24941-132">Hello Ambari пользовательского интерфейса, выберите **YARN**, нажмите кнопку **быстрые ссылки**, щелкните Диспетчер ресурсов active hello и нажмите кнопку **пользовательского интерфейса диспетчера ресурсов**.</span><span class="sxs-lookup"><span data-stu-id="24941-132">From hello Ambari UI, click **YARN**, click **Quick Links**, click hello active resource manager, and then click **ResourceManager UI**.</span></span>
   >
   >

## <a name="what-is-hello-optimum-cluster-configuration-toorun-spark-applications"></a><span data-ttu-id="24941-133">Что такое hello оптимальной конфигурации toorun Spark приложения кластера</span><span class="sxs-lookup"><span data-stu-id="24941-133">What is hello optimum cluster configuration toorun Spark applications?</span></span>
<span data-ttu-id="24941-134">Hello три ключевых параметров, которые можно использовать для конфигурации Spark в зависимости от требований приложения являются `spark.executor.instances`, `spark.executor.cores`, и `spark.executor.memory`.</span><span class="sxs-lookup"><span data-stu-id="24941-134">hello three key parameters that can be used for Spark configuration depending on application requirements are `spark.executor.instances`, `spark.executor.cores`, and `spark.executor.memory`.</span></span> <span data-ttu-id="24941-135">Исполнитель — это процесс, запущенный для приложения Spark.</span><span class="sxs-lookup"><span data-stu-id="24941-135">An Executor is a process launched for a Spark application.</span></span> <span data-ttu-id="24941-136">Он работает на узле работника hello и отвечает toocarry hello задач для приложения hello.</span><span class="sxs-lookup"><span data-stu-id="24941-136">It runs on hello worker node and is responsible toocarry out hello tasks for hello application.</span></span> <span data-ttu-id="24941-137">Hello, по умолчанию число исполнителей и размеры hello исполнителя для каждого кластера, рассчитывается на основании hello число рабочих узлов и размер узла hello рабочего потока.</span><span class="sxs-lookup"><span data-stu-id="24941-137">hello default number of executors and hello executor sizes for each cluster is calculated based on hello number of worker nodes and hello worker node size.</span></span> <span data-ttu-id="24941-138">Эти значения хранятся в `spark-defaults.conf` на головного узла кластера hello.</span><span class="sxs-lookup"><span data-stu-id="24941-138">These are stored in `spark-defaults.conf` on hello cluster head nodes.</span></span>

<span data-ttu-id="24941-139">Hello трех параметров конфигурации можно настроить на уровне кластера hello (для всех приложений, работающих на кластере hello) или могут быть указаны для каждого отдельного приложения.</span><span class="sxs-lookup"><span data-stu-id="24941-139">hello three configuration parameters can be configured at hello cluster level (for all applications that run on hello cluster) or can be specified for each individual application as well.</span></span>

### <a name="change-hello-parameters-using-ambari-ui"></a><span data-ttu-id="24941-140">Изменение параметров hello, с помощью Ambari пользовательского интерфейса</span><span class="sxs-lookup"><span data-stu-id="24941-140">Change hello parameters using Ambari UI</span></span>
1. <span data-ttu-id="24941-141">Hello Ambari пользовательского интерфейса выберите **Spark**, нажмите кнопку **Configs**и разверните **spark значения по умолчанию пользовательский**.</span><span class="sxs-lookup"><span data-stu-id="24941-141">From hello Ambari UI click **Spark**, click **Configs**, and then expand **Custom spark-defaults**.</span></span>

    ![Изменение параметров с помощью Ambari](./media/hdinsight-apache-spark-resource-manager/set-parameters-using-ambari.png)
2. <span data-ttu-id="24941-143">значения по умолчанию Hello — хороший toohave 4 Spark приложения, одновременно запускать на кластере hello.</span><span class="sxs-lookup"><span data-stu-id="24941-143">hello default values are good toohave 4 Spark applications run concurrently on hello cluster.</span></span> <span data-ttu-id="24941-144">Можно изменять эти значения из hello пользовательского интерфейса, как показано ниже.</span><span class="sxs-lookup"><span data-stu-id="24941-144">You can changes these values from hello user interface, as shown below.</span></span>

    ![Изменение параметров с помощью Ambari](./media/hdinsight-apache-spark-resource-manager/set-executor-parameters.png)
3. <span data-ttu-id="24941-146">Нажмите кнопку **Сохранить** изменения конфигурации toosave hello.</span><span class="sxs-lookup"><span data-stu-id="24941-146">Click **Save** toosave hello configuration changes.</span></span> <span data-ttu-id="24941-147">В начале hello страницы приветствия, вам будет предложено toorestart hello все затронутые службы.</span><span class="sxs-lookup"><span data-stu-id="24941-147">At hello top of hello page, you will be prompted toorestart all hello affected services.</span></span> <span data-ttu-id="24941-148">Щелкните **Перезапустить**.</span><span class="sxs-lookup"><span data-stu-id="24941-148">Click **Restart**.</span></span>

    ![Перезапуск служб](./media/hdinsight-apache-spark-resource-manager/restart-services.png)

### <a name="change-hello-parameters-for-an-application-running-in-jupyter-notebook"></a><span data-ttu-id="24941-150">Изменение параметров приложения, работающего в записной книжке Jupyter hello</span><span class="sxs-lookup"><span data-stu-id="24941-150">Change hello parameters for an application running in Jupyter notebook</span></span>
<span data-ttu-id="24941-151">Для приложений, работающих в записной книжке Jupyter hello, можно использовать hello `%%configure` магическая изменения конфигурации toomake hello.</span><span class="sxs-lookup"><span data-stu-id="24941-151">For applications running in hello Jupyter notebook, you can use hello `%%configure` magic toomake hello configuration changes.</span></span> <span data-ttu-id="24941-152">В идеальном случае необходимо внести такие изменения в начале приложения hello, прежде чем выполнять первой ячейки кода hello.</span><span class="sxs-lookup"><span data-stu-id="24941-152">Ideally, you must make such changes at hello beginning of hello application, before you run your first code cell.</span></span> <span data-ttu-id="24941-153">Это гарантирует, что конфигурация hello примененных toohello Livy сеанса, когда он создается.</span><span class="sxs-lookup"><span data-stu-id="24941-153">This ensures that hello configuration is applied toohello Livy session, when it gets created.</span></span> <span data-ttu-id="24941-154">Если необходимо, чтобы конфигурация toochange hello позже в приложении hello, необходимо использовать hello `-f` параметра.</span><span class="sxs-lookup"><span data-stu-id="24941-154">If you want toochange hello configuration at a later stage in hello application, you must use hello `-f` parameter.</span></span> <span data-ttu-id="24941-155">Однако предположим, что все хода выполнения работы в hello приложения будут потеряны.</span><span class="sxs-lookup"><span data-stu-id="24941-155">However, by doing so all progress in hello application will be lost.</span></span>

<span data-ttu-id="24941-156">фрагмент кода Hello ниже показано, как toochange hello конфигурации для приложения, работающего в Jupyter.</span><span class="sxs-lookup"><span data-stu-id="24941-156">hello snippet below shows how toochange hello configuration for an application running in Jupyter.</span></span>

    %%configure
    {"executorMemory": "3072M", "executorCores": 4, "numExecutors":10}

<span data-ttu-id="24941-157">Параметры конфигурации должны передаваться в виде строки JSON и должен быть на следующую строку hello после hello magic, как показано в примере столбец hello.</span><span class="sxs-lookup"><span data-stu-id="24941-157">Configuration parameters must be passed in as a JSON string and must be on hello next line after hello magic, as shown in hello example column.</span></span>

### <a name="change-hello-parameters-for-an-application-submitted-using-spark-submit"></a><span data-ttu-id="24941-158">Изменение параметров hello для отправки с помощью приложения команду spark-submit</span><span class="sxs-lookup"><span data-stu-id="24941-158">Change hello parameters for an application submitted using spark-submit</span></span>
<span data-ttu-id="24941-159">Следующая команда является примером как toochange hello параметры конфигурации для пакета приложения, которое отправляется с помощью `spark-submit`.</span><span class="sxs-lookup"><span data-stu-id="24941-159">Following command is an example of how toochange hello configuration parameters for a batch application that is submitted using `spark-submit`.</span></span>

    spark-submit --class <hello application class tooexecute> --executor-memory 3072M --executor-cores 4 –-num-executors 10 <location of application jar file> <application parameters>

### <a name="change-hello-parameters-for-an-application-submitted-using-curl"></a><span data-ttu-id="24941-160">Изменение параметров отправки с помощью перелистывание приложения hello</span><span class="sxs-lookup"><span data-stu-id="24941-160">Change hello parameters for an application submitted using cURL</span></span>
<span data-ttu-id="24941-161">Следующая команда является примером как toochange hello параметры конфигурации для пакета приложения, которое отправляется с помощью cURL.</span><span class="sxs-lookup"><span data-stu-id="24941-161">Following command is an example of how toochange hello configuration parameters for a batch application that is submitted using using cURL.</span></span>

    curl -k -v -H 'Content-Type: application/json' -X POST -d '{"file":"<location of application jar file>", "className":"<hello application class tooexecute>", "args":[<application parameters>], "numExecutors":10, "executorMemory":"2G", "executorCores":5' localhost:8998/batches

### <a name="how-do-i-change-these-parameters-on-a-spark-thrift-server"></a><span data-ttu-id="24941-162">Как изменить эти параметры на сервере Thrift Spark?</span><span class="sxs-lookup"><span data-stu-id="24941-162">How do I change these parameters on a Spark Thrift Server?</span></span>
<span data-ttu-id="24941-163">Сервера Thrift Spark предоставляет кластера Spark tooa доступа JDBC/ODBC и используется tooservice Spark SQL-запросов.</span><span class="sxs-lookup"><span data-stu-id="24941-163">Spark Thrift Server provides JDBC/ODBC access tooa Spark cluster and is used tooservice Spark SQL queries.</span></span> <span data-ttu-id="24941-164">Он используется для обслуживания запросов к службе Spark SQL.</span><span class="sxs-lookup"><span data-stu-id="24941-164">Tools like Power BI, Tableau etc.</span></span> <span data-ttu-id="24941-165">Используйте toocommunicate протокол ODBC с запросами Spark SQL tooexecute сервера Thrift Spark как приложение Spark.</span><span class="sxs-lookup"><span data-stu-id="24941-165">use ODBC protocol toocommunicate with Spark Thrift Server tooexecute Spark SQL queries as a Spark Application.</span></span> <span data-ttu-id="24941-166">При создании кластера Spark двух экземпляров hello запуска сервера Thrift Spark на каждый головной узел.</span><span class="sxs-lookup"><span data-stu-id="24941-166">When a Spark cluster is created, two instances of hello Spark Thrift Server are started, one on each head node.</span></span> <span data-ttu-id="24941-167">Каждый сервер Thrift Spark отображается как приложение Spark в hello YARN пользовательского интерфейса.</span><span class="sxs-lookup"><span data-stu-id="24941-167">Each Spark Thrift Server is visible as a Spark application in hello YARN UI.</span></span>

<span data-ttu-id="24941-168">Использует сервера Thrift Spark усилить исполнителя динамического выделения и поэтому hello `spark.executor.instances` не используется.</span><span class="sxs-lookup"><span data-stu-id="24941-168">Spark Thrift Server uses Spark dynamic executor allocation and hence hello `spark.executor.instances` is not used.</span></span> <span data-ttu-id="24941-169">Вместо этого использует сервера Thrift Spark `spark.dynamicAllocation.minExecutors` и `spark.dynamicAllocation.maxExecutors` toospecify hello исполнителя count.</span><span class="sxs-lookup"><span data-stu-id="24941-169">Instead, Spark Thrift Server uses `spark.dynamicAllocation.minExecutors` and `spark.dynamicAllocation.maxExecutors` toospecify hello executor count.</span></span> <span data-ttu-id="24941-170">Здравствуйте, параметры конфигурации `spark.executor.cores` и `spark.executor.memory` — используемый размер исполнителя toomodify hello.</span><span class="sxs-lookup"><span data-stu-id="24941-170">hello configuration parameters `spark.executor.cores` and `spark.executor.memory` is used toomodify hello executor size.</span></span> <span data-ttu-id="24941-171">Все эти параметры вы можете изменять, как показано ниже.</span><span class="sxs-lookup"><span data-stu-id="24941-171">You can change these parameters as shown below.</span></span>

* <span data-ttu-id="24941-172">Разверните hello **Advanced spark thrift-sparkconf** параметры hello категории tooupdate `spark.dynamicAllocation.minExecutors`, `spark.dynamicAllocation.maxExecutors`, и `spark.executor.memory`.</span><span class="sxs-lookup"><span data-stu-id="24941-172">Expand hello **Advanced spark-thrift-sparkconf** category tooupdate hello parameters `spark.dynamicAllocation.minExecutors`, `spark.dynamicAllocation.maxExecutors`, and `spark.executor.memory`.</span></span>

    ![Настройка сервера Thrift Spark](./media/hdinsight-apache-spark-resource-manager/spark-thrift-server-1.png)    
* <span data-ttu-id="24941-174">Разверните hello **настраиваемый spark-thrift-sparkconf** параметр hello категории tooupdate `spark.executor.cores`.</span><span class="sxs-lookup"><span data-stu-id="24941-174">Expand hello **Custom spark-thrift-sparkconf** category tooupdate hello parameter `spark.executor.cores`.</span></span>

    ![Настройка сервера Thrift Spark](./media/hdinsight-apache-spark-resource-manager/spark-thrift-server-2.png)

### <a name="how-do-i-change-hello-driver-memory-of-hello-spark-thrift-server"></a><span data-ttu-id="24941-176">Изменение памяти драйвера hello hello сервера Thrift Spark</span><span class="sxs-lookup"><span data-stu-id="24941-176">How do I change hello driver memory of hello Spark Thrift Server?</span></span>
<span data-ttu-id="24941-177">Драйвер памяти сервера Thrift Spark предоставляется настроенных too25% от размера головного узла ОЗУ hello, общий размер ОЗУ hello головного узла hello больше 14 ГБ.</span><span class="sxs-lookup"><span data-stu-id="24941-177">Spark Thrift Server driver memory is configured too25% of hello head node RAM size, provided hello total RAM size of hello head node is greater than 14GB.</span></span> <span data-ttu-id="24941-178">Можно использовать hello конфигурации памяти драйвера hello toochange Ambari пользовательского интерфейса, как показано ниже.</span><span class="sxs-lookup"><span data-stu-id="24941-178">You can use hello Ambari UI toochange hello driver memory configuration, as shown below.</span></span>

* <span data-ttu-id="24941-179">Hello Ambari пользовательского интерфейса выберите **Spark**, нажмите кнопку **конфигураций**, разверните **Advanced spark env**и затем задайте значение hello **spark_thrift_cmd_opts**.</span><span class="sxs-lookup"><span data-stu-id="24941-179">From hello Ambari UI click **Spark**, click **Configs**, expand **Advanced spark-env**, and then provide hello value for **spark_thrift_cmd_opts**.</span></span>

    ![Настройка памяти сервера Thrift Spark](./media/hdinsight-apache-spark-resource-manager/spark-thrift-server-ram.png)

## <a name="i-do-not-use-bi-with-spark-cluster-how-do-i-take-hello-resources-back"></a><span data-ttu-id="24941-181">Я не использую бизнес-аналитику с кластером Spark.</span><span class="sxs-lookup"><span data-stu-id="24941-181">I do not use BI with Spark cluster.</span></span> <span data-ttu-id="24941-182">Как сделать ресурсы hello назад</span><span class="sxs-lookup"><span data-stu-id="24941-182">How do I take hello resources back?</span></span>
<span data-ttu-id="24941-183">Поскольку используется динамическое выделение Spark, hello только ресурсы, используемые сервером thrift — это hello ресурсы для двух шаблонов приложения hello.</span><span class="sxs-lookup"><span data-stu-id="24941-183">Since we use Spark dynamic allocation, hello only resources that are consumed by thrift server are hello resources for hello two application masters.</span></span> <span data-ttu-id="24941-184">Эти ресурсы, которые необходимо остановить hello сервера Thrift служб, работающих в кластере hello tooreclaim.</span><span class="sxs-lookup"><span data-stu-id="24941-184">tooreclaim these resources you must stop hello Thrift Server services running on hello cluster.</span></span>

1. <span data-ttu-id="24941-185">Hello Ambari пользовательского интерфейса, hello левой панели щелкните **Spark**.</span><span class="sxs-lookup"><span data-stu-id="24941-185">From hello Ambari UI, from hello left pane, click **Spark**.</span></span>
2. <span data-ttu-id="24941-186">На следующей странице приветствия щелкните **серверы Thrift Spark**.</span><span class="sxs-lookup"><span data-stu-id="24941-186">In hello next page, click **Spark Thrift Servers**.</span></span>

    ![Перезапуск сервера Thrift](./media/hdinsight-apache-spark-resource-manager/restart-thrift-server-1.png)
3. <span data-ttu-id="24941-188">Вы увидите два headnodes hello, на какие hello выполняется сервера Thrift Spark.</span><span class="sxs-lookup"><span data-stu-id="24941-188">You should see hello two headnodes on which hello Spark Thrift Server is running.</span></span> <span data-ttu-id="24941-189">Выберите один из hello headnodes.</span><span class="sxs-lookup"><span data-stu-id="24941-189">Click one of hello headnodes.</span></span>

    ![Перезапуск сервера Thrift](./media/hdinsight-apache-spark-resource-manager/restart-thrift-server-2.png)
4. <span data-ttu-id="24941-191">Следующая страница приветствия перечислены все hello службы, запущенные на этом головному узлу.</span><span class="sxs-lookup"><span data-stu-id="24941-191">hello next page lists all hello services running on that headnode.</span></span> <span data-ttu-id="24941-192">Щелкните hello разворачивающуюся кнопку Далее tooSpark сервера Thrift hello списке и нажмите кнопку **остановить**.</span><span class="sxs-lookup"><span data-stu-id="24941-192">From hello list click hello drop-down button next tooSpark Thrift Server, and then click **Stop**.</span></span>

    ![Перезапуск сервера Thrift](./media/hdinsight-apache-spark-resource-manager/restart-thrift-server-3.png)
5. <span data-ttu-id="24941-194">Повторите эти действия на hello других головному узлу.</span><span class="sxs-lookup"><span data-stu-id="24941-194">Repeat these steps on hello other headnode as well.</span></span>

## <a name="my-jupyter-notebooks-are-not-running-as-expected-how-can-i-restart-hello-service"></a><span data-ttu-id="24941-195">Мои записные книжки Jupyter работают не так, как ожидалось.</span><span class="sxs-lookup"><span data-stu-id="24941-195">My Jupyter notebooks are not running as expected.</span></span> <span data-ttu-id="24941-196">Как можно перезапустить службу hello?</span><span class="sxs-lookup"><span data-stu-id="24941-196">How can I restart hello service?</span></span>
<span data-ttu-id="24941-197">Запустите hello Ambari веб-интерфейса, как показано выше.</span><span class="sxs-lookup"><span data-stu-id="24941-197">Launch hello Ambari Web UI as shown above.</span></span> <span data-ttu-id="24941-198">Hello левой области навигации щелкните **Jupyter**, нажмите кнопку **действий службы**, а затем нажмите кнопку **перезапустите все**.</span><span class="sxs-lookup"><span data-stu-id="24941-198">From hello left navigation pane, click **Jupyter**, click **Service Actions**, and then click **Restart All**.</span></span> <span data-ttu-id="24941-199">Это приведет к запуску hello Jupyter службы на всех headnodes hello.</span><span class="sxs-lookup"><span data-stu-id="24941-199">This will start hello Jupyter service on all hello headnodes.</span></span>

    ![Restart Jupyter](./media/hdinsight-apache-spark-resource-manager/restart-jupyter.png "Restart Jupyter")

## <a name="how-do-i-know-if-i-am-running-out-of-resources"></a><span data-ttu-id="24941-200">Как узнать, что ресурсы заканчиваются?</span><span class="sxs-lookup"><span data-stu-id="24941-200">How do I know if I am running out of resources?</span></span>
<span data-ttu-id="24941-201">Запустите hello Yarn пользовательского интерфейса, как показано выше.</span><span class="sxs-lookup"><span data-stu-id="24941-201">Launch hello Yarn UI as shown above.</span></span> <span data-ttu-id="24941-202">В таблице показателей кластера поверх экрана приветствия, проверьте значения **памяти,** и **общей памяти** столбцов.</span><span class="sxs-lookup"><span data-stu-id="24941-202">In Cluster Metrics table on top of hello screen, check values of **Memory Used** and **Memory Total** columns.</span></span> <span data-ttu-id="24941-203">Если очень близкие значения hello 2, может не иметься достаточно ресурсов toostart hello Далее приложение.</span><span class="sxs-lookup"><span data-stu-id="24941-203">If hello 2 values are very close, there might not be enough resources toostart hello next application.</span></span> <span data-ttu-id="24941-204">Hello применимо и к toohello **используется VCores** и **VCores всего** столбцов.</span><span class="sxs-lookup"><span data-stu-id="24941-204">hello same applies toohello **VCores Used** and **VCores Total** columns.</span></span> <span data-ttu-id="24941-205">Кроме того, в основном представлении hello, если имеется приложение лет в **ПРИНЯТО** состоянии и не переходит **под УПРАВЛЕНИЕМ** , ни **сбой** состоянии, это может также свидетельствовать об не становится toostart достаточно ресурсов.</span><span class="sxs-lookup"><span data-stu-id="24941-205">Also, in hello main view, if there is an application stayed in **ACCEPTED** state and not transitioning into **RUNNING** nor **FAILED** state, this could also be an indication that it is not getting enough resources toostart.</span></span>

    ![Resource Limit](./media/hdinsight-apache-spark-resource-manager/resource-limit.png "Resource Limit")

## <a name="how-do-i-kill-a-running-application-toofree-up-resource"></a><span data-ttu-id="24941-206">Как kill работающего приложения toofree ресурса?</span><span class="sxs-lookup"><span data-stu-id="24941-206">How do I kill a running application toofree up resource?</span></span>
1. <span data-ttu-id="24941-207">В hello Yarn пользовательского интерфейса, с помощью hello левой панели, щелкните **под управлением**.</span><span class="sxs-lookup"><span data-stu-id="24941-207">In hello Yarn UI, from hello left panel, click **Running**.</span></span> <span data-ttu-id="24941-208">Из списка выполняющихся приложений hello, определить toobe приложения hello завершен и щелкнуть hello **идентификатор**.</span><span class="sxs-lookup"><span data-stu-id="24941-208">From hello list of running applications, determine hello application toobe killed and click on hello **ID**.</span></span>

    <span data-ttu-id="24941-209">![Завершение работы приложения 1](./media/hdinsight-apache-spark-resource-manager/kill-app1.png "Завершение работы приложения 1")</span><span class="sxs-lookup"><span data-stu-id="24941-209">![Kill App1](./media/hdinsight-apache-spark-resource-manager/kill-app1.png "Kill App1")</span></span>

2. <span data-ttu-id="24941-210">Нажмите кнопку **Kill приложения** hello правом верхнем углу, затем щелкните **ОК**.</span><span class="sxs-lookup"><span data-stu-id="24941-210">Click **Kill Application** on hello top right corner, then click **OK**.</span></span>

    <span data-ttu-id="24941-211">![Завершение работы приложения 2](./media/hdinsight-apache-spark-resource-manager/kill-app2.png "Завершение работы приложения 2")</span><span class="sxs-lookup"><span data-stu-id="24941-211">![Kill App2](./media/hdinsight-apache-spark-resource-manager/kill-app2.png "Kill App2")</span></span>

## <a name="see-also"></a><span data-ttu-id="24941-212">См. также</span><span class="sxs-lookup"><span data-stu-id="24941-212">See also</span></span>
* [<span data-ttu-id="24941-213">Отслеживание и отладка заданий в кластере Apache Spark в HDInsight на платформе Linux</span><span class="sxs-lookup"><span data-stu-id="24941-213">Track and debug jobs running on an Apache Spark cluster in HDInsight</span></span>](hdinsight-apache-spark-job-debugging.md)

### <a name="for-data-analysts"></a><span data-ttu-id="24941-214">Для специалистов по анализу данных</span><span class="sxs-lookup"><span data-stu-id="24941-214">For data analysts</span></span>

* [<span data-ttu-id="24941-215">Использование Spark с машинным обучением. Использование Spark в HDInsight для анализа температуры в здании на основе данных системы кондиционирования</span><span class="sxs-lookup"><span data-stu-id="24941-215">Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)
* [<span data-ttu-id="24941-216">Spark с машинного обучения: используйте Spark в HDInsight toopredict food проверки результатов</span><span class="sxs-lookup"><span data-stu-id="24941-216">Spark with Machine Learning: Use Spark in HDInsight toopredict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)
* [<span data-ttu-id="24941-217">Анализ журнала веб-сайта с использованием Spark в HDInsight</span><span class="sxs-lookup"><span data-stu-id="24941-217">Website log analysis using Spark in HDInsight</span></span>](hdinsight-apache-spark-custom-library-website-log-analysis.md)
* [<span data-ttu-id="24941-218">Analyze Application Insights telemetry logs with Spark on HDInsight (Анализ журналов телеметрии Application Insights с помощью Spark в HDInsight)</span><span class="sxs-lookup"><span data-stu-id="24941-218">Application Insight telemetry data analysis using Spark in HDInsight</span></span>](hdinsight-spark-analyze-application-insight-logs.md)
* [<span data-ttu-id="24941-219">Использование Caffe в кластере Azure HDInsight Spark для распределенного глубокого обучения</span><span class="sxs-lookup"><span data-stu-id="24941-219">Use Caffe on Azure HDInsight Spark for distributed deep learning</span></span>](hdinsight-deep-learning-caffe-spark.md)

### <a name="for-spark-developers"></a><span data-ttu-id="24941-220">Для разработчиков Spark</span><span class="sxs-lookup"><span data-stu-id="24941-220">For Spark developers</span></span>

* [<span data-ttu-id="24941-221">Создание автономного приложения с использованием Scala</span><span class="sxs-lookup"><span data-stu-id="24941-221">Create a standalone application using Scala</span></span>](hdinsight-apache-spark-create-standalone-application.md)
* [<span data-ttu-id="24941-222">Удаленный запуск заданий с помощью Livy в кластере Spark</span><span class="sxs-lookup"><span data-stu-id="24941-222">Run jobs remotely on a Spark cluster using Livy</span></span>](hdinsight-apache-spark-livy-rest-interface.md)
* [<span data-ttu-id="24941-223">Использование подключаемого модуля средства HDInsight для toocreate ИДЕЯ IntelliJ и отправка Spark Scala приложений</span><span class="sxs-lookup"><span data-stu-id="24941-223">Use HDInsight Tools Plugin for IntelliJ IDEA toocreate and submit Spark Scala applications</span></span>](hdinsight-apache-spark-intellij-tool-plugin.md)
* [<span data-ttu-id="24941-224">Потоковая передача Spark. Использование Spark в HDInsight для сборки приложений потоковой передачи данных в режиме реального времени</span><span class="sxs-lookup"><span data-stu-id="24941-224">Spark Streaming: Use Spark in HDInsight for building real-time streaming applications</span></span>](hdinsight-apache-spark-eventhub-streaming.md)
* [<span data-ttu-id="24941-225">Удаленно использовать подключаемый модуль средства HDInsight для приложений Spark toodebug ИДЕЯ IntelliJ</span><span class="sxs-lookup"><span data-stu-id="24941-225">Use HDInsight Tools Plugin for IntelliJ IDEA toodebug Spark applications remotely</span></span>](hdinsight-apache-spark-intellij-tool-plugin-debug-jobs-remotely.md)
* [<span data-ttu-id="24941-226">Использование записных книжек Zeppelin с кластером Spark в HDInsight</span><span class="sxs-lookup"><span data-stu-id="24941-226">Use Zeppelin notebooks with a Spark cluster on HDInsight</span></span>](hdinsight-apache-spark-zeppelin-notebook.md)
* [<span data-ttu-id="24941-227">Ядра, доступные для записной книжки Jupyter в кластере Spark в HDInsight</span><span class="sxs-lookup"><span data-stu-id="24941-227">Kernels available for Jupyter notebook in Spark cluster for HDInsight</span></span>](hdinsight-apache-spark-jupyter-notebook-kernels.md)
* [<span data-ttu-id="24941-228">Использование внешних пакетов с записными книжками Jupyter</span><span class="sxs-lookup"><span data-stu-id="24941-228">Use external packages with Jupyter notebooks</span></span>](hdinsight-apache-spark-jupyter-notebook-use-external-packages.md)
* [<span data-ttu-id="24941-229">Установка Jupyter на вашем компьютере и подключение tooan кластера HDInsight Spark</span><span class="sxs-lookup"><span data-stu-id="24941-229">Install Jupyter on your computer and connect tooan HDInsight Spark cluster</span></span>](hdinsight-apache-spark-jupyter-notebook-install-locally.md)
