---
title: "aaaKernels записной книжки Jupyter на Spark кластеров в Azure HDInsight | Документы Microsoft"
description: "Дополнительные сведения о версии ядра PySpark PySpark3 и Spark hello записной книжки Jupyter, доступные с кластерами Spark на Azure HDInsight."
keywords: "записная книжка jupyter в spark, jupyter в spark"
services: hdinsight
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: 0719e503-ee6d-41ac-b37e-3d77db8b121b
ms.service: hdinsight
ms.custom: hdinsightactive,hdiseo17may2017
ms.workload: big-data
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 05/15/2017
ms.author: nitinme
ms.openlocfilehash: 560c944fe850c5753ac9fa90550b804f0c47d14c
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 10/06/2017
---
# <a name="kernels-for-jupyter-notebook-on-spark-clusters-in-azure-hdinsight"></a><span data-ttu-id="ff9f6-104">Ядра для записной книжки Jupyter в кластерах Spark в Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="ff9f6-104">Kernels for Jupyter notebook on Spark clusters in Azure HDInsight</span></span> 

<span data-ttu-id="ff9f6-105">Кластеры HDInsight Spark предоставляют ядер, которые можно использовать для тестирования приложений с записной книжке Jupyter hello Spark.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-105">HDInsight Spark clusters provide kernels that you can use with hello Jupyter notebook on Spark for testing your applications.</span></span> <span data-ttu-id="ff9f6-106">Ядра — это программа, которая выполняет и интерпретирует ваш код.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-106">A kernel is a program that runs and interprets your code.</span></span> <span data-ttu-id="ff9f6-107">приведены три ядра Hello.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-107">hello three kernels are:</span></span>

- <span data-ttu-id="ff9f6-108">**PySpark** (для приложений, написанных на языке Python2).</span><span class="sxs-lookup"><span data-stu-id="ff9f6-108">**PySpark** - for applications written in Python2</span></span>
- <span data-ttu-id="ff9f6-109">**PySpark3** (для приложений, написанных на языке Python3).</span><span class="sxs-lookup"><span data-stu-id="ff9f6-109">**PySpark3** - for applications written in Python3</span></span>
- <span data-ttu-id="ff9f6-110">**Spark** (для приложений, написанных на языке Scala).</span><span class="sxs-lookup"><span data-stu-id="ff9f6-110">**Spark** - for applications written in Scala</span></span>

<span data-ttu-id="ff9f6-111">В этой статье вы узнаете, как toouse эти ядер и hello преимущества их использования.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-111">In this article, you learn how toouse these kernels and hello benefits of using them.</span></span>

## <a name="prerequisites"></a><span data-ttu-id="ff9f6-112">Предварительные требования</span><span class="sxs-lookup"><span data-stu-id="ff9f6-112">Prerequisites</span></span>

* <span data-ttu-id="ff9f6-113">Кластер Apache Spark в HDInsight.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-113">An Apache Spark cluster in HDInsight.</span></span> <span data-ttu-id="ff9f6-114">Инструкции см. в статье [Начало работы. Создание кластера Apache Spark в HDInsight на платформе Linux и выполнение интерактивных запросов с помощью SQL Spark](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="ff9f6-114">For instructions, see [Create Apache Spark clusters in Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span>

## <a name="create-a-jupyter-notebook-on-spark-hdinsight"></a><span data-ttu-id="ff9f6-115">Создание записной книжки Jupyter в Spark HDInsight</span><span class="sxs-lookup"><span data-stu-id="ff9f6-115">Create a Jupyter notebook on Spark HDInsight</span></span>

1. <span data-ttu-id="ff9f6-116">Из hello [портал Azure](https://portal.azure.com/), откройте кластера.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-116">From hello [Azure portal](https://portal.azure.com/), open your cluster.</span></span>  <span data-ttu-id="ff9f6-117">В разделе [списка и Показывать кластеры](hdinsight-administer-use-portal-linux.md#list-and-show-clusters) hello инструкции.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-117">See [List and show clusters](hdinsight-administer-use-portal-linux.md#list-and-show-clusters) for hello instructions.</span></span> <span data-ttu-id="ff9f6-118">Hello кластера будет открыт в Новая колонка портала.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-118">hello cluster is opened in a new portal blade.</span></span>

2. <span data-ttu-id="ff9f6-119">Из hello **быстрые ссылки** щелкните **кластера панелей мониторинга** tooopen hello **кластера панелей мониторинга** колонку.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-119">From hello **Quick links** section, click **Cluster dashboards** tooopen hello **Cluster dashboards** blade.</span></span>  <span data-ttu-id="ff9f6-120">Если вы не видите **быстрые ссылки**, нажмите кнопку **Обзор** из меню слева hello в колонке hello.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-120">If you don't see **Quick Links**, click **Overview** from hello left menu on hello blade.</span></span>

    <span data-ttu-id="ff9f6-121">![Записная книжка Jupyter в Spark](./media/hdinsight-apache-spark-jupyter-notebook-kernels/hdinsight-jupyter-notebook-on-spark.png "Записная книжка Jupyter в Spark")</span><span class="sxs-lookup"><span data-stu-id="ff9f6-121">![Jupyter notebook on Spark](./media/hdinsight-apache-spark-jupyter-notebook-kernels/hdinsight-jupyter-notebook-on-spark.png "Jupyter notebook on Spark")</span></span> 

3. <span data-ttu-id="ff9f6-122">Щелкните **Записная книжка Jupyter**.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-122">Click **Jupyter Notebook**.</span></span> <span data-ttu-id="ff9f6-123">При появлении запроса введите учетные данные администратора hello hello кластера.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-123">If prompted, enter hello admin credentials for hello cluster.</span></span>
   
   > [!NOTE]
   > <span data-ttu-id="ff9f6-124">Кроме того, может попасть книжке Jupyter hello на кластере Spark путем открытия hello следующий URL-адрес в браузере.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-124">You may also reach hello Jupyter notebook on Spark cluster by opening hello following URL in your browser.</span></span> <span data-ttu-id="ff9f6-125">Замените **CLUSTERNAME** с hello имя кластера:</span><span class="sxs-lookup"><span data-stu-id="ff9f6-125">Replace **CLUSTERNAME** with hello name of your cluster:</span></span>
   >
   > `https://CLUSTERNAME.azurehdinsight.net/jupyter`
   > 
   > 

3. <span data-ttu-id="ff9f6-126">Нажмите кнопку **New**, а затем — **Pyspark**, **PySpark3**, или **Spark** toocreate записной книжке.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-126">Click **New**, and then click either **Pyspark**, **PySpark3**, or **Spark** toocreate a notebook.</span></span> <span data-ttu-id="ff9f6-127">Используйте hello Spark ядра для приложений Scala PySpark ядра для Python2 приложений и PySpark3 ядра для Python3 приложений.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-127">Use hello Spark kernel for Scala applications, PySpark kernel for Python2 applications, and PySpark3 kernel for Python3 applications.</span></span>
   
    <span data-ttu-id="ff9f6-128">![Ядра для записной книжки Jupyter в Spark](./media/hdinsight-apache-spark-jupyter-notebook-kernels/kernel-jupyter-notebook-on-spark.png "Ядра для записной книжки Jupyter в Spark")</span><span class="sxs-lookup"><span data-stu-id="ff9f6-128">![Kernels for Jupyter notebook on Spark](./media/hdinsight-apache-spark-jupyter-notebook-kernels/kernel-jupyter-notebook-on-spark.png "Kernels for Jupyter notebook on Spark")</span></span> 

4. <span data-ttu-id="ff9f6-129">Записной книжке откроется ядра hello выбранный.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-129">A notebook opens with hello kernel you selected.</span></span>

## <a name="benefits-of-using-hello-kernels"></a><span data-ttu-id="ff9f6-130">Преимущества использования ядра hello</span><span class="sxs-lookup"><span data-stu-id="ff9f6-130">Benefits of using hello kernels</span></span>

<span data-ttu-id="ff9f6-131">Ниже приведены несколько преимуществ использования новой версии ядра hello с книжке Jupyter в кластерах Spark HDInsight.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-131">Here are a few benefits of using hello new kernels with Jupyter notebook on Spark HDInsight clusters.</span></span>

- <span data-ttu-id="ff9f6-132">**Предустановленные контексты**.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-132">**Preset contexts**.</span></span> <span data-ttu-id="ff9f6-133">С **PySpark**, **PySpark3**, или hello **Spark** ядра, не требуется tooset hello Spark или куст контекстов явно перед началом работы с приложениями.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-133">With  **PySpark**, **PySpark3**, or hello **Spark** kernels, you do not need tooset hello Spark or Hive contexts explicitly before you start working with your applications.</span></span> <span data-ttu-id="ff9f6-134">Они доступны по умолчанию.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-134">These are available by default.</span></span> <span data-ttu-id="ff9f6-135">а именно:</span><span class="sxs-lookup"><span data-stu-id="ff9f6-135">These contexts are:</span></span>
   
   * <span data-ttu-id="ff9f6-136">**sc** для контекста Spark;</span><span class="sxs-lookup"><span data-stu-id="ff9f6-136">**sc** - for Spark context</span></span>
   * <span data-ttu-id="ff9f6-137">**sqlContext** для контекста Hive.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-137">**sqlContext** - for Hive context</span></span>

    <span data-ttu-id="ff9f6-138">Таким образом не имеют toorun выражения, например hello следующие tooset hello контекстах:</span><span class="sxs-lookup"><span data-stu-id="ff9f6-138">So, you don't have toorun statements like hello following tooset hello contexts:</span></span>

        <span data-ttu-id="ff9f6-139">sc = SparkContext('yarn-client')    sqlContext = HiveContext(sc)</span><span class="sxs-lookup"><span data-stu-id="ff9f6-139">sc = SparkContext('yarn-client')    sqlContext = HiveContext(sc)</span></span>

    <span data-ttu-id="ff9f6-140">Вместо этого можно использовать непосредственно hello предустановленный набор контекстов в приложении.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-140">Instead, you can directly use hello preset contexts in your application.</span></span>

- <span data-ttu-id="ff9f6-141">**Волшебные команды.**</span><span class="sxs-lookup"><span data-stu-id="ff9f6-141">**Cell magics**.</span></span> <span data-ttu-id="ff9f6-142">Hello ядра PySpark предоставляет некоторые предопределенные «magics», которые являются специальные команды, которые можно вызвать с `%%` (например, `%%MAGIC` <args>).</span><span class="sxs-lookup"><span data-stu-id="ff9f6-142">hello PySpark kernel provides some predefined “magics”, which are special commands that you can call with `%%` (for example, `%%MAGIC` <args>).</span></span> <span data-ttu-id="ff9f6-143">Команда magic Hello должно быть первое слово hello в ячейке кода и разрешить для нескольких строк содержимого.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-143">hello magic command must be hello first word in a code cell and allow for multiple lines of content.</span></span> <span data-ttu-id="ff9f6-144">magic слово Hello должен быть первым словом hello hello ячейки.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-144">hello magic word should be hello first word in hello cell.</span></span> <span data-ttu-id="ff9f6-145">Добавление ничего перед magic hello, даже комментарии, приводит к ошибке.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-145">Adding anything before hello magic, even comments, causes an error.</span></span>     <span data-ttu-id="ff9f6-146">Дополнительные сведения о волшебных командах см. [здесь](http://ipython.readthedocs.org/en/stable/interactive/magics.html).</span><span class="sxs-lookup"><span data-stu-id="ff9f6-146">For more information on magics, see [here](http://ipython.readthedocs.org/en/stable/interactive/magics.html).</span></span>
   
    <span data-ttu-id="ff9f6-147">Hello следующей таблице перечислены hello различных magics через hello ядер.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-147">hello following table lists hello different magics available through hello kernels.</span></span>

   | <span data-ttu-id="ff9f6-148">Волшебная команда</span><span class="sxs-lookup"><span data-stu-id="ff9f6-148">Magic</span></span> | <span data-ttu-id="ff9f6-149">Пример</span><span class="sxs-lookup"><span data-stu-id="ff9f6-149">Example</span></span> | <span data-ttu-id="ff9f6-150">Описание</span><span class="sxs-lookup"><span data-stu-id="ff9f6-150">Description</span></span> |
   | --- | --- | --- |
   | <span data-ttu-id="ff9f6-151">help</span><span class="sxs-lookup"><span data-stu-id="ff9f6-151">help</span></span> |`%%help` |<span data-ttu-id="ff9f6-152">Создает таблицу из всех доступных magics hello пример и описание</span><span class="sxs-lookup"><span data-stu-id="ff9f6-152">Generates a table of all hello available magics with example and description</span></span> |
   | <span data-ttu-id="ff9f6-153">info</span><span class="sxs-lookup"><span data-stu-id="ff9f6-153">info</span></span> |`%%info` |<span data-ttu-id="ff9f6-154">Выводит сведения сеанса для hello текущей конечной точки Livy</span><span class="sxs-lookup"><span data-stu-id="ff9f6-154">Outputs session information for hello current Livy endpoint</span></span> |
   | <span data-ttu-id="ff9f6-155">Настройка</span><span class="sxs-lookup"><span data-stu-id="ff9f6-155">configure</span></span> |`%%configure -f`<br><span data-ttu-id="ff9f6-156">`{"executorMemory": "1000M"`,</span><span class="sxs-lookup"><span data-stu-id="ff9f6-156">`{"executorMemory": "1000M"`,</span></span><br><span data-ttu-id="ff9f6-157">`"executorCores": 4`}</span><span class="sxs-lookup"><span data-stu-id="ff9f6-157">`"executorCores": 4`}</span></span> |<span data-ttu-id="ff9f6-158">Настраивает параметры hello для создания сеанса.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-158">Configures hello parameters for creating a session.</span></span> <span data-ttu-id="ff9f6-159">Здравствуйте, флаг force (-f) является обязательным, если сеанс уже создан, который гарантирует hello сеанса удалить и создать заново.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-159">hello force flag (-f) is mandatory if a session has already been created, which ensures that hello session is dropped and recreated.</span></span> <span data-ttu-id="ff9f6-160">Список допустимых параметров приведен в разделе, посвященном [тексту запроса сеансов POST Livy](https://github.com/cloudera/livy#request-body) .</span><span class="sxs-lookup"><span data-stu-id="ff9f6-160">Look at [Livy's POST /sessions Request Body](https://github.com/cloudera/livy#request-body) for a list of valid parameters.</span></span> <span data-ttu-id="ff9f6-161">Параметры должны передаваться в виде строки JSON и должен быть на следующую строку hello после hello magic, как показано в примере столбец hello.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-161">Parameters must be passed in as a JSON string and must be on hello next line after hello magic, as shown in hello example column.</span></span> |
   | <span data-ttu-id="ff9f6-162">sql</span><span class="sxs-lookup"><span data-stu-id="ff9f6-162">sql</span></span> |`%%sql -o <variable name>`<br> `SHOW TABLES` |<span data-ttu-id="ff9f6-163">Выполняет запрос Hive в отношении hello sqlContext.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-163">Executes a Hive query against hello sqlContext.</span></span> <span data-ttu-id="ff9f6-164">Если hello `-o` передается параметр, результат hello hello запроса сохраняется в hello %% локального контекста Python как [Pandas](http://pandas.pydata.org/) кадр данных.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-164">If hello `-o` parameter is passed, hello result of hello query is persisted in hello %%local Python context as a [Pandas](http://pandas.pydata.org/) dataframe.</span></span> |
   | <span data-ttu-id="ff9f6-165">local</span><span class="sxs-lookup"><span data-stu-id="ff9f6-165">local</span></span> |`%%local`<br>`a=1` |<span data-ttu-id="ff9f6-166">Весь код hello в последующих строках выполняется локально.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-166">All hello code in subsequent lines is executed locally.</span></span> <span data-ttu-id="ff9f6-167">Код должен быть допустимым кодом Python2 даже независимо от ядра hello, которую вы используете.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-167">Code must be valid Python2 code even irrespective of hello kernel you are using.</span></span> <span data-ttu-id="ff9f6-168">Таким образом, даже если вы выбрали **PySpark3** или **Spark** ядра при создании hello записной книжки, если вы используете hello `%%local` magic в ячейке, что ячейка должна иметь только допустимый код Python2...</span><span class="sxs-lookup"><span data-stu-id="ff9f6-168">So, even if you selected **PySpark3** or **Spark** kernels while creating hello notebook, if you use hello `%%local` magic in a cell, that cell must only have valid Python2 code..</span></span> |
   | <span data-ttu-id="ff9f6-169">журналы</span><span class="sxs-lookup"><span data-stu-id="ff9f6-169">logs</span></span> |`%%logs` |<span data-ttu-id="ff9f6-170">Выходные данные журналов hello для текущего сеанса Livy hello.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-170">Outputs hello logs for hello current Livy session.</span></span> |
   | <span data-ttu-id="ff9f6-171">удалить</span><span class="sxs-lookup"><span data-stu-id="ff9f6-171">delete</span></span> |`%%delete -f -s <session number>` |<span data-ttu-id="ff9f6-172">Удаляет определенный сеанс hello текущей Livy конечной точки.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-172">Deletes a specific session of hello current Livy endpoint.</span></span> <span data-ttu-id="ff9f6-173">Обратите внимание, нельзя удалить сеанс hello, обычно инициируемой для ядра hello сам.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-173">Note that you cannot delete hello session that is initiated for hello kernel itself.</span></span> |
   | <span data-ttu-id="ff9f6-174">cleanup</span><span class="sxs-lookup"><span data-stu-id="ff9f6-174">cleanup</span></span> |`%%cleanup -f` |<span data-ttu-id="ff9f6-175">Удаляет все сеансы hello для hello текущей конечной точки Livy, включая записной книжки сеанс.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-175">Deletes all hello sessions for hello current Livy endpoint, including this notebook's session.</span></span> <span data-ttu-id="ff9f6-176">флаг force Hello -f является обязательным.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-176">hello force flag -f is mandatory.</span></span> |

   > [!NOTE]
   > <span data-ttu-id="ff9f6-177">В дополнение к этому toohello magics добавленные ядра PySpark hello, можно также использовать hello [встроенные magics IPython](https://ipython.org/ipython-doc/3/interactive/magics.html#cell-magics), в том числе `%%sh`.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-177">In addition toohello magics added by hello PySpark kernel, you can also use hello [built-in IPython magics](https://ipython.org/ipython-doc/3/interactive/magics.html#cell-magics), including `%%sh`.</span></span> <span data-ttu-id="ff9f6-178">Можно использовать hello `%%sh` магическая toorun сценарии и блока кода на головному узлу кластера hello.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-178">You can use hello `%%sh` magic toorun scripts and block of code on hello cluster headnode.</span></span>
   >
   >
2. <span data-ttu-id="ff9f6-179">**Автоматическая визуализация**.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-179">**Auto visualization**.</span></span> <span data-ttu-id="ff9f6-180">Hello **Pyspark** ядра автоматически визуализирует hello выходных данных Hive и SQL-запросов.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-180">hello **Pyspark** kernel automatically visualizes hello output of Hive and SQL queries.</span></span> <span data-ttu-id="ff9f6-181">Вы можете выбрать различные типы средства визуализации, включая таблицы, круговые диаграммы, графики, диаграммы с областями и линейчатые диаграммы.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-181">You can choose between several different types of visualizations including Table, Pie, Line, Area, Bar.</span></span>

## <a name="parameters-supported-with-hello-sql-magic"></a><span data-ttu-id="ff9f6-182">Параметры, поддерживаемые с hello %% sql magic</span><span class="sxs-lookup"><span data-stu-id="ff9f6-182">Parameters supported with hello %%sql magic</span></span>
<span data-ttu-id="ff9f6-183">Hello `%%sql` magic поддерживает различные параметры, которые можно использовать toocontrol hello тип выходных данных, которое появляется при выполнении запросов.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-183">hello `%%sql` magic supports different parameters that you can use toocontrol hello kind of output that you receive when you run queries.</span></span> <span data-ttu-id="ff9f6-184">Привет, в следующей таблице перечислены hello выходных данных.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-184">hello following table lists hello output.</span></span>

| <span data-ttu-id="ff9f6-185">Параметр</span><span class="sxs-lookup"><span data-stu-id="ff9f6-185">Parameter</span></span> | <span data-ttu-id="ff9f6-186">Пример</span><span class="sxs-lookup"><span data-stu-id="ff9f6-186">Example</span></span> | <span data-ttu-id="ff9f6-187">Описание</span><span class="sxs-lookup"><span data-stu-id="ff9f6-187">Description</span></span> |
| --- | --- | --- |
| <span data-ttu-id="ff9f6-188">-o</span><span class="sxs-lookup"><span data-stu-id="ff9f6-188">-o</span></span> |`-o <VARIABLE NAME>` |<span data-ttu-id="ff9f6-189">Используйте этот параметр toopersist hello результат запроса hello в hello %% локального контекста Python как [Pandas](http://pandas.pydata.org/) кадр данных.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-189">Use this parameter toopersist hello result of hello query, in hello %%local Python context, as a [Pandas](http://pandas.pydata.org/) dataframe.</span></span> <span data-ttu-id="ff9f6-190">Hello переменной hello кадр данных называется hello переменной имя.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-190">hello name of hello dataframe variable is hello variable name you specify.</span></span> |
| <span data-ttu-id="ff9f6-191">-q</span><span class="sxs-lookup"><span data-stu-id="ff9f6-191">-q</span></span> |`-q` |<span data-ttu-id="ff9f6-192">Используйте этот tooturn off визуализации для hello ячейки.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-192">Use this tooturn off visualizations for hello cell.</span></span> <span data-ttu-id="ff9f6-193">Если вы не хотите tooauto-визуализировать hello содержимого ячейки и просто хотят toocapture его как кадр данных, затем с помощью `-q -o <VARIABLE>`.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-193">If you don't want tooauto-visualize hello content of a cell and just want toocapture it as a dataframe, then use `-q -o <VARIABLE>`.</span></span> <span data-ttu-id="ff9f6-194">Если требуется tooturn off визуализации без записи hello результаты (например, выполнение запроса SQL, таких как `CREATE TABLE` инструкции), используйте `-q` без указания `-o` аргумент.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-194">If you want tooturn off visualizations without capturing hello results (for example, for running a SQL query, like a `CREATE TABLE` statement), use `-q` without specifying a `-o` argument.</span></span> |
| <span data-ttu-id="ff9f6-195">-m</span><span class="sxs-lookup"><span data-stu-id="ff9f6-195">-m</span></span> |`-m <METHOD>` |<span data-ttu-id="ff9f6-196">Параметр **METHOD** имеет значение **take** или **sample** (по умолчанию используется значение **take**).</span><span class="sxs-lookup"><span data-stu-id="ff9f6-196">Where **METHOD** is either **take** or **sample** (default is **take**).</span></span> <span data-ttu-id="ff9f6-197">Если метод hello **принимать**, hello ядра выбирает элементы сверху hello hello результирующего набора данных, заданные MAXROWS (описывается далее в этой таблице).</span><span class="sxs-lookup"><span data-stu-id="ff9f6-197">If hello method is **take**, hello kernel picks elements from hello top of hello result data set specified by MAXROWS (described later in this table).</span></span> <span data-ttu-id="ff9f6-198">Если метод hello **пример**, hello ядра выполняют случайную выборку элементов набора данных hello слишком в соответствии с`-r` параметра, описанные далее в этой таблице.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-198">If hello method is **sample**, hello kernel randomly samples elements of hello data set according too`-r` parameter, described next in this table.</span></span> |
| <span data-ttu-id="ff9f6-199">-r</span><span class="sxs-lookup"><span data-stu-id="ff9f6-199">-r</span></span> |`-r <FRACTION>` |<span data-ttu-id="ff9f6-200">Здесь **FRACTION** — это число с плавающей запятой от 0,0 до 1,0.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-200">Here **FRACTION** is a floating-point number between 0.0 and 1.0.</span></span> <span data-ttu-id="ff9f6-201">Если метод образец hello hello SQL-запрос `sample`, а затем hello ядра выполняют случайную выборку hello заданную долю элементов hello hello результирующего набора можно.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-201">If hello sample method for hello SQL query is `sample`, then hello kernel randomly samples hello specified fraction of hello elements of hello result set for you.</span></span> <span data-ttu-id="ff9f6-202">Например, если выполнить SQL-запрос с аргументами hello `-m sample -r 0.01`, а затем случайным образом выбирается hello результирующие строки % 1.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-202">For example, if you run a SQL query with hello arguments `-m sample -r 0.01`, then 1% of hello result rows are randomly sampled.</span></span> |
| -n |`-n <MAXROWS>` |<span data-ttu-id="ff9f6-203">**MAXROWS** должно быть выражено целым числом.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-203">**MAXROWS** is an integer value.</span></span> <span data-ttu-id="ff9f6-204">Hello ядра ограничивает hello число выходных строк слишком**MAXROWS**.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-204">hello kernel limits hello number of output rows too**MAXROWS**.</span></span> <span data-ttu-id="ff9f6-205">Если **MAXROWS** является отрицательным числом, такие как **-1**, то hello количество строк в результирующем наборе hello не ограничено.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-205">If **MAXROWS** is a negative number such as **-1**, then hello number of rows in hello result set is not limited.</span></span> |

<span data-ttu-id="ff9f6-206">**Пример**</span><span class="sxs-lookup"><span data-stu-id="ff9f6-206">**Example:**</span></span>

    %%sql -q -m sample -r 0.1 -n 500 -o query2
    SELECT * FROM hivesampletable

<span data-ttu-id="ff9f6-207">выше инструкция Hello hello следующие:</span><span class="sxs-lookup"><span data-stu-id="ff9f6-207">hello statement above does hello following:</span></span>

* <span data-ttu-id="ff9f6-208">Выбирает все записи из таблицы **hivesampletable**.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-208">Selects all records from **hivesampletable**.</span></span>
* <span data-ttu-id="ff9f6-209">Отключает автоматическую визуализацию, так как включает параметр -q.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-209">Because we use -q, it turns off auto-visualization.</span></span>
* <span data-ttu-id="ff9f6-210">Так как мы используем `-m sample -r 0.1 -n 500` его выполняют случайную выборку 10% строк hello в hello hivesampletable и ограничения hello размер строк too500 hello результирующего набора.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-210">Because we use `-m sample -r 0.1 -n 500` it randomly samples 10% of hello rows in hello hivesampletable and limits hello size of hello result set too500 rows.</span></span>
* <span data-ttu-id="ff9f6-211">Наконец так как мы использовали `-o query2` также сохраняет выходные данные hello в кадр данных под именем **query2**.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-211">Finally, because we used `-o query2` it also saves hello output into a dataframe called **query2**.</span></span>

## <a name="considerations-while-using-hello-new-kernels"></a><span data-ttu-id="ff9f6-212">Рекомендации при использовании нового ядра hello</span><span class="sxs-lookup"><span data-stu-id="ff9f6-212">Considerations while using hello new kernels</span></span>

<span data-ttu-id="ff9f6-213">Независимо от ядра используется, если оставить hello портативные компьютеры под управлением потребляет ресурсы кластера hello.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-213">Whichever kernel you use, leaving hello notebooks running consumes hello cluster resources.</span></span>  <span data-ttu-id="ff9f6-214">С этими ядер, поскольку заданы контексты hello, просто выход из записных книжек hello завершать контекст hello и таким образом ресурсы кластера hello продолжить toobe используется.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-214">With these kernels, because hello contexts are preset, simply exiting hello notebooks does not kill hello context and hence hello cluster resources continue toobe in use.</span></span> <span data-ttu-id="ff9f6-215">Рекомендуется toouse hello **закрыть и остановить** параметр из записной книжки hello **файл** меню, появляющемся при завершении использования hello ноутбук, который ликвидирует контекст hello и затем завершает работу hello записной книжке.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-215">A good practice is toouse hello **Close and Halt** option from hello notebook's **File** menu when you are finished using hello notebook, which kills hello context and then exits hello notebook.</span></span>     

## <a name="show-me-some-examples"></a><span data-ttu-id="ff9f6-216">Примеры</span><span class="sxs-lookup"><span data-stu-id="ff9f6-216">Show me some examples</span></span>

<span data-ttu-id="ff9f6-217">При открытии записной книжке Jupyter, вы видите две папки на корневом уровне hello.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-217">When you open a Jupyter notebook, you see two folders available at hello root level.</span></span>

* <span data-ttu-id="ff9f6-218">Hello **PySpark** папка содержит примеры записных книжек hello, используйте новый **Python** ядра.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-218">hello **PySpark** folder has sample notebooks that use hello new **Python** kernel.</span></span>
* <span data-ttu-id="ff9f6-219">Hello **Scala** папка содержит примеры записных книжек hello, используйте новый **Spark** ядра.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-219">hello **Scala** folder has sample notebooks that use hello new **Spark** kernel.</span></span>

<span data-ttu-id="ff9f6-220">Можно открыть hello **00 - [чтения первое Знакомство] компоненты ядра Magic Spark** записной книжки из hello **PySpark** или **Spark** папки toolearn о различных magics hello доступны.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-220">You can open hello **00 - [READ ME FIRST] Spark Magic Kernel Features** notebook from hello **PySpark** or **Spark** folder toolearn about hello different magics available.</span></span> <span data-ttu-id="ff9f6-221">Также можно использовать как hello другие примеры записных книжек доступен в разделе hello двух папок toolearn tooachieve различных сценариев с помощью записные книжки Jupyter с кластерами HDInsight Spark.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-221">You can also use hello other sample notebooks available under hello two folders toolearn how tooachieve different scenarios using Jupyter notebooks with HDInsight Spark clusters.</span></span>

## <a name="where-are-hello-notebooks-stored"></a><span data-ttu-id="ff9f6-222">Где хранятся записных книжек hello</span><span class="sxs-lookup"><span data-stu-id="ff9f6-222">Where are hello notebooks stored?</span></span>

<span data-ttu-id="ff9f6-223">Записные книжки Jupyter сохраняются в учетной записи хранилища toohello, связанные с кластером hello под hello **/HdiNotebooks** папки.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-223">Jupyter notebooks are saved toohello storage account associated with hello cluster under hello **/HdiNotebooks** folder.</span></span>  <span data-ttu-id="ff9f6-224">Портативные компьютеры, текстовые файлы и папки, создаваемые на основе внутри Jupyter доступны из учетной записи хранилища hello.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-224">Notebooks, text files, and folders that you create from within Jupyter are accessible from hello storage account.</span></span>  <span data-ttu-id="ff9f6-225">Например, при использовании Jupyter toocreate папку **myfolder** и записной книжке **myfolder/mynotebook.ipynb**, можно получить доступ к этой записной книжки в `/HdiNotebooks/myfolder/mynotebook.ipynb` в учетной записи хранилища hello.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-225">For example, if you use Jupyter toocreate a folder **myfolder** and a notebook **myfolder/mynotebook.ipynb**, you can access that notebook at `/HdiNotebooks/myfolder/mynotebook.ipynb` within hello storage account.</span></span>  <span data-ttu-id="ff9f6-226">Hello обратного также имеет значение true, то есть, при передаче записной книжке непосредственно учетной записи хранилища tooyour в `/HdiNotebooks/mynotebook1.ipynb`, записной книжки hello также будет видимым в Jupyter.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-226">hello reverse is also true, that is, if you upload a notebook directly tooyour storage account at `/HdiNotebooks/mynotebook1.ipynb`, hello notebook is visible from Jupyter as well.</span></span>  <span data-ttu-id="ff9f6-227">Портативные компьютеры оставаться в учетной записи хранилища hello даже после удаления кластера hello.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-227">Notebooks remain in hello storage account even after hello cluster is deleted.</span></span>

<span data-ttu-id="ff9f6-228">Hello способом, сохраняются в учетной записи хранилища toohello записных книжек совместим с HDFS.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-228">hello way notebooks are saved toohello storage account is compatible with HDFS.</span></span> <span data-ttu-id="ff9f6-229">Таким образом, если вы SSH в кластер hello, которые можно использовать файл команды управления, как показано в следующий фрагмент кода hello:</span><span class="sxs-lookup"><span data-stu-id="ff9f6-229">So, if you SSH into hello cluster you can use file management commands as shown in hello following snippet:</span></span>

    hdfs dfs -ls /HdiNotebooks                               # List everything at hello root directory – everything in this directory is visible tooJupyter from hello home page
    hdfs dfs –copyToLocal /HdiNotebooks                    # Download hello contents of hello HdiNotebooks folder
    hdfs dfs –copyFromLocal example.ipynb /HdiNotebooks   # Upload a notebook example.ipynb toohello root folder so it’s visible from Jupyter


<span data-ttu-id="ff9f6-230">Если имеются проблемы с доступом к учетной записи хранилища hello кластера hello, портативные компьютеры hello также сохраняются на головному узлу hello `/var/lib/jupyter`.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-230">In case there are issues accessing hello storage account for hello cluster, hello notebooks are also saved on hello headnode `/var/lib/jupyter`.</span></span>

## <a name="supported-browser"></a><span data-ttu-id="ff9f6-231">Поддерживаемый браузер</span><span class="sxs-lookup"><span data-stu-id="ff9f6-231">Supported browser</span></span>

<span data-ttu-id="ff9f6-232">Записные книжки Jupyter, выполняемые в кластерах HDInsight Spark, поддерживаются только браузером Google Chrome.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-232">Jupyter notebooks on Spark HDInsight clusters are supported only on Google Chrome.</span></span>

## <a name="feedback"></a><span data-ttu-id="ff9f6-233">Отзыв</span><span class="sxs-lookup"><span data-stu-id="ff9f6-233">Feedback</span></span>
<span data-ttu-id="ff9f6-234">новые версии ядра Hello находятся в развивается рабочей области и будет взрослых со временем.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-234">hello new kernels are in evolving stage and will mature over time.</span></span> <span data-ttu-id="ff9f6-235">Кроме того, это может означать, что по мере развития этих ядер API могут измениться.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-235">This could also mean that APIs could change as these kernels mature.</span></span> <span data-ttu-id="ff9f6-236">Мы будем признательны вам за любые отзывы о работе с новыми ядрами.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-236">We would appreciate any feedback that you have while using these new kernels.</span></span> <span data-ttu-id="ff9f6-237">Это полезно при формировании hello окончательной версии этих ядер.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-237">This is useful in shaping hello final release of these kernels.</span></span> <span data-ttu-id="ff9f6-238">Можно оставить ваши комментарии и отзывы под hello **комментарии** раздел hello нижней части этой статьи.</span><span class="sxs-lookup"><span data-stu-id="ff9f6-238">You can leave your comments/feedback under hello **Comments** section at hello bottom of this article.</span></span>

## <span data-ttu-id="ff9f6-239"><a name="seealso"></a>Дополнительные материалы</span><span class="sxs-lookup"><span data-stu-id="ff9f6-239"><a name="seealso"></a>See also</span></span>
* [<span data-ttu-id="ff9f6-240">Обзор: Apache Spark в Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="ff9f6-240">Overview: Apache Spark on Azure HDInsight</span></span>](hdinsight-apache-spark-overview.md)

### <a name="scenarios"></a><span data-ttu-id="ff9f6-241">Сценарии</span><span class="sxs-lookup"><span data-stu-id="ff9f6-241">Scenarios</span></span>
* [<span data-ttu-id="ff9f6-242">Использование Spark со средствами бизнес-аналитики. Выполнение интерактивного анализа данных с использованием Spark в HDInsight с помощью средств бизнес-аналитики</span><span class="sxs-lookup"><span data-stu-id="ff9f6-242">Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools</span></span>](hdinsight-apache-spark-use-bi-tools.md)
* [<span data-ttu-id="ff9f6-243">Использование Spark с машинным обучением. Использование Spark в HDInsight для анализа температуры в здании на основе данных системы кондиционирования</span><span class="sxs-lookup"><span data-stu-id="ff9f6-243">Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)
* [<span data-ttu-id="ff9f6-244">Spark с машинного обучения: используйте Spark в HDInsight toopredict food проверки результатов</span><span class="sxs-lookup"><span data-stu-id="ff9f6-244">Spark with Machine Learning: Use Spark in HDInsight toopredict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)
* [<span data-ttu-id="ff9f6-245">Потоковая передача Spark. Использование Spark в HDInsight для сборки приложений потоковой передачи данных в режиме реального времени</span><span class="sxs-lookup"><span data-stu-id="ff9f6-245">Spark Streaming: Use Spark in HDInsight for building real-time streaming applications</span></span>](hdinsight-apache-spark-eventhub-streaming.md)
* [<span data-ttu-id="ff9f6-246">Анализ журнала веб-сайта с использованием Spark в HDInsight</span><span class="sxs-lookup"><span data-stu-id="ff9f6-246">Website log analysis using Spark in HDInsight</span></span>](hdinsight-apache-spark-custom-library-website-log-analysis.md)

### <a name="create-and-run-applications"></a><span data-ttu-id="ff9f6-247">Создание и запуск приложений</span><span class="sxs-lookup"><span data-stu-id="ff9f6-247">Create and run applications</span></span>
* [<span data-ttu-id="ff9f6-248">Создание автономного приложения с использованием Scala</span><span class="sxs-lookup"><span data-stu-id="ff9f6-248">Create a standalone application using Scala</span></span>](hdinsight-apache-spark-create-standalone-application.md)
* [<span data-ttu-id="ff9f6-249">Удаленный запуск заданий с помощью Livy в кластере Spark</span><span class="sxs-lookup"><span data-stu-id="ff9f6-249">Run jobs remotely on a Spark cluster using Livy</span></span>](hdinsight-apache-spark-livy-rest-interface.md)

### <a name="tools-and-extensions"></a><span data-ttu-id="ff9f6-250">Средства и расширения</span><span class="sxs-lookup"><span data-stu-id="ff9f6-250">Tools and extensions</span></span>
* [<span data-ttu-id="ff9f6-251">Использование подключаемого модуля средства HDInsight для toocreate ИДЕЯ IntelliJ и отправка Spark Scala приложений</span><span class="sxs-lookup"><span data-stu-id="ff9f6-251">Use HDInsight Tools Plugin for IntelliJ IDEA toocreate and submit Spark Scala applications</span></span>](hdinsight-apache-spark-intellij-tool-plugin.md)
* [<span data-ttu-id="ff9f6-252">Удаленно использовать подключаемый модуль средства HDInsight для приложений Spark toodebug ИДЕЯ IntelliJ</span><span class="sxs-lookup"><span data-stu-id="ff9f6-252">Use HDInsight Tools Plugin for IntelliJ IDEA toodebug Spark applications remotely</span></span>](hdinsight-apache-spark-intellij-tool-plugin-debug-jobs-remotely.md)
* [<span data-ttu-id="ff9f6-253">Использование записных книжек Zeppelin с кластером Spark в HDInsight</span><span class="sxs-lookup"><span data-stu-id="ff9f6-253">Use Zeppelin notebooks with a Spark cluster on HDInsight</span></span>](hdinsight-apache-spark-zeppelin-notebook.md)
* [<span data-ttu-id="ff9f6-254">Использование внешних пакетов с записными книжками Jupyter</span><span class="sxs-lookup"><span data-stu-id="ff9f6-254">Use external packages with Jupyter notebooks</span></span>](hdinsight-apache-spark-jupyter-notebook-use-external-packages.md)
* [<span data-ttu-id="ff9f6-255">Установка Jupyter на вашем компьютере и подключение tooan кластера HDInsight Spark</span><span class="sxs-lookup"><span data-stu-id="ff9f6-255">Install Jupyter on your computer and connect tooan HDInsight Spark cluster</span></span>](hdinsight-apache-spark-jupyter-notebook-install-locally.md)

### <a name="manage-resources"></a><span data-ttu-id="ff9f6-256">Управление ресурсами</span><span class="sxs-lookup"><span data-stu-id="ff9f6-256">Manage resources</span></span>
* [<span data-ttu-id="ff9f6-257">Управление ресурсами кластера hello Apache Spark в Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="ff9f6-257">Manage resources for hello Apache Spark cluster in Azure HDInsight</span></span>](hdinsight-apache-spark-resource-manager.md)
* [<span data-ttu-id="ff9f6-258">Отслеживание и отладка заданий в кластере Apache Spark в HDInsight на платформе Linux</span><span class="sxs-lookup"><span data-stu-id="ff9f6-258">Track and debug jobs running on an Apache Spark cluster in HDInsight</span></span>](hdinsight-apache-spark-job-debugging.md)
