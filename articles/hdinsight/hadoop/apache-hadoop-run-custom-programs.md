---
title: "Запуск настраиваемых программ MapReduce в Azure HDInsight | Документация Майкрософт"
description: "Когда и как запускать настраиваемые программы MapReduce в HDInsight."
services: hdinsight
documentationcenter: 
author: ashishthaps
manager: jhubbard
editor: cgronlun
ms.assetid: 
ms.service: hdinsight
ms.custom: hdinsightactive
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 12/04/2017
ms.author: ashishth
ms.openlocfilehash: 8e65c946d2cfcc830a1b9fa59b3f7886857f4f7d
ms.sourcegitcommit: be9a42d7b321304d9a33786ed8e2b9b972a5977e
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/19/2018
---
# <a name="run-custom-mapreduce-programs"></a>Запуск настраиваемых программ MapReduce

Системы для работы с большими данными Hadoop, такие как HDInsight, позволяют обрабатывать данные с использованием широкого спектра инструментов и технологий. Преимущества и рекомендации каждого из них описаны в следующей таблице.

| Механизм запроса | Преимущества | Рекомендации |
| --- | --- | --- |
| **Hive с использованием HiveQL** | <ul><li>Это идеальное решение для пакетной обработки и анализа больших объемов неизменяемых данных, для обобщения данных и отправки запросов данных по требованию. Использует знакомый синтаксис типа SQL.</li><li>С его помощью можно создавать постоянные таблицы данных, которые легко секционируются и индексируются.</li><li>Для одних и тех же данных можно создать несколько внешних таблиц и представлений.</li><li>Поддерживает простую реализацию хранилища данных, которая обеспечивает широкие возможности горизонтального масштабирования и отказоустойчивости для хранения и обработки данных.</li></ul> | <ul><li>Требует, чтобы исходные данные имели хотя бы какую-то идентифицируемую структуру.</li><li>Не подходит для запросов в режиме реального времени и обновлений на уровне строк. Лучше всего подходит для выполнения пакетных заданий с большими наборами данных.</li><li>Возможно, не сможет выполнять некоторые типы сложных задач обработки.</li></ul> |
| **Pig с использованием Pig Latin** | <ul><li>Это идеальное решение для обработки данных в виде наборов, объединения и фильтрации наборов данных, применения функций к записям или группам записей, а также для реструктуризации данных путем определения столбцов, группировки значений или преобразования столбцов в строки.</li><li>Для последовательности операций с данными может использовать подход на основе рабочих процессов.</li></ul> | <ul><li>Для пользователей SQL Pig Latin может быть менее знакомым и более сложным в использовании, чем HiveQL.</li><li>По умолчанию выходные данные обычно представляют собой текстовый файл, поэтому их сложнее использовать с инструментами визуализации, такими как Excel. Как правило, вам нужно будет накладывать таблицу Hive на выходные данные.</li></ul> |
| **Настраиваемое сопоставление и сжатие** | <ul><li>Обеспечивает полный контроль над этапами сопоставления, сжатия и выполнения.</li><li>Позволяет оптимизировать запросы, чтобы достичь максимальной производительности кластера или чтобы свести к минимуму нагрузку на серверах и в сети.</li><li>Компоненты могут быть написаны на одном из общеизвестных языков из широкого диапазона.</li></ul> | <ul><li>Более сложный в использовании, чем Pig или Hive, так как вам нужно будет создать собственные компоненты сопоставления и сжатия.</li><li>Процессы, для которых нужно объединение наборов данных, сложнее реализовать.</li><li>Несмотря на наличие доступных тестовых платформ, код отладки сложнее, чем в обычном приложении, так как он выполняется как пакетное задание под управлением планировщика заданий Hadoop.</li></ul> |
| **HCatalog** | <ul><li>Абстрагирует сведения о пути хранилища, что упрощает администрирование. К тому же при его использовании пользователям не нужно знать, где хранятся данные.</li><li>Предоставляет уведомления о событиях, таких как доступность данных, позволяя другим средствам, например Oozie, определять, когда выполнялись операции.</li><li>Обеспечивает реляционное представление данных, включая секционирование по ключу, а также упрощает доступ к данным.</li></ul> | <ul><li>Поддерживает RCFile, текст в формате CSV, текст в формате JSON, SequenceFile и форматы файла ORC по умолчанию, однако для него может потребоваться написание пользовательских SerDe для других форматов.</li><li>HCatalog не является потокобезопасным.</li><li>Существуют некоторые ограничения для типов данных столбцов при использовании загрузчика HCatalog в скриптах Pig. Дополнительные сведения см. в документации по Apache HCatalog в разделе о [типах данных HCatLoader](http://cwiki.apache.org/confluence/display/Hive/HCatalog%20LoadStore#HCatalogLoadStore-HCatLoaderDataTypes).</li></ul> |

Как правило, из подходов, которые могут предоставить нужные результаты, используется самый простой. Например, таких результатов можно достичь с помощью Hive, однако для более сложных сценариев нужно использовать Pig или даже написать собственные компоненты сопоставления и сжатия. Поэкспериментировав с Hive или Pig, вы можете решить, что настраиваемые компоненты сопоставления и сжатия обеспечивают лучшую производительность, позволяя настроить и оптимизировать обработку.

## <a name="custom-mapreduce-components"></a>Настраиваемые компоненты сопоставления и сжатия

Код сопоставления и сжатия состоит из двух отдельных функций, которые реализованы в виде компонентов **map** и **reduce**. Компонент **map** выполняется параллельно на нескольких узлах кластера, причем каждый узел применяет сопоставление к собственному подмножеству данных узла. Компонент **reduce** объединяет и суммирует результаты всех функций сопоставления. Дополнительные сведения об этих компонентах см. в статье [Использование MapReduce в Hadoop в HDInsight](hdinsight-use-mapreduce.md).

В большинстве сценариев обработки HDInsight проще и эффективнее использовать абстракцию более высокого уровня, такую как Pig или Hive. Вы также можете создать компоненты настраиваемого сопоставления и сжатия для использования в скриптах Hive, чтобы выполнить более сложную обработку.

Обычно компоненты настраиваемого сопоставления и сжатия пишутся на языке Java. Hadoop предоставляет интерфейс потоковой передачи, который также позволяет использовать компоненты, разработанные на других языках, таких как C#, F#, Visual Basic, Python и JavaScript.

* Пошаговые инструкции по разработке настраиваемых программ MapReduce на Java см. в статье [Разработка программ MapReduce на Java для Hadoop в HDInsight](apache-hadoop-develop-deploy-java-mapreduce-linux.md).
* Пример использования Python см. в статье [Разработка программ MapReduce с потоковой передачей Python для HDInsight](apache-hadoop-streaming-python.md).

Рекомендуем создать собственные компоненты сопоставления и сжатия при следующих условиях:

* Для получения структурированных сведений из неструктурированных данных вам необходимо обработать эти данные путем анализа и использовать настраиваемую логику.
* Вам требуется выполнять сложные задачи, которые трудно (или невозможно) выразить в Pig или Hive, не создавая определяемые пользователем функции (UDF). Например, вам потребуется внешняя служба геокодирования, чтобы преобразовать широту и долготу координат или IP-адресов в исходных данных в названия географических расположений.
* Вам нужно повторно использовать имеющиеся коды .NET, Python или JavaScript в компонентах сопоставления и сжатия с помощью интерфейса потоковой передачи Hadoop.

## <a name="upload-and-run-your-custom-mapreduce-program"></a>Загрузка и запуск настраиваемой программы MapReduce

Самые распространенные программы MapReduce написаны на языке Java и скомпилированы в виде JAR-файла.

1. После разработки, компиляции и тестирования программы MapReduce отправьте JAR-файл на головной узел с помощью команды `scp`.

    ```bash
    scp mycustomprogram.jar USERNAME@CLUSTERNAME-ssh.azurehdinsight.net
    ```

    Замените **USERNAME** именем учетной записи пользователя SSH для кластера. Замените **CLUSTERNAME** именем кластера. Если для защиты учетной записи SSH используется пароль, отобразится запрос на его ввод. Если используется сертификат, может потребоваться использовать параметр `-i` , чтобы указать соответствующий файл закрытого ключа.

2. Подключитесь к кластеру с помощью [SSH](../hdinsight-hadoop-linux-use-ssh-unix.md).

    ```bash
    ssh USERNAME@CLUSTERNAME-ssh.azurehdinsight.net
    ```

3. Из сеанса SSH выполните свою программу MapReduce через YARN.

    ```bash
    yarn jar mycustomprogram.jar mynamespace.myclass /example/data/sample.log /example/data/logoutput
    ```

    Эта команда отправляет задание MapReduce в YARN. Входной файл — `/example/data/sample.log`, а выходной каталог — `/example/data/logoutput`. Файлы ввода и любые файлы вывода хранятся в хранилище кластера по умолчанию.

## <a name="next-steps"></a>Дополнительная информация

* [Использование языка C# для потоковой передачи MapReduce в Hadoop в HDInsight](apache-hadoop-dotnet-csharp-mapreduce-streaming.md)
* [Разработка программ MapReduce на Java для Hadoop в HDInsight](apache-hadoop-develop-deploy-java-mapreduce-linux.md)
* [Разработка программ MapReduce с потоковой передачей Python для HDInsight](apache-hadoop-streaming-python.md)
* [Создание приложений Spark для кластера HDInsight с помощью набора средств Azure для Eclipse](../spark/apache-spark-eclipse-tool-plugin.md)
* [Использование пользовательских функций Python с Hive и Pig в Azure HDInsight](python-udf-hdinsight.md)
