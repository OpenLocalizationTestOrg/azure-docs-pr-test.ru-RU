---
title: "Использование Apache Hive как средства для извлечения, преобразования и загрузки (Azure HDInsight) | Документация Майкрософт"
description: "Apache Hive можно использовать в Azure HDInsight для извлечения, преобразования и загрузки данных."
services: hdinsight
documentationcenter: 
author: ashishthaps
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: 
ms.service: hdinsight
ms.custom: hdinsightactive
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 11/14/2017
ms.author: ashishth
ms.openlocfilehash: 1ccbfe23e9c887a98a0dbfa8031078a15c6e41b6
ms.sourcegitcommit: 562a537ed9b96c9116c504738414e5d8c0fd53b1
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/12/2018
---
# <a name="use-apache-hive-as-an-extract-transform-and-load-etl-tool"></a>Использование Apache Hive как средства для извлечения, преобразования и загрузки

Обычно перед загрузкой входных данных в целевое назначение для аналитики вам нужно очистить и преобразовать эти данные. Операции извлечения, преобразования и загрузки используются для подготовки данных и загрузки в целевое назначение.  Hive в HDInsight умеет принимать неструктурированные данные, обрабатывать их по определенным правилам и передавать в реляционное хранилище данных, чтобы их могли использовать системы поддержки принятия решений. При таком подходе данные извлекаются из источника и хранятся в масштабируемом хранилище, например в хранилище BLOB-объектов Azure или Azure Data Lake Store. Затем данные преобразуются набором запросов Hive и размещаются в Hive в ожидании массовой загрузки в целевое хранилище данных.

## <a name="use-case-and-model-overview"></a>Обзор модели и примера использования

На следующем рисунке представлена схема примера использования и модель для автоматизации процессов извлечения, преобразования и загрузки. Входные данные преобразуются в выходные данные определенного формата.  В процессе этой трансформации может изменяться форма данных, тип и даже язык.  Процессы извлечения, преобразования и загрузки могут переводить имперские единицы измерения в метрические, изменять часовые пояса и повышать точность данных, чтобы новые данные в точности соответствовали тем, которые уже существуют в целевом хранилище.  Процессы извлечения, преобразования и загрузки можно даже применить для объединения новых и существующих данных, чтобы поддерживать актуальность отчетов или повышать информативность существующих данных.  После такой обработки приложения и службы, например средства создания отчетов, смогут получить данные в удобном для них формате.

![Apache Hive в роли средства извлечения, преобразования и загрузки](./media/apache-hadoop-using-apache-hive-as-an-etl-tool/hdinsight-etl-architecture.png)

Обычно Hadoop используется для процессов извлечения, преобразования и загрузки, если нужно передать большое число текстовых файлов (например, CSV) или файлы с часто изменяющимся содержимым.  Hive — это прекрасный инструмент для подготовки данных перед отправкой в целевое назначение.  Hive позволяет создать схему для CSV и применять язык запросов, близкий к SQL, чтобы создавать программы MapReduce для взаимодействия с данными. 

Ниже приведены типичные шаги при работе с Hive для задач извлечения, преобразования и загрузки.

1. Передайте данные в Azure Data Lake Store или в хранилище BLOB-объектов Azure.
2. Создайте базу данных для хранения метаданных (на основе Базы данных SQL Azure), в которой Hive будет хранить схемы данных.
3. Создайте кластер HDInsight и подключите хранилище данных.
4. Определите схему, которая будет применяться в хранилище данных при считывании данных.

    ```
    DROP TABLE IF EXISTS hvac;

    --create the hvac table on comma-separated sensor data stored in Azure Storage blobs
    
    CREATE EXTERNAL TABLE hvac(`date` STRING, time STRING, targettemp BIGINT,
        actualtemp BIGINT, 
        system BIGINT, 
        systemage BIGINT, 
        buildingid BIGINT)
    ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' 
    STORED AS TEXTFILE LOCATION 'wasb://{container}@{storageaccount}.blob.core.windows.net/HdiSamples/SensorSampleData/hvac/';
    ```

5. Преобразуйте данные и передайте их в целевое расположение.  Есть несколько способов применить Hive для преобразования и загрузки.

    * Выполните с помощью Hive запросы и подготовку данных, затем сохраните данные в формате CSV в Azure Data Lake Store или в хранилище BLOB-объектов Azure.  После этого вы сможете применить внешнее средство, например SQL Server Integration Services (SSIS), для получения данных в формате CSV и их передачи в реляционную базу данных, такую как SQL Server.
    * Выполняйте запросы непосредственно из Excel или C# с помощью драйвера Hive ODBC.
    * Используйте [Apache Sqoop](apache-hadoop-use-sqoop-mac-linux.md) для чтения подготовленных неструктурированных CSV-файлов и передачи данных в целевую реляционную базу данных.

## <a name="data-sources"></a>Источники данных

Источниками данных обычно являются внешние данные, которые можно сопоставить с существующими данными в хранилище данных, например:

* социальные сети, файлы журналов, данные от датчиков и приложений, которые создают файлы данных;
* наборы данных от поставщиков данных, например статистика погоды или продаж;
* данные потоковой передачи, собранные, отфильтрованные и обработанные с помощью соответствующих средств или платформ.

<!-- TODO: (see Collecting and loading data into HDInsight). -->

## <a name="output-targets"></a>Целевые назначения

С помощью Hive можно выводить данные в разные целевые объекты, в том числе:

* реляционные базы данных, например SQL Server или Базу данных SQL Azure;
* службы хранилища данных, например хранилище данных SQL Microsoft Azure;
* Excel;
* хранилища Azure для таблиц и больших двоичных объектов;
* приложения или службы, которым нужны данные в определенных форматах или в виде файлов с определенным типом структуры информации;
* хранилища документов JSON, такие как <a href="https://azure.microsoft.com/services/cosmos-db/">CosmosDB</a>.

## <a name="considerations"></a>Рекомендации

Модель извлечения, преобразования и загрузки обычно используется в следующих ситуациях.

* Для загрузки потоковых или очень объемных данных (частично структурированных или неструктурированных) из внешних источников в существующую базу данных или информационную систему.
* Для очистки, преобразования и проверки данных перед загрузкой, возможно с неоднократным проходом через кластер для преобразования.
* Для составления регулярно обновляемых отчетов и визуализаций.  Например, если создание отчета занимает слишком много времени и не может выполняться в течение дня, вы можете генерировать его по расписанию в ночное время.  Вы можете автоматизировать запросы Hive с помощью планировщика Microsoft Azure и PowerShell.

Если целевое назначение не является базой данных, прямо внутри запроса вы можете сохранить данные в файле соответствующего формата, например в CSV-файле. Затем этот файл можно затем в Microsoft Excel или Power BI.

Если в процессе извлечения, преобразования и загрузки вам нужно выполнять несколько операций с данными, уделите внимание координации этих действий. Если операции управляются внешней программой, а не внутренним рабочим процессом, важно оценить возможность параллельного выполнения некоторых операций и правильно определять, когда завершается каждое задание. Зачастую проще применить механизм управления рабочим процессом, например Oozie в среде Hadoop, чем самостоятельно распределять последовательность операций внешними скриптами или программами. Дополнительные сведения о средстве Oozie вы найдете в статье [об оркестрации рабочих процессов и заданий](https://msdn.microsoft.com/library/dn749829.aspx).

<!-- ## Next steps -->
<!-- * [ETL at scale](../hdinsight-etl-at-scale.md): Learn more about performing ETL at scale. -->
<!-- * [Operationalize Data Pipelines with Oozie](hdinsight-operationalize-data-pipeline.md): Learn how to build a data pipeline that uses Hive to summarize CSV flight delay data, stage the prepared data in Azure Storage blobs, and then use Sqoop to load the summarized data into Azure SQL Database. -->
<!-- * [ETL Deep Dive](../hdinsight-etl-deep-dive.md): Walk through an end-to-end ETL pipeline.  -->
