---
title: "Параметры контекста вычислений для R Server в HDInsight — Azure | Документы Майкрософт"
description: "Сведения о разных вариантах контекста вычислений, доступных для пользователей R Server в HDInsight."
services: HDInsight
documentationcenter: 
author: bradsev
manager: jhubbard
editor: cgronlun
ms.assetid: 0deb0b1c-4094-459b-94fc-ec9b774c1f8a
ms.service: HDInsight
ms.custom: hdinsightactive
ms.devlang: R
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: data-services
ms.date: 06/19/2017
ms.author: bradsev
ms.openlocfilehash: 47f4441612be4f363ba82cc22b09786a6f3bfdc3
ms.sourcegitcommit: 18ad9bc049589c8e44ed277f8f43dcaa483f3339
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 08/29/2017
---
# <a name="compute-context-options-for-r-server-on-hdinsight"></a><span data-ttu-id="ce213-103">Варианты контекста вычислений для R Server в HDInsight</span><span class="sxs-lookup"><span data-stu-id="ce213-103">Compute context options for R Server on HDInsight</span></span>

<span data-ttu-id="ce213-104">Microsoft R Server в Azure HDInsight управляет выполнением вызовов, задавая контекст вычисления.</span><span class="sxs-lookup"><span data-stu-id="ce213-104">Microsoft R Server on Azure HDInsight controls how calls are executed by setting the compute context.</span></span> <span data-ttu-id="ce213-105">В этой статье приведены параметры, которые доступны для указания необходимости и способа выполнения параллелизации между ядрами граничного узла или кластера HDInsight.</span><span class="sxs-lookup"><span data-stu-id="ce213-105">This article outlines the options that are available to specify whether and how execution is parallelized across cores of the edge node or HDInsight cluster.</span></span>

<span data-ttu-id="ce213-106">Для подключения к кластеру и выполнения скриптов на языке R удобно использовать граничный узел кластеров.</span><span class="sxs-lookup"><span data-stu-id="ce213-106">The edge node of a cluster provides a convenient place to connect to the cluster and to run your R scripts.</span></span> <span data-ttu-id="ce213-107">На граничном узле вы можете выполнять распараллеленные распределенные функции ScaleR на ядрах сервера граничного узла.</span><span class="sxs-lookup"><span data-stu-id="ce213-107">With an edge node, you have the option of running the parallelized distributed functions of ScaleR across the cores of the edge node server.</span></span> <span data-ttu-id="ce213-108">Кроме того, вы можете выполнять эти функции на узлах кластера с помощью контекста вычислений Hadoop Map Reduce или Spark ScaleR.</span><span class="sxs-lookup"><span data-stu-id="ce213-108">You can also run them across the nodes of the cluster by using ScaleR’s Hadoop Map Reduce or Spark compute contexts.</span></span>

## <a name="microsoft-r-server-on-azure-hdinsight"></a><span data-ttu-id="ce213-109">Microsoft R Server в Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="ce213-109">Microsoft R Server on Azure HDInsight</span></span>
<span data-ttu-id="ce213-110">[Microsoft R Server в кластере Azure HDInsight](hdinsight-hadoop-r-server-overview.md) предоставляет новейшие возможности для анализа на основе R.</span><span class="sxs-lookup"><span data-stu-id="ce213-110">[Microsoft R Server on Azure HDInsight](hdinsight-hadoop-r-server-overview.md) provides the latest capabilities for R-based analytics.</span></span> <span data-ttu-id="ce213-111">Это решение может использовать данные, хранящиеся в контейнере HDFS, размещенном в учетной записи хранения [BLOB-объектов Azure](../storage/common/storage-introduction.md "хранилище BLOB-объектов Azure"), Data Lake Store или локальной файловой системе Linux.</span><span class="sxs-lookup"><span data-stu-id="ce213-111">It can use data that is stored in an HDFS container in your [Azure Blob](../storage/common/storage-introduction.md "Azure Blob storage") storage account, a Data Lake store, or the local Linux file system.</span></span> <span data-ttu-id="ce213-112">Так как R Server основывается на R с открытым кодом, вы сможете использовать в своих приложениях на основе R любые из более чем 8000 пакетов R с открытым исходным кодом.</span><span class="sxs-lookup"><span data-stu-id="ce213-112">Since R Server is built on open source R, the R-based applications you build can apply any of the 8000+ open source R packages.</span></span> <span data-ttu-id="ce213-113">Также вы можете использовать подпрограммы [RevoScaleR](https://msdn.microsoft.com/microsoft-r/scaler/scaler), пакета аналитики больших данных от корпорации Майкрософт, который предоставляется вместе с R Server.</span><span class="sxs-lookup"><span data-stu-id="ce213-113">They can also use the routines in [RevoScaleR](https://msdn.microsoft.com/microsoft-r/scaler/scaler), Microsoft’s big data analytics package that is included with R Server.</span></span>  

## <a name="compute-contexts-for-an-edge-node"></a><span data-ttu-id="ce213-114">Контексты вычислений для граничного узла</span><span class="sxs-lookup"><span data-stu-id="ce213-114">Compute contexts for an edge node</span></span>
<span data-ttu-id="ce213-115">Как правило, сценарий R, выполняемый на R Server на граничном узле, выполняется в интерпретаторе R на этом узле.</span><span class="sxs-lookup"><span data-stu-id="ce213-115">In general, an R script that's run in R Server on the edge node runs within the R interpreter on that node.</span></span> <span data-ttu-id="ce213-116">Исключением являются те действия, которые вызывают функцию ScaleR.</span><span class="sxs-lookup"><span data-stu-id="ce213-116">The exceptions are those steps that call a ScaleR function.</span></span> <span data-ttu-id="ce213-117">Вызовы ScaleR будут осуществляться в среде вычислений с учетом настройки контекста вычислений ScaleR.</span><span class="sxs-lookup"><span data-stu-id="ce213-117">The ScaleR calls run in a compute environment that is determined by how you set the ScaleR compute context.</span></span>  <span data-ttu-id="ce213-118">При выполнении скрипта R из граничного узла возможны следующие значения контекста вычислений:</span><span class="sxs-lookup"><span data-stu-id="ce213-118">When you run your R script from an edge node, the possible values of the compute context are:</span></span>

- <span data-ttu-id="ce213-119">локальный последовательный (*‘local’*);</span><span class="sxs-lookup"><span data-stu-id="ce213-119">local sequential (*‘local’*)</span></span>
- <span data-ttu-id="ce213-120">локальный параллельный (*‘localpar’*);</span><span class="sxs-lookup"><span data-stu-id="ce213-120">local parallel (*‘localpar’*)</span></span>
- <span data-ttu-id="ce213-121">Map Reduce</span><span class="sxs-lookup"><span data-stu-id="ce213-121">Map Reduce</span></span>
- <span data-ttu-id="ce213-122">Spark</span><span class="sxs-lookup"><span data-stu-id="ce213-122">Spark</span></span>

<span data-ttu-id="ce213-123">Значения *local* и *localpar* отличаются только способом выполнения вызовов **rxExec**.</span><span class="sxs-lookup"><span data-stu-id="ce213-123">The *‘local’* and *‘localpar’* options differ only in how **rxExec** calls are executed.</span></span> <span data-ttu-id="ce213-124">Они оба выполняют другие вызовы функций RX параллельно по всем доступным ядрам, если только не указаны другие действия посредством параметра ScaleR **numCoresToUse**, например `rxOptions(numCoresToUse=6)`.</span><span class="sxs-lookup"><span data-stu-id="ce213-124">They both execute other rx-function calls in a parallel manner across all available cores unless specified otherwise through use of the ScaleR **numCoresToUse** option, for example `rxOptions(numCoresToUse=6)`.</span></span> <span data-ttu-id="ce213-125">Параметры параллельного выполнения обеспечивают оптимальную производительность.</span><span class="sxs-lookup"><span data-stu-id="ce213-125">Parallel execution options offer optimal performance.</span></span>

<span data-ttu-id="ce213-126">В таблице ниже приведена сводка различных параметров контекста вычислений, определяющих способ выполнения вызовов.</span><span class="sxs-lookup"><span data-stu-id="ce213-126">The following table summarizes the various compute context options to set how calls are executed:</span></span>

| <span data-ttu-id="ce213-127">Контекст вычислений</span><span class="sxs-lookup"><span data-stu-id="ce213-127">Compute context</span></span>  | <span data-ttu-id="ce213-128">Метод настройки</span><span class="sxs-lookup"><span data-stu-id="ce213-128">How to set</span></span>                      | <span data-ttu-id="ce213-129">Контекст выполнения</span><span class="sxs-lookup"><span data-stu-id="ce213-129">Execution context</span></span>                        |
| ---------------- | ------------------------------- | ---------------------------------------- |
| <span data-ttu-id="ce213-130">Локальный последовательный</span><span class="sxs-lookup"><span data-stu-id="ce213-130">Local sequential</span></span> | <span data-ttu-id="ce213-131">rxSetComputeContext(‘local’)</span><span class="sxs-lookup"><span data-stu-id="ce213-131">rxSetComputeContext(‘local’)</span></span>    | <span data-ttu-id="ce213-132">Распараллеленное выполнение во всех ядрах сервера граничного узла, за исключением вызовов rxExec, которые выполняются последовательно.</span><span class="sxs-lookup"><span data-stu-id="ce213-132">Parallelized execution across the cores of the edge node server, except for rxExec calls, which are executed serially</span></span> |
| <span data-ttu-id="ce213-133">Локальный параллельный</span><span class="sxs-lookup"><span data-stu-id="ce213-133">Local parallel</span></span>   | <span data-ttu-id="ce213-134">rxSetComputeContext(‘localpar’)</span><span class="sxs-lookup"><span data-stu-id="ce213-134">rxSetComputeContext(‘localpar’)</span></span> | <span data-ttu-id="ce213-135">Распараллеленное выполнение во всех ядрах сервера граничного узла.</span><span class="sxs-lookup"><span data-stu-id="ce213-135">Parallelized execution across the cores of the edge node server</span></span> |
| <span data-ttu-id="ce213-136">Spark</span><span class="sxs-lookup"><span data-stu-id="ce213-136">Spark</span></span>            | <span data-ttu-id="ce213-137">RxSpark()</span><span class="sxs-lookup"><span data-stu-id="ce213-137">RxSpark()</span></span>                       | <span data-ttu-id="ce213-138">Распараллеленное распределенное выполнение с использованием Spark во всех узлах кластера HDI</span><span class="sxs-lookup"><span data-stu-id="ce213-138">Parallelized distributed execution via Spark across the nodes of the HDI cluster</span></span> |
| <span data-ttu-id="ce213-139">Map Reduce</span><span class="sxs-lookup"><span data-stu-id="ce213-139">Map Reduce</span></span>       | <span data-ttu-id="ce213-140">RxHadoopMR()</span><span class="sxs-lookup"><span data-stu-id="ce213-140">RxHadoopMR()</span></span>                    | <span data-ttu-id="ce213-141">Распараллеленное распределенное выполнение с использованием Map Reduce во всех узлах кластера HDI</span><span class="sxs-lookup"><span data-stu-id="ce213-141">Parallelized distributed execution via Map Reduce across the nodes of the HDI cluster</span></span> |

## <a name="guidelines-for-deciding-on-a-compute-context"></a><span data-ttu-id="ce213-142">Рекомендации по выбору контекста вычислений</span><span class="sxs-lookup"><span data-stu-id="ce213-142">Guidelines for deciding on a compute context</span></span>

<span data-ttu-id="ce213-143">Выбор варианта распараллеленного выполнения зависит от характера задач анализа, а также размера и местонахождения данных.</span><span class="sxs-lookup"><span data-stu-id="ce213-143">Which of the three options you choose that provide parallelized execution depends on the nature of your analytics work, the size, and the location of your data.</span></span> <span data-ttu-id="ce213-144">Простого правила для выбора контекста вычислений нет.</span><span class="sxs-lookup"><span data-stu-id="ce213-144">There is no simple formula that tells you which compute context to use.</span></span> <span data-ttu-id="ce213-145">Однако есть некоторые базовые принципы, которые помогут вам определиться или хотя бы сузить выбор еще до запуска теста производительности.</span><span class="sxs-lookup"><span data-stu-id="ce213-145">There are, however, some guiding principles that can help you make the right choice, or, at least, help you narrow down your choices before you run a benchmark.</span></span> <span data-ttu-id="ce213-146">К ним относятся следующие:</span><span class="sxs-lookup"><span data-stu-id="ce213-146">These guiding principles include:</span></span>

- <span data-ttu-id="ce213-147">Локальная файловая система Linux работает быстрее, чем HDFS.</span><span class="sxs-lookup"><span data-stu-id="ce213-147">The local Linux file system is faster than HDFS.</span></span>
- <span data-ttu-id="ce213-148">Повторный анализ выполняется быстрее для данных в локальной среде, особенно в формате XDF.</span><span class="sxs-lookup"><span data-stu-id="ce213-148">Repeated analyses are faster if the data is local, and if it's in XDF.</span></span>
- <span data-ttu-id="ce213-149">Из текстовых источников данных желательно передавать небольшие объемы данных.</span><span class="sxs-lookup"><span data-stu-id="ce213-149">It's preferable to stream small amounts of data from a text data source.</span></span> <span data-ttu-id="ce213-150">Если данные имеют большой объем, преобразуйте их в формат XDF перед анализом.</span><span class="sxs-lookup"><span data-stu-id="ce213-150">If the amount of data is larger, convert it to XDF before analysis.</span></span>
- <span data-ttu-id="ce213-151">При копировании или потоковой передаче на граничный узел больших объемов данных для анализа нагрузка быстро становится запредельной.</span><span class="sxs-lookup"><span data-stu-id="ce213-151">The overhead of copying or streaming the data to the edge node for analysis becomes unmanageable for very large amounts of data.</span></span>
- <span data-ttu-id="ce213-152">Spark работает быстрее, чем MapReduce для анализа в Hadoop.</span><span class="sxs-lookup"><span data-stu-id="ce213-152">Spark is faster than Map Reduce for analysis in Hadoop.</span></span>

<span data-ttu-id="ce213-153">С учетом этих принципов в следующем разделе приведены некоторые общие правила выбора контекста вычислений.</span><span class="sxs-lookup"><span data-stu-id="ce213-153">Given these principles, the following sections offer some general rules of thumb for selecting a compute context.</span></span>

### <a name="local"></a><span data-ttu-id="ce213-154">Local</span><span class="sxs-lookup"><span data-stu-id="ce213-154">Local</span></span>
* <span data-ttu-id="ce213-155">Если нужно проанализировать данные небольшого объема и не требуется повторный анализ, их следует направить потоком прямо в подпрограмму анализа и использовать контекст *local* или *localpar*.</span><span class="sxs-lookup"><span data-stu-id="ce213-155">If the amount of data to analyze is small and does not require repeated analysis, then stream it directly into the analysis routine using *'local'* or *'localpar'*.</span></span>
* <span data-ttu-id="ce213-156">Если нужно проанализировать данные небольшого или среднего объема, для которых потребуется повторный анализ, скопируйте их в локальную файловую систему, импортируйте в XDF-формат и проанализируйте в контексте *local* или *localpar*.</span><span class="sxs-lookup"><span data-stu-id="ce213-156">If the amount of data to analyze is small or medium-sized and requires repeated analysis, then copy it to the local file system, import it to XDF, and analyze it via *'local'* or *'localpar'*.</span></span>

### <a name="hadoop-spark"></a><span data-ttu-id="ce213-157">Hadoop Spark</span><span class="sxs-lookup"><span data-stu-id="ce213-157">Hadoop Spark</span></span>
* <span data-ttu-id="ce213-158">Если нужно проанализировать большой объем данных, импортируйте их в Spark DataFrame с помощью **RxHiveData** или **RxParquetData** либо в XDF-файл в файловой системе HDFS (при наличии достаточного пространства для хранения) и проанализируйте эти данные в контексте вычислений Spark.</span><span class="sxs-lookup"><span data-stu-id="ce213-158">If the amount of data to analyze is large, then import it to a Spark DataFrame using **RxHiveData** or **RxParquetData**, or to XDF in HDFS (unless storage is an issue), and analyze it using the Spark compute context.</span></span>

### <a name="hadoop-map-reduce"></a><span data-ttu-id="ce213-159">Hadoop Map Reduce</span><span class="sxs-lookup"><span data-stu-id="ce213-159">Hadoop Map Reduce</span></span>
* <span data-ttu-id="ce213-160">Используйте контекст вычислений Map Reduce только для проблем, которые не решаются с использованием контекста вычислений Spark из-за снижения производительности.</span><span class="sxs-lookup"><span data-stu-id="ce213-160">Use the Map Reduce compute context only if you encounter an insurmountable problem with the Spark compute context since it is generally slower.</span></span>  

## <a name="inline-help-on-rxsetcomputecontext"></a><span data-ttu-id="ce213-161">Встроенная справка по rxSetComputeContext</span><span class="sxs-lookup"><span data-stu-id="ce213-161">Inline help on rxSetComputeContext</span></span>
<span data-ttu-id="ce213-162">Чтобы получить дополнительные сведения по контекстам вычислений ScaleR с соответствующими примерами, воспользуйтесь встроенной справкой в консоли R с помощью метода rxSetComputeContext, например:</span><span class="sxs-lookup"><span data-stu-id="ce213-162">For more information and examples of ScaleR compute contexts, see the inline help in R on the rxSetComputeContext method, for example:</span></span>

    > ?rxSetComputeContext

<span data-ttu-id="ce213-163">Можно также просмотреть [руководство по распределенным вычислениям ScaleR](https://msdn.microsoft.com/microsoft-r/scaler-distributed-computing), доступное в библиотеке [R Server MSDN](https://msdn.microsoft.com/library/mt674634.aspx "R Server в библиотеке MSDN").</span><span class="sxs-lookup"><span data-stu-id="ce213-163">You can also refer to the “[ScaleR Distributed Computing Guide](https://msdn.microsoft.com/microsoft-r/scaler-distributed-computing)” that's available from the [R Server MSDN](https://msdn.microsoft.com/library/mt674634.aspx "R Server on MSDN") library.</span></span>

## <a name="next-steps"></a><span data-ttu-id="ce213-164">Дальнейшие действия</span><span class="sxs-lookup"><span data-stu-id="ce213-164">Next steps</span></span>
<span data-ttu-id="ce213-165">В этой статье вы ознакомились с параметрами, которые доступны для указания необходимости и способа выполнения параллелизации между ядрами граничного узла или кластера HDInsight.</span><span class="sxs-lookup"><span data-stu-id="ce213-165">In this article, you learned about the options that are available to specify whether and how execution is parallelized across cores of the edge node or HDInsight cluster.</span></span> <span data-ttu-id="ce213-166">Дополнительные сведения об использовании R Server для работы с кластерами HDInsight см. в следующих статьях:</span><span class="sxs-lookup"><span data-stu-id="ce213-166">To learn more about how to use R Server with HDInsight clusters, see the following topics:</span></span>

* [<span data-ttu-id="ce213-167">Общие сведения об R Server в HDInsight (предварительная версия)</span><span class="sxs-lookup"><span data-stu-id="ce213-167">Overview of R Server for Hadoop</span></span>](hdinsight-hadoop-r-server-overview.md)
* [<span data-ttu-id="ce213-168">Приступая к работе с R Server в HDInsight (предварительная версия)</span><span class="sxs-lookup"><span data-stu-id="ce213-168">Get started with R Server for Hadoop</span></span>](hdinsight-hadoop-r-server-get-started.md)
* [<span data-ttu-id="ce213-169">Установка RStudio Server в HDInsight (если установка не была выполнена при создании кластера)</span><span class="sxs-lookup"><span data-stu-id="ce213-169">Add RStudio Server to HDInsight (if not added during cluster creation)</span></span>](hdinsight-hadoop-r-server-install-r-studio.md)
* [<span data-ttu-id="ce213-170">Параметры службы хранилища Azure для R Server в HDInsight (предварительная версия)</span><span class="sxs-lookup"><span data-stu-id="ce213-170">Azure Storage options for R Server on HDInsight</span></span>](hdinsight-hadoop-r-server-storage.md)

