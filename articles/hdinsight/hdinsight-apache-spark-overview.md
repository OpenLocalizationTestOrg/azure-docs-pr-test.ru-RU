---
title: "Общие сведения о Spark в Azure HDInsight | Документация Майкрософт"
description: "В этой статье представлены общие сведения о Spark в HDInsight и различные сценарии, в которых вы можете использовать кластер Spark в HDInsight."
keywords: "что такое apache spark, кластер spark, введение в spark, spark в hdinsight"
services: hdinsight
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: 82334b9e-4629-4005-8147-19f875c8774e
ms.service: hdinsight
ms.custom: hdinsightactive,hdiseo17may2017
ms.workload: big-data
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: get-started-article
ms.date: 05/12/2017
ms.author: nitinme
ms.openlocfilehash: acb80aa98cc978a906ccd6e4b4132a439e505bc8
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 07/11/2017
---
# <a name="introduction-to-spark-on-hdinsight"></a><span data-ttu-id="e49ae-104">Общие сведения о Spark в HDInsight</span><span class="sxs-lookup"><span data-stu-id="e49ae-104">Introduction to Spark on HDInsight</span></span>

<span data-ttu-id="e49ae-105">В этой статье предоставляются общие сведения о Spark в HDInsight.</span><span class="sxs-lookup"><span data-stu-id="e49ae-105">This article provides you with an introduction to Spark on HDInsight.</span></span> <span data-ttu-id="e49ae-106"><a href="http://spark.apache.org/" target="_blank">Apache Spark</a> — это платформа параллельной обработки с открытым исходным кодом, которая поддерживает обработку в памяти, чтобы повысить производительность приложений для анализа данных большого размера.</span><span class="sxs-lookup"><span data-stu-id="e49ae-106"><a href="http://spark.apache.org/" target="_blank">Apache Spark</a> is an open-source parallel processing framework that supports in-memory processing to boost the performance of big-data analytic applications.</span></span> <span data-ttu-id="e49ae-107">Кластер Spark в HDInsight совместим со службой хранилища Azure (WASB), а также с Azure Data Lake Store. Поэтому имеющиеся данные, хранящиеся в Azure, можно легко обработать с помощью кластера Spark.</span><span class="sxs-lookup"><span data-stu-id="e49ae-107">Spark cluster on HDInsight is compatible with Azure Storage (WASB) as well as Azure Data Lake Store so your existing data stored in Azure can easily be processed via a Spark cluster.</span></span>

<span data-ttu-id="e49ae-108">При создании кластера Spark в HDInsight создание вычислительных ресурсов Azure следует выполнять после установки и настройки Spark.</span><span class="sxs-lookup"><span data-stu-id="e49ae-108">When you create a Spark cluster on HDInsight, you create Azure compute resources with Spark installed and configured.</span></span> <span data-ttu-id="e49ae-109">Создание кластера Spark в HDInsight не займет больше десяти минут.</span><span class="sxs-lookup"><span data-stu-id="e49ae-109">It only takes about ten minutes to create a Spark cluster in HDInsight.</span></span> <span data-ttu-id="e49ae-110">Данные для обработки находятся в службе хранилища Azure или Azure Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="e49ae-110">The data to be processed is stored in Azure Storage or Azure Data Lake Store.</span></span> <span data-ttu-id="e49ae-111">Дополнительные сведения см. в статье [Использование HDFS-совместимой службы хранилища с Hadoop в HDInsight](hdinsight-hadoop-use-blob-storage.md).</span><span class="sxs-lookup"><span data-stu-id="e49ae-111">See [Use Azure Storage with HDInsight](hdinsight-hadoop-use-blob-storage.md).</span></span>

<span data-ttu-id="e49ae-112">**Для создания кластера Spark в HDInsight** см. статью [Начало работы. Создание кластера Apache Spark в Azure HDInsight и выполнение интерактивных запросов с помощью SQL Spark](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="e49ae-112">**To create a Spark cluster on HDInsight**, see [QuickStart: create a Spark cluster on HDInsight and run interactive query using Jupyter](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span>


## <a name="what-is-apache-spark-on-azure-hdinsight"></a><span data-ttu-id="e49ae-113">Apache Spark в Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="e49ae-113">What is Apache Spark on Azure HDInsight?</span></span>
<span data-ttu-id="e49ae-114">Кластеры Spark в HDInsight предлагают полностью управляемую службу Spark.</span><span class="sxs-lookup"><span data-stu-id="e49ae-114">Spark clusters on HDInsight offer a fully managed Spark service.</span></span> <span data-ttu-id="e49ae-115">Преимущества создания кластера Spark в HDInsight приведены здесь.</span><span class="sxs-lookup"><span data-stu-id="e49ae-115">Benefits of creating a Spark cluster on HDInsight are listed here.</span></span>

| <span data-ttu-id="e49ae-116">Функция</span><span class="sxs-lookup"><span data-stu-id="e49ae-116">Feature</span></span> | <span data-ttu-id="e49ae-117">Описание</span><span class="sxs-lookup"><span data-stu-id="e49ae-117">Description</span></span> |
| --- | --- |
| <span data-ttu-id="e49ae-118">Простота создания кластеров Spark</span><span class="sxs-lookup"><span data-stu-id="e49ae-118">Ease of creating Spark clusters</span></span> |<span data-ttu-id="e49ae-119">Создание кластера Spark в HDInsight с помощью портала Azure, Azure PowerShell или пакета SDK .NET HDInsight занимает всего несколько минут.</span><span class="sxs-lookup"><span data-stu-id="e49ae-119">You can create a new Spark cluster on HDInsight in minutes using the Azure Portal, Azure PowerShell, or the HDInsight .NET SDK.</span></span> <span data-ttu-id="e49ae-120">См. инструкции по [началу работы с кластером Spark в HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="e49ae-120">See [Get started with Spark cluster in HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md)</span></span> |
| <span data-ttu-id="e49ae-121">Простота использования</span><span class="sxs-lookup"><span data-stu-id="e49ae-121">Ease of use</span></span> |<span data-ttu-id="e49ae-122">Кластер Spark в HDInsight включает записные книжки Jupyter и Zeppelin.</span><span class="sxs-lookup"><span data-stu-id="e49ae-122">Spark cluster in HDInsight include Jupyter and Zeppelin notebooks.</span></span> <span data-ttu-id="e49ae-123">Их можно использовать для интерактивной обработки и визуализации данных.</span><span class="sxs-lookup"><span data-stu-id="e49ae-123">You can use these for interactive data processing and visualization.</span></span>|
| <span data-ttu-id="e49ae-124">Интерфейсы API REST</span><span class="sxs-lookup"><span data-stu-id="e49ae-124">REST APIs</span></span> |<span data-ttu-id="e49ae-125">Кластеры Spark в HDInsight включают [Livy](https://github.com/cloudera/hue/tree/master/apps/spark/java#welcome-to-livy-the-rest-spark-server), сервер заданий Spark на основе API REST, который позволяет пользователям удаленно отправлять задания и отслеживать их.</span><span class="sxs-lookup"><span data-stu-id="e49ae-125">Spark clusters in HDInsight include [Livy](https://github.com/cloudera/hue/tree/master/apps/spark/java#welcome-to-livy-the-rest-spark-server), a REST API-based Spark job server to remotely submit and monitor jobs.</span></span> |
| <span data-ttu-id="e49ae-126">Поддержка хранилища озера данных Azure</span><span class="sxs-lookup"><span data-stu-id="e49ae-126">Support for Azure Data Lake Store</span></span> | <span data-ttu-id="e49ae-127">Кластер Spark в HDInsight можно настроить так, чтобы Azure Data Lake Store использовалось в качестве как дополнительного, так и основного хранилища (только с кластерами HDInsight версии 3.5).</span><span class="sxs-lookup"><span data-stu-id="e49ae-127">Spark cluster on HDInsight can be configured to use Azure Data Lake Store as an additional storage, as well as primary storage (only with HDInsight 3.5 clusters) .</span></span> <span data-ttu-id="e49ae-128">Дополнительные сведения о Data Lake Store см. в [обзоре Azure Data Lake Store](../data-lake-store/data-lake-store-overview.md).</span><span class="sxs-lookup"><span data-stu-id="e49ae-128">For more information on Data Lake Store, see [Overview of Azure Data Lake Store](../data-lake-store/data-lake-store-overview.md).</span></span> |
| <span data-ttu-id="e49ae-129">Интеграция со службами Azure</span><span class="sxs-lookup"><span data-stu-id="e49ae-129">Integration with Azure services</span></span> |<span data-ttu-id="e49ae-130">Кластер Spark в HDInsight поставляется с соединителем для концентраторов событий Azure.</span><span class="sxs-lookup"><span data-stu-id="e49ae-130">Spark cluster on HDInsight comes with a connector to Azure Event Hubs.</span></span> <span data-ttu-id="e49ae-131">Клиенты могут создавать приложения потоковой передачи с помощью концентраторов событий (в дополнение к системе [Kafka](http://kafka.apache.org/), которая уже входит в состав Spark).</span><span class="sxs-lookup"><span data-stu-id="e49ae-131">Customers can build streaming applications using the Event Hubs, in addition to [Kafka](http://kafka.apache.org/), which is already available as part of Spark.</span></span> |
| <span data-ttu-id="e49ae-132">Поддержка R Server</span><span class="sxs-lookup"><span data-stu-id="e49ae-132">Support for R Server</span></span> | <span data-ttu-id="e49ae-133">В кластере HDInsight Spark можно настроить R Server для выполнения распределенных вычислений в среде R со скоростью, заявленной для кластера Spark.</span><span class="sxs-lookup"><span data-stu-id="e49ae-133">You can set up a R Server on HDInsight Spark cluster to run distributed R computations with the speeds promised with a Spark cluster.</span></span> <span data-ttu-id="e49ae-134">Дополнительные сведения см. в статье [Приступая к работе с R Server в HDInsight](hdinsight-hadoop-r-server-get-started.md).</span><span class="sxs-lookup"><span data-stu-id="e49ae-134">For more information, see [Get started using R Server on HDInsight](hdinsight-hadoop-r-server-get-started.md).</span></span> |
| <span data-ttu-id="e49ae-135">Интеграция со сторонними IDE</span><span class="sxs-lookup"><span data-stu-id="e49ae-135">Integration with third-party IDEs</span></span> | <span data-ttu-id="e49ae-136">HDInsight предоставляет подключаемые модули для IDE, например IntelliJ IDEA и Eclipse, которые вы можете использовать для создания и отправки приложений в кластер Spark в HDInsight.</span><span class="sxs-lookup"><span data-stu-id="e49ae-136">HDInsight provides plugins for IDEs like IntelliJ IDEA and Eclipse that you can use to create and submit applications to an HDInsight Spark cluster.</span></span> <span data-ttu-id="e49ae-137">Дополнительные сведения см. в статье [Создание приложений Spark для кластера HDInsight с помощью набора средств Azure для IntelliJ](hdinsight-apache-spark-intellij-tool-plugin.md) и [Создание приложений Spark для кластера HDInsight с помощью набора средств Azure для Eclipse](hdinsight-apache-spark-eclipse-tool-plugin.md).</span><span class="sxs-lookup"><span data-stu-id="e49ae-137">For more information see [Use Azure Toolkit for IntelliJ IDEA](hdinsight-apache-spark-intellij-tool-plugin.md) and [Use Azure Toolkit for Eclipse](hdinsight-apache-spark-eclipse-tool-plugin.md).</span></span>|
| <span data-ttu-id="e49ae-138">Параллельные запросы</span><span class="sxs-lookup"><span data-stu-id="e49ae-138">Concurrent Queries</span></span> |<span data-ttu-id="e49ae-139">Кластеры Spark в HDInsight поддерживают параллельные запросы.</span><span class="sxs-lookup"><span data-stu-id="e49ae-139">Spark clusters in HDInsight support concurrent queries.</span></span> <span data-ttu-id="e49ae-140">Благодаря этому несколько запросов от одного пользователя или несколько запросов от разных пользователей и из различных приложений могут использовать одни и те же ресурсы кластера.</span><span class="sxs-lookup"><span data-stu-id="e49ae-140">This enables multiple queries from one user or multiple queries from various users and applications to share the same cluster resources.</span></span> |
| <span data-ttu-id="e49ae-141">Кэширование на накопители SSD</span><span class="sxs-lookup"><span data-stu-id="e49ae-141">Caching on SSDs</span></span> |<span data-ttu-id="e49ae-142">Можно выбрать кэширование данных в памяти или на накопители SSD, подключенные к узлам кластера.</span><span class="sxs-lookup"><span data-stu-id="e49ae-142">You can choose to cache data either in memory or in SSDs attached to the cluster nodes.</span></span> <span data-ttu-id="e49ae-143">Кэширование в память обеспечивает наилучшую производительность, однако может оказаться ресурсоемким; кэширование на накопители SSD предоставляет возможность повысить производительность запросов без необходимости создания кластера такого размера, который необходим для размещения всего набора данных в памяти.</span><span class="sxs-lookup"><span data-stu-id="e49ae-143">Caching in memory provides the best query performance but could be expensive; caching in SSDs provides a great option for improving query performance without the need to create a cluster of a size that is required to fit the entire dataset in memory.</span></span> |
| <span data-ttu-id="e49ae-144">Интеграция со средствами бизнес-аналитики</span><span class="sxs-lookup"><span data-stu-id="e49ae-144">Integration with BI Tools</span></span> |<span data-ttu-id="e49ae-145">В состав кластеров Spark для HDInsight входят соединители для средств бизнес-аналитики, таких как [Power BI](http://www.powerbi.com/) и [Tableau](http://www.tableau.com/products/desktop) для анализа данных.</span><span class="sxs-lookup"><span data-stu-id="e49ae-145">Spark clusters on HDInsight provide connectors for  BI tools such as [Power BI](http://www.powerbi.com/) and [Tableau](http://www.tableau.com/products/desktop) for data analytics.</span></span> |
| <span data-ttu-id="e49ae-146">Предварительно загруженные библиотеки Anaconda</span><span class="sxs-lookup"><span data-stu-id="e49ae-146">Pre-loaded Anaconda libraries</span></span> |<span data-ttu-id="e49ae-147">Кластеры Spark в HDInsight поставляются с предустановленными библиотеками Anaconda.</span><span class="sxs-lookup"><span data-stu-id="e49ae-147">Spark clusters on HDInsight come with Anaconda libraries pre-installed.</span></span> <span data-ttu-id="e49ae-148">[Anaconda](http://docs.continuum.io/anaconda/) содержит порядка 200 библиотек для машинного обучения, анализа данных, визуализации и т. д.</span><span class="sxs-lookup"><span data-stu-id="e49ae-148">[Anaconda](http://docs.continuum.io/anaconda/) provides close to 200 libraries for machine learning, data analysis, visualization, etc.</span></span> |
| <span data-ttu-id="e49ae-149">Масштабируемость</span><span class="sxs-lookup"><span data-stu-id="e49ae-149">Scalability</span></span> |<span data-ttu-id="e49ae-150">Количество узлов указывается во время создания кластера. Тем не менее рабочая нагрузка может меняться, и тогда возникает необходимость увеличить или уменьшить размер кластера.</span><span class="sxs-lookup"><span data-stu-id="e49ae-150">Although you can specify the number of nodes in your cluster during creation, you may want to grow or shrink the cluster to match workload.</span></span> <span data-ttu-id="e49ae-151">Все кластеры HDInsight позволяют изменять количество узлов в кластере.</span><span class="sxs-lookup"><span data-stu-id="e49ae-151">All HDInsight clusters allow you to change the number of nodes in the cluster.</span></span> <span data-ttu-id="e49ae-152">Кроме того, кластеры Spark можно удалить без потери данных, так как все данные хранятся в службе хранилища Azure или Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="e49ae-152">Also, Spark clusters can be dropped with no loss of data since all the data is stored in Azure Storage or Data Lake Store.</span></span> |
| <span data-ttu-id="e49ae-153">Круглосуточная и ежедневная поддержка</span><span class="sxs-lookup"><span data-stu-id="e49ae-153">24/7 Support</span></span> |<span data-ttu-id="e49ae-154">Для кластеров Spark в HDInsight предоставляется круглосуточная и ежедневная поддержка корпоративного уровня и соглашения об уровне обслуживания, гарантирующие время 99,9 % бесперебойной работы.</span><span class="sxs-lookup"><span data-stu-id="e49ae-154">Spark clusters on HDInsight come with  enterprise-level 24/7 support and an SLA of 99.9% up-time.</span></span> |

## <a name="what-are-the-use-cases-for-spark-on-hdinsight"></a><span data-ttu-id="e49ae-155">Каковы примеры использования Spark в HDInsight?</span><span class="sxs-lookup"><span data-stu-id="e49ae-155">What are the use cases for Spark on HDInsight?</span></span>
<span data-ttu-id="e49ae-156">Использование кластеров Spark в HDInsight включает следующие основные сценарии.</span><span class="sxs-lookup"><span data-stu-id="e49ae-156">Spark clusters in HDInsight enable the following key scenarios.</span></span>

### <a name="interactive-data-analysis-and-bi"></a><span data-ttu-id="e49ae-157">Интерактивный анализ данных и бизнес-аналитика</span><span class="sxs-lookup"><span data-stu-id="e49ae-157">Interactive data analysis and BI</span></span>
[<span data-ttu-id="e49ae-158">Учебник</span><span class="sxs-lookup"><span data-stu-id="e49ae-158">Look at a tutorial</span></span>](hdinsight-apache-spark-use-bi-tools.md)

<span data-ttu-id="e49ae-159">Apache Spark в HDInsight хранит данные в службе хранилища Azure или Azure Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="e49ae-159">Apache Spark in HDInsight stores data in Azure Storage or Azure Data Lake Store.</span></span> <span data-ttu-id="e49ae-160">Бизнес-эксперты и лица, ответственные за принятие решений, могут анализировать и создавать отчеты на основе этих данных, а также создавать интерактивные отчеты из проанализированных данных с помощью средств Microsoft Power BI.</span><span class="sxs-lookup"><span data-stu-id="e49ae-160">Business experts and key decision makers can analyze and build reports over that data and use Microsoft Power BI to build interactive reports from the analyzed data.</span></span> <span data-ttu-id="e49ae-161">Аналитики могут использовать неструктурированные или полуструктурированные данные в хранилище кластеров, определить схему для данных с помощью записных книжек, а затем создать модели данных с помощью средств Microsoft Power BI.</span><span class="sxs-lookup"><span data-stu-id="e49ae-161">Analysts can start from unstructured/semi structured data in cluster storage, define a schema for the data using notebooks, and then build data models using Microsoft Power BI.</span></span> <span data-ttu-id="e49ae-162">Кластеры Spark в HDInsight также поддерживают ряд средств бизнес-аналитики сторонних разработчиков, такие как Tableau, что делает Spark идеальной платформой для аналитиков, бизнес-экспертов и лиц, ответственных за принятие решений.</span><span class="sxs-lookup"><span data-stu-id="e49ae-162">Spark clusters in HDInsight also support a number of third party BI tools such as Tableau making it an ideal platform for data analysts, business experts, and key decision makers.</span></span>

### <a name="spark-machine-learning"></a><span data-ttu-id="e49ae-163">Машинное обучение Spark</span><span class="sxs-lookup"><span data-stu-id="e49ae-163">Spark Machine Learning</span></span>
[<span data-ttu-id="e49ae-164">Учебник. Прогнозирование температуры зданий с помощью данных системы кондиционирования</span><span class="sxs-lookup"><span data-stu-id="e49ae-164">Look at a tutorial: Predict building temperatures uisng HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)

[<span data-ttu-id="e49ae-165">Учебник. Прогнозирование результатов контроля качества пищевых продуктов</span><span class="sxs-lookup"><span data-stu-id="e49ae-165">Look at a tutorial: Predict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)

<span data-ttu-id="e49ae-166">В состав Apache Spark входит [MLlib](http://spark.apache.org/mllib/), библиотека машинного обучения, созданная на основе Spark, которую вы можете использовать из кластера Spark в HDInsight.</span><span class="sxs-lookup"><span data-stu-id="e49ae-166">Apache Spark comes with [MLlib](http://spark.apache.org/mllib/), a machine learning library built on top of Spark that you can use from a Spark cluster in HDInsight.</span></span> <span data-ttu-id="e49ae-167">Кластер Spark в HDInsight также включает библиотеку Anaconda, распространяемую Python и содержащую различные пакеты для машинного обучения.</span><span class="sxs-lookup"><span data-stu-id="e49ae-167">Spark cluster on HDInsight also includes Anaconda, a Python distribution with a variety of packages for machine learning.</span></span> <span data-ttu-id="e49ae-168">Все это дополнено встроенной поддержкой записных книжек Jupyter и Zeppelin — в итоге вы получаете в свое распоряжение первоклассную среду для создания приложений машинного обучения.</span><span class="sxs-lookup"><span data-stu-id="e49ae-168">Couple this with a built-in support for Jupyter and Zeppelin notebooks, and you have a top-of-the-line environment for creating machine learning applications.</span></span>

### <a name="spark-streaming-and-real-time-data-analysis"></a><span data-ttu-id="e49ae-169">Потоковая передача и анализ данных в режиме реального времени в Spark</span><span class="sxs-lookup"><span data-stu-id="e49ae-169">Spark streaming and real-time data analysis</span></span>
[<span data-ttu-id="e49ae-170">Учебник</span><span class="sxs-lookup"><span data-stu-id="e49ae-170">Look at a tutorial</span></span>](hdinsight-apache-spark-eventhub-streaming.md)

<span data-ttu-id="e49ae-171">Кластеры Spark в HDInsight обладают широкой поддержкой для создания решений для аналитики в режиме реального времени.</span><span class="sxs-lookup"><span data-stu-id="e49ae-171">Spark clusters in HDInsight offer a rich support for building real-time analytics solutions.</span></span> <span data-ttu-id="e49ae-172">Поскольку в состав Spark уже входят соединители для приема данных из различных источников, таких как Flume, Kafka, Twitter, ZeroMQ или сокеты TCP, Spark в HDInsight позволяет реализовать первоклассную поддержку для приема данных из концентраторов событий Azure.</span><span class="sxs-lookup"><span data-stu-id="e49ae-172">While Spark already has connectors to ingest data from many sources like Kafka, Flume, Twitter, ZeroMQ, or TCP sockets, Spark in HDInsight adds first-class support for ingesting data from Azure Event Hubs.</span></span> <span data-ttu-id="e49ae-173">Концентраторы событий — это наиболее широко используемые службы очередей в Azure.</span><span class="sxs-lookup"><span data-stu-id="e49ae-173">Event Hubs are the most widely used queuing service on Azure.</span></span> <span data-ttu-id="e49ae-174">Встроенная поддержка концентраторов событий делает кластеры Spark в HDInsight идеальной платформой для создания конвейеров аналитики в режиме реального времени.</span><span class="sxs-lookup"><span data-stu-id="e49ae-174">Having an out-of-the-box support for Event Hubs makes Spark clusters in HDInsight an ideal platform for building real time analytics pipeline.</span></span>

## <span data-ttu-id="e49ae-175"><a name="next-steps"></a>Какие компоненты входят в состав кластера Spark?</span><span class="sxs-lookup"><span data-stu-id="e49ae-175"><a name="next-steps"></a>What components are included as part of a Spark cluster?</span></span>
<span data-ttu-id="e49ae-176">Кластеры Spark в HDInsight включают следующие компоненты, доступные в кластерах по умолчанию.</span><span class="sxs-lookup"><span data-stu-id="e49ae-176">Spark clusters in HDInsight include the following components that are available on the clusters by default.</span></span>

* <span data-ttu-id="e49ae-177">[Ядро Spark](https://spark.apache.org/docs/1.5.1/).</span><span class="sxs-lookup"><span data-stu-id="e49ae-177">[Spark Core](https://spark.apache.org/docs/1.5.1/).</span></span> <span data-ttu-id="e49ae-178">Включает ядро Spark, Spark SQL, потоковые API-интерфейсы Spark, GraphX и MLlib.</span><span class="sxs-lookup"><span data-stu-id="e49ae-178">Includes Spark Core, Spark SQL, Spark streaming APIs, GraphX, and MLlib.</span></span>
* [<span data-ttu-id="e49ae-179">Anaconda</span><span class="sxs-lookup"><span data-stu-id="e49ae-179">Anaconda</span></span>](http://docs.continuum.io/anaconda/)
* [<span data-ttu-id="e49ae-180">Livy</span><span class="sxs-lookup"><span data-stu-id="e49ae-180">Livy</span></span>](https://github.com/cloudera/hue/tree/master/apps/spark/java#welcome-to-livy-the-rest-spark-server)
* [<span data-ttu-id="e49ae-181">Записная книжка Jupyter</span><span class="sxs-lookup"><span data-stu-id="e49ae-181">Jupyter notebook</span></span>](https://jupyter.org)
* [<span data-ttu-id="e49ae-182">Записная книжка Zeppelin</span><span class="sxs-lookup"><span data-stu-id="e49ae-182">Zeppelin notebook</span></span>](http://zeppelin-project.org/)

<span data-ttu-id="e49ae-183">Кроме того, кластеры Spark в HDInsight включают [драйвер ODBC](http://go.microsoft.com/fwlink/?LinkId=616229) для подключения к кластерам Spark в HDInsight из таких средств бизнес-аналитики, как Microsoft Power BI и Tableau.</span><span class="sxs-lookup"><span data-stu-id="e49ae-183">Spark clusters on HDInsight also provide an [ODBC driver](http://go.microsoft.com/fwlink/?LinkId=616229) for connectivity to Spark clusters in HDInsight from BI tools such as Microsoft Power BI and Tableau.</span></span>

## <a name="where-do-i-start"></a><span data-ttu-id="e49ae-184">С чего начать?</span><span class="sxs-lookup"><span data-stu-id="e49ae-184">Where do I start?</span></span>
<span data-ttu-id="e49ae-185">Начните с создания кластера Spark в HDInsight.</span><span class="sxs-lookup"><span data-stu-id="e49ae-185">Start with creating a Spark cluster on HDInsight.</span></span> <span data-ttu-id="e49ae-186">Дополнительные сведения см. в статье [Начало работы. Создание кластера Apache Spark в Azure HDInsight и выполнение интерактивных запросов с помощью SQL Spark](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="e49ae-186">See [QuickStart: create a Spark cluster on HDInsight Linux and run interactive query using Jupyter](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span> 

## <a name="next-steps"></a><span data-ttu-id="e49ae-187">Дальнейшие действия</span><span class="sxs-lookup"><span data-stu-id="e49ae-187">Next Steps</span></span>
### <a name="scenarios"></a><span data-ttu-id="e49ae-188">Сценарии</span><span class="sxs-lookup"><span data-stu-id="e49ae-188">Scenarios</span></span>
* [<span data-ttu-id="e49ae-189">Использование Spark со средствами бизнес-аналитики. Выполнение интерактивного анализа данных с использованием Spark в HDInsight с помощью средств бизнес-аналитики</span><span class="sxs-lookup"><span data-stu-id="e49ae-189">Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools</span></span>](hdinsight-apache-spark-use-bi-tools.md)
* [<span data-ttu-id="e49ae-190">Использование Spark с машинным обучением. Использование Spark в HDInsight для анализа температуры в здании на основе данных системы кондиционирования</span><span class="sxs-lookup"><span data-stu-id="e49ae-190">Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)
* [<span data-ttu-id="e49ae-191">Использование Spark с машинным обучением. Использование Spark в HDInsight для прогнозирования результатов контроля качества пищевых продуктов</span><span class="sxs-lookup"><span data-stu-id="e49ae-191">Spark with Machine Learning: Use Spark in HDInsight to predict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)
* [<span data-ttu-id="e49ae-192">Потоковая передача Spark. Использование Spark в HDInsight для сборки приложений потоковой передачи данных в режиме реального времени</span><span class="sxs-lookup"><span data-stu-id="e49ae-192">Spark Streaming: Use Spark in HDInsight for building real-time streaming applications</span></span>](hdinsight-apache-spark-eventhub-streaming.md)
* [<span data-ttu-id="e49ae-193">Анализ журнала веб-сайта с использованием Spark в HDInsight</span><span class="sxs-lookup"><span data-stu-id="e49ae-193">Website log analysis using Spark in HDInsight</span></span>](hdinsight-apache-spark-custom-library-website-log-analysis.md)

### <a name="create-and-run-applications"></a><span data-ttu-id="e49ae-194">Создание и запуск приложений</span><span class="sxs-lookup"><span data-stu-id="e49ae-194">Create and run applications</span></span>
* [<span data-ttu-id="e49ae-195">Создание автономного приложения с использованием Scala</span><span class="sxs-lookup"><span data-stu-id="e49ae-195">Create a standalone application using Scala</span></span>](hdinsight-apache-spark-create-standalone-application.md)
* [<span data-ttu-id="e49ae-196">Удаленный запуск заданий с помощью Livy в кластере Spark</span><span class="sxs-lookup"><span data-stu-id="e49ae-196">Run jobs remotely on a Spark cluster using Livy</span></span>](hdinsight-apache-spark-livy-rest-interface.md)

### <a name="tools-and-extensions"></a><span data-ttu-id="e49ae-197">Средства и расширения</span><span class="sxs-lookup"><span data-stu-id="e49ae-197">Tools and extensions</span></span>
* [<span data-ttu-id="e49ae-198">Использование подключаемого модуля средств HDInsight для IntelliJ IDEA для создания и отправки приложений Spark Scala</span><span class="sxs-lookup"><span data-stu-id="e49ae-198">Use HDInsight Tools Plugin for IntelliJ IDEA to create and submit Spark Scala applicatons</span></span>](hdinsight-apache-spark-intellij-tool-plugin.md)
* [<span data-ttu-id="e49ae-199">Удаленная отладка приложений Spark в кластере HDInsight Spark Linux с помощью подключаемого модуля средств HDInsight для IntelliJ IDEA</span><span class="sxs-lookup"><span data-stu-id="e49ae-199">Use HDInsight Tools Plugin for IntelliJ IDEA to debug Spark applications remotely</span></span>](hdinsight-apache-spark-intellij-tool-plugin-debug-jobs-remotely.md)
* [<span data-ttu-id="e49ae-200">Использование записных книжек Zeppelin с кластером Spark в HDInsight</span><span class="sxs-lookup"><span data-stu-id="e49ae-200">Use Zeppelin notebooks with a Spark cluster on HDInsight</span></span>](hdinsight-apache-spark-zeppelin-notebook.md)
* [<span data-ttu-id="e49ae-201">Ядра, доступные для записной книжки Jupyter в кластере Spark в HDInsight</span><span class="sxs-lookup"><span data-stu-id="e49ae-201">Kernels available for Jupyter notebook in Spark cluster for HDInsight</span></span>](hdinsight-apache-spark-jupyter-notebook-kernels.md)
* [<span data-ttu-id="e49ae-202">Использование внешних пакетов с записными книжками Jupyter</span><span class="sxs-lookup"><span data-stu-id="e49ae-202">Use external packages with Jupyter notebooks</span></span>](hdinsight-apache-spark-jupyter-notebook-use-external-packages.md)
* [<span data-ttu-id="e49ae-203">Установка записной книжки Jupyter на компьютере и ее подключение к кластеру Apache Spark в Azure HDInsight (предварительная версия)</span><span class="sxs-lookup"><span data-stu-id="e49ae-203">Install Jupyter on your computer and connect to an HDInsight Spark cluster</span></span>](hdinsight-apache-spark-jupyter-notebook-install-locally.md)

### <a name="manage-resources"></a><span data-ttu-id="e49ae-204">Управление ресурсами</span><span class="sxs-lookup"><span data-stu-id="e49ae-204">Manage resources</span></span>
* [<span data-ttu-id="e49ae-205">Управление ресурсами кластера Apache Spark в Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="e49ae-205">Manage resources for the Apache Spark cluster in Azure HDInsight</span></span>](hdinsight-apache-spark-resource-manager.md)
* [<span data-ttu-id="e49ae-206">Отслеживание и отладка заданий в кластере Apache Spark в HDInsight на платформе Linux</span><span class="sxs-lookup"><span data-stu-id="e49ae-206">Track and debug jobs running on an Apache Spark cluster in HDInsight</span></span>](hdinsight-apache-spark-job-debugging.md)
* <span data-ttu-id="e49ae-207">[Известные проблемы в работе кластера Apache Spark в HDInsight](hdinsight-apache-spark-known-issues.md).</span><span class="sxs-lookup"><span data-stu-id="e49ae-207">[Known issues of Apache Spark in Azure HDInsight](hdinsight-apache-spark-known-issues.md).</span></span>
