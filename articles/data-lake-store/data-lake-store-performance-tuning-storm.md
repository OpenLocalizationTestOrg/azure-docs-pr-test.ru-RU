---
title: "рекомендации по настройке производительности Storm хранилища Озера данных aaaAzure | Документы Microsoft"
description: "Рекомендации по настройке производительности для Storm в Azure Data Lake Store"
services: data-lake-store
documentationcenter: 
author: stewu
manager: amitkul
editor: stewu
ms.assetid: ebde7b9f-2e51-4d43-b7ab-566417221335
ms.service: data-lake-store
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 12/19/2016
ms.author: stewu
ms.openlocfilehash: 5412fd46cf2373f5877030913df4fe1fc6f5473a
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 10/06/2017
---
# <a name="performance-tuning-guidance-for-storm-on-hdinsight-and-azure-data-lake-store"></a><span data-ttu-id="293ba-103">Рекомендации по настройке производительности для Storm в HDInsight и Azure Data Lake Store</span><span class="sxs-lookup"><span data-stu-id="293ba-103">Performance tuning guidance for Storm on HDInsight and Azure Data Lake Store</span></span>

<span data-ttu-id="293ba-104">Понимать hello факторы, которые следует учитывать при настройке производительности hello Azure Storm топологии.</span><span class="sxs-lookup"><span data-stu-id="293ba-104">Understand hello factors that should be considered when you tune hello performance of an Azure Storm topology.</span></span> <span data-ttu-id="293ba-105">Например это toounderstand важные характеристики hello hello работы, выполненной hello spouts и винты hello (hello рабочих является ли ввода-вывода или большим объемом памяти).</span><span class="sxs-lookup"><span data-stu-id="293ba-105">For example, it's important toounderstand hello characteristics of hello work done by hello spouts and hello bolts (whether hello work is I/O or memory intensive).</span></span> <span data-ttu-id="293ba-106">В этой статье рассматривается ряд рекомендаций по улучшению производительности, в том числе по устранению типичных неполадок.</span><span class="sxs-lookup"><span data-stu-id="293ba-106">This article covers a range of performance tuning guidelines, including troubleshooting common issues.</span></span>

## <a name="prerequisites"></a><span data-ttu-id="293ba-107">Предварительные требования</span><span class="sxs-lookup"><span data-stu-id="293ba-107">Prerequisites</span></span>

* <span data-ttu-id="293ba-108">**Подписка Azure**.</span><span class="sxs-lookup"><span data-stu-id="293ba-108">**An Azure subscription**.</span></span> <span data-ttu-id="293ba-109">Ознакомьтесь с [бесплатной пробной версией Azure](https://azure.microsoft.com/pricing/free-trial/).</span><span class="sxs-lookup"><span data-stu-id="293ba-109">See [Get Azure free trial](https://azure.microsoft.com/pricing/free-trial/).</span></span>
* <span data-ttu-id="293ba-110">**Учетная запись Azure Data Lake Store.**</span><span class="sxs-lookup"><span data-stu-id="293ba-110">**An Azure Data Lake Store account**.</span></span> <span data-ttu-id="293ba-111">Инструкции о том, как один, см. в разделе toocreate [Приступая к работе с хранилища Озера данных Azure](data-lake-store-get-started-portal.md).</span><span class="sxs-lookup"><span data-stu-id="293ba-111">For instructions on how toocreate one, see [Get started with Azure Data Lake Store](data-lake-store-get-started-portal.md).</span></span>
* <span data-ttu-id="293ba-112">**Кластер Azure HDInsight** с tooa доступа к учетной записи хранилища Озера данных.</span><span class="sxs-lookup"><span data-stu-id="293ba-112">**An Azure HDInsight cluster** with access tooa Data Lake Store account.</span></span> <span data-ttu-id="293ba-113">См. статью [Создание кластера HDInsight с Data Lake Store с помощью портала Azure](data-lake-store-hdinsight-hadoop-use-portal.md).</span><span class="sxs-lookup"><span data-stu-id="293ba-113">See [Create an HDInsight cluster with Data Lake Store](data-lake-store-hdinsight-hadoop-use-portal.md).</span></span> <span data-ttu-id="293ba-114">Убедитесь, что включить удаленный рабочий стол для кластера hello.</span><span class="sxs-lookup"><span data-stu-id="293ba-114">Make sure you enable Remote Desktop for hello cluster.</span></span>
* <span data-ttu-id="293ba-115">**Запущенный кластер Storm в Data Lake Store**.</span><span class="sxs-lookup"><span data-stu-id="293ba-115">**Running a Storm cluster on Data Lake Store**.</span></span> <span data-ttu-id="293ba-116">Дополнительные сведения см. в статье [Основные сведения об Apache Storm в службе HDInsight. Аналитика в реальном времени для Hadoop](https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-storm-overview).</span><span class="sxs-lookup"><span data-stu-id="293ba-116">For more information, see [Storm on HDInsight](https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-storm-overview).</span></span>
* <span data-ttu-id="293ba-117">**Рекомендации по настройке производительности для Data Lake Store**.</span><span class="sxs-lookup"><span data-stu-id="293ba-117">**Performance tuning guidelines on Data Lake Store**.</span></span>  <span data-ttu-id="293ba-118">Общие вопросы производительности описаны в [рекомендациях по настройке](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-performance-tuning-guidance).</span><span class="sxs-lookup"><span data-stu-id="293ba-118">For general performance concepts, see [Data Lake Store Performance Tuning Guidance](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-performance-tuning-guidance).</span></span>  

## <a name="tune-hello-parallelism-of-hello-topology"></a><span data-ttu-id="293ba-119">Настройка параллелизма hello hello топологии</span><span class="sxs-lookup"><span data-stu-id="293ba-119">Tune hello parallelism of hello topology</span></span>

<span data-ttu-id="293ba-120">Возможно, производительность может tooimprove по возрастающей параллелизм hello hello tooand ввода-вывода из хранилища Озера данных.</span><span class="sxs-lookup"><span data-stu-id="293ba-120">You might be able tooimprove performance by increasing hello concurrency of hello I/O tooand from Data Lake Store.</span></span> <span data-ttu-id="293ba-121">Топология Storm имеет набор конфигураций, которые определяют hello параллелизма.</span><span class="sxs-lookup"><span data-stu-id="293ba-121">A Storm topology has a set of configurations that determine hello parallelism:</span></span>
* <span data-ttu-id="293ba-122">Число рабочих процессов (hello работников равномерно распределяются между hello виртуальные машины).</span><span class="sxs-lookup"><span data-stu-id="293ba-122">Number of worker processes (hello workers are evenly distributed across hello VMs).</span></span>
* <span data-ttu-id="293ba-123">Количество экземпляров исполнителей spout.</span><span class="sxs-lookup"><span data-stu-id="293ba-123">Number of spout executor instances.</span></span>
* <span data-ttu-id="293ba-124">Количество экземпляров исполнителей bolt.</span><span class="sxs-lookup"><span data-stu-id="293ba-124">Number of bolt executor instances.</span></span>
* <span data-ttu-id="293ba-125">Количество задач spout.</span><span class="sxs-lookup"><span data-stu-id="293ba-125">Number of spout tasks.</span></span>
* <span data-ttu-id="293ba-126">Количество задач bolt.</span><span class="sxs-lookup"><span data-stu-id="293ba-126">Number of bolt tasks.</span></span>

<span data-ttu-id="293ba-127">В кластере с 4 виртуальных машин и 4 рабочих процессов, 32 spout исполнителей и 32 spout задач и 256 молнии исполнителей и задач 512 молнии, рассмотрим следующие hello:</span><span class="sxs-lookup"><span data-stu-id="293ba-127">For example, on a cluster with 4 VMs and 4 worker processes, 32 spout executors and 32 spout tasks, and 256 bolt executors and 512 bolt tasks, consider hello following:</span></span>

<span data-ttu-id="293ba-128">Каждый супервизор, то есть рабочий узел, имеет один рабочий процесс виртуальной машины Java (JVM).</span><span class="sxs-lookup"><span data-stu-id="293ba-128">Each supervisor, which is a worker node, has a single worker Java virtual machine (JVM) process.</span></span> <span data-ttu-id="293ba-129">Этот процесс JVM управляет 4-мя потоками spout и 64-ю потоками bolt.</span><span class="sxs-lookup"><span data-stu-id="293ba-129">This JVM process manages 4 spout threads and 64 bolt threads.</span></span> <span data-ttu-id="293ba-130">Внутри каждого потока задачи выполняются последовательно.</span><span class="sxs-lookup"><span data-stu-id="293ba-130">Within each thread, tasks are run sequentially.</span></span> <span data-ttu-id="293ba-131">Каждый поток spout имеет 1 задача hello предшествующий конфигурации, и каждый поток молнии имеет 2 задачи.</span><span class="sxs-lookup"><span data-stu-id="293ba-131">With hello preceding configuration, each spout thread has 1 task, and each bolt thread has 2 tasks.</span></span>

<span data-ttu-id="293ba-132">В Storm Вот различные компоненты, участвующие hello и их влиянии на hello уровень параллелизма, к которым у вас есть:</span><span class="sxs-lookup"><span data-stu-id="293ba-132">In Storm, here are hello various components involved, and how they affect hello level of parallelism you have:</span></span>
* <span data-ttu-id="293ba-133">используется toosubmit и управление заданиями Hello головного узла (именем Nimbus в Storm).</span><span class="sxs-lookup"><span data-stu-id="293ba-133">hello head node (called Nimbus in Storm) is used toosubmit and manage jobs.</span></span> <span data-ttu-id="293ba-134">Эти узлы не оказывают влияния на hello степень параллелизма.</span><span class="sxs-lookup"><span data-stu-id="293ba-134">These nodes have no impact on hello degree of parallelism.</span></span>
* <span data-ttu-id="293ba-135">узлы начальника Hello.</span><span class="sxs-lookup"><span data-stu-id="293ba-135">hello supervisor nodes.</span></span> <span data-ttu-id="293ba-136">В HDInsight соответствует tooa рабочий узел виртуальной Машины Azure.</span><span class="sxs-lookup"><span data-stu-id="293ba-136">In HDInsight, this corresponds tooa worker node Azure VM.</span></span>
* <span data-ttu-id="293ba-137">Hello рабочим задачам, Storm процессы, запущенные в hello виртуальных машин.</span><span class="sxs-lookup"><span data-stu-id="293ba-137">hello worker tasks are Storm processes running in hello VMs.</span></span> <span data-ttu-id="293ba-138">Каждая рабочая задача соответствует tooa экземпляр виртуальной машины Java.</span><span class="sxs-lookup"><span data-stu-id="293ba-138">Each worker task corresponds tooa JVM instance.</span></span> <span data-ttu-id="293ba-139">Storm распределяет hello число рабочих процессов укажите toohello рабочих узлов максимально равномерно.</span><span class="sxs-lookup"><span data-stu-id="293ba-139">Storm distributes hello number of worker processes you specify toohello worker nodes as evenly as possible.</span></span>
* <span data-ttu-id="293ba-140">Количество экземпляров исполнителей spout и bolt.</span><span class="sxs-lookup"><span data-stu-id="293ba-140">Spout and bolt executor instances.</span></span> <span data-ttu-id="293ba-141">Каждый экземпляр исполнителя соответствует tooa потока, запущенного в рамках рабочих процессов hello (JVM).</span><span class="sxs-lookup"><span data-stu-id="293ba-141">Each executor instance corresponds tooa thread running within hello workers (JVMs).</span></span>
* <span data-ttu-id="293ba-142">Задачи Storm.</span><span class="sxs-lookup"><span data-stu-id="293ba-142">Storm tasks.</span></span> <span data-ttu-id="293ba-143">Это логические задачи, которые выполняет каждый из потоков.</span><span class="sxs-lookup"><span data-stu-id="293ba-143">These are logical tasks that each of these threads run.</span></span> <span data-ttu-id="293ba-144">Это не меняет hello степень параллелизма, поэтому следует оценить, если требуется несколько задач на исполнителя или не.</span><span class="sxs-lookup"><span data-stu-id="293ba-144">This does not change hello level of parallelism, so you should evaluate if you need multiple tasks per executor or not.</span></span>

### <a name="get-hello-best-performance-from-data-lake-store"></a><span data-ttu-id="293ba-145">Обеспечения высокой производительности hello из хранилища Озера данных</span><span class="sxs-lookup"><span data-stu-id="293ba-145">Get hello best performance from Data Lake Store</span></span>

<span data-ttu-id="293ba-146">При работе с хранилищем данных Озера получить hello наилучшей производительности, если hello следующие:</span><span class="sxs-lookup"><span data-stu-id="293ba-146">When working with Data Lake Store, you get hello best performance if you do hello following:</span></span>
* <span data-ttu-id="293ba-147">Объедините маленькие добавления в пакеты большего размера (в идеале размером по 4 МБ).</span><span class="sxs-lookup"><span data-stu-id="293ba-147">Coalesce your small appends into larger sizes (ideally 4 MB).</span></span>
* <span data-ttu-id="293ba-148">Выполняйте максимально возможное количество одновременных запросов.</span><span class="sxs-lookup"><span data-stu-id="293ba-148">Do as many concurrent requests as you can.</span></span> <span data-ttu-id="293ba-149">Так как каждый поток молнии выполняет блокирующих операций чтения, следует toohave в любом месте hello диапазона 8-12 потока на ядро.</span><span class="sxs-lookup"><span data-stu-id="293ba-149">Because each bolt thread is doing blocking reads, you want toohave somewhere in hello range of 8-12 threads per core.</span></span> <span data-ttu-id="293ba-150">В этом случае hello сетевых КАРТ и hello ресурсов ЦП также.</span><span class="sxs-lookup"><span data-stu-id="293ba-150">This keeps hello NIC and hello CPU well utilized.</span></span> <span data-ttu-id="293ba-151">Крупная виртуальная машина позволяет выполнять большее число параллельных запросов.</span><span class="sxs-lookup"><span data-stu-id="293ba-151">A larger VM enables more concurrent requests.</span></span>  

### <a name="example-topology"></a><span data-ttu-id="293ba-152">Пример топологии</span><span class="sxs-lookup"><span data-stu-id="293ba-152">Example topology</span></span>

<span data-ttu-id="293ba-153">Предположим, что у вас есть кластер из 8 рабочих узлов на виртуальной машине Azure D13v2.</span><span class="sxs-lookup"><span data-stu-id="293ba-153">Let’s assume you have an 8 worker node cluster with a D13v2 Azure VM.</span></span> <span data-ttu-id="293ba-154">Эта виртуальная машина имеет 8 ядер, поэтому среди Здравствуйте 8 рабочих узлов, у вас есть 64 общего количества ядер.</span><span class="sxs-lookup"><span data-stu-id="293ba-154">This VM has 8 cores, so among hello 8 worker nodes, you have 64 total cores.</span></span>

<span data-ttu-id="293ba-155">Предположим, что мы запускаем 8 потоков элементов bolt на ядро.</span><span class="sxs-lookup"><span data-stu-id="293ba-155">Let’s say we do 8 bolt threads per core.</span></span> <span data-ttu-id="293ba-156">Так как у нас есть 64 ядра, мы получаем 512 экземпляров исполнителей элемента bolt (т. е. потоков).</span><span class="sxs-lookup"><span data-stu-id="293ba-156">Given 64 cores, that means we want 512 total bolt executor instances (that is, threads).</span></span> <span data-ttu-id="293ba-157">В этом случае предположим, что мы начать с одной виртуальной машины Java на виртуальную Машину затем главным образом параллелизме потоков hello в tooachieve параллелизма hello виртуальной машины Java.</span><span class="sxs-lookup"><span data-stu-id="293ba-157">In this case, let’s say we start with one JVM per VM, and mainly use hello thread concurrency within hello JVM tooachieve concurrency.</span></span> <span data-ttu-id="293ba-158">Это означает, что нам нужно 8 рабочих задач (по одной на каждую виртуальную машину Azure) и 512 исполнителей элемента bolt.</span><span class="sxs-lookup"><span data-stu-id="293ba-158">That means we need 8 worker tasks (one per Azure VM), and 512 bolt executors.</span></span> <span data-ttu-id="293ba-159">При такой конфигурации Storm пытается toodistribute hello рабочих процессов равномерно между узлами работника (также известный как узлы начальника), предоставляя каждый рабочий узел 1 виртуальной машины Java.</span><span class="sxs-lookup"><span data-stu-id="293ba-159">Given this configuration, Storm tries toodistribute hello workers evenly across worker nodes (also known as supervisor nodes), giving each worker node 1 JVM.</span></span> <span data-ttu-id="293ba-160">Теперь в руководителями hello Storm пытается toodistribute исполнителей Привет между руководителями, предоставляя каждого руководителя (то есть JVM) 8 потоков каждого.</span><span class="sxs-lookup"><span data-stu-id="293ba-160">Now within hello supervisors, Storm tries toodistribute hello executors evenly between supervisors, giving each supervisor (that is, JVM) 8 threads each.</span></span>

## <a name="tune-additional-parameters"></a><span data-ttu-id="293ba-161">Настройка дополнительных параметров</span><span class="sxs-lookup"><span data-stu-id="293ba-161">Tune additional parameters</span></span>
<span data-ttu-id="293ba-162">После того как вы базовая топология hello, можно рассмотреть, следует ли tootweak hello параметры:</span><span class="sxs-lookup"><span data-stu-id="293ba-162">After you have hello basic topology, you can consider whether you want tootweak any of hello parameters:</span></span>
* <span data-ttu-id="293ba-163">**Число виртуальных машин Java на рабочий узел.**</span><span class="sxs-lookup"><span data-stu-id="293ba-163">**Number of JVMs per worker node.**</span></span> <span data-ttu-id="293ba-164">Если вы размещаете в памяти структуру данных большого объема (например, таблицу подстановки), потребуется отдельный экземпляр этой структуры для каждой виртуальной машины Java.</span><span class="sxs-lookup"><span data-stu-id="293ba-164">If you have a large data structure (for example, a lookup table) that you host in memory, each JVM requires a separate copy.</span></span> <span data-ttu-id="293ba-165">Кроме того можно использовать структуры данных hello через много потоков при наличии меньше JVM.</span><span class="sxs-lookup"><span data-stu-id="293ba-165">Alternatively, you can use hello data structure across many threads if you have fewer JVMs.</span></span> <span data-ttu-id="293ba-166">Для операций ввода-вывода hello молнии hello число JVM не делает столько различие hello число потоков, которые добавлены в эти JVM.</span><span class="sxs-lookup"><span data-stu-id="293ba-166">For hello bolt’s I/O, hello number of JVMs does not make as much of a difference as hello number of threads added across those JVMs.</span></span> <span data-ttu-id="293ba-167">Для простоты это toohave смысл, одной виртуальной машины Java для работника.</span><span class="sxs-lookup"><span data-stu-id="293ba-167">For simplicity, it's a good idea toohave one JVM per worker.</span></span> <span data-ttu-id="293ba-168">В зависимости от действия вашей молнии или какое приложение обработка требуется, хотя может потребоваться toochange этот номер.</span><span class="sxs-lookup"><span data-stu-id="293ba-168">Depending on what your bolt is doing or what application processing you require, though, you may need toochange this number.</span></span>
* <span data-ttu-id="293ba-169">**Количество экземпляров исполнителей spout.**</span><span class="sxs-lookup"><span data-stu-id="293ba-169">**Number of spout executors.**</span></span> <span data-ttu-id="293ba-170">Поскольку hello в предыдущем примере элементы для хранилища Озера tooData записи, количество hello spouts не связаны непосредственно toohello молнии производительности.</span><span class="sxs-lookup"><span data-stu-id="293ba-170">Because hello preceding example uses bolts for writing tooData Lake Store, hello number of spouts is not directly relevant toohello bolt performance.</span></span> <span data-ttu-id="293ba-171">Тем не менее в зависимости от hello объем обработки или ввода-вывода, происходит в hello spout рекомендуется tootune hello spouts для достижения оптимальной производительности.</span><span class="sxs-lookup"><span data-stu-id="293ba-171">However, depending on hello amount of processing or I/O happening in hello spout, it's a good idea tootune hello spouts for best performance.</span></span> <span data-ttu-id="293ba-172">Убедитесь, что имеется достаточно spouts toobe может tookeep hello винты занят.</span><span class="sxs-lookup"><span data-stu-id="293ba-172">Ensure that you have enough spouts toobe able tookeep hello bolts busy.</span></span> <span data-ttu-id="293ba-173">скорость hello spouts Hello выходные данные должны соответствовать hello пропускной способности винты hello.</span><span class="sxs-lookup"><span data-stu-id="293ba-173">hello output rates of hello spouts should match hello throughput of hello bolts.</span></span> <span data-ttu-id="293ba-174">Фактическая конфигурация Hello зависит от hello spout.</span><span class="sxs-lookup"><span data-stu-id="293ba-174">hello actual configuration depends on hello spout.</span></span>
* <span data-ttu-id="293ba-175">**Число задач.**</span><span class="sxs-lookup"><span data-stu-id="293ba-175">**Number of tasks.**</span></span> <span data-ttu-id="293ba-176">Каждый элемент bolt выполняется как один поток.</span><span class="sxs-lookup"><span data-stu-id="293ba-176">Each bolt runs as a single thread.</span></span> <span data-ttu-id="293ba-177">Увеличение количества задач для каждого элемента bolt не повышает уровень параллелизма.</span><span class="sxs-lookup"><span data-stu-id="293ba-177">Additional tasks per bolt don't provide any additional concurrency.</span></span> <span data-ttu-id="293ba-178">Hello единственный случай, когда они имеют преимущество затрачивается большую часть времени выполнения молнии Если ваш процесс подтверждения hello кортежа.</span><span class="sxs-lookup"><span data-stu-id="293ba-178">hello only time they are of benefit is if your process of acknowledging hello tuple takes a large proportion of your bolt execution time.</span></span> <span data-ttu-id="293ba-179">Это toogroup смысл, который множество кортежей в большее append перед отправкой подтверждения из молнии hello.</span><span class="sxs-lookup"><span data-stu-id="293ba-179">It's a good idea toogroup many tuples into a larger append before you send an acknowledgement from hello bolt.</span></span> <span data-ttu-id="293ba-180">Поэтому в большинстве случаев увеличение количества задач не дает дополнительных преимуществ.</span><span class="sxs-lookup"><span data-stu-id="293ba-180">So, in most cases, multiple tasks provide no additional benefit.</span></span>
* <span data-ttu-id="293ba-181">**Локальное группирование или группирование в случайном порядке.**</span><span class="sxs-lookup"><span data-stu-id="293ba-181">**Local or shuffle grouping.**</span></span> <span data-ttu-id="293ba-182">Если этот параметр включен, кортежей отправляются toobolts внутри hello же рабочего процесса.</span><span class="sxs-lookup"><span data-stu-id="293ba-182">When this setting is enabled, tuples are sent toobolts within hello same worker process.</span></span> <span data-ttu-id="293ba-183">Это уменьшает межпроцессное взаимодействие и количество сетевых вызовов.</span><span class="sxs-lookup"><span data-stu-id="293ba-183">This reduces inter-process communication and network calls.</span></span> <span data-ttu-id="293ba-184">Мы рекомендуем использовать этот параметр для большинства топологий.</span><span class="sxs-lookup"><span data-stu-id="293ba-184">This is recommended for most topologies.</span></span>

<span data-ttu-id="293ba-185">Такой вариант хорошо подойдет в качестве базового.</span><span class="sxs-lookup"><span data-stu-id="293ba-185">This basic scenario is a good starting point.</span></span> <span data-ttu-id="293ba-186">Тестирование с предыдущих параметров tooachieve оптимальной производительности tootweak hello собственных данных система.</span><span class="sxs-lookup"><span data-stu-id="293ba-186">Test with your own data tootweak hello preceding parameters tooachieve optimal performance.</span></span>

## <a name="tune-hello-spout"></a><span data-ttu-id="293ba-187">Настройка hello spout</span><span class="sxs-lookup"><span data-stu-id="293ba-187">Tune hello spout</span></span>

<span data-ttu-id="293ba-188">Можно изменить следующие параметры tootune hello spout hello.</span><span class="sxs-lookup"><span data-stu-id="293ba-188">You can modify hello following settings tootune hello spout.</span></span>

- <span data-ttu-id="293ba-189">**Время ожидания кортежа: topology.message.timeout.secs**.</span><span class="sxs-lookup"><span data-stu-id="293ba-189">**Tuple timeout: topology.message.timeout.secs**.</span></span> <span data-ttu-id="293ba-190">Этот параметр определяет интервал времени, toocomplete принимает сообщение hello и получения подтверждения, чтобы считать не удалось.</span><span class="sxs-lookup"><span data-stu-id="293ba-190">This setting determines hello amount of time a message takes toocomplete, and receive acknowledgement, before it is considered failed.</span></span>

- <span data-ttu-id="293ba-191">**Максимальный объем памяти для каждого рабочего процесса: worker.childopts**.</span><span class="sxs-lookup"><span data-stu-id="293ba-191">**Max memory per worker process: worker.childopts**.</span></span> <span data-ttu-id="293ba-192">Этот параметр позволяет указать дополнительные параметры командной строки toohello Java работников.</span><span class="sxs-lookup"><span data-stu-id="293ba-192">This setting lets you specify additional command-line parameters toohello Java workers.</span></span> <span data-ttu-id="293ba-193">Hello чаще всего используется параметр здесь — XmX, определяющий JVM hello Максимальная память, выделенную tooa кучи.</span><span class="sxs-lookup"><span data-stu-id="293ba-193">hello most commonly used setting here is XmX, which determines hello maximum memory allocated tooa JVM’s heap.</span></span>

- <span data-ttu-id="293ba-194">**Максимальное количество ожидающих spout: topology.max.spout.pending**.</span><span class="sxs-lookup"><span data-stu-id="293ba-194">**Max spout pending: topology.max.spout.pending**.</span></span> <span data-ttu-id="293ba-195">Этот параметр определяет hello число кортежей, возможного в полете (еще не подтверждено на всех узлах в топологии hello) для потока spout в любое время.</span><span class="sxs-lookup"><span data-stu-id="293ba-195">This setting determines hello number of tuples that can in be flight (not yet acknowledged at all nodes in hello topology) per spout thread at any time.</span></span>

 <span data-ttu-id="293ba-196">Toodo хорошо вычисления — tooestimate hello размер каждого из вашего кортежей.</span><span class="sxs-lookup"><span data-stu-id="293ba-196">A good calculation toodo is tooestimate hello size of each of your tuples.</span></span> <span data-ttu-id="293ba-197">и разобраться, сколько памяти выделяется для потока spout.</span><span class="sxs-lookup"><span data-stu-id="293ba-197">Then figure out how much memory one spout thread has.</span></span> <span data-ttu-id="293ba-198">Hello общий объем памяти, выделенный поток tooa, деленное на это значение будет предоставлять hello верхнюю границу hello max spout ожидающих параметра.</span><span class="sxs-lookup"><span data-stu-id="293ba-198">hello total memory allocated tooa thread, divided by this value, should give you hello upper bound for hello max spout pending parameter.</span></span>

## <a name="tune-hello-bolt"></a><span data-ttu-id="293ba-199">Настройка молнии hello</span><span class="sxs-lookup"><span data-stu-id="293ba-199">Tune hello bolt</span></span>
<span data-ttu-id="293ba-200">При написании хранилища Озера tooData задать политику синхронизации размер (буфер на стороне клиента hello) too4 МБ.</span><span class="sxs-lookup"><span data-stu-id="293ba-200">When you're writing tooData Lake Store, set a size sync policy (buffer on hello client side) too4 MB.</span></span> <span data-ttu-id="293ba-201">Запись на диск или hsync() затем выполняется только в том случае, если размер буфера hello — hello в это значение.</span><span class="sxs-lookup"><span data-stu-id="293ba-201">A flushing or hsync() is then performed only when hello buffer size is hello at this value.</span></span> <span data-ttu-id="293ba-202">Драйвер хранилища Озера данных Hello в рабочем процессе hello виртуальной Машины автоматически эта буферизация не, пока не выполняется явным образом hsync().</span><span class="sxs-lookup"><span data-stu-id="293ba-202">hello Data Lake Store driver on hello worker VM automatically does this buffering, unless you explicitly perform an hsync().</span></span>

<span data-ttu-id="293ba-203">молнии Storm хранилища Озера данных по умолчанию Hello имеет параметр политики синхронизации размер (fileBufferSize), может быть tootune используется этот параметр.</span><span class="sxs-lookup"><span data-stu-id="293ba-203">hello default Data Lake Store Storm bolt has a size sync policy parameter (fileBufferSize) that can be used tootune this parameter.</span></span>

<span data-ttu-id="293ba-204">В топологиях O-интенсивной это toohave смысл каждый поток молнии написать собственный файл tooits и tooset файловая политика поворота (fileRotationSize).</span><span class="sxs-lookup"><span data-stu-id="293ba-204">In I/O-intensive topologies, it's a good idea toohave each bolt thread write tooits own file, and tooset a file rotation policy (fileRotationSize).</span></span> <span data-ttu-id="293ba-205">Если файл hello достигает определенного размера, поток hello автоматически очищается и новый файл записывается в.</span><span class="sxs-lookup"><span data-stu-id="293ba-205">When hello file reaches a certain size, hello stream is automatically flushed and a new file is written to.</span></span> <span data-ttu-id="293ba-206">Рекомендуемый размер файла для поворота Hello составляет 1 ГБ.</span><span class="sxs-lookup"><span data-stu-id="293ba-206">hello recommended file size for rotation is 1 GB.</span></span>

### <a name="handle-tuple-data"></a><span data-ttu-id="293ba-207">Обработка данных кортежа</span><span class="sxs-lookup"><span data-stu-id="293ba-207">Handle tuple data</span></span>

<span data-ttu-id="293ba-208">В Storm spout удерживает кортежа tooa пока не будет явно подтверждается hello молнии.</span><span class="sxs-lookup"><span data-stu-id="293ba-208">In Storm, a spout holds on tooa tuple until it is explicitly acknowledged by hello bolt.</span></span> <span data-ttu-id="293ba-209">Если кортеж считанные молнии hello, но еще не подтверждены, hello spout может не удается сохранить в хранилище Озера данных серверной части.</span><span class="sxs-lookup"><span data-stu-id="293ba-209">If a tuple has been read by hello bolt but has not been acknowledged yet, hello spout might not have persisted into Data Lake Store back end.</span></span> <span data-ttu-id="293ba-210">После подтверждения кортеж hello spout может гарантироваться сохраняемости молнии hello и можно удалить из любого источника, она считывает данные из источника данных hello.</span><span class="sxs-lookup"><span data-stu-id="293ba-210">After a tuple is acknowledged, hello spout can be guaranteed persistence by hello bolt, and can then delete hello source data from whatever source it is reading from.</span></span>  

<span data-ttu-id="293ba-211">Для обеспечения максимальной производительности в хранилище Озера данных имеют молнии hello буфера 4 МБ данных кортежа.</span><span class="sxs-lookup"><span data-stu-id="293ba-211">For best performance on Data Lake Store, have hello bolt buffer 4 MB of tuple data.</span></span> <span data-ttu-id="293ba-212">Затем напишите toohello резервное хранилище Озера данных приводят к одной записи 4 МБ.</span><span class="sxs-lookup"><span data-stu-id="293ba-212">Then write toohello Data Lake Store back end as one 4-MB write.</span></span> <span data-ttu-id="293ba-213">После hello данные были успешно письменного toohello хранилища (вызывающий hflush()) молнии hello можно Подтверждаете spout задней toohello данных hello.</span><span class="sxs-lookup"><span data-stu-id="293ba-213">After hello data has been successfully written toohello store (by calling hflush()), hello bolt can acknowledge hello data back toohello spout.</span></span> <span data-ttu-id="293ba-214">Это пример какие hello винта здесь не.</span><span class="sxs-lookup"><span data-stu-id="293ba-214">This is what hello example bolt supplied here does.</span></span> <span data-ttu-id="293ba-215">Это также допустимого toohold увеличения числа кортежей перед hello hflush() вызов и hello кортежей подтверждения.</span><span class="sxs-lookup"><span data-stu-id="293ba-215">It is also acceptable toohold a larger number of tuples before hello hflush() call is made and hello tuples acknowledged.</span></span> <span data-ttu-id="293ba-216">Однако при этом увеличивается hello число кортежей в полете, которая hello spout требуется toohold, и поэтому увеличивается hello объем памяти, необходимый каждой виртуальной машины Java.</span><span class="sxs-lookup"><span data-stu-id="293ba-216">However, this increases hello number of tuples in flight that hello spout needs toohold, and therefore increases hello amount of memory required per JVM.</span></span>

> [!NOTE]
<span data-ttu-id="293ba-217">Приложения могут содержать кортежи tooacknowledge требование чаще (на размер данных меньше 4 МБ) по другим причинам не производительности.</span><span class="sxs-lookup"><span data-stu-id="293ba-217">Applications might have a requirement tooacknowledge tuples more frequently (at data sizes less than 4 MB) for other non-performance reasons.</span></span> <span data-ttu-id="293ba-218">Тем не менее, которые могут повлиять на серверной части toohello пропускной способности хранилища hello ввода-вывода.</span><span class="sxs-lookup"><span data-stu-id="293ba-218">However, that might affect hello I/O throughput toohello storage back end.</span></span> <span data-ttu-id="293ba-219">Тщательно взвесить этот компромисс с точки зрения производительности операций ввода-вывода hello молнии.</span><span class="sxs-lookup"><span data-stu-id="293ba-219">Carefully weigh this tradeoff against hello bolt’s I/O performance.</span></span>

<span data-ttu-id="293ba-220">Если интенсивность поступления hello кортежей не велико, поэтому hello 4 МБ буфера будет toofill много времени, рассмотрите возможность устранения это по:</span><span class="sxs-lookup"><span data-stu-id="293ba-220">If hello incoming rate of tuples is not high, so hello 4-MB buffer takes a long time toofill, consider mitigating this by:</span></span>
* <span data-ttu-id="293ba-221">Уменьшение числа hello винты, поэтому существуют toofill меньшее число буферов.</span><span class="sxs-lookup"><span data-stu-id="293ba-221">Reducing hello number of bolts, so there are fewer buffers toofill.</span></span>
* <span data-ttu-id="293ba-222">Наличие политику на основе времени или на основе количества, где hflush() каждые х удалений или каждые миллисекунд y, а также hello кортежей, собранные до сих подтверждения назад.</span><span class="sxs-lookup"><span data-stu-id="293ba-222">Having a time-based or count-based policy, where an hflush() is triggered every x flushes or every y milliseconds, and hello tuples accumulated so far are acknowledged back.</span></span>

<span data-ttu-id="293ba-223">Обратите внимание, что hello пропускной способности в этом случае меньше, но с медленным частота возникновения событий, максимальная пропускная способность не крупнейших цель hello все равно.</span><span class="sxs-lookup"><span data-stu-id="293ba-223">Note that hello throughput in this case is lower, but with a slow rate of events, maximum throughput is not hello biggest objective anyway.</span></span> <span data-ttu-id="293ba-224">Эти исправления позволяют сократить hello общее время, необходимое для tooflow кортежа через магазин toohello.</span><span class="sxs-lookup"><span data-stu-id="293ba-224">These mitigations help you reduce hello total time that it takes for a tuple tooflow through toohello store.</span></span> <span data-ttu-id="293ba-225">Это будет полезно, если конвейер должен работать в режиме реального времени даже при низкой частоте событий.</span><span class="sxs-lookup"><span data-stu-id="293ba-225">This might matter if you want a real-time pipeline even with a low event rate.</span></span> <span data-ttu-id="293ba-226">Также Обратите внимание, в случае низкой скорости входящих кортежа следует изменить параметр topology.message.timeout_secs hello, поэтому кортежи hello времени ожидания не происходит при их получении в буфер или обработаны.</span><span class="sxs-lookup"><span data-stu-id="293ba-226">Also note that if your incoming tuple rate is low, you should adjust hello topology.message.timeout_secs parameter, so hello tuples don’t time out while they are getting buffered or processed.</span></span>

## <a name="monitor-your-topology-in-storm"></a><span data-ttu-id="293ba-227">Мониторинг топологии в Storm</span><span class="sxs-lookup"><span data-stu-id="293ba-227">Monitor your topology in Storm</span></span>  
<span data-ttu-id="293ba-228">Пока выполняется топологии, вы можете отслеживать ее в пользовательском интерфейсе Storm hello.</span><span class="sxs-lookup"><span data-stu-id="293ba-228">While your topology is running, you can monitor it in hello Storm user interface.</span></span> <span data-ttu-id="293ba-229">Ниже приведены toolook основными параметрами hello в.</span><span class="sxs-lookup"><span data-stu-id="293ba-229">Here are hello main parameters toolook at:</span></span>

* <span data-ttu-id="293ba-230">**Общая задержка выполнения процесса.**</span><span class="sxs-lookup"><span data-stu-id="293ba-230">**Total process execution latency.**</span></span> <span data-ttu-id="293ba-231">Это hello среднее время, затрачиваемое toobe испускаемый hello spout, обрабатываемых молнии hello и подтверждения один кортеж.</span><span class="sxs-lookup"><span data-stu-id="293ba-231">This is hello average time one tuple takes toobe emitted by hello spout, processed by hello bolt, and acknowledged.</span></span>

* <span data-ttu-id="293ba-232">**Общая задержка процесса bolt.**</span><span class="sxs-lookup"><span data-stu-id="293ba-232">**Total bolt process latency.**</span></span> <span data-ttu-id="293ba-233">Это hello среднее время, затраченное кортеж hello в молнии hello, пока не получит подтверждение.</span><span class="sxs-lookup"><span data-stu-id="293ba-233">This is hello average time spent by hello tuple at hello bolt until it receives an acknowledgement.</span></span>

* <span data-ttu-id="293ba-234">**Общая задержка выполнения bolt.**</span><span class="sxs-lookup"><span data-stu-id="293ba-234">**Total bolt execute latency.**</span></span> <span data-ttu-id="293ba-235">Это hello среднее время, затраченное молнии hello в hello метод execute.</span><span class="sxs-lookup"><span data-stu-id="293ba-235">This is hello average time spent by hello bolt in hello execute method.</span></span>

* <span data-ttu-id="293ba-236">**Количество сбоев.**</span><span class="sxs-lookup"><span data-stu-id="293ba-236">**Number of failures.**</span></span> <span data-ttu-id="293ba-237">Это относится toohello число кортежей, которые не удалось toobe полностью обработать, прежде чем они истекло время ожидания.</span><span class="sxs-lookup"><span data-stu-id="293ba-237">This refers toohello number of tuples that failed toobe fully processed before they timed out.</span></span>

* <span data-ttu-id="293ba-238">**Емкость.**</span><span class="sxs-lookup"><span data-stu-id="293ba-238">**Capacity.**</span></span> <span data-ttu-id="293ba-239">Это мера занятости вашей системы.</span><span class="sxs-lookup"><span data-stu-id="293ba-239">This is a measure of how busy your system is.</span></span> <span data-ttu-id="293ba-240">Если это значение равно 1, элементы bolt работают с максимально возможной скоростью.</span><span class="sxs-lookup"><span data-stu-id="293ba-240">If this number is 1, your bolts are working as fast as they can.</span></span> <span data-ttu-id="293ba-241">Если это значение меньше 1, увеличение параллелизма hello.</span><span class="sxs-lookup"><span data-stu-id="293ba-241">If it is less than 1, increase hello parallelism.</span></span> <span data-ttu-id="293ba-242">Если это значение больше 1, уменьшите параллелизм hello.</span><span class="sxs-lookup"><span data-stu-id="293ba-242">If it is greater than 1, reduce hello parallelism.</span></span>

## <a name="troubleshoot-common-problems"></a><span data-ttu-id="293ba-243">Устранение распространенных неполадок</span><span class="sxs-lookup"><span data-stu-id="293ba-243">Troubleshoot common problems</span></span>
<span data-ttu-id="293ba-244">Здесь описано несколько типичных сценариев устранения неполадок.</span><span class="sxs-lookup"><span data-stu-id="293ba-244">Here are a few common troubleshooting scenarios.</span></span>
* <span data-ttu-id="293ba-245">**Множество кортежей завершается по времени ожидания.** Посмотрите на каждый узел в топологии toodetermine hello, где находится узкое место hello.</span><span class="sxs-lookup"><span data-stu-id="293ba-245">**Many tuples are timing out.** Look at each node in hello topology toodetermine where hello bottleneck is.</span></span> <span data-ttu-id="293ba-246">Hello наиболее распространенной причиной этого является то, винты hello не может tookeep вверх с hello spouts.</span><span class="sxs-lookup"><span data-stu-id="293ba-246">hello most common reason for this is that hello bolts are not able tookeep up with hello spouts.</span></span> <span data-ttu-id="293ba-247">Это порождает tootuples переполнения hello внутренние буферы при обработке toobe ожидания.</span><span class="sxs-lookup"><span data-stu-id="293ba-247">This leads tootuples clogging hello internal buffers while waiting toobe processed.</span></span> <span data-ttu-id="293ba-248">Рекомендуется увеличить значение времени ожидания hello или уменьшение hello max spout ожидания.</span><span class="sxs-lookup"><span data-stu-id="293ba-248">Consider increasing hello timeout value or decreasing hello max spout pending.</span></span>

* <span data-ttu-id="293ba-249">**Высокая общая задержка выполнения процесса, но при этом низкая задержка процесса bolt.**</span><span class="sxs-lookup"><span data-stu-id="293ba-249">**There is a high total process execution latency, but a low bolt process latency.**</span></span> <span data-ttu-id="293ba-250">В этом случае возможна, hello кортежи не подтверждаемого достаточно быстро.</span><span class="sxs-lookup"><span data-stu-id="293ba-250">In this case, it is possible that hello tuples are not being acknowledged fast enough.</span></span> <span data-ttu-id="293ba-251">Убедитесь, что имеется достаточное количество подтверждающих.</span><span class="sxs-lookup"><span data-stu-id="293ba-251">Check that there are a sufficient number of acknowledgers.</span></span> <span data-ttu-id="293ba-252">Другая возможность заключается в том, что они ожидают в очереди hello слишком долго, до начала обработки их болтов hello.</span><span class="sxs-lookup"><span data-stu-id="293ba-252">Another possibility is that they are waiting in hello queue for too long before hello bolts start processing them.</span></span> <span data-ttu-id="293ba-253">Уменьшение hello max spout ожидания.</span><span class="sxs-lookup"><span data-stu-id="293ba-253">Decrease hello max spout pending.</span></span>

* <span data-ttu-id="293ba-254">**Высокая задержка выполнения bolt.**</span><span class="sxs-lookup"><span data-stu-id="293ba-254">**There is a high bolt execute latency.**</span></span> <span data-ttu-id="293ba-255">Это означает, что метод execute() hello вашей молнии занимает слишком много времени.</span><span class="sxs-lookup"><span data-stu-id="293ba-255">This means that hello execute() method of your bolt is taking too long.</span></span> <span data-ttu-id="293ba-256">Оптимизация кода hello, или просмотрите записи размеры и сбрасывает его поведение.</span><span class="sxs-lookup"><span data-stu-id="293ba-256">Optimize hello code, or look at write sizes and flush behavior.</span></span>

### <a name="data-lake-store-throttling"></a><span data-ttu-id="293ba-257">Регулирование в Data Lake Store</span><span class="sxs-lookup"><span data-stu-id="293ba-257">Data Lake Store throttling</span></span>
<span data-ttu-id="293ba-258">Если вы столкнулись hello ограничения пропускной способности, предоставляемые хранилища Озера данных, могут происходить сбои задач.</span><span class="sxs-lookup"><span data-stu-id="293ba-258">If you hit hello limits of bandwidth provided by Data Lake Store, you might see task failures.</span></span> <span data-ttu-id="293ba-259">Проверьте журналы задач на наличие ошибок регулирования.</span><span class="sxs-lookup"><span data-stu-id="293ba-259">Check task logs for throttling errors.</span></span> <span data-ttu-id="293ba-260">Можно уменьшить hello параллелизма, увеличив размер контейнера.</span><span class="sxs-lookup"><span data-stu-id="293ba-260">You can decrease hello parallelism by increasing container size.</span></span>    

<span data-ttu-id="293ba-261">toocheck, если вы начало регулируются, Включение журнала на стороне клиента hello hello отладки:</span><span class="sxs-lookup"><span data-stu-id="293ba-261">toocheck if you are getting throttled, enable hello debug logging on hello client side:</span></span>

1. <span data-ttu-id="293ba-262">В **Ambari** > **Storm** > **Config** > **Advanced storm-worker-log4j**, изменение  **&lt;корневой уровень = «info»&gt;**  слишком**&lt;корневой уровень = «debug»&gt;**.</span><span class="sxs-lookup"><span data-stu-id="293ba-262">In **Ambari** > **Storm** > **Config** > **Advanced storm-worker-log4j**, change **&lt;root level="info"&gt;** too**&lt;root level=”debug”&gt;**.</span></span> <span data-ttu-id="293ba-263">Перезапустите все hello узлы или службы hello конфигурации tootake эффект.</span><span class="sxs-lookup"><span data-stu-id="293ba-263">Restart all hello nodes/service for hello configuration tootake effect.</span></span>
2. <span data-ttu-id="293ba-264">Монитор hello Storm топологии входе рабочих узлов (в разделе /var/log/storm/worker-artifacts /&lt;TopologyName&gt;/&lt;порт&gt;/worker.log) для хранилища Озера данных форме исключений регулирования.</span><span class="sxs-lookup"><span data-stu-id="293ba-264">Monitor hello Storm topology logs on worker nodes (under /var/log/storm/worker-artifacts/&lt;TopologyName&gt;/&lt;port&gt;/worker.log) for Data Lake Store throttling exceptions.</span></span>

## <a name="next-steps"></a><span data-ttu-id="293ba-265">Дальнейшие действия</span><span class="sxs-lookup"><span data-stu-id="293ba-265">Next steps</span></span>
<span data-ttu-id="293ba-266">Сведения о дополнительных настройках производительности Storm см. в этом [блоге](https://blogs.msdn.microsoft.com/shanyu/2015/05/14/performance-tuning-for-hdinsight-storm-and-microsoft-azure-eventhubs/).</span><span class="sxs-lookup"><span data-stu-id="293ba-266">Additional performance tuning for Storm can be referenced in [this blog](https://blogs.msdn.microsoft.com/shanyu/2015/05/14/performance-tuning-for-hdinsight-storm-and-microsoft-azure-eventhubs/).</span></span>

<span data-ttu-id="293ba-267">Toorun дополнительный пример в разделе [такой на GitHub](https://github.com/hdinsight/storm-performance-automation).</span><span class="sxs-lookup"><span data-stu-id="293ba-267">For an additional example toorun, see [this one on GitHub](https://github.com/hdinsight/storm-performance-automation).</span></span>
