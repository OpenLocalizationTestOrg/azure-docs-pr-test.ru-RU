---
title: "Сценарии работы с данными с использованием Data Lake Store | Документация Майкрософт"
description: "Сведения о различных сценариях и средствах для приема, обработки, загрузки и визуализации данных в хранилище озера данных"
services: data-lake-store
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
ms.assetid: 37409a71-a563-4bb7-bc46-2cbd426a2ece
ms.service: data-lake-store
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 05/10/2017
ms.author: nitinme
ms.openlocfilehash: 2a2801e5c506dcc8aa9ca2ecd275b52c72d5fbbf
ms.sourcegitcommit: 18ad9bc049589c8e44ed277f8f43dcaa483f3339
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 08/29/2017
---
# <a name="using-azure-data-lake-store-for-big-data-requirements"></a><span data-ttu-id="f2967-103">Использование хранилища озера данных Azure для потребностей больших данных</span><span class="sxs-lookup"><span data-stu-id="f2967-103">Using Azure Data Lake Store for big data requirements</span></span>
<span data-ttu-id="f2967-104">Процесс обработки больших данных состоит из указанных далее четырех ключевых этапов.</span><span class="sxs-lookup"><span data-stu-id="f2967-104">There are four key stages in big data processing:</span></span>

* <span data-ttu-id="f2967-105">Прием больших объемов данных в хранилище данных в режиме реального времени или в пакетах</span><span class="sxs-lookup"><span data-stu-id="f2967-105">Ingesting large amounts of data into a data store, at real-time or in batches</span></span>
* <span data-ttu-id="f2967-106">Обработка данных</span><span class="sxs-lookup"><span data-stu-id="f2967-106">Processing the data</span></span>
* <span data-ttu-id="f2967-107">Загрузка данных</span><span class="sxs-lookup"><span data-stu-id="f2967-107">Downloading the data</span></span>
* <span data-ttu-id="f2967-108">Визуализация данных</span><span class="sxs-lookup"><span data-stu-id="f2967-108">Visualizing the data</span></span>

<span data-ttu-id="f2967-109">В этой статье мы рассмотрим эти этапы применительно к хранилищу озера данных Azure, чтобы понять параметры и средства, доступные для удовлетворения потребностей в обработке больших объемов данных.</span><span class="sxs-lookup"><span data-stu-id="f2967-109">In this article, we look at these stages with respect to Azure Data Lake Store to understand the options and tools available to meet your big data needs.</span></span>

## <a name="ingest-data-into-data-lake-store"></a><span data-ttu-id="f2967-110">Прием данных в хранилище озера данных</span><span class="sxs-lookup"><span data-stu-id="f2967-110">Ingest data into Data Lake Store</span></span>
<span data-ttu-id="f2967-111">В этом разделе описываются различные источники данных и способы поступления этих данных в учетную запись хранения озера данных.</span><span class="sxs-lookup"><span data-stu-id="f2967-111">This section highlights the different sources of data and the different ways in which that data can be ingested into a Data Lake Store account.</span></span>

<span data-ttu-id="f2967-112">![Прием данных в Data Lake Store](./media/data-lake-store-data-scenarios/ingest-data.png "прием данных в Data Lake Store")</span><span class="sxs-lookup"><span data-stu-id="f2967-112">![Ingest data into Data Lake Store](./media/data-lake-store-data-scenarios/ingest-data.png "Ingest data into Data Lake Store")</span></span>

### <a name="ad-hoc-data"></a><span data-ttu-id="f2967-113">Специальные данные</span><span class="sxs-lookup"><span data-stu-id="f2967-113">Ad hoc data</span></span>
<span data-ttu-id="f2967-114">Это небольшие наборы данных, которые используются для создания прототипов приложений для работы с большими данными.</span><span class="sxs-lookup"><span data-stu-id="f2967-114">This represents smaller data sets that are used for prototyping a big data application.</span></span> <span data-ttu-id="f2967-115">В зависимости от источника данных применяются разные способы приема специальных данных.</span><span class="sxs-lookup"><span data-stu-id="f2967-115">There are different ways of ingesting ad hoc data depending on the source of the data.</span></span>

| <span data-ttu-id="f2967-116">Источник данных</span><span class="sxs-lookup"><span data-stu-id="f2967-116">Data Source</span></span> | <span data-ttu-id="f2967-117">Средство для приема</span><span class="sxs-lookup"><span data-stu-id="f2967-117">Ingest it using</span></span> |
| --- | --- |
| <span data-ttu-id="f2967-118">Локальный компьютер</span><span class="sxs-lookup"><span data-stu-id="f2967-118">Local computer</span></span> |<ul> <li>[<span data-ttu-id="f2967-119">Портал Azure</span><span class="sxs-lookup"><span data-stu-id="f2967-119">Azure Portal</span></span>](/data-lake-store-get-started-portal.md)</li> <li>[<span data-ttu-id="f2967-120">Azure PowerShell</span><span class="sxs-lookup"><span data-stu-id="f2967-120">Azure PowerShell</span></span>](data-lake-store-get-started-powershell.md)</li> <li>[<span data-ttu-id="f2967-121">Кроссплатформенный интерфейс командной строки Azure 2.0</span><span class="sxs-lookup"><span data-stu-id="f2967-121">Azure Cross-platform CLI 2.0</span></span>](data-lake-store-get-started-cli-2.0.md)</li> <li>[<span data-ttu-id="f2967-122">Data Lake Tools для Visual Studio</span><span class="sxs-lookup"><span data-stu-id="f2967-122">Using Data Lake Tools for Visual Studio</span></span>](../data-lake-analytics/data-lake-analytics-data-lake-tools-get-started.md) </li></ul> |
| <span data-ttu-id="f2967-123">Большой двоичный объект хранилища Azure</span><span class="sxs-lookup"><span data-stu-id="f2967-123">Azure Storage Blob</span></span> |<ul> <li>[<span data-ttu-id="f2967-124">Фабрика данных Azure</span><span class="sxs-lookup"><span data-stu-id="f2967-124">Azure Data Factory</span></span>](../data-factory/data-factory-azure-datalake-connector.md)</li> <li>[<span data-ttu-id="f2967-125">инструмента AdlCopy</span><span class="sxs-lookup"><span data-stu-id="f2967-125">AdlCopy tool</span></span>](data-lake-store-copy-data-azure-storage-blob.md)</li><li>[<span data-ttu-id="f2967-126">DistCp, запущенный на кластере HDInsight</span><span class="sxs-lookup"><span data-stu-id="f2967-126">DistCp running on HDInsight cluster</span></span>](data-lake-store-copy-data-wasb-distcp.md)</li> </ul> |

### <a name="streamed-data"></a><span data-ttu-id="f2967-127">Потоковые данные</span><span class="sxs-lookup"><span data-stu-id="f2967-127">Streamed data</span></span>
<span data-ttu-id="f2967-128">Это данные, создаваемые различными источниками, такими как приложения, устройства, датчики и т. д. Для ввода этих данных в хранилище озера данных можно использовать множество средств.</span><span class="sxs-lookup"><span data-stu-id="f2967-128">This represents data that can be generated by various sources such as applications, devices, sensors, etc. This data can be ingested into a Data Lake Store by variety tools.</span></span> <span data-ttu-id="f2967-129">Как правило, эти средства собирают и обрабатывают данные на основе событий в режиме реального времени и затем записывают события в пакетном режиме в хранилище озера данных для последующей обработки.</span><span class="sxs-lookup"><span data-stu-id="f2967-129">These tools will usually capture and process the data on an event-by-event basis in real-time, and then write the events in batches into Data Lake Store so that they can be further processed.</span></span>

<span data-ttu-id="f2967-130">Ниже перечислены средства, которые можно использовать:</span><span class="sxs-lookup"><span data-stu-id="f2967-130">Following are tools that you can use:</span></span>

* <span data-ttu-id="f2967-131">[Azure Stream Analytics.](../stream-analytics/stream-analytics-data-lake-output.md) События, принятые в концентраторы событий, могут записываться в Azure Data Lake с помощью выходных данных Azure Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="f2967-131">[Azure Stream Analytics](../stream-analytics/stream-analytics-data-lake-output.md) - Events ingested into Event Hubs can be written to Azure Data Lake using an Azure Data Lake Store output.</span></span>
* <span data-ttu-id="f2967-132">[Azure HDInsight Storm.](../hdinsight/hdinsight-storm-write-data-lake-store.md) Данные из кластера Storm можно напрямую записывать в Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="f2967-132">[Azure HDInsight Storm](../hdinsight/hdinsight-storm-write-data-lake-store.md) - You can write data directly to Data Lake Store from the Storm cluster.</span></span>
* <span data-ttu-id="f2967-133">[EventProcessorHost.](../event-hubs/event-hubs-dotnet-standard-getstarted-receive-eph.md) Можно получать события из концентраторов событий, а затем записывать их в Data Lake Store с помощью [пакета SDK для .NET Data Lake Store](data-lake-store-get-started-net-sdk.md).</span><span class="sxs-lookup"><span data-stu-id="f2967-133">[EventProcessorHost](../event-hubs/event-hubs-dotnet-standard-getstarted-receive-eph.md) – You can receive events from Event Hubs and then write it to Data Lake Store using the [Data Lake Store .NET SDK](data-lake-store-get-started-net-sdk.md).</span></span>

### <a name="relational-data"></a><span data-ttu-id="f2967-134">Реляционные данные</span><span class="sxs-lookup"><span data-stu-id="f2967-134">Relational data</span></span>
<span data-ttu-id="f2967-135">Можно также извлекать данные из реляционных баз данных.</span><span class="sxs-lookup"><span data-stu-id="f2967-135">You can also source data from relational databases.</span></span> <span data-ttu-id="f2967-136">В течение определенного периода времени реляционные базы данных собирают огромные объемы данных, которые после обработки с помощью конвейера больших данных могут предоставлять ценные сведения.</span><span class="sxs-lookup"><span data-stu-id="f2967-136">Over a period of time, relational databases collect huge amounts of data which can provide key insights if processed through a big data pipeline.</span></span> <span data-ttu-id="f2967-137">Для перемещения таких данных в хранилище озера данных можно использовать следующие средства.</span><span class="sxs-lookup"><span data-stu-id="f2967-137">You can use the following tools to move such data into Data Lake Store.</span></span>

* [<span data-ttu-id="f2967-138">Apache Sqoop</span><span class="sxs-lookup"><span data-stu-id="f2967-138">Apache Sqoop</span></span>](data-lake-store-data-transfer-sql-sqoop.md)
* [<span data-ttu-id="f2967-139">Фабрика данных Azure</span><span class="sxs-lookup"><span data-stu-id="f2967-139">Azure Data Factory</span></span>](../data-factory/data-factory-data-movement-activities.md)

### <a name="web-server-log-data-upload-using-custom-applications"></a><span data-ttu-id="f2967-140">Данные журналов веб-сервера (отправка с помощью настраиваемых приложений)</span><span class="sxs-lookup"><span data-stu-id="f2967-140">Web server log data (upload using custom applications)</span></span>
<span data-ttu-id="f2967-141">Этот тип набора данных вызывается специально, так как анализ данных журналов веб-сервера часто используется в приложениях по работе с большими данными, и для его выполнения требуется отправка больших объемов файлов журналов в хранилище озера данных.</span><span class="sxs-lookup"><span data-stu-id="f2967-141">This type of dataset is specifically called out because analysis of web server log data is a common use case for big data applications and requires large volumes of log files to be uploaded to the Data Lake Store.</span></span> <span data-ttu-id="f2967-142">Для отправки таких данных воспользуйтесь следующими средствами или напишите собственные сценарии или приложения.</span><span class="sxs-lookup"><span data-stu-id="f2967-142">You can use any of the following tools to write your own scripts or applications to upload such data.</span></span>

* [<span data-ttu-id="f2967-143">Кроссплатформенный интерфейс командной строки Azure 2.0</span><span class="sxs-lookup"><span data-stu-id="f2967-143">Azure Cross-platform CLI 2.0</span></span>](data-lake-store-get-started-cli-2.0.md)
* [<span data-ttu-id="f2967-144">Azure PowerShell</span><span class="sxs-lookup"><span data-stu-id="f2967-144">Azure PowerShell</span></span>](data-lake-store-get-started-powershell.md)
* [<span data-ttu-id="f2967-145">Пакет SDK для .NET хранилища озера данных Azure</span><span class="sxs-lookup"><span data-stu-id="f2967-145">Azure Data Lake Store .NET SDK</span></span>](data-lake-store-get-started-net-sdk.md)
* [<span data-ttu-id="f2967-146">Фабрика данных Azure</span><span class="sxs-lookup"><span data-stu-id="f2967-146">Azure Data Factory</span></span>](../data-factory/data-factory-data-movement-activities.md)

<span data-ttu-id="f2967-147">Отличным способом отправки данных журналов веб-сервера и других типов данных (например данных общественных мнений) является использование собственных написанных сценариев или приложений, поскольку вы можете включить компонент отправки данных в состав более масштабного приложения по работе с большими объемами данных.</span><span class="sxs-lookup"><span data-stu-id="f2967-147">For uploading web server log data, and also for uploading other kinds of data (e.g. social sentiments data), it is a good approach to write your own custom scripts/applications because it gives you the flexibility to include your data uploading component as part of your larger big data application.</span></span> <span data-ttu-id="f2967-148">В одних случаях этот код может иметь форму сценария или простой программы командной строки.</span><span class="sxs-lookup"><span data-stu-id="f2967-148">In some cases this code may take the form of a script or simple command line utility.</span></span> <span data-ttu-id="f2967-149">В других случаях код может использоваться для интеграции обработки больших данных в бизнес-приложение или решение.</span><span class="sxs-lookup"><span data-stu-id="f2967-149">In other cases, the code may be used to integrate big data processing into a business application or solution.</span></span>

### <a name="data-associated-with-azure-hdinsight-clusters"></a><span data-ttu-id="f2967-150">Данные, связанные с кластерами HDInsight Azure</span><span class="sxs-lookup"><span data-stu-id="f2967-150">Data associated with Azure HDInsight clusters</span></span>
<span data-ttu-id="f2967-151">Большинство типов кластера HDInsight (Hadoop, HBase, Storm) поддерживают хранилище озера данных в качестве репозитория хранения данных.</span><span class="sxs-lookup"><span data-stu-id="f2967-151">Most HDInsight cluster types (Hadoop, HBase, Storm) support Data Lake Store as a data storage repository.</span></span> <span data-ttu-id="f2967-152">Кластеры HDInsight обращаются к данным из BLOB-объектов хранилища Azure (WASB).</span><span class="sxs-lookup"><span data-stu-id="f2967-152">HDInsight clusters access data from Azure Storage Blobs (WASB).</span></span> <span data-ttu-id="f2967-153">Для повышения производительности можно скопировать данные из WASB в учетную запись хранения озера данных, связанную с кластером.</span><span class="sxs-lookup"><span data-stu-id="f2967-153">For better performance, you can copy the data from WASB into a Data Lake Store account associated with the cluster.</span></span> <span data-ttu-id="f2967-154">Для копирования данных можно использовать указанные далее средства.</span><span class="sxs-lookup"><span data-stu-id="f2967-154">You can use the following tools to copy the data.</span></span>

* [<span data-ttu-id="f2967-155">Apache DistCp</span><span class="sxs-lookup"><span data-stu-id="f2967-155">Apache DistCp</span></span>](data-lake-store-copy-data-wasb-distcp.md)
* [<span data-ttu-id="f2967-156">Служба AdlCopy</span><span class="sxs-lookup"><span data-stu-id="f2967-156">AdlCopy Service</span></span>](data-lake-store-copy-data-azure-storage-blob.md)
* [<span data-ttu-id="f2967-157">Фабрика данных Azure</span><span class="sxs-lookup"><span data-stu-id="f2967-157">Azure Data Factory</span></span>](../data-factory/data-factory-azure-datalake-connector.md)

### <a name="data-stored-in-on-premises-or-iaas-hadoop-clusters"></a><span data-ttu-id="f2967-158">Данные, хранящиеся в локальных кластерах Hadoop или кластерах Hadoop в IaaS</span><span class="sxs-lookup"><span data-stu-id="f2967-158">Data stored in on-premises or IaaS Hadoop clusters</span></span>
<span data-ttu-id="f2967-159">Большие объемы данных могут храниться в кластерах Hadoop, размещенных локально на компьютерах, использующих HDFS.</span><span class="sxs-lookup"><span data-stu-id="f2967-159">Large amounts of data may be stored in existing Hadoop clusters, locally on machines using HDFS.</span></span> <span data-ttu-id="f2967-160">Кластеры Hadoop могут быть развернуты локально или работать в кластере IaaS в Azure.</span><span class="sxs-lookup"><span data-stu-id="f2967-160">The Hadoop clusters may be in an on-premises deployment or may be within an IaaS cluster on Azure.</span></span> <span data-ttu-id="f2967-161">К копированию таких данных в хранилище озера данных Azure могут предъявляться требования, в зависимости от того, является ли эта операция одноразовой или повторяющейся.</span><span class="sxs-lookup"><span data-stu-id="f2967-161">There could be requirements to copy such data to Azure Data Lake Store for a one-off approach or in a recurring fashion.</span></span> <span data-ttu-id="f2967-162">Существуют различные возможности выполнить их.</span><span class="sxs-lookup"><span data-stu-id="f2967-162">There are various options that you can use to achieve this.</span></span> <span data-ttu-id="f2967-163">Ниже приведен список альтернативных вариантов и связанные с ними компромиссы.</span><span class="sxs-lookup"><span data-stu-id="f2967-163">Below is a list of alternatives and the associated trade-offs.</span></span>

| <span data-ttu-id="f2967-164">Подход</span><span class="sxs-lookup"><span data-stu-id="f2967-164">Approach</span></span> | <span data-ttu-id="f2967-165">Сведения</span><span class="sxs-lookup"><span data-stu-id="f2967-165">Details</span></span> | <span data-ttu-id="f2967-166">Преимущества</span><span class="sxs-lookup"><span data-stu-id="f2967-166">Advantages</span></span> | <span data-ttu-id="f2967-167">Рекомендации</span><span class="sxs-lookup"><span data-stu-id="f2967-167">Considerations</span></span> |
| --- | --- | --- | --- |
| <span data-ttu-id="f2967-168">Использование фабрики данных Azure (ADF) для копирования данных напрямую из кластеров Hadoop в хранилище озера данных Azure.</span><span class="sxs-lookup"><span data-stu-id="f2967-168">Use Azure Data Factory (ADF) to copy data directly from Hadoop clusters to Azure Data Lake Store</span></span> |[<span data-ttu-id="f2967-169">ADF поддерживает HDFS в качестве источника данных.</span><span class="sxs-lookup"><span data-stu-id="f2967-169">ADF supports HDFS as a data source</span></span>](../data-factory/data-factory-hdfs-connector.md) |<span data-ttu-id="f2967-170">ADF реализована готовая поддержка HDFS, а также первоклассные инструменты комплексного управления и мониторинга.</span><span class="sxs-lookup"><span data-stu-id="f2967-170">ADF provides out-of-the-box support for HDFS and first class end-to-end management and monitoring</span></span> |<span data-ttu-id="f2967-171">Требуется развернуть шлюз управления данными в локальном кластере или кластере IaaS.</span><span class="sxs-lookup"><span data-stu-id="f2967-171">Requires Data Management Gateway to be deployed on-premises or in the IaaS cluster</span></span> |
| <span data-ttu-id="f2967-172">Экспорт данных из Hadoop в виде файлов.</span><span class="sxs-lookup"><span data-stu-id="f2967-172">Export data from Hadoop as files.</span></span> <span data-ttu-id="f2967-173">Затем — копирование этих файлов в хранилище озера данных Azure с помощью соответствующего механизма.</span><span class="sxs-lookup"><span data-stu-id="f2967-173">Then copy the files to Azure Data Lake Store using appropriate mechanism.</span></span> |<span data-ttu-id="f2967-174">Скопировать файлы в Azure Data Lake Store можно с помощью: </span><span class="sxs-lookup"><span data-stu-id="f2967-174">You can copy files to Azure Data Lake Store using:</span></span> <ul><li>[<span data-ttu-id="f2967-175">Azure PowerShell только для Windows</span><span class="sxs-lookup"><span data-stu-id="f2967-175">Azure PowerShell for Windows OS</span></span>](data-lake-store-get-started-powershell.md)</li><li>[<span data-ttu-id="f2967-176">Кроссплатформенный интерфейс командной строки Azure 2.0 для ОС, отличных от Windows</span><span class="sxs-lookup"><span data-stu-id="f2967-176">Azure Cross-platform CLI 2.0 for non-Windows OS</span></span>](data-lake-store-get-started-cli-2.0.md)</li><li><span data-ttu-id="f2967-177">Пользовательское приложение, использующее любой пакет SDK Data Lake Store</span><span class="sxs-lookup"><span data-stu-id="f2967-177">Custom app using any Data Lake Store SDK</span></span></li></ul> |<span data-ttu-id="f2967-178">Можно быстро приступить к работе.</span><span class="sxs-lookup"><span data-stu-id="f2967-178">Quick to get started.</span></span> <span data-ttu-id="f2967-179">Возможны настраиваемые передачи данных.</span><span class="sxs-lookup"><span data-stu-id="f2967-179">Can do customized uploads</span></span> |<span data-ttu-id="f2967-180">Многоэтапный процесс с использованием нескольких технологий.</span><span class="sxs-lookup"><span data-stu-id="f2967-180">Multi-step process that involves multiple technologies.</span></span> <span data-ttu-id="f2967-181">Учитывая настраиваемый характер инструментов, со временем будет все сложнее осуществлять управление и мониторинг.</span><span class="sxs-lookup"><span data-stu-id="f2967-181">Management and monitoring will grow to be a challenge over time given the customized nature of the tools</span></span> |
| <span data-ttu-id="f2967-182">Использование Distcp для копирования данных из Hadoop в службу хранилища Azure.</span><span class="sxs-lookup"><span data-stu-id="f2967-182">Use Distcp to copy data from Hadoop to Azure Storage.</span></span> <span data-ttu-id="f2967-183">Затем — копирование данных из службы хранилища Azure в хранилище озера данных с помощью соответствующего механизма.</span><span class="sxs-lookup"><span data-stu-id="f2967-183">Then copy data from Azure Storage to Data Lake Store using appropriate mechanism.</span></span> |<span data-ttu-id="f2967-184">Скопировать данные из службы хранилища Azure в Data Lake Store можно с помощью: </span><span class="sxs-lookup"><span data-stu-id="f2967-184">You can copy data from Azure Storage to Data Lake Store using:</span></span> <ul><li>[<span data-ttu-id="f2967-185">Фабрика данных Azure</span><span class="sxs-lookup"><span data-stu-id="f2967-185">Azure Data Factory</span></span>](../data-factory/data-factory-data-movement-activities.md)</li><li>[<span data-ttu-id="f2967-186">инструмента AdlCopy</span><span class="sxs-lookup"><span data-stu-id="f2967-186">AdlCopy tool</span></span>](data-lake-store-copy-data-azure-storage-blob.md)</li><li>[<span data-ttu-id="f2967-187">Apache DistCp, запущенный в кластерах HDInsight</span><span class="sxs-lookup"><span data-stu-id="f2967-187">Apache DistCp running on HDInsight clusters</span></span>](data-lake-store-copy-data-wasb-distcp.md)</li></ul> |<span data-ttu-id="f2967-188">Можно использовать инструменты с открытым кодом.</span><span class="sxs-lookup"><span data-stu-id="f2967-188">You can use open-source tools.</span></span> |<span data-ttu-id="f2967-189">Многоэтапный процесс с использованием нескольких технологий.</span><span class="sxs-lookup"><span data-stu-id="f2967-189">Multi-step process that involves multiple technologies</span></span> |

### <a name="really-large-datasets"></a><span data-ttu-id="f2967-190">Очень большие наборы данных</span><span class="sxs-lookup"><span data-stu-id="f2967-190">Really large datasets</span></span>
<span data-ttu-id="f2967-191">Для отправки наборов данных размером в несколько терабайт использование описанных выше методов иногда может быть медленным и затратным процессом.</span><span class="sxs-lookup"><span data-stu-id="f2967-191">For uploading datasets that range in several terabytes, using the methods described above can sometimes be slow and costly.</span></span> <span data-ttu-id="f2967-192">В таких ситуациях будут уместны следующие варианты.</span><span class="sxs-lookup"><span data-stu-id="f2967-192">In such cases, you can use the options below.</span></span>

* <span data-ttu-id="f2967-193">**Использование Azure ExpressRoute.**</span><span class="sxs-lookup"><span data-stu-id="f2967-193">**Using Azure ExpressRoute**.</span></span> <span data-ttu-id="f2967-194">Azure ExpressRoute позволяет создавать закрытые соединения между ЦОД Azure и вашей локальной инфраструктурой.</span><span class="sxs-lookup"><span data-stu-id="f2967-194">Azure ExpressRoute lets you create private connections between Azure datacenters and infrastructure on your premises.</span></span> <span data-ttu-id="f2967-195">Это надежный вариант для передачи больших объемов данных.</span><span class="sxs-lookup"><span data-stu-id="f2967-195">This provides a reliable option for transferring large amounts of data.</span></span> <span data-ttu-id="f2967-196">Дополнительные сведения см. в [техническом обзоре ExpressRoute](../expressroute/expressroute-introduction.md).</span><span class="sxs-lookup"><span data-stu-id="f2967-196">For more information, see [Azure ExpressRoute documentation](../expressroute/expressroute-introduction.md).</span></span>
* <span data-ttu-id="f2967-197">**Автономная передача данных**.</span><span class="sxs-lookup"><span data-stu-id="f2967-197">**"Offline" upload of data**.</span></span> <span data-ttu-id="f2967-198">Если по какой-то причине использовать Azure ExpressRoute нельзя, используйте [службу импорта и экспорта Azure](../storage/common/storage-import-export-service.md) для доставки жестких дисков с данными в центр обработки данных Azure.</span><span class="sxs-lookup"><span data-stu-id="f2967-198">If using Azure ExpressRoute is not feasible for any reason, you can use [Azure Import/Export service](../storage/common/storage-import-export-service.md) to ship hard disk drives with your data to an Azure data center.</span></span> <span data-ttu-id="f2967-199">Данные сначала будут отправлены в хранилище BLOB-объектов Azure.</span><span class="sxs-lookup"><span data-stu-id="f2967-199">Your data is first uploaded to Azure Storage Blobs.</span></span> <span data-ttu-id="f2967-200">Затем с помощью [фабрики данных Azure](../data-factory/data-factory-azure-datalake-connector.md) или [инструмента AdlCopy](data-lake-store-copy-data-azure-storage-blob.md) можно скопировать данные из больших двоичных объектов хранилища Azure в Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="f2967-200">You can then use [Azure Data Factory](../data-factory/data-factory-azure-datalake-connector.md) or [AdlCopy tool](data-lake-store-copy-data-azure-storage-blob.md) to copy data from Azure Storage Blobs to Data Lake Store.</span></span>

  > [!NOTE]
  > <span data-ttu-id="f2967-201">При использовании службы импорта и экспорта размеры файлов на дисках, отправляемых в центр обработки данных Azure, не должны превышать 195 ГБ.</span><span class="sxs-lookup"><span data-stu-id="f2967-201">While using the Import/Export service, the file sizes on the disks that you ship to Azure data center should not be greater than 195 GB.</span></span>
  >
  >

## <a name="process-data-stored-in-data-lake-store"></a><span data-ttu-id="f2967-202">Обработка данных, хранящихся в хранилище озера данных </span><span class="sxs-lookup"><span data-stu-id="f2967-202">Process data stored in Data Lake Store</span></span>
<span data-ttu-id="f2967-203">Данные, доступные в хранилище озера данных, можно проанализировать с помощью поддерживаемых приложений для работы с большими данными.</span><span class="sxs-lookup"><span data-stu-id="f2967-203">Once the data is available in Data Lake Store you can run analysis on that data using the supported big data applications.</span></span> <span data-ttu-id="f2967-204">В настоящее время для запуска заданий анализа для данных, хранящихся в хранилище озера данных, можно использовать Azure HDInsight и аналитику озера данных Azure.</span><span class="sxs-lookup"><span data-stu-id="f2967-204">Currently, you can use Azure HDInsight and Azure Data Lake Analytics to run data analysis jobs on the data stored in Data Lake Store.</span></span>

<span data-ttu-id="f2967-205">![Анализ данных в Data Lake Store](./media/data-lake-store-data-scenarios/analyze-data.png "Анализ данных в Data Lake Store")</span><span class="sxs-lookup"><span data-stu-id="f2967-205">![Analyze data in Data Lake Store](./media/data-lake-store-data-scenarios/analyze-data.png "Analyze data in Data Lake Store")</span></span>

<span data-ttu-id="f2967-206">Рассмотрите следующие примеры.</span><span class="sxs-lookup"><span data-stu-id="f2967-206">You can look at the following examples.</span></span>

* [<span data-ttu-id="f2967-207">Создание кластера HDInsight с хранилищем озера данных в качестве хранилища</span><span class="sxs-lookup"><span data-stu-id="f2967-207">Create an HDInsight cluster with Data Lake Store as storage</span></span>](data-lake-store-hdinsight-hadoop-use-portal.md)
* [<span data-ttu-id="f2967-208">Использование аналитики озера данных Azure с хранилищем озера данных</span><span class="sxs-lookup"><span data-stu-id="f2967-208">Use Azure Data Lake Analytics with Data Lake Store</span></span>](../data-lake-analytics/data-lake-analytics-get-started-portal.md)

## <a name="download-data-from-data-lake-store"></a><span data-ttu-id="f2967-209">Загрузка данных из хранилища озера данных</span><span class="sxs-lookup"><span data-stu-id="f2967-209">Download data from Data Lake Store</span></span>
<span data-ttu-id="f2967-210">Возможно, вам потребуется загрузить или переместить данные из хранилища озера данных Azure в случаях, аналогичных указанным далее.</span><span class="sxs-lookup"><span data-stu-id="f2967-210">You might also want to download or move data from Azure Data Lake Store for scenarios such as:</span></span>

* <span data-ttu-id="f2967-211">Перемещение данных в другие репозитории для взаимодействия с существующими конвейерами обработки данных.</span><span class="sxs-lookup"><span data-stu-id="f2967-211">Move data to other repositories to interface with your existing data processing pipelines.</span></span> <span data-ttu-id="f2967-212">Например, можно переместить данные из хранилища озера данных в базу данных SQL Azure или на локальный сервер SQL Server.</span><span class="sxs-lookup"><span data-stu-id="f2967-212">For example, you might want to move data from Data Lake Store to Azure SQL Database or on-premises SQL Server.</span></span>
* <span data-ttu-id="f2967-213">Загрузка данных на локальный компьютер для обработки в средах IDE при создании прототипов приложений.</span><span class="sxs-lookup"><span data-stu-id="f2967-213">Download data to your local computer for processing in IDE environments while building application prototypes.</span></span>

<span data-ttu-id="f2967-214">![Вывод данных из Data Lake Store](./media/data-lake-store-data-scenarios/egress-data.png "вывод данных из Data Lake Store")</span><span class="sxs-lookup"><span data-stu-id="f2967-214">![Egress data from Data Lake Store](./media/data-lake-store-data-scenarios/egress-data.png "Egress data from Data Lake Store")</span></span>

<span data-ttu-id="f2967-215">В таких ситуациях можно использовать любой из следующих вариантов:</span><span class="sxs-lookup"><span data-stu-id="f2967-215">In such cases, you can use any of the following options:</span></span>

* [<span data-ttu-id="f2967-216">Apache Sqoop</span><span class="sxs-lookup"><span data-stu-id="f2967-216">Apache Sqoop</span></span>](data-lake-store-data-transfer-sql-sqoop.md)
* [<span data-ttu-id="f2967-217">Фабрика данных Azure</span><span class="sxs-lookup"><span data-stu-id="f2967-217">Azure Data Factory</span></span>](../data-factory/data-factory-data-movement-activities.md)
* [<span data-ttu-id="f2967-218">Apache DistCp</span><span class="sxs-lookup"><span data-stu-id="f2967-218">Apache DistCp</span></span>](data-lake-store-copy-data-wasb-distcp.md)

<span data-ttu-id="f2967-219">Для написания сценария или приложения для загрузки данных из хранилища озера данных можно воспользоваться следующими средствами.</span><span class="sxs-lookup"><span data-stu-id="f2967-219">You can also use the following methods to write your own script/application to download data from Data Lake Store.</span></span>

* [<span data-ttu-id="f2967-220">Кроссплатформенный интерфейс командной строки Azure 2.0</span><span class="sxs-lookup"><span data-stu-id="f2967-220">Azure Cross-platform CLI 2.0</span></span>](data-lake-store-get-started-cli-2.0.md)
* [<span data-ttu-id="f2967-221">Azure PowerShell</span><span class="sxs-lookup"><span data-stu-id="f2967-221">Azure PowerShell</span></span>](data-lake-store-get-started-powershell.md)
* [<span data-ttu-id="f2967-222">Пакет SDK для .NET хранилища озера данных Azure</span><span class="sxs-lookup"><span data-stu-id="f2967-222">Azure Data Lake Store .NET SDK</span></span>](data-lake-store-get-started-net-sdk.md)

## <a name="visualize-data-in-data-lake-store"></a><span data-ttu-id="f2967-223">Визуализация данных в хранилище озера данных</span><span class="sxs-lookup"><span data-stu-id="f2967-223">Visualize data in Data Lake Store</span></span>
<span data-ttu-id="f2967-224">Для создания визуальных представлений данных, хранящихся в хранилище озера данных, можно использовать сочетание служб.</span><span class="sxs-lookup"><span data-stu-id="f2967-224">You can use a mix of services to create visual representations of data stored in Data Lake Store.</span></span>

<span data-ttu-id="f2967-225">![Визуализация данных в Data Lake Store](./media/data-lake-store-data-scenarios/visualize-data.png "визуализация данных в Data Lake Store")</span><span class="sxs-lookup"><span data-stu-id="f2967-225">![Visualize data in Data Lake Store](./media/data-lake-store-data-scenarios/visualize-data.png "Visualize data in Data Lake Store")</span></span>

* <span data-ttu-id="f2967-226">Сначала с помощью [фабрики данных Azure переместите данные из Data Lake Store в хранилище данных SQL Azure](../data-factory/data-factory-data-movement-activities.md#supported-data-stores-and-formats).</span><span class="sxs-lookup"><span data-stu-id="f2967-226">You can start by using [Azure Data Factory to move data from Data Lake Store to Azure SQL Data Warehouse](../data-factory/data-factory-data-movement-activities.md#supported-data-stores-and-formats)</span></span>
* <span data-ttu-id="f2967-227">После этого вы можете [интегрировать Power BI с хранилищем данных SQL Azure](../sql-data-warehouse/sql-data-warehouse-integrate-power-bi.md) для создания визуального представления данных.</span><span class="sxs-lookup"><span data-stu-id="f2967-227">After that, you can [integrate Power BI with Azure SQL Data Warehouse](../sql-data-warehouse/sql-data-warehouse-integrate-power-bi.md) to create visual representation of the data.</span></span>
