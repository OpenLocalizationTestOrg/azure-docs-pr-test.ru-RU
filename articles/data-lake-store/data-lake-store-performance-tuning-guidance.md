---
title: "Рекомендации по настройке производительности Azure Data Lake Store | Документация Майкрософт"
description: "Рекомендации по настройке производительности Azure Data Lake Store"
services: data-lake-store
documentationcenter: 
author: stewu
manager: amitkul
editor: cgronlun
ms.assetid: ebde7b9f-2e51-4d43-b7ab-566417221335
ms.service: data-lake-store
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 06/30/2017
ms.author: stewu
ms.openlocfilehash: e7ea83465328bd4c7479dec4093cd94700463854
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 07/11/2017
---
# <a name="tuning-azure-data-lake-store-for-performance"></a><span data-ttu-id="685a2-103">Настройка Azure Data Lake Store для повышения производительности</span><span class="sxs-lookup"><span data-stu-id="685a2-103">Tuning Azure Data Lake Store for performance</span></span>

<span data-ttu-id="685a2-104">Data Lake Store поддерживает высокую пропускную способность при анализе с интенсивным использованием ввода-вывода и перемещением данных.</span><span class="sxs-lookup"><span data-stu-id="685a2-104">Data Lake Store supports high-throughput for I/O intensive analytics and data movement.</span></span>  <span data-ttu-id="685a2-105">В Azure Data Lake Store важно использовать всю доступную пропускную способность (объем данных, которые можно читать или записывать в секунду), чтобы обеспечить высокую производительность.</span><span class="sxs-lookup"><span data-stu-id="685a2-105">In Azure Data Lake Store, using all available throughput – the amount of data that can be read or written per second – is important to get the best performance.</span></span>  <span data-ttu-id="685a2-106">Для этого нужно выполнить как можно больше операций чтения и записи параллельно.</span><span class="sxs-lookup"><span data-stu-id="685a2-106">This is achieved by performing as many reads and writes in parallel as possible.</span></span>

![Производительность Data Lake Store](./media/data-lake-store-performance-tuning-guidance/throughput.png)

<span data-ttu-id="685a2-108">Azure Data Lake Store можно масштабировать, чтобы предоставить необходимую пропускную способность для всех сценариев аналитики.</span><span class="sxs-lookup"><span data-stu-id="685a2-108">Azure Data Lake Store can scale to provide the necessary throughput for all analytics scenario.</span></span> <span data-ttu-id="685a2-109">По умолчанию учетная запись Azure Data Lake Store автоматически предоставляет достаточную пропускную способность для выполнения различных сценариев использования.</span><span class="sxs-lookup"><span data-stu-id="685a2-109">By default, an Azure Data Lake Store account provides automatically enough throughput to meet the needs of a broad category of use cases.</span></span> <span data-ttu-id="685a2-110">В случаях, когда клиенты достигают лимита по умолчанию, учетную запись ADLS можно настроить для предоставления большей пропускной способности, связавшись с поддержкой Майкрософт.</span><span class="sxs-lookup"><span data-stu-id="685a2-110">For the cases where customers run into the default limit, the ADLS account can be configured to provide more throughput by contacting Microsoft support.</span></span>

## <a name="data-ingestion"></a><span data-ttu-id="685a2-111">Прием данных</span><span class="sxs-lookup"><span data-stu-id="685a2-111">Data ingestion</span></span>

<span data-ttu-id="685a2-112">При передаче данных из исходной системы в ADLS необходимо учесть, что исходное оборудование, сетевое оборудование и сетевое подключение к ADLS могут быть узким местом.</span><span class="sxs-lookup"><span data-stu-id="685a2-112">When ingesting data from a source system to ADLS, it is important to consider that the source hardware, source network hardware, and network connectivity to ADLS can be the bottleneck.</span></span>  

![Производительность Data Lake Store](./media/data-lake-store-performance-tuning-guidance/bottleneck.png)

<span data-ttu-id="685a2-114">Очень важно убедиться, что перемещение данных не зависит от следующих факторов.</span><span class="sxs-lookup"><span data-stu-id="685a2-114">It is important to ensure that the data movement is not affected by these factors.</span></span>

### <a name="source-hardware"></a><span data-ttu-id="685a2-115">Исходное оборудование</span><span class="sxs-lookup"><span data-stu-id="685a2-115">Source Hardware</span></span>

<span data-ttu-id="685a2-116">При использовании локальных компьютеров или виртуальных машин в Azure следует тщательно выбирать соответствующее оборудование.</span><span class="sxs-lookup"><span data-stu-id="685a2-116">Whether you are using on-premises machines or VMs in Azure, you should carefully select the appropriate hardware.</span></span> <span data-ttu-id="685a2-117">В качестве исходного дискового оборудования следует использовать SSD, а не жесткие диски, поэтому выбирайте дисковое оборудование с быстро работающими шпинделями.</span><span class="sxs-lookup"><span data-stu-id="685a2-117">For Source Disk Hardware, prefer SSDs to HDDs and pick disk hardware with faster spindles.</span></span> <span data-ttu-id="685a2-118">В качестве исходного сетевого оборудования используйте самые быстрые сетевые адаптеры.</span><span class="sxs-lookup"><span data-stu-id="685a2-118">For Source Network Hardware, use the fastest NICs possible.</span></span>  <span data-ttu-id="685a2-119">В Azure мы советуем виртуальные машины Azure D14 с соответствующим мощным диском и сетевым оборудованием.</span><span class="sxs-lookup"><span data-stu-id="685a2-119">On Azure, we recommend Azure D14 VMs which have the appropriately powerful disk and networking hardware.</span></span>

### <a name="network-connectivity-to-azure-data-lake-store"></a><span data-ttu-id="685a2-120">Сетевое подключение к Azure Data Lake Store</span><span class="sxs-lookup"><span data-stu-id="685a2-120">Network Connectivity to Azure Data Lake Store</span></span>

<span data-ttu-id="685a2-121">Сетевое подключение между исходными данными и Azure Data Lake Store иногда может быть узким местом.</span><span class="sxs-lookup"><span data-stu-id="685a2-121">The network connectivity between your source data and Azure Data Lake store can sometimes be the bottleneck.</span></span> <span data-ttu-id="685a2-122">Если исходные данные находятся в локальной среде, рекомендуется использовать выделенный канал с [Azure ExpressRoute](https://azure.microsoft.com/en-us/services/expressroute/).</span><span class="sxs-lookup"><span data-stu-id="685a2-122">When your source data is On-Premises, consider using a dedicated link with [Azure ExpressRoute](https://azure.microsoft.com/en-us/services/expressroute/) .</span></span> <span data-ttu-id="685a2-123">Если исходные данные находятся в Azure, вы сможете обеспечить лучшую производительность, если разместить данные в том же регионе Azure, что и Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="685a2-123">If your source data is in Azure, the performance will be best when the data is in the same Azure region as the Data Lake Store.</span></span>

### <a name="configure-data-ingestion-tools-for-maximum-parallelization"></a><span data-ttu-id="685a2-124">Настройка средств приема данных для обеспечения максимальной параллелизации</span><span class="sxs-lookup"><span data-stu-id="685a2-124">Configure Data Ingestion tools for maximum parallelization</span></span>

<span data-ttu-id="685a2-125">Решив проблему с узкими местами исходного оборудования и сетевого подключения, можно приступить к настройке средств приема.</span><span class="sxs-lookup"><span data-stu-id="685a2-125">Once you have addressed the source hardware and network connectivity bottlenecks above, you are ready to configure your ingestion tools.</span></span> <span data-ttu-id="685a2-126">В следующей таблице перечислены ключевые параметры нескольких популярных средств приема и предоставлены подробные статьи по настройке производительности для них.</span><span class="sxs-lookup"><span data-stu-id="685a2-126">The following table summarizes the key settings for several popular ingestion tools and provides in-depth performance tuning articles for them.</span></span>  <span data-ttu-id="685a2-127">Дополнительные сведения о выборе подходящего средства для вашего сценария см. в [этой статье](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-data-scenarios).</span><span class="sxs-lookup"><span data-stu-id="685a2-127">To learn more about which tool to use for your scenario, visit this [article](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-data-scenarios).</span></span>

| <span data-ttu-id="685a2-128">Средство</span><span class="sxs-lookup"><span data-stu-id="685a2-128">Tool</span></span>               | <span data-ttu-id="685a2-129">Параметры</span><span class="sxs-lookup"><span data-stu-id="685a2-129">Settings</span></span>     | <span data-ttu-id="685a2-130">Дополнительные сведения</span><span class="sxs-lookup"><span data-stu-id="685a2-130">More Details</span></span>                                                                 |
|--------------------|------------------------------------------------------|------------------------------|
| <span data-ttu-id="685a2-131">PowerShell</span><span class="sxs-lookup"><span data-stu-id="685a2-131">Powershell</span></span>       | <span data-ttu-id="685a2-132">PerFileThreadCount, ConcurrentFileCount</span><span class="sxs-lookup"><span data-stu-id="685a2-132">PerFileThreadCount, ConcurrentFileCount</span></span> |  [<span data-ttu-id="685a2-133">Ссылка</span><span class="sxs-lookup"><span data-stu-id="685a2-133">Link</span></span>](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-get-started-powershell#performance-guidance-while-using-powershell)   |
| <span data-ttu-id="685a2-134">AdlCopy</span><span class="sxs-lookup"><span data-stu-id="685a2-134">AdlCopy</span></span>    | <span data-ttu-id="685a2-135">Единицы измерения Azure Data Lake Analytics</span><span class="sxs-lookup"><span data-stu-id="685a2-135">Azure Data Lake Analytics units</span></span>  |   [<span data-ttu-id="685a2-136">Ссылка</span><span class="sxs-lookup"><span data-stu-id="685a2-136">Link</span></span>](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-copy-data-azure-storage-blob#performance-considerations-for-using-adlcopy)         |
| <span data-ttu-id="685a2-137">DistCp</span><span class="sxs-lookup"><span data-stu-id="685a2-137">DistCp</span></span>            | <span data-ttu-id="685a2-138">-m (mapper)</span><span class="sxs-lookup"><span data-stu-id="685a2-138">-m (mapper)</span></span>   | [<span data-ttu-id="685a2-139">Ссылка</span><span class="sxs-lookup"><span data-stu-id="685a2-139">Link</span></span>](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-copy-data-wasb-distcp#performance-considerations-while-using-distcp)                             |
| <span data-ttu-id="685a2-140">Фабрика данных Azure</span><span class="sxs-lookup"><span data-stu-id="685a2-140">Azure Data Factory</span></span>| <span data-ttu-id="685a2-141">parallelCopies</span><span class="sxs-lookup"><span data-stu-id="685a2-141">parallelCopies</span></span>    | [<span data-ttu-id="685a2-142">Ссылка</span><span class="sxs-lookup"><span data-stu-id="685a2-142">Link</span></span>](../data-factory/data-factory-copy-activity-performance.md)                          |
| <span data-ttu-id="685a2-143">Sqoop</span><span class="sxs-lookup"><span data-stu-id="685a2-143">Sqoop</span></span>           | <span data-ttu-id="685a2-144">fs.azure.block.size, -m (mapper)</span><span class="sxs-lookup"><span data-stu-id="685a2-144">fs.azure.block.size, -m (mapper)</span></span>    |   [<span data-ttu-id="685a2-145">Ссылка</span><span class="sxs-lookup"><span data-stu-id="685a2-145">Link</span></span>](https://blogs.msdn.microsoft.com/bigdatasupport/2015/02/17/sqoop-job-performance-tuning-in-hdinsight-hadoop/)        |

## <a name="structure-your-data-set"></a><span data-ttu-id="685a2-146">Структура набора данных</span><span class="sxs-lookup"><span data-stu-id="685a2-146">Structure your data set</span></span>

<span data-ttu-id="685a2-147">При хранении данных в Data Lake Store размер файла, число файлов и структура папок влияют на производительность.</span><span class="sxs-lookup"><span data-stu-id="685a2-147">When data is stored in Data Lake Store, the file size, number of files, and folder structure have an impact on performance.</span></span>  <span data-ttu-id="685a2-148">В следующем разделе описаны рекомендации в этих областях.</span><span class="sxs-lookup"><span data-stu-id="685a2-148">The following section describes best practices in these areas.</span></span>  

### <a name="file-size"></a><span data-ttu-id="685a2-149">Размер файла</span><span class="sxs-lookup"><span data-stu-id="685a2-149">File size</span></span>

<span data-ttu-id="685a2-150">Как правило, у модулей аналитики, таких как HDInsight и Azure Data Lake Analytics, нагрузка зависит от количества файлов.</span><span class="sxs-lookup"><span data-stu-id="685a2-150">Typically, analytics engines such as HDInsight and Azure Data Lake Analytics have a per-file overhead.</span></span>  <span data-ttu-id="685a2-151">Если вы храните данные в большом количестве небольших файлов, это может отрицательно сказаться на производительности.</span><span class="sxs-lookup"><span data-stu-id="685a2-151">If you store your data as many small files, this can negatively affect performance.</span></span>  

<span data-ttu-id="685a2-152">Упорядочивайте свои данные в файлы большого размера для лучшей производительности.</span><span class="sxs-lookup"><span data-stu-id="685a2-152">In general, organize your data into larger sized files for better performance.</span></span>  <span data-ttu-id="685a2-153">Мы рекомендуем упорядочивать наборы данных в файлы размером 256 МБ или больше.</span><span class="sxs-lookup"><span data-stu-id="685a2-153">As a rule of thumb, organize data sets in files of 256MB or larger.</span></span> <span data-ttu-id="685a2-154">В некоторых случаях, например относительно изображений и двоичных данных, их параллельная обработка невозможна.</span><span class="sxs-lookup"><span data-stu-id="685a2-154">In some cases such as images and binary data, it is not possible to process them in parallel.</span></span>  <span data-ttu-id="685a2-155">В таких случаях рекомендуется хранить отдельные файлы размером не более 2 ГБ.</span><span class="sxs-lookup"><span data-stu-id="685a2-155">In these cases, it is recommended to keep individual files under 2GB.</span></span>

<span data-ttu-id="685a2-156">В некоторых случаях конвейеры данных имеют ограниченный контроль над необработанными данными, которые содержат множество небольших файлов.</span><span class="sxs-lookup"><span data-stu-id="685a2-156">Sometimes, data pipelines have limited control over the raw data which has lots of small files.</span></span>  <span data-ttu-id="685a2-157">Рекомендуется использовать процесс подготовки, который будет создавать файлы большего размера для дочерних приложений.</span><span class="sxs-lookup"><span data-stu-id="685a2-157">It is recommended to have a “cooking” process that generates larger files to use for downstream applications.</span></span>  

### <a name="organizing-time-series-data-in-folders"></a><span data-ttu-id="685a2-158">Упорядочение данных временных рядов в папках</span><span class="sxs-lookup"><span data-stu-id="685a2-158">Organizing Time Series data in folders</span></span>

<span data-ttu-id="685a2-159">Для рабочих нагрузок Hive и ADLA удаление секций данных временных рядов может помочь некоторым запросам считывать только подмножество данных, что улучшает производительность.</span><span class="sxs-lookup"><span data-stu-id="685a2-159">For Hive and ADLA workloads, partition pruning of time-series data can help some queries read only a subset of the data which improves performance.</span></span>    

<span data-ttu-id="685a2-160">Конвейеры, принимающие данные временных рядов, часто помещают свои файлы с сильно структурированными именами файлов и папок.</span><span class="sxs-lookup"><span data-stu-id="685a2-160">Those pipelines that ingest time-series data, often place their files with a very structured naming for files and folders.</span></span> <span data-ttu-id="685a2-161">Ниже приведен обычный пример для данных, структурированных по дате:</span><span class="sxs-lookup"><span data-stu-id="685a2-161">Below is a very common example we see for data that is structured by date:</span></span>

    \DataSet\YYYY\MM\DD\datafile_YYYY_MM_DD.tsv

<span data-ttu-id="685a2-162">Обратите внимание, что данные времени и даты отображаются и как папки, и в имени файла.</span><span class="sxs-lookup"><span data-stu-id="685a2-162">Notice that the datetime information appears both as folders and in the filename.</span></span>

<span data-ttu-id="685a2-163">Ниже приведен распространенный шаблон для даты и времени:</span><span class="sxs-lookup"><span data-stu-id="685a2-163">For date and time, the following is a common pattern</span></span>

    \DataSet\YYYY\MM\DD\HH\mm\datafile_YYYY_MM_DD_HH_mm.tsv

<span data-ttu-id="685a2-164">Выбор, который вы делаете с помощью упорядочения папки и файлов, должен быть оптимизирован для больших размеров файлов и разумного количества файлов в каждой папке.</span><span class="sxs-lookup"><span data-stu-id="685a2-164">Again, the choice you make with the folder and file organization should optimize for the larger file sizes and a reasonable number of files in each folder.</span></span>

## <a name="optimizing-io-intensive-jobs-on-hadoop-and-spark-workloads-on-hdinsight"></a><span data-ttu-id="685a2-165">Оптимизация заданий с интенсивными вычислениями ввода-вывода для рабочих нагрузок Hadoop и Spark в HDInsight</span><span class="sxs-lookup"><span data-stu-id="685a2-165">Optimizing I/O intensive jobs on Hadoop and Spark workloads on HDInsight</span></span>

<span data-ttu-id="685a2-166">Задания можно отнести к одной из трех категорий:</span><span class="sxs-lookup"><span data-stu-id="685a2-166">Jobs fall into one of the following three categories:</span></span>

* <span data-ttu-id="685a2-167">**Интенсивно использующие ЦП.**</span><span class="sxs-lookup"><span data-stu-id="685a2-167">**CPU intensive.**</span></span>  <span data-ttu-id="685a2-168">Эти задания имеют долгое время вычисления с минимальным временем ввода-вывода.</span><span class="sxs-lookup"><span data-stu-id="685a2-168">These jobs have long computation times with minimal I/O times.</span></span>  <span data-ttu-id="685a2-169">Примеры включают машинное обучение и задания обработки естественных языков.</span><span class="sxs-lookup"><span data-stu-id="685a2-169">Examples include machine learning and natural language processing jobs.</span></span>  
* <span data-ttu-id="685a2-170">**С высоким объемом требуемой памяти.**</span><span class="sxs-lookup"><span data-stu-id="685a2-170">**Memory intensive.**</span></span>  <span data-ttu-id="685a2-171">Эти задания используют большой объем памяти.</span><span class="sxs-lookup"><span data-stu-id="685a2-171">These jobs use lots of memory.</span></span>  <span data-ttu-id="685a2-172">Примеры включают PageRank и задания аналитики в реальном времени.</span><span class="sxs-lookup"><span data-stu-id="685a2-172">Examples include PageRank and real-time analytics jobs.</span></span>  
* <span data-ttu-id="685a2-173">**С большим количеством операций ввода-вывода.**</span><span class="sxs-lookup"><span data-stu-id="685a2-173">**I/O intensive.**</span></span>  <span data-ttu-id="685a2-174">Эти задания большую часть своего времени выполняют операции ввода-вывода.</span><span class="sxs-lookup"><span data-stu-id="685a2-174">These jobs spend most of their time doing I/O.</span></span>  <span data-ttu-id="685a2-175">Распространенным примером является задание копирования, которое использует только операции чтения и записи.</span><span class="sxs-lookup"><span data-stu-id="685a2-175">A common example is a copy job which does only read and write operations.</span></span>  <span data-ttu-id="685a2-176">Другие примеры включают задания подготовки данных, которые считывают большое количество данных, выполняют некоторую трансформацию данных, а затем записывают данные обратно в хранилище.</span><span class="sxs-lookup"><span data-stu-id="685a2-176">Other examples include data preparation jobs that read a lot of data, performs some data transformation, and then writes the data back to the store.</span></span>  

<span data-ttu-id="685a2-177">Следующее руководство применяется только к заданиям с большим объемом операций ввода-вывода.</span><span class="sxs-lookup"><span data-stu-id="685a2-177">The following guidance is only applicable to I/O intensive jobs.</span></span>

### <a name="general-considerations-for-an-hdinsight-cluster"></a><span data-ttu-id="685a2-178">Общие рекомендации, связанные с кластером HDInsight</span><span class="sxs-lookup"><span data-stu-id="685a2-178">General Considerations for an HDInsight cluster</span></span>

* <span data-ttu-id="685a2-179">**Поддерживаемые версии HDInsight.**</span><span class="sxs-lookup"><span data-stu-id="685a2-179">**HDInsight versions.**</span></span> <span data-ttu-id="685a2-180">Для повышения производительности используйте последний выпуск HDInsight.</span><span class="sxs-lookup"><span data-stu-id="685a2-180">For best performance, use the latest release of HDInsight.</span></span>
* <span data-ttu-id="685a2-181">**Регионы.**</span><span class="sxs-lookup"><span data-stu-id="685a2-181">**Regions.**</span></span> <span data-ttu-id="685a2-182">Разместите Data Lake Store в том же регионе, что и кластер HDInsight.</span><span class="sxs-lookup"><span data-stu-id="685a2-182">Place the Data Lake Store in the same region as the HDInsight cluster.</span></span>  

<span data-ttu-id="685a2-183">Кластер HDInsight An состоит из двух головных узлов и нескольких рабочих узлов.</span><span class="sxs-lookup"><span data-stu-id="685a2-183">An HDInsight cluster is composed of two head nodes and some worker nodes.</span></span> <span data-ttu-id="685a2-184">Каждый рабочий узел предоставляет определенное количество ядер и памяти, которые определяют тип виртуальной машины.</span><span class="sxs-lookup"><span data-stu-id="685a2-184">Each worker node provides a specific number of cores and memory, which is determined by the VM-type.</span></span>  <span data-ttu-id="685a2-185">При выполнении задания YARN выступает в качестве согласователя ресурсов, который выделяет доступную память и ядра для создания контейнеров.</span><span class="sxs-lookup"><span data-stu-id="685a2-185">When running a job, YARN is the resource negotiator that allocates the available memory and cores to create containers.</span></span>  <span data-ttu-id="685a2-186">Каждый контейнер выполняет задачи, которые необходимы для выполнения задания.</span><span class="sxs-lookup"><span data-stu-id="685a2-186">Each container runs the tasks needed to complete the job.</span></span>  <span data-ttu-id="685a2-187">Контейнеры выполняются параллельно для быстрой обработки задачи.</span><span class="sxs-lookup"><span data-stu-id="685a2-187">Containers run in parallel to process tasks quickly.</span></span> <span data-ttu-id="685a2-188">Таким образом производительность повышается за счет выполнения максимально возможного количества контейнеров параллельно.</span><span class="sxs-lookup"><span data-stu-id="685a2-188">Therefore, performance is improved by running as many parallel containers as possible.</span></span>

<span data-ttu-id="685a2-189">В пределах кластера HDInsight имеется три уровня, которые можно настроить, чтобы увеличить число контейнеров и использовать всю доступную пропускную способность.</span><span class="sxs-lookup"><span data-stu-id="685a2-189">There are three layers within an HDInsight cluster that can be tuned to increase the number of containers and use all available throughput.</span></span>  

* <span data-ttu-id="685a2-190">**Физический уровень**</span><span class="sxs-lookup"><span data-stu-id="685a2-190">**Physical layer**</span></span>
* <span data-ttu-id="685a2-191">**Уровень YARN**</span><span class="sxs-lookup"><span data-stu-id="685a2-191">**YARN layer**</span></span>
* <span data-ttu-id="685a2-192">**Уровень рабочей нагрузки**</span><span class="sxs-lookup"><span data-stu-id="685a2-192">**Workload layer**</span></span>

### <a name="physical-layer"></a><span data-ttu-id="685a2-193">Физический уровень</span><span class="sxs-lookup"><span data-stu-id="685a2-193">Physical Layer</span></span>

<span data-ttu-id="685a2-194">**Запустите кластер с большим количеством узлов и/или на виртуальной машине большего размера.**</span><span class="sxs-lookup"><span data-stu-id="685a2-194">**Run cluster with more nodes and/or larger sized VMs.**</span></span>  <span data-ttu-id="685a2-195">Больший кластер позволит вам выполнять дополнительные контейнеры YARN, как это показано на рисунке ниже.</span><span class="sxs-lookup"><span data-stu-id="685a2-195">A larger cluster will enable you to run more YARN containers as shown in the picture below.</span></span>

![Производительность Data Lake Store](./media/data-lake-store-performance-tuning-guidance/VM.png)

<span data-ttu-id="685a2-197">**Используйте виртуальные машины с большей пропускной способностью сети.**</span><span class="sxs-lookup"><span data-stu-id="685a2-197">**Use VMs with more network bandwidth.**</span></span>  <span data-ttu-id="685a2-198">Пропускная способность сети может быть узким местом, если она меньше, чем пропускная способность Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="685a2-198">The amount of network bandwidth can be a bottleneck if there is less network bandwidth than Data Lake Store throughput.</span></span>  <span data-ttu-id="685a2-199">У различных виртуальных машин будет разная пропускная способность сети.</span><span class="sxs-lookup"><span data-stu-id="685a2-199">Different VMs will have varying network bandwidth sizes.</span></span>  <span data-ttu-id="685a2-200">Выберите тип виртуальной машины с самой большой пропускной способностью сети.</span><span class="sxs-lookup"><span data-stu-id="685a2-200">Choose a VM-type that has the largest possible network bandwidth.</span></span>

### <a name="yarn-layer"></a><span data-ttu-id="685a2-201">Уровень YARN</span><span class="sxs-lookup"><span data-stu-id="685a2-201">YARN Layer</span></span>

<span data-ttu-id="685a2-202">**Используйте контейнеры YARN меньшего размера.**</span><span class="sxs-lookup"><span data-stu-id="685a2-202">**Use smaller YARN containers.**</span></span>  <span data-ttu-id="685a2-203">Уменьшите размер каждого контейнера YARN, чтобы создать больше контейнеров с тем же объемом ресурсов.</span><span class="sxs-lookup"><span data-stu-id="685a2-203">Reduce the size of each YARN container to create more containers with the same amount of resources.</span></span>

![Производительность Data Lake Store](./media/data-lake-store-performance-tuning-guidance/small-containers.png)

<span data-ttu-id="685a2-205">В зависимости от рабочей нагрузки минимальный необходимый размер контейнера YARN будет иметься всегда.</span><span class="sxs-lookup"><span data-stu-id="685a2-205">Depending on your workload, there will always be a minimum YARN container size that is needed.</span></span> <span data-ttu-id="685a2-206">Если выбрать слишком маленький контейнер, у заданий будут возникать проблемы из-за нехватки памяти.</span><span class="sxs-lookup"><span data-stu-id="685a2-206">If you pick too small a container, your jobs will run into out-of-memory issues.</span></span> <span data-ttu-id="685a2-207">Как правило, контейнеры YARN должны быть размером не менее 1 ГБ.</span><span class="sxs-lookup"><span data-stu-id="685a2-207">Typically YARN containers should be no smaller than 1GB.</span></span> <span data-ttu-id="685a2-208">Обычно можно увидеть контейнеры YARN размером в 3 ГБ.</span><span class="sxs-lookup"><span data-stu-id="685a2-208">It’s common to see 3GB YARN containers.</span></span> <span data-ttu-id="685a2-209">Для некоторых рабочих нагрузок могут потребоваться контейнеры YARN большего размера.</span><span class="sxs-lookup"><span data-stu-id="685a2-209">For some workloads, you may need larger YARN containers.</span></span>  

<span data-ttu-id="685a2-210">**Увеличьте количество ядер на контейнер YARN.**</span><span class="sxs-lookup"><span data-stu-id="685a2-210">**Increase cores per YARN container.**</span></span>  <span data-ttu-id="685a2-211">Увеличьте количество ядер, выделенных для каждого контейнера, чтобы увеличить число параллельных задач, которые выполняются в каждом контейнере.</span><span class="sxs-lookup"><span data-stu-id="685a2-211">Increase the number of cores allocated to each container to increase the number of parallel tasks that run in each container.</span></span>  <span data-ttu-id="685a2-212">Это работает для приложений, которые выполняют несколько задач на контейнер, например Spark.</span><span class="sxs-lookup"><span data-stu-id="685a2-212">This works for applications like Spark which run multiple tasks per container.</span></span>  <span data-ttu-id="685a2-213">Для приложений, например Hive, которые выполняют один поток в каждом контейнере, лучше иметь несколько контейнеров, а не больше ядер на контейнер.</span><span class="sxs-lookup"><span data-stu-id="685a2-213">For applications like Hive which run a single thread in each container, it is better to have more containers rather than more cores per container.</span></span>   

### <a name="workload-layer"></a><span data-ttu-id="685a2-214">Уровень рабочей нагрузки</span><span class="sxs-lookup"><span data-stu-id="685a2-214">Workload Layer</span></span>

<span data-ttu-id="685a2-215">**Используйте все доступные контейнеры.**</span><span class="sxs-lookup"><span data-stu-id="685a2-215">**Use all available containers.**</span></span>  <span data-ttu-id="685a2-216">Задайте число задач равное или большее количества доступных контейнеров, чтобы использовать все ресурсы.</span><span class="sxs-lookup"><span data-stu-id="685a2-216">Set the number of tasks to be equal or larger than the number of available containers so that all resources are utilized.</span></span>

![Производительность Data Lake Store](./media/data-lake-store-performance-tuning-guidance/use-containers.png)

<span data-ttu-id="685a2-218">**Незавершенные задачи ресурсоемки.**</span><span class="sxs-lookup"><span data-stu-id="685a2-218">**Failed tasks are costly.**</span></span> <span data-ttu-id="685a2-219">Если у каждой задачи есть большой объем данных для обработки, неудачное выполнение задачи приводит к дорогостоящей повторной попытке.</span><span class="sxs-lookup"><span data-stu-id="685a2-219">If each task has a large amount of data to process, then failure of a task results in an expensive retry.</span></span>  <span data-ttu-id="685a2-220">Поэтому лучше создавать дополнительные задачи, каждая из которых обрабатывает небольшой объем данных.</span><span class="sxs-lookup"><span data-stu-id="685a2-220">Therefore, it is better to create more tasks, each of which processes a small amount of data.</span></span>

<span data-ttu-id="685a2-221">Помимо общих рекомендаций, приведенных выше, каждое приложение имеет различные параметры, которые можно настроить для каждого конкретного приложения.</span><span class="sxs-lookup"><span data-stu-id="685a2-221">In addition to the general guidelines above, each application has different parameters available to tune for that specific application.</span></span> <span data-ttu-id="685a2-222">В следующей таблице перечислены некоторые параметры и ссылки для начала работы с настройкой производительности для каждого приложения.</span><span class="sxs-lookup"><span data-stu-id="685a2-222">The table below lists some of the parameters and links to get started with performance tuning for each application.</span></span>

| <span data-ttu-id="685a2-223">Рабочая нагрузка</span><span class="sxs-lookup"><span data-stu-id="685a2-223">Workload</span></span>               | <span data-ttu-id="685a2-224">Параметры для настройки задач</span><span class="sxs-lookup"><span data-stu-id="685a2-224">Parameter to set tasks</span></span>                                                         |
|--------------------|-------------------------------------------------------------------------------------|
| [<span data-ttu-id="685a2-225">Spark в HDInsight</span><span class="sxs-lookup"><span data-stu-id="685a2-225">Spark on HDInisight</span></span>](data-lake-store-performance-tuning-spark.md)       | <ul><li><span data-ttu-id="685a2-226">Num-executors</span><span class="sxs-lookup"><span data-stu-id="685a2-226">Num-executors</span></span></li><li><span data-ttu-id="685a2-227">Executor-memory</span><span class="sxs-lookup"><span data-stu-id="685a2-227">Executor-memory</span></span></li><li><span data-ttu-id="685a2-228">Executor-cores</span><span class="sxs-lookup"><span data-stu-id="685a2-228">Executor-cores</span></span></li></ul> |
| [<span data-ttu-id="685a2-229">Hive в HDInsight</span><span class="sxs-lookup"><span data-stu-id="685a2-229">Hive on HDInsight</span></span>](data-lake-store-performance-tuning-hive.md)    | <ul><li><span data-ttu-id="685a2-230">hive.tez.container.size</span><span class="sxs-lookup"><span data-stu-id="685a2-230">hive.tez.container.size</span></span></li></ul>         |
| [<span data-ttu-id="685a2-231">MapReduce в HDInsight</span><span class="sxs-lookup"><span data-stu-id="685a2-231">MapReduce on HDInsight</span></span>](data-lake-store-performance-tuning-mapreduce.md)            | <ul><li><span data-ttu-id="685a2-232">Mapreduce.map.memory</span><span class="sxs-lookup"><span data-stu-id="685a2-232">Mapreduce.map.memory</span></span></li><li><span data-ttu-id="685a2-233">Mapreduce.job.maps</span><span class="sxs-lookup"><span data-stu-id="685a2-233">Mapreduce.job.maps</span></span></li><li><span data-ttu-id="685a2-234">Mapreduce.reduce.memory</span><span class="sxs-lookup"><span data-stu-id="685a2-234">Mapreduce.reduce.memory</span></span></li><li><span data-ttu-id="685a2-235">Mapreduce.job.reduces</span><span class="sxs-lookup"><span data-stu-id="685a2-235">Mapreduce.job.reduces</span></span></li></ul> |
| [<span data-ttu-id="685a2-236">Storm в HDInsight</span><span class="sxs-lookup"><span data-stu-id="685a2-236">Storm on HDInsight</span></span>](data-lake-store-performance-tuning-storm.md)| <ul><li><span data-ttu-id="685a2-237">Количество рабочих процессов</span><span class="sxs-lookup"><span data-stu-id="685a2-237">Number of worker processes</span></span></li><li><span data-ttu-id="685a2-238">Количество экземпляров исполнителей воронки</span><span class="sxs-lookup"><span data-stu-id="685a2-238">Number of spout executor instances</span></span></li><li><span data-ttu-id="685a2-239">Количество экземпляров исполнителей сита</span><span class="sxs-lookup"><span data-stu-id="685a2-239">Number of bolt executor instances</span></span> </li><li><span data-ttu-id="685a2-240">Количество задач воронки</span><span class="sxs-lookup"><span data-stu-id="685a2-240">Number of spout tasks</span></span></li><li><span data-ttu-id="685a2-241">Количество задач сита</span><span class="sxs-lookup"><span data-stu-id="685a2-241">Number of bolt tasks</span></span></li></ul>|

## <a name="see-also"></a><span data-ttu-id="685a2-242">Дополнительные материалы</span><span class="sxs-lookup"><span data-stu-id="685a2-242">See also</span></span>
* [<span data-ttu-id="685a2-243">Обзор хранилища озера данных Azure</span><span class="sxs-lookup"><span data-stu-id="685a2-243">Overview of Azure Data Lake Store</span></span>](data-lake-store-overview.md)
* [<span data-ttu-id="685a2-244">Начало работы с аналитикой озера данных Azure</span><span class="sxs-lookup"><span data-stu-id="685a2-244">Get Started with Azure Data Lake Analytics</span></span>](../data-lake-analytics/data-lake-analytics-get-started-portal.md)
