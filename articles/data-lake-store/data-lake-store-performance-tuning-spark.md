---
title: "aaaAzure данных Озера хранилища Spark производительности рекомендации по настройке | Документы Microsoft"
description: "Рекомендации по настройке производительности для Spark в Azure Data Lake Store"
services: data-lake-store
documentationcenter: 
author: stewu
manager: amitkul
editor: stewu
ms.assetid: ebde7b9f-2e51-4d43-b7ab-566417221335
ms.service: data-lake-store
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 12/19/2016
ms.author: stewu
ms.openlocfilehash: da1d172e9cb1199ad95605ea1718e78559f79650
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 10/06/2017
---
# <a name="performance-tuning-guidance-for-spark-on-hdinsight-and-azure-data-lake-store"></a><span data-ttu-id="49513-103">Рекомендации по настройке производительности для Spark в HDInsight и Azure Data Lake Store</span><span class="sxs-lookup"><span data-stu-id="49513-103">Performance tuning guidance for Spark on HDInsight and Azure Data Lake Store</span></span>

<span data-ttu-id="49513-104">При настройке производительности на Spark, необходимо tooconsider hello число приложений, которые будут выполняться в кластере.</span><span class="sxs-lookup"><span data-stu-id="49513-104">When tuning performance on Spark, you need tooconsider hello number of apps that will be running on your cluster.</span></span>  <span data-ttu-id="49513-105">По умолчанию, можно запустить 4 приложений одновременно на кластер HDI (Примечание: по умолчанию hello — toochange субъекта).</span><span class="sxs-lookup"><span data-stu-id="49513-105">By default, you can run 4 apps concurrently on your HDI cluster (Note: hello default setting is subject toochange).</span></span>  <span data-ttu-id="49513-106">Вы можете решить toouse меньшее число приложений, можно переопределить параметры по умолчанию hello и использование других hello кластера для этих приложений.</span><span class="sxs-lookup"><span data-stu-id="49513-106">You may decide toouse fewer apps so you can override hello default settings and use more of hello cluster for those apps.</span></span>  

## <a name="prerequisites"></a><span data-ttu-id="49513-107">Предварительные требования</span><span class="sxs-lookup"><span data-stu-id="49513-107">Prerequisites</span></span>

* <span data-ttu-id="49513-108">**Подписка Azure**.</span><span class="sxs-lookup"><span data-stu-id="49513-108">**An Azure subscription**.</span></span> <span data-ttu-id="49513-109">Ознакомьтесь с [бесплатной пробной версией Azure](https://azure.microsoft.com/pricing/free-trial/).</span><span class="sxs-lookup"><span data-stu-id="49513-109">See [Get Azure free trial](https://azure.microsoft.com/pricing/free-trial/).</span></span>
* <span data-ttu-id="49513-110">**Учетная запись Azure Data Lake Store.**</span><span class="sxs-lookup"><span data-stu-id="49513-110">**An Azure Data Lake Store account**.</span></span> <span data-ttu-id="49513-111">Инструкции о том, как один, см. в разделе toocreate [Приступая к работе с хранилища Озера данных Azure](data-lake-store-get-started-portal.md)</span><span class="sxs-lookup"><span data-stu-id="49513-111">For instructions on how toocreate one, see [Get started with Azure Data Lake Store](data-lake-store-get-started-portal.md)</span></span>
* <span data-ttu-id="49513-112">**Кластер Azure HDInsight** с tooa доступа к учетной записи хранилища Озера данных.</span><span class="sxs-lookup"><span data-stu-id="49513-112">**Azure HDInsight cluster** with access tooa Data Lake Store account.</span></span> <span data-ttu-id="49513-113">См. статью [Создание кластера HDInsight с Data Lake Store с помощью портала Azure](data-lake-store-hdinsight-hadoop-use-portal.md).</span><span class="sxs-lookup"><span data-stu-id="49513-113">See [Create an HDInsight cluster with Data Lake Store](data-lake-store-hdinsight-hadoop-use-portal.md).</span></span> <span data-ttu-id="49513-114">Убедитесь, что включить удаленный рабочий стол для кластера hello.</span><span class="sxs-lookup"><span data-stu-id="49513-114">Make sure you enable Remote Desktop for hello cluster.</span></span>
* <span data-ttu-id="49513-115">**Работающий кластер Spark в Azure Data Lake Store.**</span><span class="sxs-lookup"><span data-stu-id="49513-115">**Running Spark cluster on Azure Data Lake Store**.</span></span>  <span data-ttu-id="49513-116">Дополнительные сведения см. в разделе [данные tooanalyze кластера HDInsight Spark использования хранилища Озера данных](https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-apache-spark-use-with-data-lake-store)</span><span class="sxs-lookup"><span data-stu-id="49513-116">For more information, see [Use HDInsight Spark cluster tooanalyze data in Data Lake Store](https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-apache-spark-use-with-data-lake-store)</span></span>
* <span data-ttu-id="49513-117">**Рекомендации по настройке производительности в Azure Data Lake Store**.</span><span class="sxs-lookup"><span data-stu-id="49513-117">**Performance tuning guidelines on ADLS**.</span></span>  <span data-ttu-id="49513-118">См. [рекомендации по настройке производительности для Azure Data Lake Store](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-performance-tuning-guidance).</span><span class="sxs-lookup"><span data-stu-id="49513-118">For general performance concepts, see [Data Lake Store Performance Tuning Guidance](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-performance-tuning-guidance)</span></span> 

## <a name="parameters"></a><span data-ttu-id="49513-119">Параметры</span><span class="sxs-lookup"><span data-stu-id="49513-119">Parameters</span></span>

<span data-ttu-id="49513-120">При выполнении задания Spark, ниже приведены параметры наиболее важных hello, может быть настраиваемой tooincrease производительности на ADLS.</span><span class="sxs-lookup"><span data-stu-id="49513-120">When running Spark jobs, here are hello most important settings that can be tuned tooincrease performance on ADLS:</span></span>

* <span data-ttu-id="49513-121">**Исполнители NUM** -hello количество одновременно выполняемых задач, которые могут быть выполнены.</span><span class="sxs-lookup"><span data-stu-id="49513-121">**Num-executors** - hello number of concurrent tasks that can be executed.</span></span>

* <span data-ttu-id="49513-122">**Исполнитель памяти** -hello объем памяти, выделенной tooeach исполнителя.</span><span class="sxs-lookup"><span data-stu-id="49513-122">**Executor-memory** - hello amount of memory allocated tooeach executor.</span></span>

* <span data-ttu-id="49513-123">**Исполнитель ядер** -hello количество ядер, выделенных tooeach исполнителя.</span><span class="sxs-lookup"><span data-stu-id="49513-123">**Executor-cores** - hello number of cores allocated tooeach executor.</span></span>                     

<span data-ttu-id="49513-124">**Исполнители NUM** исполнителей Num установит hello максимальное число задач, которые могут выполняться параллельно.</span><span class="sxs-lookup"><span data-stu-id="49513-124">**Num-executors** Num-executors will set hello maximum number of tasks that can run in parallel.</span></span>  <span data-ttu-id="49513-125">Фактическое число задач, которые могут выполняться параллельно Hello ограничен hello памяти и ресурсов ЦП, доступных в кластере.</span><span class="sxs-lookup"><span data-stu-id="49513-125">hello actual number of tasks that can run in parallel is bounded by hello memory and CPU resources available in your cluster.</span></span>

<span data-ttu-id="49513-126">**Исполнитель памяти** hello объем памяти, выделяемой tooeach исполнителя.</span><span class="sxs-lookup"><span data-stu-id="49513-126">**Executor-memory** This is hello amount of memory that is being allocated tooeach executor.</span></span>  <span data-ttu-id="49513-127">Hello объем памяти, необходимый для каждого исполнителя является зависимым от задания hello.</span><span class="sxs-lookup"><span data-stu-id="49513-127">hello memory needed for each executor is dependent on hello job.</span></span>  <span data-ttu-id="49513-128">Для сложных операций hello памяти должен toobe выше.</span><span class="sxs-lookup"><span data-stu-id="49513-128">For complex operations, hello memory needs toobe higher.</span></span>  <span data-ttu-id="49513-129">Для более простых операций, таких как чтение и запись, требования к памяти ниже.</span><span class="sxs-lookup"><span data-stu-id="49513-129">For simple operations like read and write, memory requirements will be lower.</span></span>  <span data-ttu-id="49513-130">можно просмотреть Hello объем памяти для каждого исполнителя в Ambari.</span><span class="sxs-lookup"><span data-stu-id="49513-130">hello amount of memory for each executor can be viewed in Ambari.</span></span>  <span data-ttu-id="49513-131">В Ambari перейти tooSpark и открыть вкладку конфигураций hello.</span><span class="sxs-lookup"><span data-stu-id="49513-131">In Ambari, navigate tooSpark and view hello Configs tab.</span></span>  

<span data-ttu-id="49513-132">**Исполнитель ядер** таким образом задается hello количество ядер, используемые для каждого исполнителя, который определяет hello число параллельных потоков, которые могут быть запущены на исполнителя.</span><span class="sxs-lookup"><span data-stu-id="49513-132">**Executor-cores** This sets hello amount of cores used per executor, which determines hello number of parallel threads that can be run per executor.</span></span>  <span data-ttu-id="49513-133">Например если исполнитель ядер = 2, затем каждого исполнителя можете запустить 2 параллельных задач в hello исполнителя.</span><span class="sxs-lookup"><span data-stu-id="49513-133">For example, if executor-cores = 2, then each executor can run 2 parallel tasks in hello executor.</span></span>  <span data-ttu-id="49513-134">Исполнитель Hello-ядерными необходимые будет зависеть от задания hello.</span><span class="sxs-lookup"><span data-stu-id="49513-134">hello executor-cores needed will be dependent on hello job.</span></span>  <span data-ttu-id="49513-135">Задания, включающие большое количество операций ввода-вывода, не требуют большого объема памяти на задачу, так что каждый исполнитель может обрабатывать большее количество параллельных задач.</span><span class="sxs-lookup"><span data-stu-id="49513-135">I/O heavy jobs do not require a large amount of memory per task so each executor can handle more parallel tasks.</span></span>

<span data-ttu-id="49513-136">При выполнении Spark в HDInsight для каждого физического ядра по умолчанию определяются два виртуальных ядра YARN.</span><span class="sxs-lookup"><span data-stu-id="49513-136">By default, two virtual YARN cores are defined for each physical core when running Spark on HDInsight.</span></span>  <span data-ttu-id="49513-137">Такое количество обеспечивает хороший баланс параллелизма и объема контекста, переключающегося между несколькими потоками.</span><span class="sxs-lookup"><span data-stu-id="49513-137">This number provides a good balance of concurrecy and amount of context switching from multiple threads.</span></span>  

## <a name="guidance"></a><span data-ttu-id="49513-138">Руководство</span><span class="sxs-lookup"><span data-stu-id="49513-138">Guidance</span></span>

<span data-ttu-id="49513-139">При выполнении Spark toowork аналитических рабочих нагрузок с данными в хранилище Озера данных, рекомендуется использовать hello последней HDInsight версии tooget hello наилучшей производительности с помощью хранилища Озера данных.</span><span class="sxs-lookup"><span data-stu-id="49513-139">While running Spark analytic workloads toowork with data in Data Lake Store, we recommend that you use hello most recent HDInsight version tooget hello best performance with Data Lake Store.</span></span> <span data-ttu-id="49513-140">Когда задание находится несколько подсистему ввода-вывода, некоторые параметры могут быть настроенных tooimprove производительности.</span><span class="sxs-lookup"><span data-stu-id="49513-140">When your job is more I/O intensive, then certain parameters can be configured tooimprove performance.</span></span>  <span data-ttu-id="49513-141">Azure Data Lake Store — это высокомасштабируемая платформа хранилища, способная справиться с высокой пропускной способностью.</span><span class="sxs-lookup"><span data-stu-id="49513-141">Azure Data Lake Store is a highly scalable storage platform that can handle high throughput.</span></span>  <span data-ttu-id="49513-142">Если задание hello в основном состоит из чтения или записи, затем увеличение параллелизма для операций ввода-вывода tooand из хранилища Озера данных Azure может повысить производительность.</span><span class="sxs-lookup"><span data-stu-id="49513-142">If hello job mainly consists of read or writes, then increasing concurrency for I/O tooand from Azure Data Lake Store could increase performance.</span></span>

<span data-ttu-id="49513-143">Существует несколько параллелизма tooincrease общие способы задания большим объемом ввода-вывода.</span><span class="sxs-lookup"><span data-stu-id="49513-143">There are a few general ways tooincrease concurrency for I/O intensive jobs.</span></span>

<span data-ttu-id="49513-144">**Шаг 1: Определите, сколько приложений, запущенных на кластере** – следует знать, сколько приложений, запущенных на кластере hello в том числе hello текущего.</span><span class="sxs-lookup"><span data-stu-id="49513-144">**Step 1: Determine how many apps are running on your cluster** – You should know how many apps are running on hello cluster including hello current one.</span></span>  <span data-ttu-id="49513-145">значения по умолчанию Hello для каждого Spark, предполагается, что 4 приложений, которые выполняются параллельно.</span><span class="sxs-lookup"><span data-stu-id="49513-145">hello default values for each Spark setting assumes that there are 4 apps running concurrently.</span></span>  <span data-ttu-id="49513-146">Таким образом будет достаточно 25% hello кластера, доступные для каждого приложения.</span><span class="sxs-lookup"><span data-stu-id="49513-146">Therefore, you will only have 25% of hello cluster available for each app.</span></span>  <span data-ttu-id="49513-147">tooget более высокую производительность, можно переопределить значения по умолчанию hello, изменив hello число исполнителей.</span><span class="sxs-lookup"><span data-stu-id="49513-147">tooget better performance, you can override hello defaults by changing hello number of executors.</span></span>  

<span data-ttu-id="49513-148">**Шаг 2: Настройка памяти исполнителя** — hello первое, что tooset является hello памяти исполнителя.</span><span class="sxs-lookup"><span data-stu-id="49513-148">**Step 2: Set executor-memory** – hello first thing tooset is hello executor-memory.</span></span>  <span data-ttu-id="49513-149">Hello памяти будет зависеть, toorun текущее задание hello.</span><span class="sxs-lookup"><span data-stu-id="49513-149">hello memory will be dependent on hello job that you are going toorun.</span></span>  <span data-ttu-id="49513-150">Значение параметра параллелизма можно увеличить, выделив меньший объем памяти на каждый исполнитель.</span><span class="sxs-lookup"><span data-stu-id="49513-150">You can increase concurrency by allocating less memory per executor.</span></span>  <span data-ttu-id="49513-151">Появление исключений нехватки памяти при запуске задания, следует увеличить значение этого параметра hello.</span><span class="sxs-lookup"><span data-stu-id="49513-151">If you see out of memory exceptions when you run your job, then you should increase hello value for this parameter.</span></span>  <span data-ttu-id="49513-152">Один альтернатива — tooget больше памяти, используя кластер с высоким объемом памяти или увеличение размера hello кластера.</span><span class="sxs-lookup"><span data-stu-id="49513-152">One alternative is tooget more memory by using a cluster that has higher amounts of memory or increasing hello size of your cluster.</span></span>  <span data-ttu-id="49513-153">Больший объем памяти будет включена несколько исполнителей toobe используется, что означает более параллелизма.</span><span class="sxs-lookup"><span data-stu-id="49513-153">More memory will enable more executors toobe used, which means more concurrency.</span></span>

<span data-ttu-id="49513-154">**Шаг 3: Настройка исполнителя ядер** — для операций ввода-вывода интенсивных рабочих нагрузок, не имеющих сложные операции, это хороший toostart с большое количество ядер исполнителя tooincrease hello число параллельных задач каждого исполнителя.</span><span class="sxs-lookup"><span data-stu-id="49513-154">**Step 3: Set executor-cores** – For I/O intensive workloads that do not have complex operations, it’s good toostart with a high number of executor-cores tooincrease hello number of parallel tasks per executor.</span></span>  <span data-ttu-id="49513-155">Установка ядра исполнителя too4 — достаточно начать.</span><span class="sxs-lookup"><span data-stu-id="49513-155">Setting executor-cores too4 is a good start.</span></span>   

    executor-cores = 4
<span data-ttu-id="49513-156">При увеличении числа ядер исполнителя в hello предоставит степень параллелизма, можно поэкспериментировать с разных исполнителя ядер.</span><span class="sxs-lookup"><span data-stu-id="49513-156">Increasing hello number of executor-cores will give you more parallelism so you can experiment with different executor-cores.</span></span>  <span data-ttu-id="49513-157">Для заданий, имеющих более сложные операции следует уменьшить hello количество ядер на исполнителя.</span><span class="sxs-lookup"><span data-stu-id="49513-157">For jobs that have more complex operations, you should reduce hello number of cores per executor.</span></span>  <span data-ttu-id="49513-158">Если количество ядер исполнителя превышает 4, тогда сборка мусора может оказаться неэффективной и производительность снизится.</span><span class="sxs-lookup"><span data-stu-id="49513-158">If executor-cores is set higher than 4, then garbage collection may become inefficient and degrade performance.</span></span>

<span data-ttu-id="49513-159">**Шаг 4. Определение объема памяти YARN в кластере.** Информация об этом доступна в Ambari.</span><span class="sxs-lookup"><span data-stu-id="49513-159">**Step 4: Determine amount of YARN memory in cluster** – This information is available in Ambari.</span></span>  <span data-ttu-id="49513-160">Перейти tooYARN и открыть вкладку конфигураций hello.  в этом окне отображается Hello YARN памяти.</span><span class="sxs-lookup"><span data-stu-id="49513-160">Navigate tooYARN and view hello Configs tab.  hello YARN memory is displayed in this window.</span></span>  
<span data-ttu-id="49513-161">Примечание: находясь в окне приветствия, также появится размер контейнера YARN по умолчанию hello.</span><span class="sxs-lookup"><span data-stu-id="49513-161">Note: while you are in hello window, you can also see hello default YARN container size.</span></span>  <span data-ttu-id="49513-162">Hello размер контейнера YARN hello то же, что объем памяти для исполнителя параметра.</span><span class="sxs-lookup"><span data-stu-id="49513-162">hello YARN container size is hello same as memory per executor paramter.</span></span>

    Total YARN memory = nodes * YARN memory per node
<span data-ttu-id="49513-163">**Шаг 5. Вычисление параметра num-executors**</span><span class="sxs-lookup"><span data-stu-id="49513-163">**Step 5: Calculate num-executors**</span></span>

<span data-ttu-id="49513-164">**Ограничение памяти вычисления** -параметр num исполнителей hello ограничен объемом памяти или ЦП.</span><span class="sxs-lookup"><span data-stu-id="49513-164">**Calculate memory constraint** - hello num-executors parameter is constrained either by memory or by CPU.</span></span>  <span data-ttu-id="49513-165">ограничение памяти Hello определяется hello объем доступной памяти YARN для вашего приложения.</span><span class="sxs-lookup"><span data-stu-id="49513-165">hello memory constraint is determined by hello amount of available YARN memory for your application.</span></span>  <span data-ttu-id="49513-166">Разделите общий объем памяти YARN на значение executor-memory.</span><span class="sxs-lookup"><span data-stu-id="49513-166">You should take total YARN memory and divide that by executor-memory.</span></span>  <span data-ttu-id="49513-167">ограничение Hello должен toobe отменяется масштабировать hello количество приложений так мы разделите hello число приложений.</span><span class="sxs-lookup"><span data-stu-id="49513-167">hello constraint needs toobe de-scaled for hello number of apps so we divide by hello number of apps.</span></span>

    Memory constraint = (total YARN memory / executor memory) / # of apps   
<span data-ttu-id="49513-168">**Вычислить ограничение ЦП** -hello ограничение ЦП вычисляется как hello общее количество виртуальных ядер для hello количеству ядер на исполнителя.</span><span class="sxs-lookup"><span data-stu-id="49513-168">**Calculate CPU constraint** - hello CPU constraint is calculated as hello total virtual cores divided by hello number of cores per executor.</span></span>  <span data-ttu-id="49513-169">Для каждого физического ядра существует 2 виртуальных ядра.</span><span class="sxs-lookup"><span data-stu-id="49513-169">There are 2 virtual cores for each physical core.</span></span>  <span data-ttu-id="49513-170">Аналогичные ограничения памяти toohello, у нас есть деления по номеру hello приложений.</span><span class="sxs-lookup"><span data-stu-id="49513-170">Similar toohello memory constraint, we have divide by hello number of apps.</span></span>

    virtual cores = (nodes in cluster * # of physical cores in node * 2)
    CPU constraint = (total virtual cores / # of cores per executor) / # of apps
<span data-ttu-id="49513-171">**Задать число исполнителей** — определить параметр num исполнителей hello, выполнив hello минимум hello ограничения памяти и ЦП hello.</span><span class="sxs-lookup"><span data-stu-id="49513-171">**Set num-executors** – hello num-executors parameter is determined by taking hello minimum of hello memory constraint and hello CPU constraint.</span></span> 

    num-executors = Min (total virtual Cores / # of cores per executor, available YARN memory / executor-memory)   
<span data-ttu-id="49513-172">Увеличение количества исполнителей не обязательно влияет на повышение производительности.</span><span class="sxs-lookup"><span data-stu-id="49513-172">Setting a higher number of num-executors does not necessarily increase performance.</span></span>  <span data-ttu-id="49513-173">Следует учитывать, что добавление дополнительных исполнителей ведет к соответствующему увеличению нагрузки для каждого дополнительного исполнителя, что может снизить производительность.</span><span class="sxs-lookup"><span data-stu-id="49513-173">You should consider that adding more executors will add extra overhead for each additional executor, which can potentially degrade performance.</span></span>  <span data-ttu-id="49513-174">Число исполнителей, ограничен hello ресурсов кластера.</span><span class="sxs-lookup"><span data-stu-id="49513-174">Num-executors is bounded by hello cluster resources.</span></span>    

## <a name="example-calculation"></a><span data-ttu-id="49513-175">Пример вычисления</span><span class="sxs-lookup"><span data-stu-id="49513-175">Example Calculation</span></span>

<span data-ttu-id="49513-176">Предположим, что в настоящее время имеется кластер состоит из 8 узлов D4v2 выполнение 2 приложения hello в том числе один будет toorun.</span><span class="sxs-lookup"><span data-stu-id="49513-176">Let’s say you currently have a cluster composed of 8 D4v2 nodes that is running 2 apps including hello one you are going toorun.</span></span>  

<span data-ttu-id="49513-177">**Шаг 1: Определите, сколько приложений, запущенных на кластере** — вы знаете, что 2 приложения hello один будет toorun в кластере.</span><span class="sxs-lookup"><span data-stu-id="49513-177">**Step 1: Determine how many apps are running on your cluster** – you know that you have 2 apps on your cluster, including hello one you are going toorun.</span></span>  

<span data-ttu-id="49513-178">**Шаг 2. Задайте параметр executor-memory.** Для данного примера мы определяем, что 6 ГБ памяти на исполнитель будет достаточно для выполнения задания с большим количеством операций ввода-вывода.</span><span class="sxs-lookup"><span data-stu-id="49513-178">**Step 2: Set executor-memory** – for this example, we determine that 6GB of executor-memory will be sufficient for I/O intensive job.</span></span>  

    executor-memory = 6GB
<span data-ttu-id="49513-179">**Шаг 3: Настройка исполнителя ядер** — так как это задание большим объемом операций ввода-вывода, можно выбрать вариант hello количество ядер для каждой too4 исполнителя.</span><span class="sxs-lookup"><span data-stu-id="49513-179">**Step 3: Set executor-cores** – Since this is an I/O intensive job, we can set hello number of cores for each executor too4.</span></span>  <span data-ttu-id="49513-180">Настройка ядер на toolarger исполнителя, чем 4 может привести к проблемам сбора мусора.</span><span class="sxs-lookup"><span data-stu-id="49513-180">Setting cores per executor toolarger than 4 may cause garbage collection problems.</span></span>  

    executor-cores = 4
<span data-ttu-id="49513-181">**Шаг 4: Определение размера памяти YARN в кластере** — tooAmbari toofind out, что каждый D4v2 имеет 25 ГБ памяти YARN навигации.</span><span class="sxs-lookup"><span data-stu-id="49513-181">**Step 4: Determine amount of YARN memory in cluster** – We navigate tooAmbari toofind out that each D4v2 has 25GB of YARN memory.</span></span>  <span data-ttu-id="49513-182">Так как существуют 8 узлов, доступной памяти YARN hello умножается на 8.</span><span class="sxs-lookup"><span data-stu-id="49513-182">Since there are 8 nodes, hello available YARN memory is multiplied by 8.</span></span>

    Total YARN memory = nodes * YARN memory* per node
    Total YARN memory = 8 nodes * 25GB = 200GB
<span data-ttu-id="49513-183">**Шаг 5: Вычисление num исполнителей** — определить параметр num исполнителей hello, выполнив hello минимальное ограничение памяти hello и ограничение ЦП hello, разделенное на hello число приложений, выполняющихся в Spark.</span><span class="sxs-lookup"><span data-stu-id="49513-183">**Step 5: Calculate num-executors** – hello num-executors parameter is determined by taking hello minimum of hello memory constraint and hello CPU constraint divided by hello # of apps running on Spark.</span></span>    

<span data-ttu-id="49513-184">**Вычислить ограничение памяти** — ограничение памяти hello рассчитывается как общее YARN памяти hello деленная hello объем памяти для исполнителя.</span><span class="sxs-lookup"><span data-stu-id="49513-184">**Calculate memory constraint** – hello memory constraint is calculated as hello total YARN memory divided by hello memory per executor.</span></span>

    Memory constraint = (total YARN memory / executor memory) / # of apps   
    Memory constraint = (200GB / 6GB) / 2   
    Memory constraint = 16 (rounded)
<span data-ttu-id="49513-185">**Вычислить ограничение ЦП** -hello ограничение ЦП вычисляется как hello общее yarn ядер, деленное hello количество ядер на исполнителя.</span><span class="sxs-lookup"><span data-stu-id="49513-185">**Calculate CPU constraint** - hello CPU constraint is calculated as hello total yarn cores divided by hello number of cores per executor.</span></span>
    
    YARN cores = nodes in cluster * # of cores per node * 2   
    YARN cores = 8 nodes * 8 cores per D14 * 2 = 128
    CPU constraint = (total YARN cores / # of cores per executor) / # of apps
    CPU constraint = (128 / 4) / 2
    CPU constraint = 16
<span data-ttu-id="49513-186">**Настройте параметр num-executors.**</span><span class="sxs-lookup"><span data-stu-id="49513-186">**Set num-executors**</span></span>

    num-executors = Min (memory constraint, CPU constraint)
    num-executors = Min (16, 16)
    num-executors = 16    

