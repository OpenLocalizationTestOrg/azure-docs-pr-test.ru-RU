---
title: "aaaAzure данных Озера хранилища Spark производительности рекомендации по настройке | Документы Microsoft"
description: "Рекомендации по настройке производительности для Spark в Azure Data Lake Store"
services: data-lake-store
documentationcenter: 
author: stewu
manager: amitkul
editor: stewu
ms.assetid: ebde7b9f-2e51-4d43-b7ab-566417221335
ms.service: data-lake-store
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 12/19/2016
ms.author: stewu
ms.openlocfilehash: da1d172e9cb1199ad95605ea1718e78559f79650
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 10/06/2017
---
# <a name="performance-tuning-guidance-for-spark-on-hdinsight-and-azure-data-lake-store"></a>Рекомендации по настройке производительности для Spark в HDInsight и Azure Data Lake Store

При настройке производительности на Spark, необходимо tooconsider hello число приложений, которые будут выполняться в кластере.  По умолчанию, можно запустить 4 приложений одновременно на кластер HDI (Примечание: по умолчанию hello — toochange субъекта).  Вы можете решить toouse меньшее число приложений, можно переопределить параметры по умолчанию hello и использование других hello кластера для этих приложений.  

## <a name="prerequisites"></a>Предварительные требования

* **Подписка Azure**. Ознакомьтесь с [бесплатной пробной версией Azure](https://azure.microsoft.com/pricing/free-trial/).
* **Учетная запись Azure Data Lake Store.** Инструкции о том, как один, см. в разделе toocreate [Приступая к работе с хранилища Озера данных Azure](data-lake-store-get-started-portal.md)
* **Кластер Azure HDInsight** с tooa доступа к учетной записи хранилища Озера данных. См. статью [Создание кластера HDInsight с Data Lake Store с помощью портала Azure](data-lake-store-hdinsight-hadoop-use-portal.md). Убедитесь, что включить удаленный рабочий стол для кластера hello.
* **Работающий кластер Spark в Azure Data Lake Store.**  Дополнительные сведения см. в разделе [данные tooanalyze кластера HDInsight Spark использования хранилища Озера данных](https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-apache-spark-use-with-data-lake-store)
* **Рекомендации по настройке производительности в Azure Data Lake Store**.  См. [рекомендации по настройке производительности для Azure Data Lake Store](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-performance-tuning-guidance). 

## <a name="parameters"></a>Параметры

При выполнении задания Spark, ниже приведены параметры наиболее важных hello, может быть настраиваемой tooincrease производительности на ADLS.

* **Исполнители NUM** -hello количество одновременно выполняемых задач, которые могут быть выполнены.

* **Исполнитель памяти** -hello объем памяти, выделенной tooeach исполнителя.

* **Исполнитель ядер** -hello количество ядер, выделенных tooeach исполнителя.                     

**Исполнители NUM** исполнителей Num установит hello максимальное число задач, которые могут выполняться параллельно.  Фактическое число задач, которые могут выполняться параллельно Hello ограничен hello памяти и ресурсов ЦП, доступных в кластере.

**Исполнитель памяти** hello объем памяти, выделяемой tooeach исполнителя.  Hello объем памяти, необходимый для каждого исполнителя является зависимым от задания hello.  Для сложных операций hello памяти должен toobe выше.  Для более простых операций, таких как чтение и запись, требования к памяти ниже.  можно просмотреть Hello объем памяти для каждого исполнителя в Ambari.  В Ambari перейти tooSpark и открыть вкладку конфигураций hello.  

**Исполнитель ядер** таким образом задается hello количество ядер, используемые для каждого исполнителя, который определяет hello число параллельных потоков, которые могут быть запущены на исполнителя.  Например если исполнитель ядер = 2, затем каждого исполнителя можете запустить 2 параллельных задач в hello исполнителя.  Исполнитель Hello-ядерными необходимые будет зависеть от задания hello.  Задания, включающие большое количество операций ввода-вывода, не требуют большого объема памяти на задачу, так что каждый исполнитель может обрабатывать большее количество параллельных задач.

При выполнении Spark в HDInsight для каждого физического ядра по умолчанию определяются два виртуальных ядра YARN.  Такое количество обеспечивает хороший баланс параллелизма и объема контекста, переключающегося между несколькими потоками.  

## <a name="guidance"></a>Руководство

При выполнении Spark toowork аналитических рабочих нагрузок с данными в хранилище Озера данных, рекомендуется использовать hello последней HDInsight версии tooget hello наилучшей производительности с помощью хранилища Озера данных. Когда задание находится несколько подсистему ввода-вывода, некоторые параметры могут быть настроенных tooimprove производительности.  Azure Data Lake Store — это высокомасштабируемая платформа хранилища, способная справиться с высокой пропускной способностью.  Если задание hello в основном состоит из чтения или записи, затем увеличение параллелизма для операций ввода-вывода tooand из хранилища Озера данных Azure может повысить производительность.

Существует несколько параллелизма tooincrease общие способы задания большим объемом ввода-вывода.

**Шаг 1: Определите, сколько приложений, запущенных на кластере** – следует знать, сколько приложений, запущенных на кластере hello в том числе hello текущего.  значения по умолчанию Hello для каждого Spark, предполагается, что 4 приложений, которые выполняются параллельно.  Таким образом будет достаточно 25% hello кластера, доступные для каждого приложения.  tooget более высокую производительность, можно переопределить значения по умолчанию hello, изменив hello число исполнителей.  

**Шаг 2: Настройка памяти исполнителя** — hello первое, что tooset является hello памяти исполнителя.  Hello памяти будет зависеть, toorun текущее задание hello.  Значение параметра параллелизма можно увеличить, выделив меньший объем памяти на каждый исполнитель.  Появление исключений нехватки памяти при запуске задания, следует увеличить значение этого параметра hello.  Один альтернатива — tooget больше памяти, используя кластер с высоким объемом памяти или увеличение размера hello кластера.  Больший объем памяти будет включена несколько исполнителей toobe используется, что означает более параллелизма.

**Шаг 3: Настройка исполнителя ядер** — для операций ввода-вывода интенсивных рабочих нагрузок, не имеющих сложные операции, это хороший toostart с большое количество ядер исполнителя tooincrease hello число параллельных задач каждого исполнителя.  Установка ядра исполнителя too4 — достаточно начать.   

    executor-cores = 4
При увеличении числа ядер исполнителя в hello предоставит степень параллелизма, можно поэкспериментировать с разных исполнителя ядер.  Для заданий, имеющих более сложные операции следует уменьшить hello количество ядер на исполнителя.  Если количество ядер исполнителя превышает 4, тогда сборка мусора может оказаться неэффективной и производительность снизится.

**Шаг 4. Определение объема памяти YARN в кластере.** Информация об этом доступна в Ambari.  Перейти tooYARN и открыть вкладку конфигураций hello.  в этом окне отображается Hello YARN памяти.  
Примечание: находясь в окне приветствия, также появится размер контейнера YARN по умолчанию hello.  Hello размер контейнера YARN hello то же, что объем памяти для исполнителя параметра.

    Total YARN memory = nodes * YARN memory per node
**Шаг 5. Вычисление параметра num-executors**

**Ограничение памяти вычисления** -параметр num исполнителей hello ограничен объемом памяти или ЦП.  ограничение памяти Hello определяется hello объем доступной памяти YARN для вашего приложения.  Разделите общий объем памяти YARN на значение executor-memory.  ограничение Hello должен toobe отменяется масштабировать hello количество приложений так мы разделите hello число приложений.

    Memory constraint = (total YARN memory / executor memory) / # of apps   
**Вычислить ограничение ЦП** -hello ограничение ЦП вычисляется как hello общее количество виртуальных ядер для hello количеству ядер на исполнителя.  Для каждого физического ядра существует 2 виртуальных ядра.  Аналогичные ограничения памяти toohello, у нас есть деления по номеру hello приложений.

    virtual cores = (nodes in cluster * # of physical cores in node * 2)
    CPU constraint = (total virtual cores / # of cores per executor) / # of apps
**Задать число исполнителей** — определить параметр num исполнителей hello, выполнив hello минимум hello ограничения памяти и ЦП hello. 

    num-executors = Min (total virtual Cores / # of cores per executor, available YARN memory / executor-memory)   
Увеличение количества исполнителей не обязательно влияет на повышение производительности.  Следует учитывать, что добавление дополнительных исполнителей ведет к соответствующему увеличению нагрузки для каждого дополнительного исполнителя, что может снизить производительность.  Число исполнителей, ограничен hello ресурсов кластера.    

## <a name="example-calculation"></a>Пример вычисления

Предположим, что в настоящее время имеется кластер состоит из 8 узлов D4v2 выполнение 2 приложения hello в том числе один будет toorun.  

**Шаг 1: Определите, сколько приложений, запущенных на кластере** — вы знаете, что 2 приложения hello один будет toorun в кластере.  

**Шаг 2. Задайте параметр executor-memory.** Для данного примера мы определяем, что 6 ГБ памяти на исполнитель будет достаточно для выполнения задания с большим количеством операций ввода-вывода.  

    executor-memory = 6GB
**Шаг 3: Настройка исполнителя ядер** — так как это задание большим объемом операций ввода-вывода, можно выбрать вариант hello количество ядер для каждой too4 исполнителя.  Настройка ядер на toolarger исполнителя, чем 4 может привести к проблемам сбора мусора.  

    executor-cores = 4
**Шаг 4: Определение размера памяти YARN в кластере** — tooAmbari toofind out, что каждый D4v2 имеет 25 ГБ памяти YARN навигации.  Так как существуют 8 узлов, доступной памяти YARN hello умножается на 8.

    Total YARN memory = nodes * YARN memory* per node
    Total YARN memory = 8 nodes * 25GB = 200GB
**Шаг 5: Вычисление num исполнителей** — определить параметр num исполнителей hello, выполнив hello минимальное ограничение памяти hello и ограничение ЦП hello, разделенное на hello число приложений, выполняющихся в Spark.    

**Вычислить ограничение памяти** — ограничение памяти hello рассчитывается как общее YARN памяти hello деленная hello объем памяти для исполнителя.

    Memory constraint = (total YARN memory / executor memory) / # of apps   
    Memory constraint = (200GB / 6GB) / 2   
    Memory constraint = 16 (rounded)
**Вычислить ограничение ЦП** -hello ограничение ЦП вычисляется как hello общее yarn ядер, деленное hello количество ядер на исполнителя.
    
    YARN cores = nodes in cluster * # of cores per node * 2   
    YARN cores = 8 nodes * 8 cores per D14 * 2 = 128
    CPU constraint = (total YARN cores / # of cores per executor) / # of apps
    CPU constraint = (128 / 4) / 2
    CPU constraint = 16
**Настройте параметр num-executors.**

    num-executors = Min (memory constraint, CPU constraint)
    num-executors = Min (16, 16)
    num-executors = 16    

