---
title: "Рекомендации по настройке производительности для Spark в Azure Data Lake Store | Документация Майкрософт"
description: "Рекомендации по настройке производительности для Spark в Azure Data Lake Store"
services: data-lake-store
documentationcenter: 
author: stewu
manager: amitkul
editor: stewu
ms.assetid: ebde7b9f-2e51-4d43-b7ab-566417221335
ms.service: data-lake-store
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 12/19/2016
ms.author: stewu
ms.openlocfilehash: 2109744fb7ffdfafb7a86bbea355e119718af099
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 07/11/2017
---
# <a name="performance-tuning-guidance-for-spark-on-hdinsight-and-azure-data-lake-store"></a><span data-ttu-id="5063e-103">Рекомендации по настройке производительности для Spark в HDInsight и Azure Data Lake Store</span><span class="sxs-lookup"><span data-stu-id="5063e-103">Performance tuning guidance for Spark on HDInsight and Azure Data Lake Store</span></span>

<span data-ttu-id="5063e-104">При настройке производительности для Spark необходимо учитывать количество приложений, которые будут выполняться в кластере.</span><span class="sxs-lookup"><span data-stu-id="5063e-104">When tuning performance on Spark, you need to consider the number of apps that will be running on your cluster.</span></span>  <span data-ttu-id="5063e-105">По умолчанию в кластере HDI можно одновременно выполнять 4 приложения (настройку по умолчанию можно изменить).</span><span class="sxs-lookup"><span data-stu-id="5063e-105">By default, you can run 4 apps concurrently on your HDI cluster (Note: the default setting is subject to change).</span></span>  <span data-ttu-id="5063e-106">Вам может понадобиться использовать меньшее количество приложений. В таком случае можно переопределить параметры по умолчанию и использовать больше ресурсов кластера для этих приложений.</span><span class="sxs-lookup"><span data-stu-id="5063e-106">You may decide to use fewer apps so you can override the default settings and use more of the cluster for those apps.</span></span>  

## <a name="prerequisites"></a><span data-ttu-id="5063e-107">Предварительные требования</span><span class="sxs-lookup"><span data-stu-id="5063e-107">Prerequisites</span></span>

* <span data-ttu-id="5063e-108">**Подписка Azure**.</span><span class="sxs-lookup"><span data-stu-id="5063e-108">**An Azure subscription**.</span></span> <span data-ttu-id="5063e-109">Ознакомьтесь с [бесплатной пробной версией Azure](https://azure.microsoft.com/pricing/free-trial/).</span><span class="sxs-lookup"><span data-stu-id="5063e-109">See [Get Azure free trial](https://azure.microsoft.com/pricing/free-trial/).</span></span>
* <span data-ttu-id="5063e-110">**Учетная запись Azure Data Lake Store.**</span><span class="sxs-lookup"><span data-stu-id="5063e-110">**An Azure Data Lake Store account**.</span></span> <span data-ttu-id="5063e-111">Инструкции по созданию учетной записи см. в статье [Начало работы с Azure Data Lake Store с помощью портала Azure](data-lake-store-get-started-portal.md).</span><span class="sxs-lookup"><span data-stu-id="5063e-111">For instructions on how to create one, see [Get started with Azure Data Lake Store](data-lake-store-get-started-portal.md)</span></span>
* <span data-ttu-id="5063e-112">**Кластер Azure HDInsight** с доступом к учетной записи Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="5063e-112">**Azure HDInsight cluster** with access to a Data Lake Store account.</span></span> <span data-ttu-id="5063e-113">См. статью [Создание кластера HDInsight с Data Lake Store с помощью портала Azure](data-lake-store-hdinsight-hadoop-use-portal.md).</span><span class="sxs-lookup"><span data-stu-id="5063e-113">See [Create an HDInsight cluster with Data Lake Store](data-lake-store-hdinsight-hadoop-use-portal.md).</span></span> <span data-ttu-id="5063e-114">Убедитесь, что вы включили удаленный рабочий стол для кластера.</span><span class="sxs-lookup"><span data-stu-id="5063e-114">Make sure you enable Remote Desktop for the cluster.</span></span>
* <span data-ttu-id="5063e-115">**Работающий кластер Spark в Azure Data Lake Store.**</span><span class="sxs-lookup"><span data-stu-id="5063e-115">**Running Spark cluster on Azure Data Lake Store**.</span></span>  <span data-ttu-id="5063e-116">Дополнительные сведения см. в статье [Использование кластера HDInsight Spark для анализа данных в Data Lake Store](https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-apache-spark-use-with-data-lake-store).</span><span class="sxs-lookup"><span data-stu-id="5063e-116">For more information, see [Use HDInsight Spark cluster to analyze data in Data Lake Store](https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-apache-spark-use-with-data-lake-store)</span></span>
* <span data-ttu-id="5063e-117">**Рекомендации по настройке производительности в Azure Data Lake Store**.</span><span class="sxs-lookup"><span data-stu-id="5063e-117">**Performance tuning guidelines on ADLS**.</span></span>  <span data-ttu-id="5063e-118">См. [рекомендации по настройке производительности для Azure Data Lake Store](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-performance-tuning-guidance).</span><span class="sxs-lookup"><span data-stu-id="5063e-118">For general performance concepts, see [Data Lake Store Performance Tuning Guidance](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-performance-tuning-guidance)</span></span> 

## <a name="parameters"></a><span data-ttu-id="5063e-119">Параметры</span><span class="sxs-lookup"><span data-stu-id="5063e-119">Parameters</span></span>

<span data-ttu-id="5063e-120">Ниже приведены самые важные параметры, которые можно настроить для повышения производительности в Azure Data Lake Store при выполнении заданий Spark.</span><span class="sxs-lookup"><span data-stu-id="5063e-120">When running Spark jobs, here are the most important settings that can be tuned to increase performance on ADLS:</span></span>

* <span data-ttu-id="5063e-121">**num-executors** — количество параллельных задач, которые можно выполнить.</span><span class="sxs-lookup"><span data-stu-id="5063e-121">**Num-executors** - The number of concurrent tasks that can be executed.</span></span>

* <span data-ttu-id="5063e-122">**executor-memory** — объем памяти, выделенной для каждого исполнителя.</span><span class="sxs-lookup"><span data-stu-id="5063e-122">**Executor-memory** - The amount of memory allocated to each executor.</span></span>

* <span data-ttu-id="5063e-123">**executor-cores** — количество ядер, выделенных для каждого исполнителя.</span><span class="sxs-lookup"><span data-stu-id="5063e-123">**Executor-cores** - The number of cores allocated to each executor.</span></span>                     

<span data-ttu-id="5063e-124">**num-executors**.Этот параметр позволяет задать максимальное число задач, которые могут выполняться параллельно.</span><span class="sxs-lookup"><span data-stu-id="5063e-124">**Num-executors** Num-executors will set the maximum number of tasks that can run in parallel.</span></span>  <span data-ttu-id="5063e-125">Фактическое число задач, которые могут выполняться параллельно, ограничено ресурсами памяти и ЦП, доступными в кластере.</span><span class="sxs-lookup"><span data-stu-id="5063e-125">The actual number of tasks that can run in parallel is bounded by the memory and CPU resources available in your cluster.</span></span>

<span data-ttu-id="5063e-126">**executor-memory** — это объем памяти, выделенной для каждого исполнителя.</span><span class="sxs-lookup"><span data-stu-id="5063e-126">**Executor-memory** This is the amount of memory that is being allocated to each executor.</span></span>  <span data-ttu-id="5063e-127">Объем памяти, необходимый для каждого исполнителя, зависит от задания.</span><span class="sxs-lookup"><span data-stu-id="5063e-127">The memory needed for each executor is dependent on the job.</span></span>  <span data-ttu-id="5063e-128">При выполнении сложных операций требования к памяти возрастают.</span><span class="sxs-lookup"><span data-stu-id="5063e-128">For complex operations, the memory needs to be higher.</span></span>  <span data-ttu-id="5063e-129">Для более простых операций, таких как чтение и запись, требования к памяти ниже.</span><span class="sxs-lookup"><span data-stu-id="5063e-129">For simple operations like read and write, memory requirements will be lower.</span></span>  <span data-ttu-id="5063e-130">Объем памяти, необходимый для каждого исполнителя, можно просмотреть в Ambari.</span><span class="sxs-lookup"><span data-stu-id="5063e-130">The amount of memory for each executor can be viewed in Ambari.</span></span>  <span data-ttu-id="5063e-131">В Ambari перейдите к Spark и откройте вкладку конфигураций.</span><span class="sxs-lookup"><span data-stu-id="5063e-131">In Ambari, navigate to Spark and view the Configs tab.</span></span>  

<span data-ttu-id="5063e-132">**executor-cores**. Этот параметр задает количество ядер, используемых для каждого исполнителя, что определяет число параллельных потоков, выполняемых на исполнителя.</span><span class="sxs-lookup"><span data-stu-id="5063e-132">**Executor-cores** This sets the amount of cores used per executor, which determines the number of parallel threads that can be run per executor.</span></span>  <span data-ttu-id="5063e-133">Например, если задать executor-cores = 2, тогда каждый исполнитель может выполнять 2 параллельные задачи.</span><span class="sxs-lookup"><span data-stu-id="5063e-133">For example, if executor-cores = 2, then each executor can run 2 parallel tasks in the executor.</span></span>  <span data-ttu-id="5063e-134">Необходимое количество ядер исполнителя зависит от задания.</span><span class="sxs-lookup"><span data-stu-id="5063e-134">The executor-cores needed will be dependent on the job.</span></span>  <span data-ttu-id="5063e-135">Задания, включающие большое количество операций ввода-вывода, не требуют большого объема памяти на задачу, так что каждый исполнитель может обрабатывать большее количество параллельных задач.</span><span class="sxs-lookup"><span data-stu-id="5063e-135">I/O heavy jobs do not require a large amount of memory per task so each executor can handle more parallel tasks.</span></span>

<span data-ttu-id="5063e-136">При выполнении Spark в HDInsight для каждого физического ядра по умолчанию определяются два виртуальных ядра YARN.</span><span class="sxs-lookup"><span data-stu-id="5063e-136">By default, two virtual YARN cores are defined for each physical core when running Spark on HDInsight.</span></span>  <span data-ttu-id="5063e-137">Такое количество обеспечивает хороший баланс параллелизма и объема контекста, переключающегося между несколькими потоками.</span><span class="sxs-lookup"><span data-stu-id="5063e-137">This number provides a good balance of concurrecy and amount of context switching from multiple threads.</span></span>  

## <a name="guidance"></a><span data-ttu-id="5063e-138">Руководство</span><span class="sxs-lookup"><span data-stu-id="5063e-138">Guidance</span></span>

<span data-ttu-id="5063e-139">Во время выполнения аналитических рабочих нагрузок Spark для работы с данными в Data Lake Store рекомендуется использовать последнюю версию HDInsight для обеспечения высокой производительности Data Lake Store.</span><span class="sxs-lookup"><span data-stu-id="5063e-139">While running Spark analytic workloads to work with data in Data Lake Store, we recommend that you use the most recent HDInsight version to get the best performance with Data Lake Store.</span></span> <span data-ttu-id="5063e-140">Если во время вашего задания выполняется большое количество операций ввода-вывода, можно настроить некоторые параметры для повышения производительности.</span><span class="sxs-lookup"><span data-stu-id="5063e-140">When your job is more I/O intensive, then certain parameters can be configured to improve performance.</span></span>  <span data-ttu-id="5063e-141">Azure Data Lake Store — это высокомасштабируемая платформа хранилища, способная справиться с высокой пропускной способностью.</span><span class="sxs-lookup"><span data-stu-id="5063e-141">Azure Data Lake Store is a highly scalable storage platform that can handle high throughput.</span></span>  <span data-ttu-id="5063e-142">Если задание состоит преимущественно из операций чтения или записи, повысить производительность можно, увеличив значение параметра параллелизма для операций ввода-вывода в Azure Data Lake Store и из него.</span><span class="sxs-lookup"><span data-stu-id="5063e-142">If the job mainly consists of read or writes, then increasing concurrency for I/O to and from Azure Data Lake Store could increase performance.</span></span>

<span data-ttu-id="5063e-143">Есть несколько основных способов повышения параллелизма для заданий с большим количеством операций ввода-вывода.</span><span class="sxs-lookup"><span data-stu-id="5063e-143">There are a few general ways to increase concurrency for I/O intensive jobs.</span></span>

<span data-ttu-id="5063e-144">**Шаг 1. Определение количества приложений, выполняющихся в кластере.** Необходимо знать количество выполняющихся в кластере приложений, включая текущее.</span><span class="sxs-lookup"><span data-stu-id="5063e-144">**Step 1: Determine how many apps are running on your cluster** – You should know how many apps are running on the cluster including the current one.</span></span>  <span data-ttu-id="5063e-145">Значения по умолчанию для каждого параметра Spark подразумевают, что параллельно выполняются 4 приложения.</span><span class="sxs-lookup"><span data-stu-id="5063e-145">The default values for each Spark setting assumes that there are 4 apps running concurrently.</span></span>  <span data-ttu-id="5063e-146">Таким образом на каждое приложение доступно всего 25 % ресурсов кластера.</span><span class="sxs-lookup"><span data-stu-id="5063e-146">Therefore, you will only have 25% of the cluster available for each app.</span></span>  <span data-ttu-id="5063e-147">Чтобы получить более высокую производительность, можно переопределить значения по умолчанию, изменив число исполнителей.</span><span class="sxs-lookup"><span data-stu-id="5063e-147">To get better performance, you can override the defaults by changing the number of executors.</span></span>  

<span data-ttu-id="5063e-148">**Шаг 2. Настройка памяти исполнителя.** В первую очередь необходимо задать параметр executor-memory.</span><span class="sxs-lookup"><span data-stu-id="5063e-148">**Step 2: Set executor-memory** – the first thing to set is the executor-memory.</span></span>  <span data-ttu-id="5063e-149">Требуемый объем памяти зависит от задания, которое необходимо выполнить.</span><span class="sxs-lookup"><span data-stu-id="5063e-149">The memory will be dependent on the job that you are going to run.</span></span>  <span data-ttu-id="5063e-150">Значение параметра параллелизма можно увеличить, выделив меньший объем памяти на каждый исполнитель.</span><span class="sxs-lookup"><span data-stu-id="5063e-150">You can increase concurrency by allocating less memory per executor.</span></span>  <span data-ttu-id="5063e-151">Если во время выполнения задания возникают исключения памяти, можно повысить значение для этого параметра.</span><span class="sxs-lookup"><span data-stu-id="5063e-151">If you see out of memory exceptions when you run your job, then you should increase the value for this parameter.</span></span>  <span data-ttu-id="5063e-152">Альтернативой будет обеспечить больший объем памяти, используя кластер с большим объемом памяти или увеличивая размер кластера.</span><span class="sxs-lookup"><span data-stu-id="5063e-152">One alternative is to get more memory by using a cluster that has higher amounts of memory or increasing the size of your cluster.</span></span>  <span data-ttu-id="5063e-153">Больший объем памяти позволит использовать дополнительные исполнители, обеспечивая возможность параллельной обработки.</span><span class="sxs-lookup"><span data-stu-id="5063e-153">More memory will enable more executors to be used, which means more concurrency.</span></span>

<span data-ttu-id="5063e-154">**Шаг 3. Настройка ядер исполнителя.** Для рабочих нагрузок с большим количеством операций ввода-вывода, которые не включают сложные операции, рекомендуется настроить большее количество ядер исполнителя, чтобы увеличить число параллельно выполняемых задач на каждый исполнитель.</span><span class="sxs-lookup"><span data-stu-id="5063e-154">**Step 3: Set executor-cores** – For I/O intensive workloads that do not have complex operations, it’s good to start with a high number of executor-cores to increase the number of parallel tasks per executor.</span></span>  <span data-ttu-id="5063e-155">Оптимальный вариант — 4 ядра исполнителя.</span><span class="sxs-lookup"><span data-stu-id="5063e-155">Setting executor-cores to 4 is a good start.</span></span>   

    executor-cores = 4
<span data-ttu-id="5063e-156">Увеличение количества ядер исполнителя обеспечит больший параллелизм, так что можно поэкспериментировать с разным количеством ядер.</span><span class="sxs-lookup"><span data-stu-id="5063e-156">Increasing the number of executor-cores will give you more parallelism so you can experiment with different executor-cores.</span></span>  <span data-ttu-id="5063e-157">Для заданий, которые включают более сложные операции, количество ядер на исполнитель необходимо уменьшить.</span><span class="sxs-lookup"><span data-stu-id="5063e-157">For jobs that have more complex operations, you should reduce the number of cores per executor.</span></span>  <span data-ttu-id="5063e-158">Если количество ядер исполнителя превышает 4, тогда сборка мусора может оказаться неэффективной и производительность снизится.</span><span class="sxs-lookup"><span data-stu-id="5063e-158">If executor-cores is set higher than 4, then garbage collection may become inefficient and degrade performance.</span></span>

<span data-ttu-id="5063e-159">**Шаг 4. Определение объема памяти YARN в кластере.** Информация об этом доступна в Ambari.</span><span class="sxs-lookup"><span data-stu-id="5063e-159">**Step 4: Determine amount of YARN memory in cluster** – This information is available in Ambari.</span></span>  <span data-ttu-id="5063e-160">Перейдите к YARN и откройте вкладку конфигураций.</span><span class="sxs-lookup"><span data-stu-id="5063e-160">Navigate to YARN and view the Configs tab.</span></span>  <span data-ttu-id="5063e-161">Объем памяти YARN отобразится в этом окне.</span><span class="sxs-lookup"><span data-stu-id="5063e-161">The YARN memory is displayed in this window.</span></span>  
<span data-ttu-id="5063e-162">Примечание. В этом окне можно увидеть размер контейнера YARN по умолчанию.</span><span class="sxs-lookup"><span data-stu-id="5063e-162">Note: while you are in the window, you can also see the default YARN container size.</span></span>  <span data-ttu-id="5063e-163">Размер контейнера YARN такой же, как и параметр объема памяти на исполнителя.</span><span class="sxs-lookup"><span data-stu-id="5063e-163">The YARN container size is the same as memory per executor paramter.</span></span>

    Total YARN memory = nodes * YARN memory per node
<span data-ttu-id="5063e-164">**Шаг 5. Вычисление параметра num-executors**</span><span class="sxs-lookup"><span data-stu-id="5063e-164">**Step 5: Calculate num-executors**</span></span>

<span data-ttu-id="5063e-165">**Вычисление ограничения памяти.** Параметр num-executors ограничен памятью или ЦП.</span><span class="sxs-lookup"><span data-stu-id="5063e-165">**Calculate memory constraint** - The num-executors parameter is constrained either by memory or by CPU.</span></span>  <span data-ttu-id="5063e-166">Ограничение памяти определяется объемом доступной памяти YARN для вашего приложения.</span><span class="sxs-lookup"><span data-stu-id="5063e-166">The memory constraint is determined by the amount of available YARN memory for your application.</span></span>  <span data-ttu-id="5063e-167">Разделите общий объем памяти YARN на значение executor-memory.</span><span class="sxs-lookup"><span data-stu-id="5063e-167">You should take total YARN memory and divide that by executor-memory.</span></span>  <span data-ttu-id="5063e-168">Ограничение необходимо рассчитать для каждого приложения, так что мы разделим полученное значение на количество приложений.</span><span class="sxs-lookup"><span data-stu-id="5063e-168">The constraint needs to be de-scaled for the number of apps so we divide by the number of apps.</span></span>

    Memory constraint = (total YARN memory / executor memory) / # of apps   
<span data-ttu-id="5063e-169">**Вычисление ограничения ЦП.** Ограничение ЦП можно рассчитать, разделив общее количество виртуальных ядер на количество ядер на исполнителя.</span><span class="sxs-lookup"><span data-stu-id="5063e-169">**Calculate CPU constraint** - The CPU constraint is calculated as the total virtual cores divided by the number of cores per executor.</span></span>  <span data-ttu-id="5063e-170">Для каждого физического ядра существует 2 виртуальных ядра.</span><span class="sxs-lookup"><span data-stu-id="5063e-170">There are 2 virtual cores for each physical core.</span></span>  <span data-ttu-id="5063e-171">Как и в случае с ограничением памяти, необходимо делить на количество приложений.</span><span class="sxs-lookup"><span data-stu-id="5063e-171">Similar to the memory constraint, we have divide by the number of apps.</span></span>

    virtual cores = (nodes in cluster * # of physical cores in node * 2)
    CPU constraint = (total virtual cores / # of cores per executor) / # of apps
<span data-ttu-id="5063e-172">**Настройка параметра num-executors.** Параметр num-executors определяется минимальным значением ограничения памяти и ограничением ЦП.</span><span class="sxs-lookup"><span data-stu-id="5063e-172">**Set num-executors** – The num-executors parameter is determined by taking the minimum of the memory constraint and the CPU constraint.</span></span> 

    num-executors = Min (total virtual Cores / # of cores per executor, available YARN memory / executor-memory)   
<span data-ttu-id="5063e-173">Увеличение количества исполнителей не обязательно влияет на повышение производительности.</span><span class="sxs-lookup"><span data-stu-id="5063e-173">Setting a higher number of num-executors does not necessarily increase performance.</span></span>  <span data-ttu-id="5063e-174">Следует учитывать, что добавление дополнительных исполнителей ведет к соответствующему увеличению нагрузки для каждого дополнительного исполнителя, что может снизить производительность.</span><span class="sxs-lookup"><span data-stu-id="5063e-174">You should consider that adding more executors will add extra overhead for each additional executor, which can potentially degrade performance.</span></span>  <span data-ttu-id="5063e-175">Параметр num-executors ограничен ресурсами кластера.</span><span class="sxs-lookup"><span data-stu-id="5063e-175">Num-executors is bounded by the cluster resources.</span></span>    

## <a name="example-calculation"></a><span data-ttu-id="5063e-176">Пример вычисления</span><span class="sxs-lookup"><span data-stu-id="5063e-176">Example Calculation</span></span>

<span data-ttu-id="5063e-177">Предположим, у вас есть кластер из 8 узлов D4v2, на котором выполняется 2 приложения, включая приложение, которое вы собираетесь выполнить.</span><span class="sxs-lookup"><span data-stu-id="5063e-177">Let’s say you currently have a cluster composed of 8 D4v2 nodes that is running 2 apps including the one you are going to run.</span></span>  

<span data-ttu-id="5063e-178">**Шаг 1. Определите, сколько приложений выполняется в кластере.** Вы знаете, что в кластере выполняется 2 приложения, включая приложение, которое вы собираетесь выполнить.</span><span class="sxs-lookup"><span data-stu-id="5063e-178">**Step 1: Determine how many apps are running on your cluster** – you know that you have 2 apps on your cluster, including the one you are going to run.</span></span>  

<span data-ttu-id="5063e-179">**Шаг 2. Задайте параметр executor-memory.** Для данного примера мы определяем, что 6 ГБ памяти на исполнитель будет достаточно для выполнения задания с большим количеством операций ввода-вывода.</span><span class="sxs-lookup"><span data-stu-id="5063e-179">**Step 2: Set executor-memory** – for this example, we determine that 6GB of executor-memory will be sufficient for I/O intensive job.</span></span>  

    executor-memory = 6GB
<span data-ttu-id="5063e-180">**Шаг 3. Задайте параметр executor-cores.** Так как это задание с большим количеством операций ввода-вывода, для каждого исполнителя можно задать 4 ядра.</span><span class="sxs-lookup"><span data-stu-id="5063e-180">**Step 3: Set executor-cores** – Since this is an I/O intensive job, we can set the number of cores for each executor to 4.</span></span>  <span data-ttu-id="5063e-181">Если задать большее количество ядер на исполнитель, это может вызвать проблемы со сборкой мусора.</span><span class="sxs-lookup"><span data-stu-id="5063e-181">Setting cores per executor to larger than 4 may cause garbage collection problems.</span></span>  

    executor-cores = 4
<span data-ttu-id="5063e-182">**Шаг 4. Определите объем памяти YARN в кластере.** Перейдите в Ambari, чтобы узнать, что каждый узел D4v2 имеет 25 ГБ памяти YARN.</span><span class="sxs-lookup"><span data-stu-id="5063e-182">**Step 4: Determine amount of YARN memory in cluster** – We navigate to Ambari to find out that each D4v2 has 25GB of YARN memory.</span></span>  <span data-ttu-id="5063e-183">Так как в кластере 8 узлов, объем доступной памяти YARN увеличивается в 8 раз.</span><span class="sxs-lookup"><span data-stu-id="5063e-183">Since there are 8 nodes, the available YARN memory is multiplied by 8.</span></span>

    Total YARN memory = nodes * YARN memory* per node
    Total YARN memory = 8 nodes * 25GB = 200GB
<span data-ttu-id="5063e-184">**Шаг 5. Настройте параметр num-executors.** Параметр num-executors определяется общим минимальным значением ограничения памяти и ограничением ЦП, разделенными на количество приложений, выполняемых в Spark.</span><span class="sxs-lookup"><span data-stu-id="5063e-184">**Step 5: Calculate num-executors** – The num-executors parameter is determined by taking the minimum of the memory constraint and the CPU constraint divided by the # of apps running on Spark.</span></span>    

<span data-ttu-id="5063e-185">**Рассчитайте ограничение памяти.** Ограничение памяти рассчитывается как общий объем памяти YARN, разделенный на объем памяти на исполнитель.</span><span class="sxs-lookup"><span data-stu-id="5063e-185">**Calculate memory constraint** – The memory constraint is calculated as the total YARN memory divided by the memory per executor.</span></span>

    Memory constraint = (total YARN memory / executor memory) / # of apps   
    Memory constraint = (200GB / 6GB) / 2   
    Memory constraint = 16 (rounded)
<span data-ttu-id="5063e-186">**Рассчитайте ограничение ЦП.** Ограничение ЦП можно рассчитать, разделив общее количество ядер YARN на количество ядер на исполнителя.</span><span class="sxs-lookup"><span data-stu-id="5063e-186">**Calculate CPU constraint** - The CPU constraint is calculated as the total yarn cores divided by the number of cores per executor.</span></span>
    
    YARN cores = nodes in cluster * # of cores per node * 2   
    YARN cores = 8 nodes * 8 cores per D14 * 2 = 128
    CPU constraint = (total YARN cores / # of cores per executor) / # of apps
    CPU constraint = (128 / 4) / 2
    CPU constraint = 16
<span data-ttu-id="5063e-187">**Настройте параметр num-executors.**</span><span class="sxs-lookup"><span data-stu-id="5063e-187">**Set num-executors**</span></span>

    num-executors = Min (memory constraint, CPU constraint)
    num-executors = Min (16, 16)
    num-executors = 16    

