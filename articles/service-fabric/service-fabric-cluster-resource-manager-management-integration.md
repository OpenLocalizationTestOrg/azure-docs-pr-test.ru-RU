---
title: "Диспетчер кластерных ресурсов Service Fabric — интеграция управления | Документация Майкрософт"
description: "Обзор точек интеграции между диспетчером ресурсов кластера и управлением Service Fabric."
services: service-fabric
documentationcenter: .net
author: masnider
manager: timlt
editor: 
ms.assetid: 956cd0b8-b6e3-4436-a224-8766320e8cd7
ms.service: Service-Fabric
ms.devlang: dotnet
ms.topic: article
ms.tgt_pltfrm: NA
ms.workload: NA
ms.date: 08/18/2017
ms.author: masnider
ms.openlocfilehash: 9601e758e1033b4e2f86c2c230d4f49479fe6f45
ms.sourcegitcommit: 50e23e8d3b1148ae2d36dad3167936b4e52c8a23
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 08/18/2017
---
# <a name="cluster-resource-manager-integration-with-service-fabric-cluster-management"></a><span data-ttu-id="725ff-103">Интеграция диспетчера кластерных ресурсов с управлением кластерами Service Fabric</span><span class="sxs-lookup"><span data-stu-id="725ff-103">Cluster resource manager integration with Service Fabric cluster management</span></span>
<span data-ttu-id="725ff-104">Диспетчер кластерных ресурсов Service Fabric не инициирует обновления в Service Fabric, но участвует в них.</span><span class="sxs-lookup"><span data-stu-id="725ff-104">The Service Fabric Cluster Resource Manager doesn't drive upgrades in Service Fabric, but it is involved.</span></span> <span data-ttu-id="725ff-105">Первый способ, используемый диспетчером кластерных ресурсов при управлении, заключается в отслеживании требуемого состояния кластера и служб внутри него.</span><span class="sxs-lookup"><span data-stu-id="725ff-105">The first way that the Cluster Resource Manager helps with management is by tracking the desired state of the cluster and the services inside it.</span></span> <span data-ttu-id="725ff-106">Он отправляет отчеты о работоспособности, если не удается перевести кластер в нужное состояние.</span><span class="sxs-lookup"><span data-stu-id="725ff-106">The Cluster Resource Manager sends out health reports when it cannot put the cluster into the desired configuration.</span></span> <span data-ttu-id="725ff-107">Например, если емкости недостаточно, то диспетчер кластерных ресурсов отправляет предупреждения о работоспособности и сообщает об ошибках работоспособности, указывающие на проблему.</span><span class="sxs-lookup"><span data-stu-id="725ff-107">For example, if there is insufficient capacity the Cluster Resource Manager sends out health warnings and errors indicating the problem.</span></span> <span data-ttu-id="725ff-108">Второе направление интеграции связано с обновлениями.</span><span class="sxs-lookup"><span data-stu-id="725ff-108">Another piece of integration has to do with how upgrades work.</span></span> <span data-ttu-id="725ff-109">Во время обновлений диспетчер кластерных ресурсов изменяет свое поведение.</span><span class="sxs-lookup"><span data-stu-id="725ff-109">The Cluster Resource Manager alters its behavior slightly during upgrades.</span></span>  

## <a name="health-integration"></a><span data-ttu-id="725ff-110">Интеграция функций работоспособности</span><span class="sxs-lookup"><span data-stu-id="725ff-110">Health integration</span></span>
<span data-ttu-id="725ff-111">Диспетчер кластерных ресурсов постоянно отслеживает правила, которые вы определили для размещения служб.</span><span class="sxs-lookup"><span data-stu-id="725ff-111">The Cluster Resource Manager constantly tracks the rules you have defined for placing your services.</span></span> <span data-ttu-id="725ff-112">Он также отслеживает оставшуюся емкость для каждой метрики на узлах кластера и в кластере в целом.</span><span class="sxs-lookup"><span data-stu-id="725ff-112">It also tracks the remaining capacity for each metric on the nodes and in the cluster and in the cluster as a whole.</span></span> <span data-ttu-id="725ff-113">Он передает предупреждения о работоспособности и сообщает об ошибках работоспособности, если не может выполнить эти правила или выделить достаточную емкость.</span><span class="sxs-lookup"><span data-stu-id="725ff-113">If it can't satisfy those rules or if there is insufficient capacity, health warnings and errors are emitted.</span></span> <span data-ttu-id="725ff-114">Например, если узел перегружен и диспетчер кластерных ресурсов попытается исправить ситуацию за счет перемещения служб.</span><span class="sxs-lookup"><span data-stu-id="725ff-114">For example, if a node is over capacity and the Cluster Resource Manager will try to fix the situation by moving services.</span></span> <span data-ttu-id="725ff-115">Если диспетчер кластерных ресурсов не может исправить ситуацию, то он выведет предупреждение о работоспособности, указывающее, какой узел перегружен и по каким метрикам.</span><span class="sxs-lookup"><span data-stu-id="725ff-115">If it can't correct the situation it emits a health warning indicating which node is over capacity, and for which metrics.</span></span>

<span data-ttu-id="725ff-116">Кроме того, он выводит предупреждения о работоспособности в случае нарушения ограничений размещения.</span><span class="sxs-lookup"><span data-stu-id="725ff-116">Another example of the Resource Manager's health warnings is violations of placement constraints.</span></span> <span data-ttu-id="725ff-117">Например, если определено ограничение размещения (например, `“NodeColor == Blue”`) и диспетчер ресурсов обнаруживает его нарушение, то он выводит предупреждение о работоспособности.</span><span class="sxs-lookup"><span data-stu-id="725ff-117">For example, if you have defined a placement constraint (such as `“NodeColor == Blue”`) and the Resource Manager detects a violation of that constraint, it emits a health warning.</span></span> <span data-ttu-id="725ff-118">Это делается для настраиваемых ограничений, а также для ограничений по умолчанию (например, ограничений для доменов сбоя и доменов обновления).</span><span class="sxs-lookup"><span data-stu-id="725ff-118">This is true for custom constraints and the default constraints (like the Fault Domain and Upgrade Domain constraints).</span></span>

<span data-ttu-id="725ff-119">Ниже приведен пример такого отчета о работоспособности.</span><span class="sxs-lookup"><span data-stu-id="725ff-119">Here’s an example of one such health report.</span></span> <span data-ttu-id="725ff-120">В этом случае отчет о работоспособности формируется для одного из разделов системной службы.</span><span class="sxs-lookup"><span data-stu-id="725ff-120">In this case, the health report is for one of the system service’s partitions.</span></span> <span data-ttu-id="725ff-121">Сообщение о работоспособности указывает, что реплики этого раздела временно сгруппированы в слишком малое количество доменов обновления.</span><span class="sxs-lookup"><span data-stu-id="725ff-121">The health message indicates the replicas of that partition are temporarily packed into too few Upgrade Domains.</span></span>

```posh
PS C:\Users\User > Get-WindowsFabricPartitionHealth -PartitionId '00000000-0000-0000-0000-000000000001'


PartitionId           : 00000000-0000-0000-0000-000000000001
AggregatedHealthState : Warning
UnhealthyEvaluations  :
                        Unhealthy event: SourceId='System.PLB', Property='ReplicaConstraintViolation_UpgradeDomain', HealthState='Warning', ConsiderWarningAsError=false.

ReplicaHealthStates   :
                        ReplicaId             : 130766528804733380
                        AggregatedHealthState : Ok

                        ReplicaId             : 130766528804577821
                        AggregatedHealthState : Ok

                        ReplicaId             : 130766528854889931
                        AggregatedHealthState : Ok

                        ReplicaId             : 130766528804577822
                        AggregatedHealthState : Ok

                        ReplicaId             : 130837073190680024
                        AggregatedHealthState : Ok

HealthEvents          :
                        SourceId              : System.PLB
                        Property              : ReplicaConstraintViolation_UpgradeDomain
                        HealthState           : Warning
                        SequenceNumber        : 130837100116930204
                        SentAt                : 8/10/2015 7:53:31 PM
                        ReceivedAt            : 8/10/2015 7:53:33 PM
                        TTL                   : 00:01:05
                        Description           : The Load Balancer has detected a Constraint Violation for this Replica: fabric:/System/FailoverManagerService Secondary Partition 00000000-0000-0000-0000-000000000001 is
                        violating the Constraint: UpgradeDomain Details: UpgradeDomain ID -- 4, Replica on NodeName -- Node.8 Currently Upgrading -- false Distribution Policy -- Packing
                        RemoveWhenExpired     : True
                        IsExpired             : False
                        Transitions           : Ok->Warning = 8/10/2015 7:13:02 PM, LastError = 1/1/0001 12:00:00 AM
```

<span data-ttu-id="725ff-122">В сообщении о работоспособности содержатся следующие сведения:</span><span class="sxs-lookup"><span data-stu-id="725ff-122">Here's what this health message is telling us is:</span></span>

1. <span data-ttu-id="725ff-123">Все реплики находятся в работоспособном состоянии — их свойство AggregatedHealthState имеет значение Ok.</span><span class="sxs-lookup"><span data-stu-id="725ff-123">All the replicas themselves are healthy: Each has AggregatedHealthState : Ok</span></span>
2. <span data-ttu-id="725ff-124">Ограничение распределения в доменах обновления в настоящее время нарушается.</span><span class="sxs-lookup"><span data-stu-id="725ff-124">The Upgrade Domain distribution constraint is currently being violated.</span></span> <span data-ttu-id="725ff-125">Это означает, что в определенном домене обновления больше реплик из данной секции, чем должно быть.</span><span class="sxs-lookup"><span data-stu-id="725ff-125">This means a particular Upgrade Domain has more replicas from this partition than it should.</span></span>
3. <span data-ttu-id="725ff-126">Какой из узлов содержит реплику, которая привела к нарушению.</span><span class="sxs-lookup"><span data-stu-id="725ff-126">Which node contains the replica causing the violation.</span></span> <span data-ttu-id="725ff-127">В данном случае это узел Node.8.</span><span class="sxs-lookup"><span data-stu-id="725ff-127">In this case it's the node with the name "Node.8"</span></span>
4. <span data-ttu-id="725ff-128">Выполняется ли в данный момент обновление этой секции ("Currently Upgrading -- false").</span><span class="sxs-lookup"><span data-stu-id="725ff-128">Whether an upgrade is currently happening for this partition ("Currently Upgrading -- false")</span></span>
5. <span data-ttu-id="725ff-129">Политика распределения для этой службы ("Distribution Policy -- Packing").</span><span class="sxs-lookup"><span data-stu-id="725ff-129">The distribution policy for this service: "Distribution Policy -- Packing".</span></span> <span data-ttu-id="725ff-130">Ею управляет [политика размещения](service-fabric-cluster-resource-manager-advanced-placement-rules-placement-policies.md#requiring-replica-distribution-and-disallowing-packing) `RequireDomainDistribution`.</span><span class="sxs-lookup"><span data-stu-id="725ff-130">This is governed by the `RequireDomainDistribution` [placement policy](service-fabric-cluster-resource-manager-advanced-placement-rules-placement-policies.md#requiring-replica-distribution-and-disallowing-packing).</span></span> <span data-ttu-id="725ff-131">Значение "Packing" означает, что в этом случае распределение в доменах _не_ требовалось, поэтому нам известно, что политика размещения не была указана для этой службы.</span><span class="sxs-lookup"><span data-stu-id="725ff-131">"Packing" indicates that in this case DomainDistribution was _not_ required, so we know that placement policy was not specified for this service.</span></span> 
6. <span data-ttu-id="725ff-132">Время создания отчета (10.08.2015 в 19:13:02).</span><span class="sxs-lookup"><span data-stu-id="725ff-132">When the report happened - 8/10/2015 7:13:02 PM</span></span>

<span data-ttu-id="725ff-133">На основе таких сведений создаются оповещения, которые выводятся в рабочей среде. Они информируют о наличии проблем и позволяют выявлять и останавливать недопустимые обновления.</span><span class="sxs-lookup"><span data-stu-id="725ff-133">Information like this powers alerts that fire in production to let you know something has gone wrong and is also used to detect and halt bad upgrades.</span></span> <span data-ttu-id="725ff-134">В этом случае мы хотели бы узнать, почему диспетчер ресурсов должен группировать реплики в домен обновления.</span><span class="sxs-lookup"><span data-stu-id="725ff-134">In this case, we’d want to see if we can figure out why the Resource Manager had to pack the replicas into the Upgrade Domain.</span></span> <span data-ttu-id="725ff-135">Как правило, группирование является временным и возникает, например, из-за того, что была нарушена работа узлов в других доменах обновления.</span><span class="sxs-lookup"><span data-stu-id="725ff-135">Usually packing is transient because the nodes in the other Upgrade Domains were down, for example.</span></span>

<span data-ttu-id="725ff-136">Предположим, диспетчер кластерных ресурсов пытается разместить определенные службы, но приемлемые решения отсутствуют.</span><span class="sxs-lookup"><span data-stu-id="725ff-136">Let’s say the Cluster Resource Manager is trying to place some services, but there aren't any solutions that work.</span></span> <span data-ttu-id="725ff-137">Если размещение служб невозможно, обычно это происходит по одной из следующих причин:</span><span class="sxs-lookup"><span data-stu-id="725ff-137">When services can't be placed, it is usually for one of the following reasons:</span></span>

1. <span data-ttu-id="725ff-138">Некое переходное условие сделало невозможным правильное размещение этого экземпляра службы или реплики.</span><span class="sxs-lookup"><span data-stu-id="725ff-138">Some transient condition has made it impossible to place this service instance or replica correctly</span></span>
2. <span data-ttu-id="725ff-139">Требования к размещению службы невыполнимы.</span><span class="sxs-lookup"><span data-stu-id="725ff-139">The service’s placement requirements are unsatisfiable.</span></span>

<span data-ttu-id="725ff-140">В этих случаях отчеты о работоспособности от диспетчера кластерных ресурсов помогают определить, почему службу не удается разместить.</span><span class="sxs-lookup"><span data-stu-id="725ff-140">In these cases, health reports from the Cluster Resource Manager help you determine why the service can’t be placed.</span></span> <span data-ttu-id="725ff-141">Этот процесс называется последовательностью устранения ограничений.</span><span class="sxs-lookup"><span data-stu-id="725ff-141">We call this process the constraint elimination sequence.</span></span> <span data-ttu-id="725ff-142">В его ходе система анализирует настроенные ограничения, влияющие на службу, и записывает, что именно они исключают.</span><span class="sxs-lookup"><span data-stu-id="725ff-142">During it, the system walks through the configured constraints affecting the service and records what they eliminate.</span></span> <span data-ttu-id="725ff-143">Таким образом, когда не удается разместить какие-либо службы, можно узнать, какие узлы были исключены и почему.</span><span class="sxs-lookup"><span data-stu-id="725ff-143">This way when services aren’t able to be placed, you can see which nodes were eliminated and why.</span></span>

## <a name="constraint-types"></a><span data-ttu-id="725ff-144">Типы ограничений</span><span class="sxs-lookup"><span data-stu-id="725ff-144">Constraint types</span></span>
<span data-ttu-id="725ff-145">Давайте поговорим о каждом из ограничений в этих отчетах о работоспособности.</span><span class="sxs-lookup"><span data-stu-id="725ff-145">Let’s talk about each of the different constraints in these health reports.</span></span> <span data-ttu-id="725ff-146">Сообщения о работоспособности, связанные с этими ограничениями, отображаются, когда не удается разместить реплики.</span><span class="sxs-lookup"><span data-stu-id="725ff-146">You will see health messages related to these constraints when replicas can't be placed.</span></span>

* <span data-ttu-id="725ff-147">**ReplicaExclusionStatic** и **ReplicaExclusionDynamic**. Эти ограничения указывают, решение было отклонено, так как в противном случае пришлось бы разместить на одном узле два объекта службы из одной и той же секции.</span><span class="sxs-lookup"><span data-stu-id="725ff-147">**ReplicaExclusionStatic** and **ReplicaExclusionDynamic**: These constraints indicates that a solution was rejected because two service objects from the same partition would have to be placed on the same node.</span></span> <span data-ttu-id="725ff-148">Это недопустимо, так как сбой данного узла чрезмерно повлиял бы на эту секцию.</span><span class="sxs-lookup"><span data-stu-id="725ff-148">This isn’t allowed because then failure of that node would overly impact that partition.</span></span> <span data-ttu-id="725ff-149">ReplicaExclusionStatic и ReplicaExclusionDynamic — это практически аналогичные правила, но с незначительными отличиями.</span><span class="sxs-lookup"><span data-stu-id="725ff-149">ReplicaExclusionStatic and ReplicaExclusionDynamic are almost the same rule and the differences don't really matter.</span></span> <span data-ttu-id="725ff-150">Если вы видите последовательность устранения ограничений, содержащую ограничение ReplicaExclusionStatic или ReplicaExclusionDynamic, то диспетчер кластерных ресурсов считает, что узлов недостаточно.</span><span class="sxs-lookup"><span data-stu-id="725ff-150">If you are seeing a constraint elimination sequence containing either the ReplicaExclusionStatic or ReplicaExclusionDynamic constraint, the Cluster Resource Manager thinks that there aren’t enough nodes.</span></span> <span data-ttu-id="725ff-151">Это потребует использовать эти недопустимые размещения в оставшихся решениях, что запрещено.</span><span class="sxs-lookup"><span data-stu-id="725ff-151">This requires remaining solutions to use these invalid placements which are disallowed.</span></span> <span data-ttu-id="725ff-152">Другие ограничения в последовательности, как правило, позволяют определить, почему вообще исключаются узлы.</span><span class="sxs-lookup"><span data-stu-id="725ff-152">The other constraints in the sequence will usually tell us why nodes are being eliminated in the first place.</span></span>
* <span data-ttu-id="725ff-153">**PlacementConstraint**. Это сообщение означает, что некоторые узлы были устранены из-за несоответствия ограничениям на размещение службы.</span><span class="sxs-lookup"><span data-stu-id="725ff-153">**PlacementConstraint**: If you see this message, it means that we eliminated some nodes because they didn’t match the service’s placement constraints.</span></span> <span data-ttu-id="725ff-154">Мы рассматриваем текущие настроенные ограничения на размещения как часть этого сообщения.</span><span class="sxs-lookup"><span data-stu-id="725ff-154">We trace out the currently configured placement constraints as a part of this message.</span></span> <span data-ttu-id="725ff-155">Это нормально, если определено ограничение размещения.</span><span class="sxs-lookup"><span data-stu-id="725ff-155">This is normal if you have a placement constraint defined.</span></span> <span data-ttu-id="725ff-156">Однако если в ограничении размещения имеется ошибка, которая приводит к исключению слишком большого числа узлов, то именно так вы заметите это.</span><span class="sxs-lookup"><span data-stu-id="725ff-156">However, if placement constraint is incorrectly causing too many nodes to be eliminated this is how you would notice.</span></span>
* <span data-ttu-id="725ff-157">**NodeCapacity**. Это ограничение означает, что диспетчер кластерных ресурсов не может размещать реплики на указанных узлах, так как это приведет к превышению их емкости.</span><span class="sxs-lookup"><span data-stu-id="725ff-157">**NodeCapacity**: This constraint means that the Cluster Resource Manager couldn’t place the replicas on the indicated nodes because that would put them over capacity.</span></span>
* <span data-ttu-id="725ff-158">**Affinity**. Это ограничение означает, что нельзя размещать реплики на затронутых узлах, так как это приведет к нарушению ограничения сходства.</span><span class="sxs-lookup"><span data-stu-id="725ff-158">**Affinity**: This constraint indicates that we couldn’t place the replica on the affected nodes since it would cause a violation of the affinity constraint.</span></span> <span data-ttu-id="725ff-159">Дополнительные сведения о сходстве см. в [этой статье](service-fabric-cluster-resource-manager-advanced-placement-rules-affinity.md).</span><span class="sxs-lookup"><span data-stu-id="725ff-159">More information on affinity is in [this article](service-fabric-cluster-resource-manager-advanced-placement-rules-affinity.md)</span></span>
* <span data-ttu-id="725ff-160">**FaultDomain** и **UpgradeDomain**. Эти ограничения исключают узлы, если размещение реплики на указанных узлах привело к упаковке в конкретный домен сбоя или обновления.</span><span class="sxs-lookup"><span data-stu-id="725ff-160">**FaultDomain** and **UpgradeDomain**: This constraint eliminates nodes if placing the replica on the indicated nodes would cause packing in a particular fault or upgrade domain.</span></span> <span data-ttu-id="725ff-161">Несколько примеров, посвященных этому ограничению, представлены в разделе об [ограничениях доменов сбоя и обновления и результирующем поведении](service-fabric-cluster-resource-manager-cluster-description.md).</span><span class="sxs-lookup"><span data-stu-id="725ff-161">Several examples discussing this constraint are presented in the topic on [fault and upgrade domain constraints and resulting behavior](service-fabric-cluster-resource-manager-cluster-description.md)</span></span>
* <span data-ttu-id="725ff-162">**PreferredLocation**. Обычно это ограничение не отображается. Оно приводит к удалению узлов из решения, так как оно выполняется в качестве оптимизации по умолчанию.</span><span class="sxs-lookup"><span data-stu-id="725ff-162">**PreferredLocation**: You shouldn’t normally see this constraint removing nodes from the solution since it runs as an optimization by default.</span></span> <span data-ttu-id="725ff-163">Предпочтительное ограничение размещения также действует во время обновлений.</span><span class="sxs-lookup"><span data-stu-id="725ff-163">The preferred location constraint is also present during upgrades.</span></span> <span data-ttu-id="725ff-164">Оно используется для возврата служб в то расположение, в котором они находились при запуске обновления.</span><span class="sxs-lookup"><span data-stu-id="725ff-164">During upgrade it is used to move services back to where they were when the upgrade started.</span></span>

## <a name="blocklisting-nodes"></a><span data-ttu-id="725ff-165">Добавление узлов в список блокировки</span><span class="sxs-lookup"><span data-stu-id="725ff-165">Blocklisting Nodes</span></span>
<span data-ttu-id="725ff-166">Еще одно сообщение о работоспособности, которое передает диспетчер кластерных ресурсов, информирует о добавлении узлов в список блокировки.</span><span class="sxs-lookup"><span data-stu-id="725ff-166">Another health message the Cluster Resource Manager reports is when nodes are blocklisted.</span></span> <span data-ttu-id="725ff-167">Список блокировки можно считать временным ограничением, которое применяется автоматически.</span><span class="sxs-lookup"><span data-stu-id="725ff-167">You can think of blocklisting as a temporary constraint that is automatically applied for you.</span></span> <span data-ttu-id="725ff-168">Узлы добавляются в список блокировки, когда на них повторяются сбои при запуске экземпляров заданного типа службы.</span><span class="sxs-lookup"><span data-stu-id="725ff-168">Nodes get blocklisted when they experience repeated failures when launching instances of that service type.</span></span> <span data-ttu-id="725ff-169">Узлы добавляются в список блокировки на основе типа службы.</span><span class="sxs-lookup"><span data-stu-id="725ff-169">Nodes are blocklisted on a per-service-type basis.</span></span> <span data-ttu-id="725ff-170">Узел может быть добавлен в список блокировки для одного типа службы, но может отсутствовать в нем для другого типа службы.</span><span class="sxs-lookup"><span data-stu-id="725ff-170">A node may be blocklisted for one service type but not another.</span></span> 

<span data-ttu-id="725ff-171">Добавление в список блокировки часто можно видеть во время разработки: некоторые ошибки приводит к сбою при запуске узла службы.</span><span class="sxs-lookup"><span data-stu-id="725ff-171">You'll see blocklisting kick in often during development: some bug causes your service host to crash on startup.</span></span> <span data-ttu-id="725ff-172">Service Fabric несколько раз пытается создать узел службы, но сбои продолжаются.</span><span class="sxs-lookup"><span data-stu-id="725ff-172">Service Fabric tries to create the service host a few times, and the failure keeps occurring.</span></span> <span data-ttu-id="725ff-173">После нескольких попыток узел будет добавлен в список блокировки, и диспетчер кластерных ресурсов попытается создать службу в другом расположении.</span><span class="sxs-lookup"><span data-stu-id="725ff-173">After a few attempts, the node gets blocklisted, and the Cluster Resource Manager will try to create the service elsewhere.</span></span> <span data-ttu-id="725ff-174">Если этот сбой будет повторяться на нескольких узлах, может случиться так, что все допустимые узлы в кластере окажутся заблокированы.</span><span class="sxs-lookup"><span data-stu-id="725ff-174">If that failure keeps happening on multiple nodes, it's possible that all of the valid nodes in the cluster end up blocked.</span></span> <span data-ttu-id="725ff-175">Добавление в список блокировки может также привести к удалению столь многих узлов, что оставшейся емкости будет недостаточно для успешного запуска службы в требуемом масштабе.</span><span class="sxs-lookup"><span data-stu-id="725ff-175">Blocklisting cna also remove so many nodes that not enough can successfully launch the service to meet the desired scale.</span></span> <span data-ttu-id="725ff-176">Как правило, вы увидите дополнительные ошибки и предупреждения из диспетчера кластерных ресурсов, указывающее, что служба использует меньше требуемого числа реплик или экземпляров, а также сообщения о работоспособности, указывающие на сбой, который изначально приводит к добавлению в список блокировки.</span><span class="sxs-lookup"><span data-stu-id="725ff-176">You'll typically see additional errors or warnings from the Cluster Resource Manager indicating that the service is below the desired replica or instance count, as well as health messages indicating what the failure is that's leading to the blocklisting in the first place.</span></span>

<span data-ttu-id="725ff-177">Добавление в список блокировки не является окончательным.</span><span class="sxs-lookup"><span data-stu-id="725ff-177">Blocklisting is not a permanent condition.</span></span> <span data-ttu-id="725ff-178">Через несколько минут узел удаляется из списка блокировки, и Service Fabric может повторно активировать службы на этом узле.</span><span class="sxs-lookup"><span data-stu-id="725ff-178">After a few minutes, the node is removed from the blocklist and Service Fabric may activate the services on that node again.</span></span> <span data-ttu-id="725ff-179">Если запуск служб по-прежнему завершается сбоем, узел снова добавляется в список блокировки для этого типа службы.</span><span class="sxs-lookup"><span data-stu-id="725ff-179">If services continue to fail, the node is blocklisted for that service type again.</span></span> 

### <a name="constraint-priorities"></a><span data-ttu-id="725ff-180">Приоритеты ограничений</span><span class="sxs-lookup"><span data-stu-id="725ff-180">Constraint priorities</span></span>

> [!WARNING]
> <span data-ttu-id="725ff-181">Изменение приоритетов ограничения не рекомендуется и может иметь значительное отрицательное воздействие на кластер.</span><span class="sxs-lookup"><span data-stu-id="725ff-181">Changing constraint priorities is not recommended and may have significant adverse effects on your cluster.</span></span> <span data-ttu-id="725ff-182">Ниже приведена справочная информация о приоритетах ограничений по умолчанию и их поведении.</span><span class="sxs-lookup"><span data-stu-id="725ff-182">The below information is provided for reference of the default constraint priorities and their behavior.</span></span> 
>

<span data-ttu-id="725ff-183">Изучив все эти ограничения, вы можете прийти к выводу, что ограничения для доменов сбоя — это самый важный аспект в вашей системе.</span><span class="sxs-lookup"><span data-stu-id="725ff-183">With all of these constraints, you may have been thinking “Hey – I think that fault domain constraints are the most important thing in my system.</span></span> <span data-ttu-id="725ff-184">Чтобы обеспечить отсутствие нарушений ограничения для доменов сбоя, мне стоит нарушать другие ограничения".</span><span class="sxs-lookup"><span data-stu-id="725ff-184">In order to ensure the fault domain constraint isn't violated, I’m willing to violate other constraints.”</span></span>

<span data-ttu-id="725ff-185">Для ограничений можно настроить различные уровни приоритета,</span><span class="sxs-lookup"><span data-stu-id="725ff-185">Constraints can be configured with different priority levels.</span></span> <span data-ttu-id="725ff-186">а именно:</span><span class="sxs-lookup"><span data-stu-id="725ff-186">These are:</span></span>

   - <span data-ttu-id="725ff-187">"жесткий" (0);</span><span class="sxs-lookup"><span data-stu-id="725ff-187">“hard” (0)</span></span>
   - <span data-ttu-id="725ff-188">"мягкий" (1);</span><span class="sxs-lookup"><span data-stu-id="725ff-188">“soft” (1)</span></span>
   - <span data-ttu-id="725ff-189">"оптимизационный" (2);</span><span class="sxs-lookup"><span data-stu-id="725ff-189">“optimization” (2)</span></span>
   - <span data-ttu-id="725ff-190">"отключен" (-1).</span><span class="sxs-lookup"><span data-stu-id="725ff-190">“off” (-1).</span></span> 
   
<span data-ttu-id="725ff-191">Большинство ограничений по умолчанию настроено как жесткие ограничения.</span><span class="sxs-lookup"><span data-stu-id="725ff-191">Most of the constraints are configured as hard constraints by default.</span></span>

<span data-ttu-id="725ff-192">Изменение приоритета ограничения происходит редко.</span><span class="sxs-lookup"><span data-stu-id="725ff-192">Changing the priority of constraints is uncommon.</span></span> <span data-ttu-id="725ff-193">Случались ситуации, в которых приоритеты ограничений требовалось изменить, обычно для обхода каких-либо ошибок или поведения, которое влияло на среду.</span><span class="sxs-lookup"><span data-stu-id="725ff-193">There have been times where constraint priorities needed to change, usually to work around some other bug or behavior that was impacting the environment.</span></span> <span data-ttu-id="725ff-194">Обычно гибкость инфраструктуры приоритета ограничений давала положительные результаты, но зачастую она не нужна.</span><span class="sxs-lookup"><span data-stu-id="725ff-194">Generally the flexibility of the constraint priority infrastructure has worked very well, but it isn't needed often.</span></span> <span data-ttu-id="725ff-195">В большинстве случаев все ограничения сохраняют свои приоритеты.</span><span class="sxs-lookup"><span data-stu-id="725ff-195">Most of the time everything sits at their default priorities.</span></span> 

<span data-ttu-id="725ff-196">Уровни приоритета не означают ни то, что данное ограничение _будет_ нарушено, ни то, что оно всегда будет выполняться.</span><span class="sxs-lookup"><span data-stu-id="725ff-196">The priority levels don't mean that a given constraint _will_ be violated, nor that it will always be met.</span></span> <span data-ttu-id="725ff-197">Приоритеты ограничений определяют порядок, в котором накладываются ограничения.</span><span class="sxs-lookup"><span data-stu-id="725ff-197">Constraint priorities define an order in which constraints are enforced.</span></span> <span data-ttu-id="725ff-198">Приоритеты определяют компромиссы на случай, если невозможно выполнить все ограничения.</span><span class="sxs-lookup"><span data-stu-id="725ff-198">Priorities define the tradeoffs when it is impossible to satisfy all constraints.</span></span> <span data-ttu-id="725ff-199">Обычно все ограничения могут быть выполнены, если только в среде не выполняется что-то еще.</span><span class="sxs-lookup"><span data-stu-id="725ff-199">Usually all the constraints can be satisfied unless there's something else going on in the environment.</span></span> <span data-ttu-id="725ff-200">К примерам ситуаций, которые приводят к нарушениям ограничений, можно отнести конфликтующие ограничения или большое число одновременных сбоев.</span><span class="sxs-lookup"><span data-stu-id="725ff-200">Some examples of scenarios that will lead to constraint violations are conflicting constraints, or large numbers of concurrent failures.</span></span>

<span data-ttu-id="725ff-201">В сложных ситуациях приоритеты ограничений можно изменить.</span><span class="sxs-lookup"><span data-stu-id="725ff-201">In advanced situations, you can change the constraint priorities.</span></span> <span data-ttu-id="725ff-202">Например, вы хотите разрешить нарушение ограничений сходства ради устранения проблем с емкостью узла.</span><span class="sxs-lookup"><span data-stu-id="725ff-202">For example, say you wanted to ensure that affinity would always be violated when necessary to solve node capacity issues.</span></span> <span data-ttu-id="725ff-203">Для этого вы можете задать для ограничений сходства "мягкий" приоритет (1), а для ограничений емкости оставить "жесткий" приоритет (0).</span><span class="sxs-lookup"><span data-stu-id="725ff-203">To achieve this, you could set the priority of the affinity constraint to “soft” (1) and leave the capacity constraint set to “hard” (0).</span></span>

<span data-ttu-id="725ff-204">Ниже перечислены значения приоритета по умолчанию для различных ограничений, указанных в приведенной ниже конфигурации.</span><span class="sxs-lookup"><span data-stu-id="725ff-204">The default priority values for the different constraints are specified in the following config:</span></span>

<span data-ttu-id="725ff-205">ClusterManifest.xml</span><span class="sxs-lookup"><span data-stu-id="725ff-205">ClusterManifest.xml</span></span>

```xml
        <Section Name="PlacementAndLoadBalancing">
            <Parameter Name="PlacementConstraintPriority" Value="0" />
            <Parameter Name="CapacityConstraintPriority" Value="0" />
            <Parameter Name="AffinityConstraintPriority" Value="0" />
            <Parameter Name="FaultDomainConstraintPriority" Value="0" />
            <Parameter Name="UpgradeDomainConstraintPriority" Value="1" />
            <Parameter Name="PreferredLocationConstraintPriority" Value="2" />
        </Section>
```

<span data-ttu-id="725ff-206">Для автономных развертываний используется ClusterConfig.json, а для размещенных в Azure кластеров — Template.json.</span><span class="sxs-lookup"><span data-stu-id="725ff-206">via ClusterConfig.json for Standalone deployments or Template.json for Azure hosted clusters:</span></span>

```json
"fabricSettings": [
  {
    "name": "PlacementAndLoadBalancing",
    "parameters": [
      {
          "name": "PlacementConstraintPriority",
          "value": "0"
      },
      {
          "name": "CapacityConstraintPriority",
          "value": "0"
      },
      {
          "name": "AffinityConstraintPriority",
          "value": "0"
      },
      {
          "name": "FaultDomainConstraintPriority",
          "value": "0"
      },
      {
          "name": "UpgradeDomainConstraintPriority",
          "value": "1"
      },
      {
          "name": "PreferredLocationConstraintPriority",
          "value": "2"
      }
    ]
  }
]
```

## <a name="fault-domain-and-upgrade-domain-constraints"></a><span data-ttu-id="725ff-207">Ограничения доменов сбоя и обновления</span><span class="sxs-lookup"><span data-stu-id="725ff-207">Fault domain and upgrade domain constraints</span></span>
<span data-ttu-id="725ff-208">Диспетчер кластерных ресурсов старается распределять службы между доменами сбоя и доменами обновления.</span><span class="sxs-lookup"><span data-stu-id="725ff-208">The Cluster Resource Manager wants to keep services spread out among fault and upgrade domains.</span></span> <span data-ttu-id="725ff-209">Эта стратегия моделируется как ограничение внутри ядра диспетчера кластерных ресурсов.</span><span class="sxs-lookup"><span data-stu-id="725ff-209">It models this as a constraint inside the Cluster Resource Manager’s engine.</span></span> <span data-ttu-id="725ff-210">Дополнительные сведения об использовании ограничений и описание их поведения приведены в разделе [Ограничения доменов сбоя и обновления и соответствующее поведение](service-fabric-cluster-resource-manager-cluster-description.md#fault-and-upgrade-domain-constraints-and-resulting-behavior).</span><span class="sxs-lookup"><span data-stu-id="725ff-210">For more information on how they are used and their specific behavior, check out the article on [cluster configuration](service-fabric-cluster-resource-manager-cluster-description.md#fault-and-upgrade-domain-constraints-and-resulting-behavior).</span></span>

<span data-ttu-id="725ff-211">Диспетчеру кластерных ресурсов может потребоваться сгруппировать пару реплик в домен обновления, чтобы устранить проблемы, связанные с обновлениями, сбоями или другими нарушениями ограничений.</span><span class="sxs-lookup"><span data-stu-id="725ff-211">The Cluster Resource Manager may need to pack a couple replicas into an upgrade domain in order to deal with upgrades, failures, or other constraint violations.</span></span> <span data-ttu-id="725ff-212">Группирование в домены сбоя или домены обновления обычно происходит только при наличии нескольких сбоев или других сложностей в системе, мешающих правильному размещению.</span><span class="sxs-lookup"><span data-stu-id="725ff-212">Packing into fault or upgrade domains normally happens only when there are several failures or other churn in the system preventing correct placement.</span></span> <span data-ttu-id="725ff-213">Если вы хотите предотвратить группирование даже в таких ситуациях, можно использовать [политику размещения](service-fabric-cluster-resource-manager-advanced-placement-rules-placement-policies.md#requiring-replica-distribution-and-disallowing-packing) `RequireDomainDistribution`.</span><span class="sxs-lookup"><span data-stu-id="725ff-213">If you wish to prevent packing even during these situations, you can utilize the `RequireDomainDistribution` [placement policy](service-fabric-cluster-resource-manager-advanced-placement-rules-placement-policies.md#requiring-replica-distribution-and-disallowing-packing).</span></span> <span data-ttu-id="725ff-214">Обратите внимание, что это может вызвать побочные эффекты, затрагивающие доступность и надежность службы, поэтому следует проявить осторожность.</span><span class="sxs-lookup"><span data-stu-id="725ff-214">Note that this may affect service availability and reliability as a side effect, so consider it carefully.</span></span>

<span data-ttu-id="725ff-215">Если среда настроена правильно, то все ограничения полностью соблюдаются даже во время обновлений.</span><span class="sxs-lookup"><span data-stu-id="725ff-215">If the environment is configured correctly, all constraints are fully respected, even during upgrades.</span></span> <span data-ttu-id="725ff-216">Ключевой момент заключается в том, что диспетчер кластерных ресурсов наблюдает за вашими ограничениями.</span><span class="sxs-lookup"><span data-stu-id="725ff-216">The key thing is that the Cluster Resource Manager is watching out for your constraints.</span></span> <span data-ttu-id="725ff-217">При обнаружении нарушения он немедленно сообщает об этом и пытается устранить проблему.</span><span class="sxs-lookup"><span data-stu-id="725ff-217">When it detects a violation it immediately reports it and tries to correct the issue.</span></span>

## <a name="the-preferred-location-constraint"></a><span data-ttu-id="725ff-218">Ограничение на предпочтительное расположение</span><span class="sxs-lookup"><span data-stu-id="725ff-218">The preferred location constraint</span></span>
<span data-ttu-id="725ff-219">Ограничение PreferredLocation немного отличается от остальных, так как имеет два варианта использования.</span><span class="sxs-lookup"><span data-stu-id="725ff-219">The PreferredLocation constraint is a little different, as it has two different uses.</span></span> <span data-ttu-id="725ff-220">Во-первых, это ограничение применяется во время обновления приложений.</span><span class="sxs-lookup"><span data-stu-id="725ff-220">One use of this constraint is during application upgrades.</span></span> <span data-ttu-id="725ff-221">Диспетчер кластерных ресурсов автоматически управляет этим ограничением во время обновлений.</span><span class="sxs-lookup"><span data-stu-id="725ff-221">The Cluster Resource Manager automatically manages this constraint during upgrades.</span></span> <span data-ttu-id="725ff-222">Оно обеспечивает возврат реплик в исходные расположения после завершения обновлений.</span><span class="sxs-lookup"><span data-stu-id="725ff-222">It is used to ensure that when upgrades are complete that replicas return to their initial locations.</span></span> <span data-ttu-id="725ff-223">Во-вторых, ограничение PreferredLocation используется для [политики размещения](service-fabric-cluster-resource-manager-advanced-placement-rules-placement-policies.md) `PreferredPrimaryDomain`.</span><span class="sxs-lookup"><span data-stu-id="725ff-223">The other use of the PreferredLocation constraint is for the [`PreferredPrimaryDomain` placement policy](service-fabric-cluster-resource-manager-advanced-placement-rules-placement-policies.md).</span></span> <span data-ttu-id="725ff-224">Оба варианта использования являются оптимизацией, поэтому ограничение PreferredLocation — единственное ограничение с "оптимизационным" приоритетом по умолчанию.</span><span class="sxs-lookup"><span data-stu-id="725ff-224">Both of these are optimizations, and hence the PreferredLocation constraint is the only constraint set to "Optimization" by default.</span></span>

## <a name="upgrades"></a><span data-ttu-id="725ff-225">Обновления</span><span class="sxs-lookup"><span data-stu-id="725ff-225">Upgrades</span></span>
<span data-ttu-id="725ff-226">Диспетчер кластерных ресурсов также помогает во время обновлений приложения и кластера. Он выполняет следующие задания:</span><span class="sxs-lookup"><span data-stu-id="725ff-226">The Cluster Resource Manager also helps during application and cluster upgrades, during which it has two jobs:</span></span>

* <span data-ttu-id="725ff-227">обеспечивает соблюдение правил кластера;</span><span class="sxs-lookup"><span data-stu-id="725ff-227">ensure that the rules of the cluster are not compromised</span></span>
* <span data-ttu-id="725ff-228">обеспечивает плавное выполнение обновления.</span><span class="sxs-lookup"><span data-stu-id="725ff-228">try to help the upgrade go smoothly</span></span>

### <a name="keep-enforcing-the-rules"></a><span data-ttu-id="725ff-229">Применение правил</span><span class="sxs-lookup"><span data-stu-id="725ff-229">Keep enforcing the rules</span></span>
<span data-ttu-id="725ff-230">В первую очередь следует иметь в виду, что правила (такие строгие ограничения, как ограничения размещения и емкости) по-прежнему действуют во время обновлений.</span><span class="sxs-lookup"><span data-stu-id="725ff-230">The main thing to be aware of is that the rules – the strict constraints like placement constraints and capacities - are still enforced during upgrades.</span></span> <span data-ttu-id="725ff-231">Ограничения на размещение гарантируют, что все ваши рабочие нагрузки выполняются только на определенных узлах даже во время обновления.</span><span class="sxs-lookup"><span data-stu-id="725ff-231">Placement constraints ensure that your workloads only run where they are allowed to, even during upgrades.</span></span> <span data-ttu-id="725ff-232">При высокой ограниченности служб обновления могут занимать больше времени.</span><span class="sxs-lookup"><span data-stu-id="725ff-232">When services are highly constrained, upgrades can take longer.</span></span> <span data-ttu-id="725ff-233">Если служба или узел, на котором она выполняется, отключается для обновления, доступно несколько вариантов для перемещения этой службы или узла.</span><span class="sxs-lookup"><span data-stu-id="725ff-233">When the service or the node it is running on is brought down for an update there may be few options for where it can go.</span></span>

### <a name="smart-replacements"></a><span data-ttu-id="725ff-234">Интеллектуальные замены</span><span class="sxs-lookup"><span data-stu-id="725ff-234">Smart replacements</span></span>
<span data-ttu-id="725ff-235">При запуске обновления диспетчер ресурсов создает моментальный снимок текущего размещения кластера.</span><span class="sxs-lookup"><span data-stu-id="725ff-235">When an upgrade starts, the Resource Manager takes a snapshot of the current arrangement of the cluster.</span></span> <span data-ttu-id="725ff-236">Когда каждый домен обновления завершает обновление, он пытается вернуть службы, которые были размещены в этом домене обновления, в их исходное расположение.</span><span class="sxs-lookup"><span data-stu-id="725ff-236">As each Upgrade Domain completes, it attempts to return the services that were in that Upgrade Domain to their original arrangement.</span></span> <span data-ttu-id="725ff-237">Таким образом во время обновления служба перемещается не более двух раз.</span><span class="sxs-lookup"><span data-stu-id="725ff-237">This way there are at most two transitions for a service during the upgrade.</span></span> <span data-ttu-id="725ff-238">Один раз она перемещается с затронутого узла, второй раз — обратно на этот узел.</span><span class="sxs-lookup"><span data-stu-id="725ff-238">There is one move out of the affected node and one move back in.</span></span> <span data-ttu-id="725ff-239">Возврат кластера или службы в исходное расположение до обновления гарантирует также, что обновление не окажет влияния на структуру кластера.</span><span class="sxs-lookup"><span data-stu-id="725ff-239">Returning the cluster or service to how it was before the upgrade also ensures the upgrade doesn’t impact the layout of the cluster.</span></span> 

### <a name="reduced-churn"></a><span data-ttu-id="725ff-240">Сокращение оттока</span><span class="sxs-lookup"><span data-stu-id="725ff-240">Reduced churn</span></span>
<span data-ttu-id="725ff-241">Во время обновлений происходит еще кое-что — диспетчер кластерных ресурсов отключает балансировку.</span><span class="sxs-lookup"><span data-stu-id="725ff-241">Another thing that happens during upgrades is that the Cluster Resource Manager turns off balancing.</span></span> <span data-ttu-id="725ff-242">Отключение балансировки позволяет избежать ненужной реакции системы на само обновление, например избежать переноса служб на узлы, очищенные для обновления.</span><span class="sxs-lookup"><span data-stu-id="725ff-242">Preventing balancing prevents unnecessary reactions to the upgrade itself, like moving services into nodes that were emptied for the upgrade.</span></span> <span data-ttu-id="725ff-243">Если рассматривается обновление кластера, то на время обновления приостанавливается балансировка во всем кластере.</span><span class="sxs-lookup"><span data-stu-id="725ff-243">If the upgrade in question is a Cluster upgrade, then the entire cluster is not balanced during the upgrade.</span></span> <span data-ttu-id="725ff-244">Проверки ограничений остаются включенными, отключается только перемещение на основе упреждающей балансировки метрик.</span><span class="sxs-lookup"><span data-stu-id="725ff-244">Constraint checks stay active, only movement based on the proactive balancing of metrics is disabled.</span></span>

### <a name="buffered-capacity--upgrade"></a><span data-ttu-id="725ff-245">Буферизованная емкость и обновление</span><span class="sxs-lookup"><span data-stu-id="725ff-245">Buffered Capacity & Upgrade</span></span>
<span data-ttu-id="725ff-246">Обычно возникает необходимость завершить обновление, даже если кластер ограничен или почти заполнен.</span><span class="sxs-lookup"><span data-stu-id="725ff-246">Generally you want the upgrade to complete even if the cluster is constrained or close to full.</span></span> <span data-ttu-id="725ff-247">Управление емкостью кластера во время обновлений даже важнее, чем обычно.</span><span class="sxs-lookup"><span data-stu-id="725ff-247">Managing the capacity of the cluster is even more important during upgrades than usual.</span></span> <span data-ttu-id="725ff-248">При развертывании обновления в кластере требуется перенос от 5 до 20 процентов от общей емкости, в зависимости от числа доменов обновления.</span><span class="sxs-lookup"><span data-stu-id="725ff-248">Depending on the number of upgrade domains, between 5 and 20 percent of capacity must be migrated as the upgrade rolls through the cluster.</span></span> <span data-ttu-id="725ff-249">Эту нагрузку нужно перенаправить.</span><span class="sxs-lookup"><span data-stu-id="725ff-249">That work has to go somewhere.</span></span> <span data-ttu-id="725ff-250">Именно здесь пригодится понятие [буферизованных емкостей](service-fabric-cluster-resource-manager-cluster-description.md#buffered-capacity).</span><span class="sxs-lookup"><span data-stu-id="725ff-250">This is where the notion of [buffered capacities](service-fabric-cluster-resource-manager-cluster-description.md#buffered-capacity) is useful.</span></span> <span data-ttu-id="725ff-251">Буферизованная емкость учитывается во время обычной работы.</span><span class="sxs-lookup"><span data-stu-id="725ff-251">Buffered capacity is respected during normal operation.</span></span> <span data-ttu-id="725ff-252">При необходимости во время обновлений диспетчер кластерных ресурсов может заполнить узлы вплоть до их общей емкости (использовав буфер).</span><span class="sxs-lookup"><span data-stu-id="725ff-252">The Cluster Resource Manager may fill nodes up to their total capacity (consuming the buffer) during upgrades if necessary.</span></span>

## <a name="next-steps"></a><span data-ttu-id="725ff-253">Дальнейшие действия</span><span class="sxs-lookup"><span data-stu-id="725ff-253">Next steps</span></span>
* <span data-ttu-id="725ff-254">Начните с самого начала, [изучив общие сведения о диспетчере кластерных ресурсов Service Fabric](service-fabric-cluster-resource-manager-introduction.md)</span><span class="sxs-lookup"><span data-stu-id="725ff-254">Start from the beginning and [get an Introduction to the Service Fabric Cluster Resource Manager](service-fabric-cluster-resource-manager-introduction.md)</span></span>
