---
title: "aaaCommon вопросы о Microsoft Azure Service Fabric | Документы Microsoft"
description: "Часто задаваемые вопросы о Service Fabric и ответы на них"
services: service-fabric
documentationcenter: .net
author: chackdan
manager: timlt
editor: 
ms.assetid: 5a179703-ff0c-4b8e-98cd-377253295d12
ms.service: service-fabric
ms.devlang: dotnet
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: na
ms.date: 08/18/2017
ms.author: chackdan
ms.openlocfilehash: 4cbe92d2a03f7a1ea5d077807fdc982288220a7e
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 10/06/2017
---
# <a name="commonly-asked-service-fabric-questions"></a>Распространенные вопросы о Service Fabric

Пользователи задают множество схожих вопросов о возможностях и использовании Service Fabric. В этом документе приведены ответы на многие из этих вопросов.

## <a name="cluster-setup-and-management"></a>Настройка кластера и управление им

### <a name="can-i-create-a-cluster-that-spans-multiple-azure-regions-or-my-own-datacenters"></a>Можно ли создать кластер, охватывающий несколько регионов Azure или моих центров обработки данных?

Да. 

Hello core Service Fabric Технология кластеризации может быть используется toocombine машины, работающие в любом месте в Здравствуй, мир, при условии, что они имеют сетевого подключения tooeach других. Однако создание и запуск такого кластера может оказаться сложной задачей.

Если вы заинтересованы в этом сценарии, рекомендуем tooget контакта либо с помощью hello [списка проблем службы структуры Github](https://github.com/azure/service-fabric-issues) или с помощью представителю службы поддержки в порядке tooobtain Дополнительные рекомендации. группы Service Fabric Hello работает tooprovide ясности, руководство и рекомендации для этого сценария. 

Tooconsider некоторые вещи: 

1. Hello ресурса кластера Service Fabric в Azure сегодня является региональным, как данный кластер hello наборов масштабирования виртуальных машин hello основана на. Это означает, что в событии hello региональные сбоя может потерять hello возможность toomanage hello кластера через hello Azure Resource Manager hello портала Azure. Это может произойти, даже если hello кластер продолжает работать и будет toointeract может с ним напрямую. Кроме того Azure сегодня не предлагает возможность toohave hello одной виртуальной сети, которое можно использовать в разных регионах. Это означает, что в нескольких регионах кластере в Azure либо [общих IP-адресов для каждой виртуальной Машины в hello набора масштабирования виртуальных Машин](../virtual-machine-scale-sets/virtual-machine-scale-sets-networking.md#public-ipv4-per-virtual-machine) или [VPN-шлюзы Azure](../vpn-gateway/vpn-gateway-about-vpngateways.md). Эти сетевые параметры имеют влияние различных на затраты, производительности и toosome степень при разработке приложения, поэтому перед обеспечивает такой среде требуется тщательного анализа и планирования.
2. Hello обслуживания, управление и мониторинг этих машин может стать сложной, особенно в том случае, если распределены по _типы_ сред, например между разных поставщиков облачных служб, а также между локальными ресурсами и Azure . Следует соблюдать осторожность, обновляемый tooensure, мониторинга, управления и диагностики, применимые для кластера hello и приложения hello перед выполнением рабочих нагрузок в такой среде. Если у вас уже имеется значительный опыт решения этих задач в Azure или в собственных центрах обработки данных, скорее всего, аналогичные решения можно будет применить для создания или выполнения кластера Service Fabric. 

### <a name="do-service-fabric-nodes-automatically-receive-os-updates"></a>Получают ли узлы Service Fabric обновления операционной системы автоматически?

Не в настоящее время, но это также распространенный тип запросов, Azure планирует toodeliver.

В промежуточном hello, у нас есть [предоставленный приложения](service-fabric-patch-orchestration-application.md) , hello операционных систем, под Service Fabric узлы остаются программного обеспечения, установленного и копирование toodate.

Задача Hello с обновлениями операционной системы —, обычно требуется перезагрузка hello компьютере, что приводит к потере доступности временный. Сам по себе это не проблема, поскольку Service Fabric автоматически будет перенаправлять трафик для этих узлов tooother служб. Тем не менее если обновления ОС не координируются кластеру hello, есть риск hello множество узлов одновременно прекращает работу. Такие одновременные перезагрузки могут привести к полной потере доступности службы или как минимум определенного раздела (для службы с отслеживанием состояния).

В будущем hello мы планируем toosupport ОС политики обновления, которое полностью автоматических и координация между доменами обновления, гарантируя, что доступность сохраняется несмотря на после перезагрузки и других непредвиденных сбоев.

### <a name="can-i-use-large-virtual-machine-scale-sets-in-my-sf-cluster"></a>Можно ли использовать большие масштабируемые наборы виртуальных машин в кластере Service Fabric? 

**Краткий ответ**. Нет. 

**Время ответа на** — несмотря на то, что hello большие наборы масштабирования виртуальной машины позволяют tooscale набора масштабирования виртуальных машин, не более 1000 экземпляров виртуальных Машин, это делается путем использования hello размещение групп (PGs). Ошибки доменах отказоустойчивости и обновления доменах согласованы только в размещение группы структуры использует сбоя и доменам обновления toomake размещения решений, принятых экземпляров служб реплики или службы. Поскольку сравнимы hello сбоя и доменам обновления только в пределах группы размещения SF его нельзя использовать. Например, если VM1 в PG1 топологии FD = 0 и VM9 в PG2 имеет топологии FD = 4, это не значит, что VM1 и VM2 находятся на двух разных аппаратных стойках, таким образом SF нельзя использовать значения hello FD этого решения toomake вариантов размещения.

Как поддержка балансировки нагрузки уровня 4 hello отсутствие в настоящее время существуют другие проблемы с большой виртуальной машины набора масштабирования. См. toofor [сведения о больших масштабировать наборов](../virtual-machine-scale-sets/virtual-machine-scale-sets-placement-groups.md)



### <a name="what-is-hello-minimum-size-of-a-service-fabric-cluster-why-cant-it-be-smaller"></a>Что такое hello минимальный размер кластера Service Fabric Почему он не может быть меньше?

Минимальный поддерживаемый размер Hello выполнение рабочих нагрузок кластера Service Fabric — пять узлов. Для сценариев разработки и тестирования мы поддерживаем кластеры из трех узлов.

Эти минимальные значения существуют, поскольку кластер Service Fabric hello выполняет набор служб с отслеживанием состояния системы, включая службы имен hello и диспетчера отказоустойчивости hello. Эти службы, которые следят за службы, которые были развернуты toohello кластера и там, где они в настоящее время размещены, зависят от строгая согласованность. В свою очередь, зависит от возможности tooacquire hello, строгая согласованность *кворума* для любого данного обновления службы состояние toohello те из них, где кворума представляет strict большинство hello реплик (N/2 + 1) для данной службы.

С учетом этого давайте рассмотрим некоторые возможные конфигурации кластера.

**Один узел**: этот параметр не обеспечения высокого уровня доступности, поскольку потеря hello hello один узел для какой-либо причине означает потерю hello hello всего кластера.

**Два узла.** Кворум для службы, развернутой на двух узлах (N = 2), составляет 2 узла (2/2 + 1 = 2). Когда одна реплика теряется, это невозможно toocreate кворума. Так как обновление службы требует временного отключения реплики, эта конфигурация бесполезна.

**Три узла**: с тремя узлами (N = 3) toocreate hello требование кворума по-прежнему два узла (3/2 + 1 = 2). Это означает, что можно потерять один узел и по-прежнему сохранить кворум.

Hello три узла кластера конфигурация поддерживается для разработки и тестирования так, как можно выполнять обновление и сбоев отдельных узлов, сохраняются до тех пор, пока они не осуществляется одновременно. Для рабочих нагрузок должны быть устойчивыми toosuch одновременном сбое, поэтому требуются пять узлы.

### <a name="can-i-turn-off-my-cluster-at-nightweekends-toosave-costs"></a>Можно ли отключить кластер по цене toosave ночи и выходные дни

Как правило, нет. Service Fabric сохраняет состояние на локальных дисках эфемерных, это означает, что если виртуальная машина hello перемещенный tooa другой узел, hello данные не перемещаются вместе с ним. В нормальных условиях это не проблема как hello новый узел не станет активным toodate с другими узлами. Тем не менее все узлы остановить и перезапустить их позже, существует ли значительные вероятность того, что большая часть узлов hello запустить на новые узлы и сделать не удается toorecover hello системы.

При желании toocreate кластеры для тестирования приложения перед его развертыванием, мы рекомендуем динамически создавать эти кластеры как часть вашего [непрерывной интеграции и непрерывного развертывания конвейера](service-fabric-set-up-continuous-integration.md).


### <a name="how-do-i-upgrade-my-operating-system-for-example-from-windows-server-2012-toowindows-server-2016"></a>Как обновить Мои операционной системы (например, из tooWindows Windows Server 2012 Server 2016)?

Хотя мы работаем над улучшенное взаимодействие, в настоящее время вы несете ответственность за hello обновления. Необходимо обновить образ ОС hello на hello виртуальных машин из hello кластера одной виртуальной Машины одновременно. 

## <a name="container-support"></a>Поддержка контейнеров

### <a name="why-are-my-containers-that-are-deployed-toosf-unable-tooresolve-dns-addresses"></a>Почему — это контейнеры, my, не удается tooresolve развернутой tooSF DNS адрес?

Эта проблема обнаружена в кластерах версии 5.6.204.9494. 

**Устранение рисков** : выполните [в этом документе](service-fabric-dnsservice.md) tooenable hello DNS службы service fabric в кластере.

**Исправьте** : версия обновления tooa поддерживается кластера, больше, чем 5.6.204.9494, если оно доступно. Если кластер tooautomatic обновления, hello кластера автоматически обновит toohello версию, которая содержит эта проблема устранена.

  
## <a name="application-design"></a>Проектирование приложений

### <a name="whats-hello-best-way-tooquery-data-across-partitions-of-a-reliable-collection"></a>Что такое hello лучший способ tooquery данные в секциях надежного коллекции

Надежные коллекции, обычно являются [секционированных](service-fabric-concepts-partitioning.md) tooenable горизонтального масштабирования для более высокую производительность и пропускную способность. Это означает, что состояние hello для данной службы могут быть распределены между десятках или сотнях компьютеров. tooperform операций над полного набора данных, имеется несколько параметров.

- Создайте службу, которая запрашивает все разделы из другой службы toopull hello необходимых данных.
- Создать службу, которая может получать данные из всех разделов другой службы.
- Периодически отправлять данные из каждого внешнего хранилища tooan службы. Этот подход используется, только если для выполнения запросов hello не являются частью основной бизнес-логики.


### <a name="whats-hello-best-way-tooquery-data-across-my-actors"></a>Что такое hello лучшим способом tooquery данные через my субъекты

Субъекты, спроектированный toobe независимые единицы состояния и вычислений, поэтому не рекомендуется tooperform общих запросов состояния субъекта во время выполнения. При наличии tooquery необходимость во множестве hello полного состояния субъекта, следует либо:

- Заменив субъекта служб с отслеживанием состояния надежные службы таким образом, что hello число сетевых запросов toogather все данные из числа hello субъекты toohello количество секций в службе.
- Проектирование передачу tooperiodically субъекты их tooan внешнего хранилища состояний для упрощения выполнения запросов. Как выше, этот подход работоспособно только при выполнении запросов hello не являются обязательными для вашей поведения во время выполнения.

### <a name="how-much-data-can-i-store-in-a-reliable-collection"></a>Сколько данных можно сохранить в Reliable Collection?

Надежные службы обычно секционирована, поэтому сумма hello, которые можно хранить ограничивается только hello количество машин в кластере hello и hello объем доступной памяти на этих компьютерах.

Например, предположим, что есть Reliable Collection в службе со 100 разделами и 3 репликами для хранения объектов со средним размером 1 КБ. Теперь предположим, что имеется кластер из 10 компьютеров с 16 ГБ памяти на каждом компьютере. Для простоты и очень консервативной toobe Предположим, что hello операционной системы и системные службы, среда выполнения Service Fabric hello и службам принимать 6 ГБ, оставляя 10 ГБ на один компьютер или 100 ГБ для hello кластера.

Учитывая, что каждый объект должен быть сохранен трижды (основная копия и две реплики), памяти будет достаточно примерно для 35 миллионов объектов в коллекции при полной загрузке. Тем не менее рекомендуется устойчивым toohello одновременных потери домена сбоя и домене обновления, представляющего примерно треть емкости и уменьшится hello номеров tooroughly 23 миллионов.

Обратите внимание, что в этой оценке также предполагается следующее.

- Что hello распределение данных по секциям hello примерно универсальный или сообщении toohello метрики нагрузки диспетчер ресурсов кластера. По умолчанию Service Fabric будет распределять нагрузку, исходя из числа реплик. В приведенном выше примере, поместить 10 первичных реплик и 20 вторичных реплик на каждом узле в кластере hello. Хорошо подходит для нагрузки, который распределяется равномерно между hello секций. Если загрузка не совпадает, вы сообщаете нагрузки, hello диспетчер ресурсов можно вместе с пакетом обновления меньшего размера реплики и предоставлении дополнительной памяти размером tooconsume реплик на отдельный узел.

- Что hello надежной службы рассматриваемой — только один хранение состояние hello в кластере hello. Так как можно развернуть несколько служб tooa кластера, необходимы toobe учитывать hello ресурсов, каждый будет необходима toorun и управлять его состояние.

- Самого кластера, hello не увеличивается и уменьшается. При добавлении нескольких компьютеров, Service Fabric будет балансирования вашей tooleverage реплик hello дополнительную емкость до hello число машин превосходит hello количество секций в службе, так как отдельные реплика не может охватывать машины. Напротив Если уменьшить размер hello hello кластера путем удаления машины, реплики будет более плотно и меньший объем общей памяти.

### <a name="how-much-data-can-i-store-in-an-actor"></a>Сколько данных можно хранить в субъекте?

С помощью надежного обмена hello объем данных, которые могут храниться в службу субъектов ограничивается только hello общего места на диске и памяти, доступной через hello узлов в кластере. Однако отдельные субъекты наиболее эффективны, по мере используется tooencapsulate небольшой объем состояния и связанные с бизнес-логики. Как правило, состояние отдельного субъекта должно измеряться в килобайтах.

## <a name="other-questions"></a>Другие вопросы

### <a name="how-does-service-fabric-relate-toocontainers"></a>Как Service Fabric связаны toocontainers

Контейнеры обеспечивают простой способ toopackage служб и их зависимости, таким образом, что они запуска согласованно во всех средах и могут работать в изолированном режиме на одном компьютере. Service Fabric предлагает toodeploy способом и управления службами, включая [, упакованные в контейнере службы](service-fabric-containers-overview.md).

### <a name="are-you-planning-tooopen-source-service-fabric"></a>Планируется ли источник tooopen Service Fabric?

Мы планировалось tooopen источника hello надежные службы и службы reliable Actor платформы на GitHub и будет принимать проекты toothose вклады сообщества. Следуйте инструкциям hello [Service Fabric блог](https://blogs.msdn.microsoft.com/azureservicefabric/) для получения дополнительных сведений, как они все было объявлено.

Hello в данный момент нет планов tooopen источника hello среда выполнения Service Fabric.

## <a name="next-steps"></a>Дальнейшие действия

- [Дополнительные сведения об основных понятиях и рекомендациях Service Fabric](https://mva.microsoft.com/en-us/training-courses/building-microservices-applications-on-azure-service-fabric-16747?l=tbuZM46yC_5206218965)
