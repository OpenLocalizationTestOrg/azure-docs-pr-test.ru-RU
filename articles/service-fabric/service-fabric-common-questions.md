---
title: "Распространенные вопросы о Microsoft Azure Service Fabric | Документация Майкрософт"
description: "Часто задаваемые вопросы о Service Fabric и ответы на них"
services: service-fabric
documentationcenter: .net
author: chackdan
manager: timlt
editor: 
ms.assetid: 5a179703-ff0c-4b8e-98cd-377253295d12
ms.service: service-fabric
ms.devlang: dotnet
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: na
ms.date: 08/18/2017
ms.author: chackdan
ms.openlocfilehash: ee1fe4e83ce796fd50b779c0880701b9dfcefff7
ms.sourcegitcommit: 50e23e8d3b1148ae2d36dad3167936b4e52c8a23
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 08/18/2017
---
# <a name="commonly-asked-service-fabric-questions"></a>Распространенные вопросы о Service Fabric

Пользователи задают множество схожих вопросов о возможностях и использовании Service Fabric. В этом документе приведены ответы на многие из этих вопросов.

## <a name="cluster-setup-and-management"></a>Настройка кластера и управление им

### <a name="can-i-create-a-cluster-that-spans-multiple-azure-regions-or-my-own-datacenters"></a>Можно ли создать кластер, охватывающий несколько регионов Azure или моих центров обработки данных?

Да. 

Базовые технологии кластеризации Service Fabric можно использовать для объединения компьютеров, которые работают в любой точке мира, если между ними есть сетевое подключение. Однако создание и запуск такого кластера может оказаться сложной задачей.

Если вам интересен этот сценарий, мы рекомендуем вам ознакомиться со [списком проблем Service Fabric в репозитории GitHub](https://github.com/azure/service-fabric-issues) или обратиться к сотруднику службы поддержки для получения дополнительных указаний. Команда разработчиков Service Fabric работает над тем, чтобы предоставить дополнительные сведения, указания и рекомендации для данного сценария. 

Необходимо учитывать следующие факторы. 

1. На данный момент кластерный ресурс Service Fabric в Azure относится к определенному региону, как и масштабируемые наборы виртуальных машин, на основе которых создан кластер. Это означает, что в случае регионального сбоя вы можете утратить возможность управления кластером с помощью Azure Resource Manager или портала Azure. Это может произойти, даже если кластер продолжает работать и вы можете напрямую взаимодействовать с ним. Кроме того, на текущий момент Azure не предоставляет возможность использовать отдельную виртуальную сеть в разных регионах. Это означает, что для кластера, охватывающего несколько регионов Azure, требуются либо [общедоступные IP-адреса для каждой виртуальной машины в масштабируемых наборах виртуальных машин](../virtual-machine-scale-sets/virtual-machine-scale-sets-networking.md#public-ipv4-per-virtual-machine), либо [VPN-шлюзы Azure](../vpn-gateway/vpn-gateway-about-vpngateways.md). Эти варианты сетевых подключений по-разному влияют на затраты, производительность и, в некоторой степени, на структуру приложений, поэтому перед внедрением такой среды требуется выполнить тщательный анализ и планирование.
2. Обслуживание, мониторинг этих компьютеров и управление ими может стать сложной задачей, особенно в том случае, если они распределены по средам разных _типов_, например, между разными поставщиками облачных служб или между локальными ресурсами и Azure. Перед запуском производственных рабочих нагрузок в такой среде необходимо внимательно проверить, распознают ли кластер и приложения операции обновления, отслеживания, управления и диагностики. Если у вас уже имеется значительный опыт решения этих задач в Azure или в собственных центрах обработки данных, скорее всего, аналогичные решения можно будет применить для создания или выполнения кластера Service Fabric. 

### <a name="do-service-fabric-nodes-automatically-receive-os-updates"></a>Получают ли узлы Service Fabric обновления операционной системы автоматически?

Пока нет, но это популярный запрос, и мы планируем реализовать эту возможность в Azure.

Тем временем мы [предоставили приложение](service-fabric-patch-orchestration-application.md), которое устанавливает исправления и обновления для операционных систем на узлах Service Fabric.

Проблема с обновлениями ОС заключается в том, что для них обычно требуется перезагрузка компьютера, что приводит к временной потере доступности. Сама по себе это не проблема, так как Service Fabric выполнит автоматическое перенаправление трафика для этих служб на другие узлы. Тем не менее, если обновления ОС не согласованы между собой по всему кластеру, есть вероятность того, что множество узлов будут выключены одновременно. Такие одновременные перезагрузки могут привести к полной потере доступности службы или как минимум определенного раздела (для службы с отслеживанием состояния).

В будущем мы планируем реализовать поддержку полностью автоматизированной политики обновления ОС, скоординированной между доменами обновления, чтобы обеспечить доступность несмотря на перезагрузки и другие непредвиденные сбои.

### <a name="can-i-use-large-virtual-machine-scale-sets-in-my-sf-cluster"></a>Можно ли использовать большие масштабируемые наборы виртуальных машин в кластере Service Fabric? 

**Краткий ответ**. Нет. 

**Подробный ответ**. Хотя большие масштабируемые наборы виртуальных машин можно масштабировать до 1000 экземпляров виртуальных машин, это делается с помощью групп размещения. Домены сбоя и домены обновления согласовываются только в пределах группы размещения. Service Fabric использует домены сбоя и домены обновления для принятия решений о размещении экземпляров реплик или экземпляров служб. Так как домены сбоя и домены обновления сравнимы только в пределах группы размещения, Service Fabric не может ее использовать. Например, если виртуальная машина VM1 в группе размещения PG1 использует топологию с 0 доменов сбоя, а виртуальная машина VM9 в группе размещения PG2 — топологию с 4 доменами сбоя, это не значит, VM1 и VM2 размещены в двух разных аппаратных стойках. Следовательно, в этом случае Service Fabric не может использовать значения доменов сбоя для принятия решений о размещении.

Сейчас существуют и другие проблемы с большими масштабируемыми наборами виртуальных машин, в том числе отсутствие поддержки балансировки нагрузки уровня 4. Ознакомьтесь со [сведениями о больших масштабируемых наборах](../virtual-machine-scale-sets/virtual-machine-scale-sets-placement-groups.md).



### <a name="what-is-the-minimum-size-of-a-service-fabric-cluster-why-cant-it-be-smaller"></a>Каков минимальный размер кластера Service Fabric? Почему он не может быть меньше?

Минимальный поддерживаемый размер кластера Service Fabric с рабочими нагрузками — пять узлов. Для сценариев разработки и тестирования мы поддерживаем кластеры из трех узлов.

Эти минимальные значения связаны с тем, что в кластере Service Fabric выполняется ряд системных служб с отслеживанием состояния, включая службы имен и диспетчера отработки отказов. Эти службы, которые отслеживают, какие службы развернуты в кластере и где они в настоящее время размещены, существенно зависят от целостности кластера. Эта целостность, в свою очередь, зависит от возможности получения *кворума* для любого обновления состояния служб, где кворум означает строгое большинство реплик (N/2 + 1) для данной службы.

С учетом этого давайте рассмотрим некоторые возможные конфигурации кластера.

**Один узел.** Этот вариант не обеспечивает высокой доступности, так как потеря одного узла по какой-либо причине означает потерю всего кластера.

**Два узла.** Кворум для службы, развернутой на двух узлах (N = 2), составляет 2 узла (2/2 + 1 = 2). При потере одной реплики кворум создать невозможно. Так как обновление службы требует временного отключения реплики, эта конфигурация бесполезна.

**Три узла.** В случае трех узлов (N = 3) для создания кворума по-прежнему нужно два узла (3/2 + 1 = 2). Это означает, что можно потерять один узел и по-прежнему сохранить кворум.

Кластер из трех узлов поддерживается для разработки и тестирования, так как в этом случае можно безопасно выполнять обновления и справляться со сбоями отдельных узлов, если они не происходят одновременно. Для рабочих нагрузок в производственной среде кластер должен быть устойчив к таким одновременным сбоям, поэтому пять узлов являются обязательными.

### <a name="can-i-turn-off-my-cluster-at-nightweekends-to-save-costs"></a>Можно ли отключить кластер на ночь или выходные дни для снижения расходов?

Как правило, нет. Service Fabric сохраняет состояние на локальных временных дисках, и это означает, что если виртуальная машина перемещается на другой узел, данные не перемещаются вместе с ней. Во время работы это не проблема, так как состояние нового узла обновляется с помощью других узлов. Однако если остановить все узлы и затем перезагрузить их, существует значительная вероятность, что большинство узлов будут запущены на новых серверах и восстановить систему не удастся.

Если нужно создать кластеры для тестирования приложения перед его развертыванием, мы рекомендуем динамически создавать кластеры в процессе [непрерывной интеграции и непрерывного развертывания](service-fabric-set-up-continuous-integration.md).


### <a name="how-do-i-upgrade-my-operating-system-for-example-from-windows-server-2012-to-windows-server-2016"></a>Как обновить операционную систему (например, с Windows Server 2012 до Windows Server 2016)?

Хотя мы работаем над упрощением этой задачи, в настоящее время вы отвечаете за обновление. Вам необходимо обновить образ ОС на виртуальных машинах кластера поочередно. 

## <a name="container-support"></a>Поддержка контейнеров

### <a name="why-are-my-containers-that-are-deployed-to-sf-unable-to-resolve-dns-addresses"></a>Почему мои контейнеры, развернутые в Service Fabric, не могут разрешать DNS-адреса?

Эта проблема обнаружена в кластерах версии 5.6.204.9494. 

**Устранение**. Следуйте инструкциям в [этом документе](service-fabric-dnsservice.md), чтобы включить службу DNS Service Fabric в кластере.

**Исправление**. Обновите кластер до поддерживаемой версии, то есть до версии выше 5.6.204.9494, если она доступна. Если для кластера включено автоматическое обновление, он автоматически обновится до версии, в которой эта проблема устранена.

  
## <a name="application-design"></a>Проектирование приложений

### <a name="whats-the-best-way-to-query-data-across-partitions-of-a-reliable-collection"></a>Как лучше запрашивать данные из всех разделов Reliable Collection?

Reliable Collection обычно содержит несколько [разделов](service-fabric-concepts-partitioning.md) для обеспечения развертывания с целью повышения производительности и пропускной способности. Это означает, что состояние данной службы может быть распределено между десятками и сотнями компьютеров. Для выполнения операций над таким полным набором данных доступны такие возможности.

- Создать службу, которая направляет запросы во все разделы другой службы для извлечения необходимых данных.
- Создать службу, которая может получать данные из всех разделов другой службы.
- Периодически передавать данные из каждой службы во внешнее хранилище. Этот подход используется, только если выполняемые запросы не являются частью основной бизнес-логики.


### <a name="whats-the-best-way-to-query-data-across-my-actors"></a>Как лучше запрашивать данные из моих субъектов?

Субъекты должны быть независимыми единицами состояния и вычислений, поэтому не рекомендуется делать широковещательные запросы состояния субъектов во время выполнения. Если требуется направить запрос в полный набор состояния субъекта, необходимо выполнить одно из таких указаний.

- Заменить службы субъектов надежными службами с отслеживанием состояния таким образом, чтобы число сетевых запросов для сбора всех данных из нескольких субъектов выполнялось для нескольких разделов в службе.
- Разрабатывать субъекты таким образом, чтобы периодически передавать их состояние во внешнее хранилище для упрощения запросов. Как и способ выше, этот способ подходит, только если выполняемые запросы не являются обязательными для поведения среды выполнения.

### <a name="how-much-data-can-i-store-in-a-reliable-collection"></a>Сколько данных можно сохранить в Reliable Collection?

Reliable Services обычно состоит из нескольких разделов, поэтому объем данных, которые можно хранить, ограничивается только числом компьютеров в кластере и объемом доступной памяти на этих компьютерах.

Например, предположим, что есть Reliable Collection в службе со 100 разделами и 3 репликами для хранения объектов со средним размером 1 КБ. Теперь предположим, что имеется кластер из 10 компьютеров с 16 ГБ памяти на каждом компьютере. Чтобы обеспечить простоту и умеренность оценки, предположим, что операционная система и системные службы, среда выполнения Service Fabric и службы используют 6 ГБ, оставляя свободными 10 ГБ на каждом компьютере, или 100 ГБ на кластер.

Учитывая, что каждый объект должен быть сохранен трижды (основная копия и две реплики), памяти будет достаточно примерно для 35 миллионов объектов в коллекции при полной загрузке. Тем не менее рекомендуется обеспечить устойчивость к одновременной потере домена сбоя и домена обновления, для чего потребуется примерно треть емкости, и это количество может сократиться примерно до 23 миллионов объектов.

Обратите внимание, что в этой оценке также предполагается следующее.

- Распределение данных по секциям примерно равномерное, или метрики нагрузки передаются в диспетчер кластерных ресурсов. По умолчанию Service Fabric будет распределять нагрузку, исходя из числа реплик. В приведенном выше примере можно поместить 10 основных реплик и 20 дополнительных реплик на каждом узле в кластере. Этот вариант хорошо подходит для нагрузки, равномерно распределенной по разделам. Если нагрузка распределена неравномерно, необходимо сообщить о нагрузке, чтобы диспетчер ресурсов мог упаковать реплики меньшего размера вместе и разрешить репликам большего размера использовать больше памяти на отдельном узле.

- Рассматриваемая надежная служба является единственной, которая сохраняет состояние в кластере. Так как в кластере можно развернуть несколько служб, необходимо учитывать ресурсы, которые потребуется запускать для каждой из них, и управлять состоянием этих служб.

- Сам кластер не увеличивается и не сжимается. При добавлении дополнительных компьютеров Service Fabric выполнит повторную балансировку реплик для эффективного использования дополнительной емкости, пока количество компьютеров не превысит количество разделов в службе, так как отдельная реплика не может находиться на нескольких компьютерах. Напротив, если уменьшить размер кластера, удалив компьютеры, реплики будут упакованы плотнее и будут обладать меньшей общей емкостью.

### <a name="how-much-data-can-i-store-in-an-actor"></a>Сколько данных можно хранить в субъекте?

Как и в случае с надежными службами, объем данных, которые могут храниться в службе субъекта, ограничивается только общим объемом дискового пространства и доступным объемом памяти на всех узлах в кластере. Тем не менее отдельные субъекты наиболее эффективны, когда они используются для инкапсуляции небольшого объема состояния и связанной бизнес-логики. Как правило, состояние отдельного субъекта должно измеряться в килобайтах.

## <a name="other-questions"></a>Другие вопросы

### <a name="how-does-service-fabric-relate-to-containers"></a>Как Service Fabric связана с контейнерами?

Контейнеры обеспечивают простой способ для упаковки служб и их зависимостей таким образом, чтобы они согласованно запускались во всех средах и могли изолированно работать на одном компьютере. Service Fabric предлагает способ развертывания служб и управления ими, включая [службы, упакованные в контейнер](service-fabric-containers-overview.md).

### <a name="are-you-planning-to-open-source-service-fabric"></a>Планируете создать решение на базе Service Fabric с открытым исходным кодом?

Мы намерены перевести платформы Reliable Services и Reliable Actors на открытый исходный код на GitHub и будем рады участию сообщества в этих проектах. После объявления о начале их реализации с дополнительными сведениями о них можно будет ознакомиться в [блоге Service Fabric](https://blogs.msdn.microsoft.com/azureservicefabric/).

Переводить среду выполнения Service Fabric на открытый исходный код пока не планируется.

## <a name="next-steps"></a>Дальнейшие действия

- [Дополнительные сведения об основных понятиях и рекомендациях Service Fabric](https://mva.microsoft.com/en-us/training-courses/building-microservices-applications-on-azure-service-fabric-16747?l=tbuZM46yC_5206218965)
