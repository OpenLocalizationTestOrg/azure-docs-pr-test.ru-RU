---
title: "Перенос данных в хранилище данных SQL | Документация Майкрософт"
description: "Советы по переносу данных в хранилище данных SQL Azure для разработки решений."
services: sql-data-warehouse
documentationcenter: NA
author: sqlmojo
manager: jhubbard
editor: 
ms.assetid: d78f954a-f54c-4aa4-9040-919bc6414887
ms.service: sql-data-warehouse
ms.devlang: NA
ms.topic: article
ms.tgt_pltfrm: NA
ms.workload: data-services
ms.custom: migrate
ms.date: 06/29/2017
ms.author: joeyong;barbkess
ms.openlocfilehash: 0d156bc2eecf8220bd5ff4eb811d91482f216837
ms.sourcegitcommit: 6699c77dcbd5f8a1a2f21fba3d0a0005ac9ed6b7
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 10/11/2017
---
# <a name="migrate-your-data"></a>Перенос данных
Данные из различных источников можно переместить в хранилище данных SQL с помощью различных инструментов.  Для достижения этой цели можно использовать ADF Copy, службы SSIS и bcp. Тем не менее по мере увеличения объема данных есть смысл подумать о разделении процесса переноса на несколько этапов. Это позволит оптимизировать каждый этап как в плане производительности, так и в плане гибкости, обеспечивая плавный перенос данных.

В этой статье сначала будут рассмотрены простые сценарии переноса данных с помощью ADF Copy, служб SSIS и bcp. Затем мы поговорим об аспектах оптимизации переноса данных.

## <a name="azure-data-factory-adf-copy"></a>Копирование с помощью фабрики данных Azure (ADF)
[ADF Copy][ADF Copy] входит в [фабрику данных Azure][Azure Data Factory]. ADF Copy позволяет перенести данные в неструктурированные файлы на локальном диске, в удаленные неструктурированные файлы в хранилище больших двоичных объектов Azure или напрямую в хранилище данных SQL.

Если данные хранятся в неструктурированных файлах, то сначала их нужно перенести в большой двоичный объект службы хранилища Azure, а затем загрузить в хранилище данных SQL. После переноса данных в хранилище больших двоичных объектов Azure можно еще раз воспользоваться [ADF Copy][ADF Copy], чтобы перенести данные в хранилище данных SQL.

PolyBase также обеспечивает возможность высокопроизводительной загрузки данных. Однако в этом случае придется использовать два средства вместо одного. Если требуется более высокая степень производительности, воспользуйтесь PolyBase. Если необходимо использовать одно средство (и объем данных небольшой), ADF вполне подойдет.


> 
> 

[Примеры использования ADF][ADF samples] см. в следующей статье.

## <a name="integration-services"></a>Службы интеграции
Службы Integration Services (SSIS) — это мощное и гибкое средство загрузки данных, которое поддерживает сложные рабочие потоки, преобразование данных и разные параметры загрузки. Службы SSIS позволяют упростить перенос данных в Azure; службы также можно использовать как часть более сложного переноса данных.

> [!NOTE]
> Службы SSIS могут экспортировать данные в UTF-8 без маркера последовательности байтов в файле. Чтобы настроить это, сначала нужно преобразовать символьные данные в поток данных с помощью компонента производного столбца и подготовить их для использования кодовой страницы 65001 UTF-8. После преобразования столбцов запишите данные в целевой адаптер неструктурированного файла, выбрав 65001 в качестве кодовой страницы для файла.
> 
> 

Службы SSIS подключаются к хранилищу данных SQL так же, как и к SQL Server. Однако для подключения потребуется диспетчер соединений ADO.NET. Также нужно не забыть настроить параметр "Использовать массовую вставку, когда она доступна", чтобы довести пропускную способность до максимума. Дополнительные сведения об этом свойстве см. в статье об [адаптере загрузки данных ADO.NET][ADO.NET destination adapter].

> [!NOTE]
> Подключение к хранилищу данных SQL Azure с помощью OLE DB не поддерживается.
> 
> 

Кроме того, всегда существует возможность того, что пакет будет поврежден из-за регулирования или проблем с сетью. Создавайте пакеты таким образом, чтобы можно было возобновить работу с точки сбоя без необходимости повторять уже выполненную работу.

Дополнительные сведения см. в [документации по службам SSIS][SSIS documentation].

## <a name="bcp"></a>bcp
Программа bcp — средство командной строки, предназначенное для импорта и экспорта данных неструктурированных файлов. Во время экспорта можно выполнять преобразование. Для выполнения простого преобразования воспользуйтесь запросом, который выбирает и преобразует данные. После выполнения экспорта неструктурированные файлы можно загрузить напрямую в целевую базу данных хранилища данных SQL.

> [!NOTE]
> Рекомендуется включать преобразования, используемые во время экспорта данных, в представления в исходной системе. В этом случае логика будет сохранена и процесс можно будет повторить.
> 
> 

Программа bcp обладает следующими преимуществами.

* Простота. Команды bcp просты для построения и выполнения.
* Процесс загрузки можно повторять. После выполнения экспорта загрузку можно выполнять любое количество раз.

Программа bcp имеет следующие ограничения.

* Программа bcp работает только с табличными неструктурированными файлами. Программа bcp не работает с такими файлами, как XML или JSON.
* Возможности преобразования данных ограничены этапом экспорта и простые по своей природе.
* Программа bcp не является надежным средством для загрузки данных через Интернет. Любой сетевой сбой приводит к ошибке загрузки.
* Программа bcp зависит от схемы, которая присутствует в целевой базе данных до загрузки.

Дополнительные сведения см. в статье [Загрузка данных с помощью bcp][Use bcp to load data into SQL Data Warehouse].

## <a name="optimizing-data-migration"></a>Оптимизация переноса данных
Процесс переноса данных с помощью SQLDW можно эффективно разделить на три этапа:

1. Экспорт исходных данных
2. Передача данных в Azure
3. Загрузка в целевую базу данных SQLDW

Каждый этап можно оптимизировать для создания надежного, повторяемого и гибкого процесса переноса данных, который обеспечивает максимальную производительность на каждом отдельном этапе.

## <a name="optimizing-data-load"></a>Оптимизация загрузки данных
Если посмотреть на этапы в обратном порядке, самый быстрый способ загрузки данных — использовать PolyBase. Оптимизация процесса загрузки с помощью PolyBase накладывает ряд требований к предыдущим этапам, поэтому лучше сразу их рассмотреть. К ним относятся:

1. Кодирование файлов данных
2. Форматирование файлов данных
3. Размещение файлов данных

### <a name="encoding"></a>Кодирование
Для PolyBase файлы данных должны иметь кодировку UTF-8 или UTF-16FE. 



### <a name="format-of-data-files"></a>Форматирование файлов данных
PolyBase требует наличия признака конца строки \n или новой строки. Файлы данных должны соответствовать этому стандарту. Нет ограничений для признаков конца строки или столбца.

В PolyBase необходимо определить каждый столбец в файле как часть внешней таблицы. Убедитесь, что все экспортируемые столбцы обязательные и что типы соответствуют требуемым стандартам.

Сведения о поддерживаемых типах данных см. в предыдущей статье "Перенос схемы".

### <a name="location-of-data-files"></a>Размещение файлов данных
Хранилище данных SQL использует PolyBase для загрузки данных только из хранилища больших двоичных объектов Azure. Следовательно, данные должны быть перенесены в хранилище больших двоичных объектов.

## <a name="optimizing-data-transfer"></a>Оптимизация переноса данных
Один из самых медленных процессов переноса данных — это перенос данных в Azure. Проблемой может стать не только пропускная способность сети, но и ее стабильная работа. По умолчанию перенос данных в Azure выполняется через Интернет, поэтому риск ошибок во время переноса довольно высокий. Тем не менее из-за этих ошибок может потребоваться переслать повторно все данные или их часть.

К счастью, существует несколько вариантов для повышения быстродействия и устойчивости этого процесса.

### <a name="expressrouteexpressroute"></a>[ExpressRoute][ExpressRoute]
Чтобы ускорить перенос данных, вы можете воспользоваться [ExpressRoute][ExpressRoute]. [ExpressRoute][ExpressRoute] предоставляет установленное частное подключение к Azure, то есть подключение не будет проходить через Интернет. Это отнюдь не является обязательным этапом. Тем не менее это улучшит пропускную способность при передаче данных в Azure с локальных или совместно используемых серверов.

[ExpressRoute][ExpressRoute] обладает следующими преимуществами.

1. Повышенная надежность
2. Более высокая скорость сети
3. Низкая задержка сети
4. Более высокая степень сетевой безопасности

[ExpressRoute][ExpressRoute] целесообразно использовать в целом ряде сценариев, а не только для переноса данных.

Заинтересовались? Дополнительные сведения и цены см. в [документации по ExpressRoute][ExpressRoute documentation].

### <a name="azure-import-and-export-service"></a>Служба импорта и экспорта Azure
Служба импорта и экспорта Azure — это процесс переноса данных, предназначенный для больших (гигабайты данных) и очень больших (терабайты данных) объемов данных. Процесс предполагает запись данных на диски с последующей пересылкой в центр обработки данных Azure. Содержимое дисков затем загружается в большие двоичные объекты службы хранилища Azure от вашего имени.

Общая схема процесса импорта и экспорта выглядит следующим образом.

1. Настройка контейнера хранилища больших двоичных объектов Azure для получения данных
2. Экспорт данных в локальное хранилище
3. Копирование данных на жесткие диски формата 3,5 дюйма SATA II/III с помощью средства импорта и экспорта Azure
4. Создание задания импорта с помощью службы импорта и экспорта Azure с предоставлением файлов журналов, созданных средством импорта и экспорта Azure
5. Пересылка дисков в указанный центр обработки данных Azure
6. Данные перемещаются в контейнер хранилища больших двоичных объектов Azure
7. Загрузка данных в SQLDW с помощью PolyBase

### <a name="azcopyazcopy-utility"></a>Служебная программа [AZCopy][AZCopy]
Служебная программа [AZCopy][AZCopy] прекрасно подходит для передачи данных в большие двоичные объекты службы хранилища Azure. Средство предназначено для небольших (мегабайты данных) и очень больших (гигабайты данных) объемов данных. [AZCopy] также обеспечивает гибкую пропускную способность во время переноса данных в Azure, поэтому подходит для этапа переноса данных. После выполнения переноса данные можно загрузить с помощью PolyBase в хранилище данных SQL. Средство AZCopy можно также добавить в пакеты служб SSIS с помощью задания "Выполнить процесс".

Чтобы использовать AZCopy, сначала необходимо загрузить это средство и установить его. Существует [рабочая версия][production version] и [пробная версия][preview version].

Для загрузки файла из файловой системы потребуется командная строка, как та, что представлена ниже.

```
AzCopy /Source:C:\myfolder /Dest:https://myaccount.blob.core.windows.net/mycontainer /DestKey:key /Pattern:abc.txt
```

В целом процесс может выглядеть следующим образом.

1. Настройка контейнера большого двоичного объекта хранилища Azure для получения данных
2. Экспорт данных в локальное хранилище
3. Копирование данных с помощью AZCopy в контейнер хранилища больших двоичных объектов Azure
4. Загрузка данных в хранилище данных SQL с помощью PolyBase

См. полную документацию по [AZCopy][AZCopy].

## <a name="optimizing-data-export"></a>Оптимизация экспорта данных
Помимо соблюдения требований PolyBase к экспорту данных, рекомендуется оптимизировать экспорт данных, чтобы еще больше улучшить процесс.



### <a name="data-compression"></a>Сжатие данных
PolyBase может читать данные, сжатые с помощью gzip. Если есть возможность сжать файлы с помощью gzip, это позволит минимизировать объем данных, пересылаемый по сети.

### <a name="multiple-files"></a>Разделение на несколько файлов
Разделение больших таблиц на несколько файлов не только повышает скорость экспорта, но и обеспечивает возможность повторного запуска и общую управляемость данных после переноса в хранилище больших двоичных объектов Azure. Одно из преимуществ PolyBase заключается в том, что средство позволяет читать все файлы внутри папки и обрабатывать их в виде одной таблицы. Поэтому рекомендуется разложить файлы для каждой таблицы в разные папки.

PolyBase также поддерживает так называемую функцию рекурсивного перебора папок. Функция позволяет улучшить организацию экспортируемых данных и управление данными.

Дополнительные сведения о загрузке данных с помощью PolyBase в хранилище данных SQL см. в [этой статье][Use PolyBase to load data into SQL Data Warehouse].

## <a name="next-steps"></a>Дальнейшие действия
Дополнительные сведения о переносе данных см. в статье [Перенос решения в хранилище данных SQL][Migrate your solution to SQL Data Warehouse].
Дополнительные советы по разработке см. в статье [Проектные решения и методики программирования для хранилища данных SQL][development overview].

<!--Image references-->

<!--Article references-->
[AZCopy]: ../storage/common/storage-use-azcopy.md
[ADF Copy]: ../data-factory/v1/data-factory-data-movement-activities.md 
[ADF samples]: ../data-factory/v1/data-factory-samples.md
[ADF Copy examples]: ../data-factory/v1/data-factory-copy-activity-tutorial-using-visual-studio.md
[development overview]: sql-data-warehouse-overview-develop.md
[Migrate your solution to SQL Data Warehouse]: sql-data-warehouse-overview-migrate.md
[SQL Data Warehouse development overview]: sql-data-warehouse-overview-develop.md
[Use bcp to load data into SQL Data Warehouse]: sql-data-warehouse-load-with-bcp.md
[Use PolyBase to load data into SQL Data Warehouse]: sql-data-warehouse-get-started-load-with-polybase.md


<!--MSDN references-->

<!--Other Web references-->
[Azure Data Factory]: http://azure.microsoft.com/services/data-factory/
[ExpressRoute]: http://azure.microsoft.com/services/expressroute/
[ExpressRoute documentation]: http://azure.microsoft.com/documentation/services/expressroute/

[production version]: http://aka.ms/downloadazcopy/
[preview version]: http://aka.ms/downloadazcopypr/
[ADO.NET destination adapter]: https://msdn.microsoft.com/library/bb934041.aspx
[SSIS documentation]: https://msdn.microsoft.com/library/ms141026.aspx
