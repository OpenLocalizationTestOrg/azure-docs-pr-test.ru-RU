---
title: "Обзор записи концентраторов событий Azure | Документация Майкрософт"
description: "Запись телеметрических данных с помощью записи концентраторов событий."
services: event-hubs
documentationcenter: 
author: sethmanheim
manager: timlt
editor: 
ms.assetid: e53cdeea-8a6a-474e-9f96-59d43c0e8562
ms.service: event-hubs
ms.workload: na
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 12/19/2017
ms.author: sethm;darosa
ms.openlocfilehash: fbd4aef62891341ad3760b74cd8aaee7abf7b827
ms.sourcegitcommit: d6984ef8cc057423ff81efb4645af9d0b902f843
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/05/2018
---
# <a name="azure-event-hubs-capture"></a>Запись концентраторов событий Azure

Запись концентраторов событий Azure позволяет автоматически доставлять определенный объем потоковых данных из концентраторов событий в учетную запись [хранилища BLOB-объектов Azure](https://azure.microsoft.com/services/storage/blobs/) или [Azure Data Lake Store](https://azure.microsoft.com/services/data-lake-store/) с указанным интервалом времени и размера. Настройка записи выполняется быстро, ее использование не влечет дополнительных административных расходов, а масштабирование осуществляется автоматически на основе [единиц пропускной способности](event-hubs-features.md#capacity) концентратора событий. Запись концентраторов событий — это самый удобный способ передачи потоковых данных в Azure. Он позволяет сосредоточиться на обработке данных, а не на их записи.

Кроме того, запись концентраторов событий обеспечивает обработку конвейеров в режиме реального времени и на основе пакетов в одном потоке, благодаря чему вы можете создавать решения, масштабируемые по мере необходимости. Независимо от того, что вам нужно (создать системы на основе пакетов с учетом будущих потребностей в обработке данных в режиме реального времени или добавить эффективный холодный путь к имеющемуся решению для обработки в режиме реального времени), запись концентраторов событий упрощает работу с потоковыми данными.

## <a name="how-event-hubs-capture-works"></a>Принцип работы записи концентраторов событий

Концентраторы событий — это устойчивый буфер для хранения входящих данных телеметрии в течение определенного времени, подобный распределенному журналу. Масштабирование в концентраторах событий выполняется в рамках [модели секционированных потребителей](event-hubs-features.md#partitions). Каждая секция — это независимый сегмент данных, потребление которого осуществляется отдельно. По истечении настроенного срока хранения эти данные устаревают, поэтому определенный концентратор событий никогда не заполняется полностью.

Запись концентраторов событий позволяет указать собственную учетную запись хранилища BLOB-объектов Azure и контейнер, или учетную запись Azure Data Lake Store, используемые для хранения собранных данных. Эти учетные записи могут находиться в том же регионе, что и концентратор событий, или в другом. Это расширяет гибкость записи концентраторов событий.

Собранные данные записываются в формате [Apache Avro][Apache Avro] — сжатый быстрый двоичный формат, обеспечивающий эффективную структуру данных за счет встроенной схемы. Этот формат широко используется в экосистеме Hadoop, Stream Analytics и фабрике данных Azure. Работа с Avro более подробно описана далее в этой статье.

### <a name="capture-windowing"></a>Управление окнами в записи

В функции записи концентраторов событий можно настроить окно управления записью. Это окно с минимальным размером и продолжительностью, для которого предусмотрена политика "побеждает первый". Это означает, что первый обнаруженный триггер активирует операцию записи. При наличии окна записи размером в 100 МБ и продолжительностью 15 минут для отправки данных со скоростью 1 МБ/с сначала используется окно размера, а затем — окно времени. Запись каждой секции выполняется отдельно, а запись выполненного блочного BLOB-объекта осуществляется в процессе записи. Имя блочного BLOB-объекта зависит от времени создания записи. Соглашение об именовании хранилища выглядит следующим образом:

```
{Namespace}/{EventHub}/{PartitionId}/{Year}/{Month}/{Day}/{Hour}/{Minute}/{Second}
```

Обратите внимание, что значения даты дополняются нулями; Пример имени файла может быть:

```
https://mystorageaccount.blob.core.windows.net/mycontainer/mynamespace/myeventhub/0/2017/12/08/03/03/17.avro
```

### <a name="scaling-to-throughput-units"></a>Масштабирование единиц пропускной способности

Трафик концентраторов событий контролируется с помощью [единиц пропускной способности](event-hubs-features.md#capacity). Одна единица пропускной способности разрешает передачу до 1 МБ/с или 1000 событий/с для входящих данных или до 2 МБ/с или 2000 событий/с для исходящих данных. Для концентраторов событий (цен. категория "Стандартный") можно настроить от 1 до 20 единиц пропускной способности. Кроме того, можно отправить запрос на увеличение квоты в [службу поддержки][support request]. Использование единиц пропускной способности свыше приобретенного количества регулируется. Функция записи концентраторов событий копирует данные непосредственно из внутреннего хранилища концентраторов событий. При этом выполняется обход квоты на единицы пропускной способности для исходящего трафика, а этот трафик сохраняется для других средств обработки, например Stream Analytics или Spark.

После настройки функция записи концентраторов событий автоматически запускается при отправке первого события и продолжает работать. Чтобы позволить операции последующей обработки установить, что процесс выполняется, при отсутствии данных концентраторы событий записывают пустые файлы. Этот процесс обеспечивает прогнозируемую периодичность и позволяет получить маркер, необходимый для пакетных обработчиков.

## <a name="setting-up-event-hubs-capture"></a>Настройка записи концентраторов событий

Запись можно настроить при создании концентратора событий с помощью [портала Azure](https://portal.azure.com) или с помощью шаблонов Azure Resource Manager. Дополнительные сведения см. в следующих статьях:

- [Включение записи концентраторов событий с помощью портала Azure](event-hubs-capture-enable-through-portal.md)
- [Создание пространства имен концентраторов событий с концентратором событий и включение записи с помощью шаблона Azure Resource Manager](event-hubs-resource-manager-namespace-event-hub-enable-capture.md)

## <a name="exploring-the-captured-files-and-working-with-avro"></a>Просмотр собранных файлов и работа с Avro

Функция записи концентраторов событий создает файлы в формате Avro, как указано в настроенном окне времени. Эти файлы можно просмотреть в любом инструменте, например в [Azure Storage Explorer][Azure Storage Explorer]. Чтобы выполнить определенные действия с этими файлами, их можно скачать локально.

Файлы, созданные записью концентраторов событий, имеют следующую схему Avro.

![][3]

Файлы Avro можно легко просмотреть с помощью [инструментов Avro][Avro Tools] (JAR-файла) из Apache. После того как вы скачали этот JAR-файл, чтобы просмотреть схему определенного файла Avro, выполните следующую команду:

```
java -jar avro-tools-1.8.2.jar getschema <name of capture file>
```

Эта команда возвращает следующее:

```
{

    "type":"record",
    "name":"EventData",
    "namespace":"Microsoft.ServiceBus.Messaging",
    "fields":[
                 {"name":"SequenceNumber","type":"long"},
                 {"name":"Offset","type":"string"},
                 {"name":"EnqueuedTimeUtc","type":"string"},
                 {"name":"SystemProperties","type":{"type":"map","values":["long","double","string","bytes"]}},
                 {"name":"Properties","type":{"type":"map","values":["long","double","string","bytes"]}},
                 {"name":"Body","type":["null","bytes"]}
             ]
}
```

Средства Avro можно также использовать для преобразования файлов в формат JSON и выполнения других задач обработки.

Чтобы выполнить более расширенную обработку, скачайте и установите Avro для определенной платформы. На момент написания статьи средства Avro доступны для следующих платформ: C, C++, C\#, Java, NodeJS, Perl, PHP, Python и Ruby.

Apache Avro предоставляет руководства по началу работы для платформ [Java][Java] и [Python][Python]. Дополнительные сведения см. в статье [Пошаговое руководство. Использование записи концентраторов событий с Python](event-hubs-capture-python.md).

## <a name="how-event-hubs-capture-is-charged"></a>Выставление счета за запись концентраторов событий

Выставление счета за запись концентраторов событий осуществляется подобно тарификации за единицы пропускной способности, то есть каждый час. Размер платы прямо пропорционален количеству единиц пропускной способности, приобретенных для пространства имен. Так же как и с единицами пропускной способности, размер записи концентраторов событий можно регулировать, чтобы обеспечить соответствующую производительность. Единицы измерения действуют совместно. Дополнительные сведения о ценах см. на странице цен на [концентраторы событий](https://azure.microsoft.com/pricing/details/event-hubs/). 

## <a name="next-steps"></a>Дальнейшие действия

Запись концентраторов событий — это самый быстрый способ передать данные в Azure. С помощью знакомых средств и платформ (Azure Data Lake, фабрики данных Azure и Azure HDInsight) можно выполнять необходимую пакетную обработку и другие операции анализа в любом масштабе.

Дополнительные сведения о концентраторах событий см. в следующих источниках:

* [Отправка событий в концентраторы событий Azure с помощью платформы .NET Framework](event-hubs-dotnet-framework-getstarted-send.md)
* [Обзор концентраторов событий Azure][Event Hubs overview].

[Apache Avro]: http://avro.apache.org/
[support request]: https://portal.azure.com/?#blade/Microsoft_Azure_Support/HelpAndSupportBlade
[Azure Storage Explorer]: http://azurestorageexplorer.codeplex.com/
[3]: ./media/event-hubs-capture-overview/event-hubs-capture3.png
[Avro Tools]: http://www-us.apache.org/dist/avro/avro-1.8.2/java/avro-tools-1.8.2.jar
[Java]: http://avro.apache.org/docs/current/gettingstartedjava.html
[Python]: http://avro.apache.org/docs/current/gettingstartedpython.html
[Event Hubs overview]: event-hubs-what-is-event-hubs.md
